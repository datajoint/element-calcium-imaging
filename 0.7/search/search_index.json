{"config": {"lang": ["en"], "separator": "[\\s\\-]+", "pipeline": ["stopWordFilter"]}, "docs": [{"location": "", "title": "Element Calcium Imaging", "text": "<p>DataJoint Element for functional calcium imaging with  ScanImage,  Scanbox, Nikon NIS-Elements,  and <code>Bruker Prairie View</code> acquisition software; and  Suite2p,  CaImAn, and EXTRACT analysis  software. DataJoint Elements collectively standardize and automate data collection and analysis for neuroscience experiments. Each Element is a modular pipeline for data storage and processing with corresponding database tables that can be combined with other Elements to assemble a fully functional pipeline.</p>"}, {"location": "#experiment-flowchart", "title": "Experiment Flowchart", "text": ""}, {"location": "#data-pipeline-diagram", "title": "Data Pipeline Diagram", "text": "<ul> <li>We have designed three variations of the pipeline to handle different use cases. Displayed above is the default <code>imaging</code> schema.  Details on all of the <code>imaging</code> schemas can be found in the Data Pipeline documentation page.</li> </ul>"}, {"location": "#getting-started", "title": "Getting Started", "text": "<ul> <li>Install from PyPI<pre><code>pip install element-calcium-imaging\n</code></pre> </li> </ul> <ul> <li>Data Pipeline - Pipeline and table descriptions</li> </ul> <ul> <li>Tutorials - Start building your data pipeline</li> </ul> <ul> <li>Code Repository</li> </ul>"}, {"location": "#support", "title": "Support", "text": "<ul> <li>If you need help getting started or run into any errors, please contact our team by email at support@datajoint.com.</li> </ul>"}, {"location": "changelog/", "title": "Changelog", "text": "<p>Observes Semantic Versioning standard and Keep a Changelog convention.</p>"}, {"location": "changelog/#076-2023-06-30", "title": "0.7.6 - 2023-06-30", "text": "<ul> <li>Add - Null value for <code>package_version</code> in <code>imaging*</code> modules to patch bug</li> <li>Update - <code>tutorial.ipynb</code> notebook to insert values for nullable attributes</li> </ul>"}, {"location": "changelog/#075-2023-06-20", "title": "0.7.5 - 2023-06-20", "text": "<ul> <li>Update - Requirements</li> </ul>"}, {"location": "changelog/#074-2023-06-19", "title": "0.7.4 - 2023-06-19", "text": "<ul> <li>Add - Dev Container Docker image ID</li> <li>Update - Remove <code>.devcontainer/local/</code></li> <li>Update - Move <code>docker compose up</code> command from <code>devcontainer.json</code> to README</li> </ul>"}, {"location": "changelog/#073-2023-06-09", "title": "0.7.3 - 2023-06-09", "text": "<ul> <li>Fix - Output of cells within the <code>tutorial</code> notebook</li> </ul>"}, {"location": "changelog/#072-2023-06-08", "title": "0.7.2 - 2023-06-08", "text": "<ul> <li>Update - <code>tutorial</code> notebook</li> </ul>"}, {"location": "changelog/#071-2023-06-07", "title": "0.7.1 - 2023-06-07", "text": "<ul> <li>Fix - Docs to render notebooks</li> <li>Fix - <code>get_imaging_root_data_dir</code> function</li> </ul>"}, {"location": "changelog/#070-2023-06-06", "title": "0.7.0 - 2023-06-06", "text": "<ul> <li>Update - Merge <code>workflow-calcium-imaging</code> into <code>element-calcium-imaging</code> PR #135</li> <li>Add - <code>extras_require</code> feature to <code>setup.py</code></li> <li>Add - GitHub Actions that call reusable workflows in the <code>datajoint/.github</code> repository</li> <li>Update - Replace <code>get_nd2_files</code>, etc. functions with <code>get_image_files</code> function</li> <li>Add - <code>tutorial_pipeline.py</code> script for notebooks to import and activate schemas</li> <li>Update - Replace <code>reference.Equipment</code> with <code>lab.Device</code> table</li> <li>Update - Remove <code>demo_prepare.ipynb</code></li> <li>Update - Rename <code>demo_run.ipynb</code> to <code>demo.ipynb</code></li> <li>Update - <code>__init__.py</code> to use environment variables (if available) in place of <code>dj.config['custom']</code> values</li> </ul>"}, {"location": "changelog/#062-2023-05-22", "title": "0.6.2 - 2023-05-22", "text": "<ul> <li>Add - CaImAn, Suite2p, and EXTRACT citations</li> </ul>"}, {"location": "changelog/#061-2023-05-15", "title": "0.6.1 - 2023-05-15", "text": "<ul> <li>Update - Docs</li> </ul>"}, {"location": "changelog/#060-2023-05-15", "title": "0.6.0 - 2023-05-15", "text": "<ul> <li>Add - Quality metrics</li> <li>Update - Docs and readme</li> </ul>"}, {"location": "changelog/#057-2023-05-11", "title": "0.5.7 - 2023-05-11", "text": "<ul> <li>Fix - <code>.ipynb</code> dark mode output for all notebooks.</li> <li>Fix - Remove <code>GOOGLE_ANALYTICS_KEY</code> from <code>u24_element_release_call.yml</code>.</li> </ul>"}, {"location": "changelog/#056-2023-04-28", "title": "0.5.6 - 2023-04-28", "text": "<ul> <li>Fix - <code>.ipynb</code> output in tutorials is not visible in dark mode.</li> <li>Fix - typos in docstrings.</li> </ul>"}, {"location": "changelog/#055-2023-04-06", "title": "0.5.5 - 2023-04-06", "text": "<ul> <li>Update - Bump <code>element-interface</code> requirement to <code>0.5.1</code>.</li> </ul>"}, {"location": "changelog/#054-2023-03-08", "title": "0.5.4 - 2023-03-08", "text": "<ul> <li>Add - Requirement for <code>ipywidgets</code></li> <li>Update - Docker Compose file for docs release</li> </ul>"}, {"location": "changelog/#053-2023-02-23", "title": "0.5.3 - 2023-02-23", "text": "<ul> <li>Add - spelling, markdown, and pre-commit config files</li> <li>Add - Notebook rendering to docs</li> </ul>"}, {"location": "changelog/#052-2023-01-11", "title": "0.5.2 - 2023-01-11", "text": "<ul> <li>Bugfix - fix errors in ingesting single-plane PrairieView scans into <code>ScanInfo</code></li> <li>Add - Optional installation of caiman and suite2p through pip</li> </ul>"}, {"location": "changelog/#051-2022-12-15", "title": "0.5.1 - 2022-12-15", "text": "<ul> <li>Add - Imports for prairieview loader</li> </ul>"}, {"location": "changelog/#050-2022-12-14", "title": "0.5.0 - 2022-12-14", "text": "<ul> <li>Add - Cell extraction with EXTRACT package</li> </ul>"}, {"location": "changelog/#042-2022-11-02", "title": "0.4.2 - 2022-11-02", "text": "<ul> <li>Bugfix - Add plotting package to the requirements to generate the figures</li> <li>Add - Scan date parser from nd2 files</li> </ul>"}, {"location": "changelog/#041-2022-10-28", "title": "0.4.1 - 2022-10-28", "text": "<ul> <li>Update - Bump version to trigger PyPI release to revert updates from incorrect tag</li> </ul>"}, {"location": "changelog/#040-2022-10-28", "title": "0.4.0 - 2022-10-28", "text": "<ul> <li>Add - New schema <code>imaging_report</code> to compute and store figures from results</li> <li>Add - Widget to display figures</li> </ul>"}, {"location": "changelog/#030-2022-10-07", "title": "0.3.0 - 2022-10-07", "text": "<ul> <li>Add - Reader for <code>Bruker PrairieView</code> acquisition system</li> </ul>"}, {"location": "changelog/#022-2022-09-28", "title": "0.2.2 - 2022-09-28", "text": "<ul> <li>Update - Minor table explanation edits</li> <li>Update - Query simplifications</li> <li>Update - Minor code refactoring</li> </ul>"}, {"location": "changelog/#021-2022-09-12", "title": "0.2.1 - 2022-09-12", "text": "<ul> <li>Bugfix - fix errors in auto generating new ProcessingTask</li> </ul>"}, {"location": "changelog/#020-2022-07-01", "title": "0.2.0 - 2022-07-01", "text": "<ul> <li>Add - Imaging module (imaging_preprocess.py) for pre-processing steps</li> </ul>"}, {"location": "changelog/#010-2022-06-29", "title": "0.1.0 - 2022-06-29", "text": "<ul> <li>Add - Support for element-interface</li> <li>Add - Trigger Suite2p and CaImAn</li> <li>Add - Imaging module for no curation</li> <li>Add - Support for Nikon acquisition system</li> <li>Add - <code>scan_datetime</code> and <code>scan_duration</code> attributes</li> <li>Add - Estimate for scan duration</li> <li>Add - Citation section to README</li> <li>Update - Move background file to elements.datajoint.org</li> <li>Add - Adopt black formatting into code base</li> </ul>"}, {"location": "changelog/#010b0-2021-05-07", "title": "0.1.0b0 - 2021-05-07", "text": "<ul> <li>Update - First beta release</li> </ul>"}, {"location": "changelog/#010a4-2021-05-07", "title": "0.1.0a4 - 2021-05-07", "text": "<ul> <li>Update - Add workaround to handle DataJoint 0.13.* issue #914</li> </ul>"}, {"location": "changelog/#010a3-2021-05-03", "title": "0.1.0a3 - 2021-05-03", "text": "<ul> <li>Add - GitHub Action release process</li> <li>Add - <code>scan</code> and <code>imaging</code> modules</li> <li>Add - Readers for <code>ScanImage</code>, <code>ScanBox</code>, <code>Suite2p</code>, <code>CaImAn</code></li> </ul>"}, {"location": "citation/", "title": "Citation", "text": "<p>If your work uses the following resources, please cite the respective manuscript and/or Research Resource Identifier (RRID):</p> <ul> <li> <p>DataJoint Element Calcium Imaging - Version 0.7.6</p> <ul> <li>Yatsenko D, Nguyen T, Shen S, Gunalan K, Turner CA, Guzman R, Sasaki M, Sitonic D,   Reimer J, Walker EY, Tolias AS. DataJoint Elements: Data Workflows for   Neurophysiology. bioRxiv. 2021 Jan 1. doi: https://doi.org/10.1101/2021.03.30.437358</li> </ul> <ul> <li>RRID:SCR_021894</li> </ul> </li> </ul> <ul> <li>CaImAn<ul> <li>Manuscripts</li> </ul> </li> </ul> <ul> <li>Suite2p<ul> <li>Manuscripts</li> </ul> </li> </ul> <ul> <li>EXTRACT<ul> <li>Manuscripts</li> </ul> </li> </ul>"}, {"location": "concepts/", "title": "Concepts", "text": ""}, {"location": "concepts/#multiphoton-calcium-imaging", "title": "Multiphoton Calcium Imaging", "text": "<p>Over the past two decades, in vivo two-photon laser-scanning imaging of calcium signals has evolved into a mainstream modality for neurophysiology experiments to record population activity in intact neural circuits. The tools for signal acquisition and analysis continue to evolve but common patterns and elements of standardization have emerged.</p> <p>The preprocessing pipeline for two-photon laser-scanning microscopy includes motion correction (rigid or non-rigid), cell segmentation, and calcium event extraction (sometimes described as \"deconvolution\" or \"spike inference\"). Some include raster artifact correction, cropping and stitching operations.</p> <p> </p>      Left to right: Raw scans, Motion corrected scans, Cell segmentation, Calcium events    <p>For a long time, most labs developed custom processing pipelines, sharing them with others as academic open-source projects. This has changed recently with the emerging of a few leaders as the standardization candidates for the initial preprocessing.</p> <ul> <li>CaImAn (Originally developed by Andrea   Giovannucci, current support by FlatIron Institute: Eftychios A. Pnevmatikakis,   Johannes Friedrich)</li> <li>Suite2p (Carsen Stringer and Marius Pachitariu   at Janelia), 200+ users, active support</li> <li>EXTRACT (Hakan Inan et al. 2017,   2021).</li> </ul> <p>Element Calcium Imaging encapsulates these packages to ease the management of data and its analysis.</p>"}, {"location": "concepts/#acquisition-tools", "title": "Acquisition tools", "text": ""}, {"location": "concepts/#hardware", "title": "Hardware", "text": "<p>The primary acquisition systems are:</p> <ul> <li>Sutter</li> <li>Thorlabs</li> <li>Bruker</li> <li>Neurolabware</li> </ul> <p>We do not include Miniscopes in these estimates. In, all there are perhaps on the order of 3000 two-photon setups globally but their processing needs may need to be further segmented.</p>"}, {"location": "concepts/#software", "title": "Software", "text": "<ul> <li>Vidrio ScanImage</li> <li>Thorlabs ThorImageLS</li> <li>Scanbox</li> <li>Nikon NIS-Elements</li> <li>Bruker Prairie View</li> </ul>"}, {"location": "partnerships/", "title": "Key partnerships", "text": "<p>Several labs have developed DataJoint-based data management and processing pipelines for two-photon calcium imaging. Our team collaborated with several of them during their projects. Additionally, we interviewed these teams to understand their experiment workflow, pipeline design, associated tools, and interfaces.</p> <p>These teams include:</p> <ul> <li>MICrONS (Andreas Tolias Lab, BCM) - https://github.com/cajal</li> <li>BrainCoGS (Princeton) - https://github.com/BrainCOGS</li> <li>Moser Group (Kavli Institute/NTNU) - private repository</li> <li>Anne Churchland Lab (UCLA)</li> </ul>"}, {"location": "pipeline/", "title": "Data Pipeline", "text": "<p>Each node in the following diagram represents the analysis code in the pipeline and the corresponding table in the database.  Within the pipeline, Element Calcium Imaging connects to upstream Elements including Lab, Animal, Session, and Event. For more  detailed documentation on each table, see the API docs for the respective schemas.</p> <p>The Element is composed of two main schemas, <code>scan</code> and <code>imaging</code>. To handle several use cases of this pipeline, we have designed two alternatives to the <code>imaging</code>  schema, including <code>imaging_no_curation</code> and <code>imaging_preprocess</code>.</p>"}, {"location": "pipeline/#diagrams", "title": "Diagrams", "text": ""}, {"location": "pipeline/#imaging-module", "title": "<code>imaging</code> module", "text": "<ul> <li>Multiple scans are acquired during each session and each scan is processed independently. </li> </ul>"}, {"location": "pipeline/#imaging_no_curation-module", "title": "<code>imaging_no_curation</code> module", "text": "<ul> <li>Same as the <code>imaging</code> module, but without the <code>Curation</code> table. </li> </ul>"}, {"location": "pipeline/#imaging_preprocess-module", "title": "<code>imaging_preprocess</code> module", "text": "<ul> <li>Same as the <code>imaging</code> module, and additional pre-processing steps can be performed on each scan prior to processing with Suite2p or CaImAn. </li> </ul>"}, {"location": "pipeline/#multi-scan-processing-branch", "title": "<code>multi-scan-processing</code> branch", "text": "<ul> <li>The processing pipeline is typically performed on a per-scan basis, however, depending on the nature of the research questions, different labs may opt to perform processing/segmentation on a concatenated set of data from multiple scans. To this end, we have extended the Calcium Imaging Element and provided a design version capable of supporting a multi-scan processing scheme.</li> </ul>"}, {"location": "pipeline/#table-descriptions", "title": "Table descriptions", "text": ""}, {"location": "pipeline/#lab-schema", "title": "<code>lab</code> schema", "text": "<ul> <li>For further details see the lab schema API docs</li> </ul> Table Description Device Scanner metadata"}, {"location": "pipeline/#subject-schema", "title": "<code>subject</code> schema", "text": "<ul> <li>Although not required, most choose to connect the <code>Session</code> table to a <code>Subject</code> table.</li> </ul> <ul> <li>For further details see the subject schema API docs</li> </ul> Table Description Subject Basic information of the research subject"}, {"location": "pipeline/#session-schema", "title": "<code>session</code> schema", "text": "<ul> <li>For further details see the session schema API docs</li> </ul> Table Description Session Unique experimental session identifier"}, {"location": "pipeline/#scan-schema", "title": "<code>scan</code> schema", "text": "<ul> <li>For further details see the scan schema API docs</li> </ul> Table Description AcquisitionSoftware Software used in the acquisition of the imaging scans Channel Recording Channel Scan A set of imaging scans performed in a single session ScanLocation Anatomical location of the region scanned ScanInfo Metadata of the imaging scan ScanInfo.Field Metadata of the fields imaged ScanInfo.ScanFile Path of the scan file ScanQualityMetrics Metrics to assess the quality of the scan ScanQualityMetrics.Frames Metrics used to evaluate each frame"}, {"location": "pipeline/#imaging-schema", "title": "<code>imaging</code> schema", "text": "<ul> <li>For further details see the imaging schema API docs</li> </ul> Table Description ProcessingMethod Available analysis suites that can be used in processing of the imaging scans ProcessingParamSet All parameters required to process a calcium imaging scan CellCompartment Cell compartments that can be imaged MaskType Available labels for segmented masks ProcessingTask Task defined by a combination of Scan and ProcessingParamSet Processing The core table that executes a ProcessingTask Curation Curated results MotionCorrection Results of the motion correction procedure MotionCorrection.RigidMotionCorrection Details of the rigid motion correction performed on the imaging data MotionCorrection.NonRigidMotionCorrection Details of nonrigid motion correction performed on the imaging data MotionCorrection.NonRigidMotionCorrection.Block Results of non-rigid motion correction for each block MotionCorrection.Summary Summary images for each field and channel after motion corrections Segmentation Results of the segmentation Segmentation.Mask Masks identified in the segmentation procedure MaskClassificationMethod Method used in the mask classification procedure MaskClassification Result of the mask classification procedure MaskClassification.MaskType Type assigned to each mask Fluorescence Fluorescence measurements Fluorescence.Trace Fluorescence traces for each region of interest ActivityExtractionMethod Method used in activity extraction Activity Inferred neural activity Activity.Trace Inferred neural activity from fluorescence traces ProcessingQualityMetrics Quality metrics used to evaluate the results of the calcium imaging analysis pipeline ProcessingQualityMetrics.Mask Quality metrics used to evaluate the masks ProcessingQualityMetrics.Trace Quality metrics used to evaluate the fluorescence traces"}, {"location": "roadmap/", "title": "Roadmap", "text": "<p>Through our interviews and direct collaboration on key projects, we identified the common motifs to create Element Calcium Imaging. Major features include:</p> <ul> <li> Ingestion of scan metadata, also compatible with mesoscale imaging and   multi-ROI scanning mode</li> <li> Tables for all processing steps: motion correction, cell segmentation,    fluorescence trace extraction, spike inference, and cell classification</li> <li> Store different curations of the segmentation results</li> <li> Ingestion of data acquired with ScanImage, Scanbox, Nikon NIS-Elements, and   Bruker Prairie View acquisition systems</li> <li> Ingestion of processing outputs from both Suite2p and CaImAn analysis suites</li> <li> Sample data and complete test suite for quality assurance</li> <li> Cell extraction with the EXTRACT analysis package</li> <li> Quality metrics</li> <li> Data compression</li> <li> Deepinterpolation</li> <li> Data export to NWB</li> <li> Data publishing to DANDI</li> </ul> <p>Further development of this Element is community driven. Upon user requests and based on guidance from the Scientific Steering Group we will continue adding features to this  Element.</p>"}, {"location": "api/element_calcium_imaging/analysis/", "title": "analysis.py", "text": ""}, {"location": "api/element_calcium_imaging/analysis/#element_calcium_imaging.analysis.activate", "title": "<code>activate(schema_name, *, create_schema=True, create_tables=True, linking_module=None)</code>", "text": "<p>Activate this schema.</p> <p>Parameters:</p> Name Type Description Default <code>schema_name</code> <code>str</code> <p>Schema name on the database server to activate the <code>subject</code> element.</p> required <code>create_schema</code> <code>bool</code> <p>When True (default), create schema in the database if it does not yet exist.</p> <code>True</code> <code>create_tables</code> <code>bool</code> <p>When True (default), create tables in the database if they do not yet exist.</p> <code>True</code> <code>linking_module</code> <code>str</code> <p>A module name or a module containing the required dependencies to activate the <code>subject</code> element: Upstream schema: scan, session, trial.</p> <code>None</code> Source code in <code>element_calcium_imaging/analysis.py</code> <pre><code>def activate(\n    schema_name, *, create_schema=True, create_tables=True, linking_module=None\n):\n\"\"\"Activate this schema.\n\n    Args:\n        schema_name (str): Schema name on the database server to activate the `subject`\n            element.\n        create_schema (bool): When True (default), create schema in the database if it\n            does not yet exist.\n        create_tables (bool): When True (default), create tables in the database if they\n            do not yet exist.\n        linking_module (str): A module name or a module containing the required\n            dependencies to activate the `subject` element: Upstream schema: scan,\n            session, trial.\n    \"\"\"\n    if isinstance(linking_module, str):\n        linking_module = importlib.import_module(linking_module)\n    assert inspect.ismodule(linking_module), (\n        \"The argument 'dependency' must \" + \"be a module's name or a module\"\n    )\n\n    global _linking_module\n    _linking_module = linking_module\n\n    schema.activate(\n        schema_name,\n        create_schema=create_schema,\n        create_tables=create_tables,\n        add_objects=linking_module.__dict__,\n    )\n</code></pre>"}, {"location": "api/element_calcium_imaging/analysis/#element_calcium_imaging.analysis.ActivityAlignmentCondition", "title": "<code>ActivityAlignmentCondition</code>", "text": "<p>         Bases: <code>dj.Manual</code></p> <p>Activity alignment condition.</p> <p>Attributes:</p> Name Type Description <code>imaging.Activity</code> <code>foreign key</code> <p>Primary key from imaging.Activity.</p> <code>event.AlignmentEvent</code> <code>foreign key</code> <p>Primary key from event.AlignmentEvent.</p> <code>trial_condition</code> <code>str</code> <p>User-friendly name of condition.</p> <code>bin_size</code> <code>float</code> <p>bin-size (in second) used to compute the PSTH,</p> Source code in <code>element_calcium_imaging/analysis.py</code> <pre><code>@schema\nclass ActivityAlignmentCondition(dj.Manual):\n\"\"\"Activity alignment condition.\n\n    Attributes:\n        imaging.Activity (foreign key): Primary key from imaging.Activity.\n        event.AlignmentEvent (foreign key): Primary key from event.AlignmentEvent.\n        trial_condition (str): User-friendly name of condition.\n        condition_description (str). Optional. Description. Default is ''.\n        bin_size (float): bin-size (in second) used to compute the PSTH,\n    \"\"\"\n\n    definition = \"\"\"\n    -&gt; imaging.Activity\n    -&gt; event.AlignmentEvent\n    trial_condition: varchar(128) # user-friendly name of condition\n    ---\n    condition_description='': varchar(1000)\n    bin_size=0.04: float # bin-size (in second) used to compute the PSTH\n    \"\"\"\n\n    class Trial(dj.Part):\n\"\"\"Trial\n\n        Attributes:\n            ActivityAlignmentCondition (foreign key): Primary key from\n                ActivityAlignmentCondition.\n            trial.Trial: Primary key from trial.Trial.\n        \"\"\"\n\n        definition = \"\"\"  # Trials (or subset) to compute event-aligned activity\n        -&gt; master\n        -&gt; trial.Trial\n        \"\"\"\n</code></pre>"}, {"location": "api/element_calcium_imaging/analysis/#element_calcium_imaging.analysis.ActivityAlignmentCondition.Trial", "title": "<code>Trial</code>", "text": "<p>         Bases: <code>dj.Part</code></p> <p>Trial</p> <p>Attributes:</p> Name Type Description <code>ActivityAlignmentCondition</code> <code>foreign key</code> <p>Primary key from ActivityAlignmentCondition.</p> <code>trial.Trial</code> <code>foreign key</code> <p>Primary key from trial.Trial.</p> Source code in <code>element_calcium_imaging/analysis.py</code> <pre><code>class Trial(dj.Part):\n\"\"\"Trial\n\n    Attributes:\n        ActivityAlignmentCondition (foreign key): Primary key from\n            ActivityAlignmentCondition.\n        trial.Trial: Primary key from trial.Trial.\n    \"\"\"\n\n    definition = \"\"\"  # Trials (or subset) to compute event-aligned activity\n    -&gt; master\n    -&gt; trial.Trial\n    \"\"\"\n</code></pre>"}, {"location": "api/element_calcium_imaging/analysis/#element_calcium_imaging.analysis.ActivityAlignment", "title": "<code>ActivityAlignment</code>", "text": "<p>         Bases: <code>dj.Computed</code></p> <p>Attributes:</p> Name Type Description <code>ActivityAlignmentCondition</code> <code>foreign key</code> <p>Primary key from ActivityAlignmentCondition.</p> <code>aligned_timestamps</code> <code>longblob</code> <p>Aligned timestamps.</p> Source code in <code>element_calcium_imaging/analysis.py</code> <pre><code>@schema\nclass ActivityAlignment(dj.Computed):\n\"\"\"\n    Attributes:\n        ActivityAlignmentCondition (foreign key): Primary key from\n            ActivityAlignmentCondition.\n        aligned_timestamps (longblob): Aligned timestamps.\n    \"\"\"\n\n    definition = \"\"\"\n    -&gt; ActivityAlignmentCondition\n    ---\n    aligned_timestamps: longblob\n    \"\"\"\n\n    class AlignedTrialActivity(dj.Part):\n\"\"\"Aligned trial activity.\n\n        Attributes:\n            ActivityAlignment (foreign key): Primary key from ActivityAlignment.\n            imaging.Activity.Trace (foreign key): Primary key from\n                imaging.Activity.Trace.\n            ActivityAlignmentCondition.Trial (foreign key): Primary key from\n                ActivityAlignmentCondition.Trial.\n            aligned_trace (longblob): Calcium activity aligned to the event time (s).\n        \"\"\"\n\n        definition = \"\"\"\n        -&gt; master\n        -&gt; imaging.Activity.Trace\n        -&gt; ActivityAlignmentCondition.Trial\n        ---\n        aligned_trace: longblob  # (s) Calcium activity aligned to the event time\n        \"\"\"\n\n    def make(self, key):\n        sess_time, scan_time, nframes, frame_rate = (\n            _linking_module.scan.ScanInfo * _linking_module.session.Session &amp; key\n        ).fetch1(\"session_datetime\", \"scan_datetime\", \"nframes\", \"fps\")\n\n        trialized_event_times = (\n            _linking_module.trial.get_trialized_alignment_event_times(\n                key,\n                _linking_module.trial.Trial &amp; (ActivityAlignmentCondition.Trial &amp; key),\n            )\n        )\n\n        min_limit = (trialized_event_times.event - trialized_event_times.start).max()\n        max_limit = (trialized_event_times.end - trialized_event_times.event).max()\n\n        aligned_timestamps = np.arange(-min_limit, max_limit, 1 / frame_rate)\n        nsamples = len(aligned_timestamps)\n\n        trace_keys, activity_traces = (\n            _linking_module.imaging.Activity.Trace &amp; key\n        ).fetch(\"KEY\", \"activity_trace\", order_by=\"mask\")\n        activity_traces = np.vstack(activity_traces)\n\n        aligned_trial_activities = []\n        for _, r in trialized_event_times.iterrows():\n            if r.event is None or np.isnan(r.event):\n                continue\n            alignment_start_idx = int((r.event - min_limit) * frame_rate)\n            roi_aligned_activities = activity_traces[\n                :, alignment_start_idx : (alignment_start_idx + nsamples)\n            ]\n            if roi_aligned_activities.shape[-1] != nsamples:\n                shape_diff = nsamples - roi_aligned_activities.shape[-1]\n                roi_aligned_activities = np.pad(\n                    roi_aligned_activities,\n                    ((0, 0), (0, shape_diff)),\n                    mode=\"constant\",\n                    constant_values=np.nan,\n                )\n\n            aligned_trial_activities.extend(\n                [\n                    {**key, **r.trial_key, **trace_key, \"aligned_trace\": aligned_trace}\n                    for trace_key, aligned_trace in zip(\n                        trace_keys, roi_aligned_activities\n                    )\n                ]\n            )\n\n        self.insert1({**key, \"aligned_timestamps\": aligned_timestamps})\n        self.AlignedTrialActivity.insert(aligned_trial_activities)\n\n    def plot_aligned_activities(self, key, roi, axs=None, title=None):\n\"\"\"Plot event-aligned activities for selected trials, and trial-averaged\n            activity (e.g. dF/F, neuropil-corrected dF/F, Calcium events, etc.).\n\n        Args:\n            key (dict): key of ActivityAlignment master table\n            roi (int): imaging segmentation mask\n            axs (matplotlib.ax): optional definition of axes for plot.\n                Default is plt.subplots(2, 1, figsize=(12, 8))\n            title (str): Optional title label\n\n        Returns:\n            fig (matplotlib.pyplot.figure): Figure of the event aligned activities.\n        \"\"\"\n        import matplotlib.pyplot as plt\n\n        fig = None\n        if axs is None:\n            fig, (ax0, ax1) = plt.subplots(2, 1, figsize=(12, 8))\n        else:\n            ax0, ax1 = axs\n\n        aligned_timestamps = (self &amp; key).fetch1(\"aligned_timestamps\")\n        trial_ids, aligned_spikes = (\n            self.AlignedTrialActivity &amp; key &amp; {\"mask\": roi}\n        ).fetch(\"trial_id\", \"aligned_trace\", order_by=\"trial_id\")\n\n        aligned_spikes = np.vstack(aligned_spikes)\n\n        ax0.imshow(\n            aligned_spikes,\n            cmap=\"inferno\",\n            interpolation=\"nearest\",\n            aspect=\"auto\",\n            extent=(\n                aligned_timestamps[0],\n                aligned_timestamps[-1],\n                0,\n                aligned_spikes.shape[0],\n            ),\n        )\n        ax0.axvline(x=0, linestyle=\"--\", color=\"white\")\n        ax0.set_axis_off()\n\n        ax1.plot(aligned_timestamps, np.nanmean(aligned_spikes, axis=0))\n        ax1.axvline(x=0, linestyle=\"--\", color=\"black\")\n        ax1.set_xlabel(\"Time (s)\")\n        ax1.set_xlim(aligned_timestamps[0], aligned_timestamps[-1])\n\n        if title:\n            plt.suptitle(title)\n\n        return fig\n</code></pre>"}, {"location": "api/element_calcium_imaging/analysis/#element_calcium_imaging.analysis.ActivityAlignment.AlignedTrialActivity", "title": "<code>AlignedTrialActivity</code>", "text": "<p>         Bases: <code>dj.Part</code></p> <p>Aligned trial activity.</p> <p>Attributes:</p> Name Type Description <code>ActivityAlignment</code> <code>foreign key</code> <p>Primary key from ActivityAlignment.</p> <code>imaging.Activity.Trace</code> <code>foreign key</code> <p>Primary key from imaging.Activity.Trace.</p> <code>ActivityAlignmentCondition.Trial</code> <code>foreign key</code> <p>Primary key from ActivityAlignmentCondition.Trial.</p> <code>aligned_trace</code> <code>longblob</code> <p>Calcium activity aligned to the event time (s).</p> Source code in <code>element_calcium_imaging/analysis.py</code> <pre><code>class AlignedTrialActivity(dj.Part):\n\"\"\"Aligned trial activity.\n\n    Attributes:\n        ActivityAlignment (foreign key): Primary key from ActivityAlignment.\n        imaging.Activity.Trace (foreign key): Primary key from\n            imaging.Activity.Trace.\n        ActivityAlignmentCondition.Trial (foreign key): Primary key from\n            ActivityAlignmentCondition.Trial.\n        aligned_trace (longblob): Calcium activity aligned to the event time (s).\n    \"\"\"\n\n    definition = \"\"\"\n    -&gt; master\n    -&gt; imaging.Activity.Trace\n    -&gt; ActivityAlignmentCondition.Trial\n    ---\n    aligned_trace: longblob  # (s) Calcium activity aligned to the event time\n    \"\"\"\n</code></pre>"}, {"location": "api/element_calcium_imaging/analysis/#element_calcium_imaging.analysis.ActivityAlignment.plot_aligned_activities", "title": "<code>plot_aligned_activities(key, roi, axs=None, title=None)</code>", "text": "<p>Plot event-aligned activities for selected trials, and trial-averaged     activity (e.g. dF/F, neuropil-corrected dF/F, Calcium events, etc.).</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>dict</code> <p>key of ActivityAlignment master table</p> required <code>roi</code> <code>int</code> <p>imaging segmentation mask</p> required <code>axs</code> <code>matplotlib.ax</code> <p>optional definition of axes for plot. Default is plt.subplots(2, 1, figsize=(12, 8))</p> <code>None</code> <code>title</code> <code>str</code> <p>Optional title label</p> <code>None</code> <p>Returns:</p> Name Type Description <code>fig</code> <code>matplotlib.pyplot.figure</code> <p>Figure of the event aligned activities.</p> Source code in <code>element_calcium_imaging/analysis.py</code> <pre><code>def plot_aligned_activities(self, key, roi, axs=None, title=None):\n\"\"\"Plot event-aligned activities for selected trials, and trial-averaged\n        activity (e.g. dF/F, neuropil-corrected dF/F, Calcium events, etc.).\n\n    Args:\n        key (dict): key of ActivityAlignment master table\n        roi (int): imaging segmentation mask\n        axs (matplotlib.ax): optional definition of axes for plot.\n            Default is plt.subplots(2, 1, figsize=(12, 8))\n        title (str): Optional title label\n\n    Returns:\n        fig (matplotlib.pyplot.figure): Figure of the event aligned activities.\n    \"\"\"\n    import matplotlib.pyplot as plt\n\n    fig = None\n    if axs is None:\n        fig, (ax0, ax1) = plt.subplots(2, 1, figsize=(12, 8))\n    else:\n        ax0, ax1 = axs\n\n    aligned_timestamps = (self &amp; key).fetch1(\"aligned_timestamps\")\n    trial_ids, aligned_spikes = (\n        self.AlignedTrialActivity &amp; key &amp; {\"mask\": roi}\n    ).fetch(\"trial_id\", \"aligned_trace\", order_by=\"trial_id\")\n\n    aligned_spikes = np.vstack(aligned_spikes)\n\n    ax0.imshow(\n        aligned_spikes,\n        cmap=\"inferno\",\n        interpolation=\"nearest\",\n        aspect=\"auto\",\n        extent=(\n            aligned_timestamps[0],\n            aligned_timestamps[-1],\n            0,\n            aligned_spikes.shape[0],\n        ),\n    )\n    ax0.axvline(x=0, linestyle=\"--\", color=\"white\")\n    ax0.set_axis_off()\n\n    ax1.plot(aligned_timestamps, np.nanmean(aligned_spikes, axis=0))\n    ax1.axvline(x=0, linestyle=\"--\", color=\"black\")\n    ax1.set_xlabel(\"Time (s)\")\n    ax1.set_xlim(aligned_timestamps[0], aligned_timestamps[-1])\n\n    if title:\n        plt.suptitle(title)\n\n    return fig\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging/", "title": "imaging.py", "text": ""}, {"location": "api/element_calcium_imaging/imaging/#element_calcium_imaging.imaging.activate", "title": "<code>activate(imaging_schema_name, scan_schema_name=None, *, create_schema=True, create_tables=True, linking_module=None)</code>", "text": "<p>Activate this schema.</p> <p>Parameters:</p> Name Type Description Default <code>imaging_schema_name</code> <code>str</code> <p>Schema name on the database server to activate the <code>imaging</code> module.</p> required <code>scan_schema_name</code> <code>str</code> <p>Schema name on the database server to activate the <code>scan</code> module. Omitted, if the <code>scan</code> module is already activated.</p> <code>None</code> <code>create_schema</code> <code>bool</code> <p>When True (default), create schema in the database if it does not yet exist.</p> <code>True</code> <code>create_tables</code> <code>bool</code> <p>When True (default), create tables in the database if they do not yet exist.</p> <code>True</code> <code>linking_module</code> <code>str</code> <p>A module name or a module containing the required dependencies to activate the <code>imaging</code> module: + all that are required by the <code>scan</code> module.</p> <code>None</code> <p>Dependencies:</p> Upstream tables <ul> <li>Session: A parent table to Scan, identifying a scanning session.</li> <li>Equipment: A parent table to Scan, identifying a scanning device.</li> </ul> Source code in <code>element_calcium_imaging/imaging.py</code> <pre><code>def activate(\n    imaging_schema_name: str,\n    scan_schema_name: str = None,\n    *,\n    create_schema: bool = True,\n    create_tables: bool = True,\n    linking_module: str = None,\n):\n\"\"\"Activate this schema.\n\n    Args:\n        imaging_schema_name (str): Schema name on the database server to activate the\n            `imaging` module.\n        scan_schema_name (str): Schema name on the database server to activate the\n            `scan` module. Omitted, if the `scan` module is already activated.\n        create_schema (bool): When True (default), create schema in the database if it\n            does not yet exist.\n        create_tables (bool): When True (default), create tables in the database if they\n            do not yet exist.\n        linking_module (str): A module name or a module containing the required\n            dependencies to activate the `imaging` module: + all that are required by\n            the `scan` module.\n\n    Dependencies:\n    Upstream tables:\n        + Session: A parent table to Scan, identifying a scanning session.\n        + Equipment: A parent table to Scan, identifying a scanning device.\n    \"\"\"\n\n    if isinstance(linking_module, str):\n        linking_module = importlib.import_module(linking_module)\n    assert inspect.ismodule(\n        linking_module\n    ), \"The argument 'dependency' must be a module's name or a module\"\n\n    global _linking_module\n    _linking_module = linking_module\n\n    scan.activate(\n        scan_schema_name,\n        create_schema=create_schema,\n        create_tables=create_tables,\n        linking_module=linking_module,\n    )\n    schema.activate(\n        imaging_schema_name,\n        create_schema=create_schema,\n        create_tables=create_tables,\n        add_objects=_linking_module.__dict__,\n    )\n    imaging_report.activate(f\"{imaging_schema_name}_report\", imaging_schema_name)\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging/#element_calcium_imaging.imaging.get_imaging_root_data_dir", "title": "<code>get_imaging_root_data_dir()</code>", "text": "<p>Return imaging root data director(y/ies)</p> <p>Retrieve the root data director(y/ies) containing the imaging data for all subjects/sessions (e.g. acquired ScanImage raw files, output files from processing routines, etc.). All data paths and directories in DataJoint Elements are recommended to be stored as relative paths (posix format), with respect to some user-configured \"root\" directory, which varies from machine to machine (e.g. different mounted drive locations).</p> <p>Returns:</p> Name Type Description <code>dirs</code> <code>list</code> <p>A list of string(s) or Path(s) for the absolute paths of the imaging root data director(y/ies).</p> Source code in <code>element_calcium_imaging/scan.py</code> <pre><code>def get_imaging_root_data_dir() -&gt; list:\n\"\"\"Return imaging root data director(y/ies)\n\n    Retrieve the root data director(y/ies) containing the imaging data\n    for all subjects/sessions (e.g. acquired ScanImage raw files, output files from\n    processing routines, etc.). All data paths and directories in DataJoint Elements are\n    recommended to be stored as relative paths (posix format), with respect to some\n    user-configured \"root\" directory, which varies from machine to machine\n    (e.g. different mounted drive locations).\n\n    Returns:\n        dirs (list): A list of string(s) or Path(s) for the absolute paths of the imaging root data\n            director(y/ies).\n    \"\"\"\n\n    root_directories = _linking_module.get_imaging_root_data_dir()\n    if isinstance(root_directories, (str, pathlib.Path)):\n        root_directories = [root_directories]\n\n    if hasattr(_linking_module, \"get_processed_root_data_dir\"):\n        root_directories.append(_linking_module.get_processed_root_data_dir())\n\n    return root_directories\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging/#element_calcium_imaging.imaging.ProcessingMethod", "title": "<code>ProcessingMethod</code>", "text": "<p>         Bases: <code>dj.Lookup</code></p> <p>Package used for processing of calcium imaging data (e.g. Suite2p, CaImAn, etc.).</p> <p>Attributes:</p> Name Type Description <code>processing_method</code> <code>str</code> <p>Processing method.</p> <code>processing_method_desc</code> <code>str</code> <p>Processing method description.</p> Source code in <code>element_calcium_imaging/imaging.py</code> <pre><code>@schema\nclass ProcessingMethod(dj.Lookup):\n\"\"\"Package used for processing of calcium imaging data (e.g. Suite2p, CaImAn, etc.).\n\n    Attributes:\n        processing_method (str): Processing method.\n        processing_method_desc (str): Processing method description.\n    \"\"\"\n\n    definition = \"\"\"# Package used for processing of calcium imaging data (e.g. Suite2p, CaImAn, etc.).\n    processing_method: char(8)\n    ---\n    processing_method_desc: varchar(1000)  # Processing method description\n    \"\"\"\n\n    contents = [\n        (\"suite2p\", \"suite2p analysis suite\"),\n        (\"caiman\", \"caiman analysis suite\"),\n        (\"extract\", \"extract analysis suite\"),\n    ]\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging/#element_calcium_imaging.imaging.get_processed_root_data_dir", "title": "<code>get_processed_root_data_dir()</code>", "text": "<p>Retrieve the root directory for all processed data.</p> <p>All data paths and directories in DataJoint Elements are recommended to be stored as relative paths (posix format), with respect to some user-configured \"root\" directory, which varies from machine to machine (e.g. different mounted drive locations).</p> <p>Returns:</p> Name Type Description <code>dir</code> <code>str | pathlib.Path</code> <p>Absolute path of the processed imaging root data directory.</p> Source code in <code>element_calcium_imaging/scan.py</code> <pre><code>def get_processed_root_data_dir() -&gt; Union[str, pathlib.Path]:\n\"\"\"Retrieve the root directory for all processed data.\n\n    All data paths and directories in DataJoint Elements are recommended to be stored as\n    relative paths (posix format), with respect to some user-configured \"root\"\n    directory, which varies from machine to machine (e.g. different mounted drive\n    locations).\n\n    Returns:\n        dir (str| pathlib.Path): Absolute path of the processed imaging root data\n            directory.\n    \"\"\"\n\n    if hasattr(_linking_module, \"get_processed_root_data_dir\"):\n        return _linking_module.get_processed_root_data_dir()\n    else:\n        return get_imaging_root_data_dir()[0]\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging/#element_calcium_imaging.imaging.ProcessingParamSet", "title": "<code>ProcessingParamSet</code>", "text": "<p>         Bases: <code>dj.Lookup</code></p> <p>Parameter set used for the processing of the calcium imaging scans, including both the analysis suite and its respective input parameters.</p> <p>A hash of the parameters of the analysis suite is also stored in order to avoid duplicated entries.</p> <p>Attributes:</p> Name Type Description <code>paramset_idx</code> <code>int</code> <p>Unique parameter set ID.</p> <code>ProcessingMethod</code> <code>foreign key</code> <p>A primary key from ProcessingMethod.</p> <code>paramset_desc</code> <code>str</code> <p>Parameter set description.</p> <code>param_set_hash</code> <code>uuid</code> <p>A universally unique identifier for the parameter set.</p> <code>params</code> <code>longblob</code> <p>Parameter Set, a dictionary of all applicable parameters to the analysis suite.</p> Source code in <code>element_calcium_imaging/imaging.py</code> <pre><code>@schema\nclass ProcessingParamSet(dj.Lookup):\n\"\"\"Parameter set used for the processing of the calcium imaging scans,\n    including both the analysis suite and its respective input parameters.\n\n    A hash of the parameters of the analysis suite is also stored in order\n    to avoid duplicated entries.\n\n    Attributes:\n        paramset_idx (int): Unique parameter set ID.\n        ProcessingMethod (foreign key): A primary key from ProcessingMethod.\n        paramset_desc (str): Parameter set description.\n        param_set_hash (uuid): A universally unique identifier for the parameter set.\n        params (longblob): Parameter Set, a dictionary of all applicable parameters to\n            the analysis suite.\n    \"\"\"\n\n    definition = \"\"\"# Processing Parameter Set\n    paramset_idx: smallint  # Unique parameter set ID.\n    ---\n    -&gt; ProcessingMethod\n    paramset_desc: varchar(1280)  # Parameter-set description\n    param_set_hash: uuid  # A universally unique identifier for the parameter set\n    unique index (param_set_hash)\n    params: longblob  # Parameter Set, a dictionary of all applicable parameters to the analysis suite.\n    \"\"\"\n\n    @classmethod\n    def insert_new_params(\n        cls,\n        processing_method: str,\n        paramset_idx: int,\n        paramset_desc: str,\n        params: dict,\n    ):\n\"\"\"Insert a parameter set into ProcessingParamSet table.\n\n        This function automates the parameter set hashing and avoids insertion of an\n            existing parameter set.\n\n        Attributes:\n            processing_method (str): Processing method/package used for processing of\n                calcium imaging.\n            paramset_idx (int): Unique parameter set ID.\n            paramset_desc (str): Parameter set description.\n            params (dict): Parameter Set, all applicable parameters to the analysis\n                suite.\n        \"\"\"\n        if processing_method == \"extract\":\n            assert (\n                params.get(\"extract\") is not None and params.get(\"suite2p\") is not None\n            ), ValueError(\n                \"Please provide the processing parameters in the {'suite2p': {...}, 'extract': {...}} dictionary format.\"\n            )\n\n            # Force Suite2p to only run motion correction.\n            params[\"suite2p\"][\"do_registration\"] = True\n            params[\"suite2p\"][\"roidetect\"] = False\n\n        param_dict = {\n            \"processing_method\": processing_method,\n            \"paramset_idx\": paramset_idx,\n            \"paramset_desc\": paramset_desc,\n            \"params\": params,\n            \"param_set_hash\": dict_to_uuid(params),\n        }\n        q_param = cls &amp; {\"param_set_hash\": param_dict[\"param_set_hash\"]}\n\n        if q_param:  # If the specified param-set already exists\n            p_name = q_param.fetch1(\"paramset_idx\")\n            if p_name == paramset_idx:  # If the existed set has the same name: job done\n                return\n            else:  # If not same name: human error, trying to add the same paramset with different name\n                raise dj.DataJointError(\n                    \"The specified param-set already exists - name: {}\".format(p_name)\n                )\n        else:\n            cls.insert1(param_dict)\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging/#element_calcium_imaging.imaging.ProcessingParamSet.insert_new_params", "title": "<code>insert_new_params(processing_method, paramset_idx, paramset_desc, params)</code>  <code>classmethod</code>", "text": "<p>Insert a parameter set into ProcessingParamSet table.</p> <p>This function automates the parameter set hashing and avoids insertion of an     existing parameter set.</p> <p>Attributes:</p> Name Type Description <code>processing_method</code> <code>str</code> <p>Processing method/package used for processing of calcium imaging.</p> <code>paramset_idx</code> <code>int</code> <p>Unique parameter set ID.</p> <code>paramset_desc</code> <code>str</code> <p>Parameter set description.</p> <code>params</code> <code>dict</code> <p>Parameter Set, all applicable parameters to the analysis suite.</p> Source code in <code>element_calcium_imaging/imaging.py</code> <pre><code>@classmethod\ndef insert_new_params(\n    cls,\n    processing_method: str,\n    paramset_idx: int,\n    paramset_desc: str,\n    params: dict,\n):\n\"\"\"Insert a parameter set into ProcessingParamSet table.\n\n    This function automates the parameter set hashing and avoids insertion of an\n        existing parameter set.\n\n    Attributes:\n        processing_method (str): Processing method/package used for processing of\n            calcium imaging.\n        paramset_idx (int): Unique parameter set ID.\n        paramset_desc (str): Parameter set description.\n        params (dict): Parameter Set, all applicable parameters to the analysis\n            suite.\n    \"\"\"\n    if processing_method == \"extract\":\n        assert (\n            params.get(\"extract\") is not None and params.get(\"suite2p\") is not None\n        ), ValueError(\n            \"Please provide the processing parameters in the {'suite2p': {...}, 'extract': {...}} dictionary format.\"\n        )\n\n        # Force Suite2p to only run motion correction.\n        params[\"suite2p\"][\"do_registration\"] = True\n        params[\"suite2p\"][\"roidetect\"] = False\n\n    param_dict = {\n        \"processing_method\": processing_method,\n        \"paramset_idx\": paramset_idx,\n        \"paramset_desc\": paramset_desc,\n        \"params\": params,\n        \"param_set_hash\": dict_to_uuid(params),\n    }\n    q_param = cls &amp; {\"param_set_hash\": param_dict[\"param_set_hash\"]}\n\n    if q_param:  # If the specified param-set already exists\n        p_name = q_param.fetch1(\"paramset_idx\")\n        if p_name == paramset_idx:  # If the existed set has the same name: job done\n            return\n        else:  # If not same name: human error, trying to add the same paramset with different name\n            raise dj.DataJointError(\n                \"The specified param-set already exists - name: {}\".format(p_name)\n            )\n    else:\n        cls.insert1(param_dict)\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging/#element_calcium_imaging.imaging.get_image_files", "title": "<code>get_image_files(scan_key, file_type)</code>", "text": "<p>Retrieve the list of image files associated with a given Scan.</p> <p>Parameters:</p> Name Type Description Default <code>scan_key</code> <code>dict</code> <p>Primary key of a Scan entry.</p> required <p>Returns:</p> Type Description <code>list</code> <p>A list of full file paths.</p> Source code in <code>element_calcium_imaging/scan.py</code> <pre><code>def get_image_files(scan_key: dict, file_type: str) -&gt; list:\n\"\"\"Retrieve the list of image files associated with a given Scan.\n\n    Args:\n        scan_key: Primary key of a Scan entry.\n\n    Returns:\n        A list of full file paths.\n    \"\"\"\n    return _linking_module.get_image_files(scan_key, file_type)\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging/#element_calcium_imaging.imaging.CellCompartment", "title": "<code>CellCompartment</code>", "text": "<p>         Bases: <code>dj.Lookup</code></p> <p>Cell compartments that can be imaged (e.g. 'axon', 'soma', etc.)</p> <p>Attributes:</p> Name Type Description <code>cell_compartment</code> <code>str</code> <p>Cell compartment.</p> Source code in <code>element_calcium_imaging/imaging.py</code> <pre><code>@schema\nclass CellCompartment(dj.Lookup):\n\"\"\"Cell compartments that can be imaged (e.g. 'axon', 'soma', etc.)\n\n    Attributes:\n        cell_compartment (str): Cell compartment.\n    \"\"\"\n\n    definition = \"\"\"# Cell compartments\n    cell_compartment: char(16)\n    \"\"\"\n\n    contents = zip([\"axon\", \"soma\", \"bouton\"])\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging/#element_calcium_imaging.imaging.MaskType", "title": "<code>MaskType</code>", "text": "<p>         Bases: <code>dj.Lookup</code></p> <p>Available labels for segmented masks (e.g. 'soma', 'axon', 'dendrite', 'neuropil').</p> <p>Attributes:</p> Name Type Description <code>mask_type</code> <code>str</code> <p>Mask type.</p> Source code in <code>element_calcium_imaging/imaging.py</code> <pre><code>@schema\nclass MaskType(dj.Lookup):\n\"\"\"Available labels for segmented masks (e.g. 'soma', 'axon', 'dendrite', 'neuropil').\n\n    Attributes:\n        mask_type (str): Mask type.\n    \"\"\"\n\n    definition = \"\"\"# Possible types of a segmented mask\n    mask_type: varchar(16)\n    \"\"\"\n\n    contents = zip([\"soma\", \"axon\", \"dendrite\", \"neuropil\", \"artefact\", \"unknown\"])\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging/#element_calcium_imaging.imaging.ProcessingTask", "title": "<code>ProcessingTask</code>", "text": "<p>         Bases: <code>dj.Manual</code></p> <p>A pairing of processing params and scans to be loaded or triggered</p> <p>This table defines a calcium imaging processing task for a combination of a <code>Scan</code> and a <code>ProcessingParamSet</code> entries, including all the inputs (scan, method, method's parameters). The task defined here is then run in the downstream table <code>Processing</code>. This table supports definitions of both loading of pre-generated results and the triggering of new analysis for all supported analysis methods.</p> <p>Attributes:</p> Name Type Description <code>scan.Scan</code> <code>foreign key</code> <p>Primary key from scan.Scan.</p> <code>ProcessingParamSet</code> <code>foreign key</code> <p>Primary key from ProcessingParamSet.</p> <code>processing_output_dir</code> <code>str</code> <p>Output directory of the processed scan relative to the root data directory.</p> <code>task_mode</code> <code>str</code> <p>One of 'load' (load computed analysis results) or 'trigger' (trigger computation).</p> Source code in <code>element_calcium_imaging/imaging.py</code> <pre><code>@schema\nclass ProcessingTask(dj.Manual):\n\"\"\"A pairing of processing params and scans to be loaded or triggered\n\n    This table defines a calcium imaging processing task for a combination of a\n    `Scan` and a `ProcessingParamSet` entries, including all the inputs (scan, method,\n    method's parameters). The task defined here is then run in the downstream table\n    `Processing`. This table supports definitions of both loading of pre-generated results\n    and the triggering of new analysis for all supported analysis methods.\n\n    Attributes:\n        scan.Scan (foreign key): Primary key from scan.Scan.\n        ProcessingParamSet (foreign key): Primary key from ProcessingParamSet.\n        processing_output_dir (str): Output directory of the processed scan relative to the root data directory.\n        task_mode (str): One of 'load' (load computed analysis results) or 'trigger'\n            (trigger computation).\n    \"\"\"\n\n    definition = \"\"\"# Manual table for defining a processing task ready to be run\n    -&gt; scan.Scan\n    -&gt; ProcessingParamSet\n    ---\n    processing_output_dir: varchar(255)  #  Output directory of the processed scan relative to root data directory\n    task_mode='load': enum('load', 'trigger')  # 'load': load computed analysis results, 'trigger': trigger computation\n    \"\"\"\n\n    @classmethod\n    def infer_output_dir(cls, key, relative=False, mkdir=False):\n\"\"\"Infer an output directory for an entry in ProcessingTask table.\n\n        Args:\n            key (dict): Primary key from the ProcessingTask table.\n            relative (bool): If True, processing_output_dir is returned relative to\n                imaging_root_dir. Default False.\n            mkdir (bool): If True, create the processing_output_dir directory.\n                Default True.\n\n        Returns:\n            dir (str): A default output directory for the processed results (processed_output_dir\n                in ProcessingTask) based on the following convention:\n                processed_dir / scan_dir / {processing_method}_{paramset_idx}\n                e.g.: sub4/sess1/scan0/suite2p_0\n        \"\"\"\n        acq_software = (scan.Scan &amp; key).fetch1(\"acq_software\")\n        filetypes = dict(\n            ScanImage=\"*.tif\", Scanbox=\"*.sbx\", NIS=\"*.nd2\", PrairieView=\"*.tif\"\n        )\n\n        scan_dir = find_full_path(\n            get_imaging_root_data_dir(),\n            get_image_files(key, filetypes[acq_software])[0],\n        ).parent\n        root_dir = find_root_directory(get_imaging_root_data_dir(), scan_dir)\n\n        method = (\n            (ProcessingParamSet &amp; key).fetch1(\"processing_method\").replace(\".\", \"-\")\n        )\n\n        processed_dir = pathlib.Path(get_processed_root_data_dir())\n        output_dir = (\n            processed_dir\n            / scan_dir.relative_to(root_dir)\n            / f'{method}_{key[\"paramset_idx\"]}'\n        )\n\n        if mkdir:\n            output_dir.mkdir(parents=True, exist_ok=True)\n\n        return output_dir.relative_to(processed_dir) if relative else output_dir\n\n    @classmethod\n    def generate(cls, scan_key, paramset_idx=0):\n\"\"\"Generate a ProcessingTask for a Scan using an parameter ProcessingParamSet\n\n        Generate an entry in the ProcessingTask table for a particular scan using an\n        existing parameter set from the ProcessingParamSet table.\n\n        Args:\n            scan_key (dict): Primary key from Scan table.\n            paramset_idx (int): Unique parameter set ID.\n        \"\"\"\n        key = {**scan_key, \"paramset_idx\": paramset_idx}\n\n        processed_dir = get_processed_root_data_dir()\n        output_dir = cls.infer_output_dir(key, relative=False, mkdir=True)\n\n        method = (ProcessingParamSet &amp; {\"paramset_idx\": paramset_idx}).fetch1(\n            \"processing_method\"\n        )\n\n        try:\n            if method == \"suite2p\":\n                from element_interface import suite2p_loader\n\n                suite2p_loader.Suite2p(output_dir)\n            elif method == \"caiman\":\n                from element_interface import caiman_loader\n\n                caiman_loader.CaImAn(output_dir)\n            elif method == \"extract\":\n                from element_interface import extract_loader\n\n                extract_loader.EXTRACT(output_dir)\n\n            else:\n                raise NotImplementedError(\n                    \"Unknown/unimplemented method: {}\".format(method)\n                )\n        except FileNotFoundError:\n            task_mode = \"trigger\"\n        else:\n            task_mode = \"load\"\n\n        cls.insert1(\n            {\n                **key,\n                \"processing_output_dir\": output_dir.relative_to(\n                    processed_dir\n                ).as_posix(),\n                \"task_mode\": task_mode,\n            }\n        )\n\n    auto_generate_entries = generate\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging/#element_calcium_imaging.imaging.ProcessingTask.infer_output_dir", "title": "<code>infer_output_dir(key, relative=False, mkdir=False)</code>  <code>classmethod</code>", "text": "<p>Infer an output directory for an entry in ProcessingTask table.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>dict</code> <p>Primary key from the ProcessingTask table.</p> required <code>relative</code> <code>bool</code> <p>If True, processing_output_dir is returned relative to imaging_root_dir. Default False.</p> <code>False</code> <code>mkdir</code> <code>bool</code> <p>If True, create the processing_output_dir directory. Default True.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>dir</code> <code>str</code> <p>A default output directory for the processed results (processed_output_dir in ProcessingTask) based on the following convention: processed_dir / scan_dir / {processing_method}_{paramset_idx} e.g.: sub4/sess1/scan0/suite2p_0</p> Source code in <code>element_calcium_imaging/imaging.py</code> <pre><code>@classmethod\ndef infer_output_dir(cls, key, relative=False, mkdir=False):\n\"\"\"Infer an output directory for an entry in ProcessingTask table.\n\n    Args:\n        key (dict): Primary key from the ProcessingTask table.\n        relative (bool): If True, processing_output_dir is returned relative to\n            imaging_root_dir. Default False.\n        mkdir (bool): If True, create the processing_output_dir directory.\n            Default True.\n\n    Returns:\n        dir (str): A default output directory for the processed results (processed_output_dir\n            in ProcessingTask) based on the following convention:\n            processed_dir / scan_dir / {processing_method}_{paramset_idx}\n            e.g.: sub4/sess1/scan0/suite2p_0\n    \"\"\"\n    acq_software = (scan.Scan &amp; key).fetch1(\"acq_software\")\n    filetypes = dict(\n        ScanImage=\"*.tif\", Scanbox=\"*.sbx\", NIS=\"*.nd2\", PrairieView=\"*.tif\"\n    )\n\n    scan_dir = find_full_path(\n        get_imaging_root_data_dir(),\n        get_image_files(key, filetypes[acq_software])[0],\n    ).parent\n    root_dir = find_root_directory(get_imaging_root_data_dir(), scan_dir)\n\n    method = (\n        (ProcessingParamSet &amp; key).fetch1(\"processing_method\").replace(\".\", \"-\")\n    )\n\n    processed_dir = pathlib.Path(get_processed_root_data_dir())\n    output_dir = (\n        processed_dir\n        / scan_dir.relative_to(root_dir)\n        / f'{method}_{key[\"paramset_idx\"]}'\n    )\n\n    if mkdir:\n        output_dir.mkdir(parents=True, exist_ok=True)\n\n    return output_dir.relative_to(processed_dir) if relative else output_dir\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging/#element_calcium_imaging.imaging.ProcessingTask.generate", "title": "<code>generate(scan_key, paramset_idx=0)</code>  <code>classmethod</code>", "text": "<p>Generate a ProcessingTask for a Scan using an parameter ProcessingParamSet</p> <p>Generate an entry in the ProcessingTask table for a particular scan using an existing parameter set from the ProcessingParamSet table.</p> <p>Parameters:</p> Name Type Description Default <code>scan_key</code> <code>dict</code> <p>Primary key from Scan table.</p> required <code>paramset_idx</code> <code>int</code> <p>Unique parameter set ID.</p> <code>0</code> Source code in <code>element_calcium_imaging/imaging.py</code> <pre><code>@classmethod\ndef generate(cls, scan_key, paramset_idx=0):\n\"\"\"Generate a ProcessingTask for a Scan using an parameter ProcessingParamSet\n\n    Generate an entry in the ProcessingTask table for a particular scan using an\n    existing parameter set from the ProcessingParamSet table.\n\n    Args:\n        scan_key (dict): Primary key from Scan table.\n        paramset_idx (int): Unique parameter set ID.\n    \"\"\"\n    key = {**scan_key, \"paramset_idx\": paramset_idx}\n\n    processed_dir = get_processed_root_data_dir()\n    output_dir = cls.infer_output_dir(key, relative=False, mkdir=True)\n\n    method = (ProcessingParamSet &amp; {\"paramset_idx\": paramset_idx}).fetch1(\n        \"processing_method\"\n    )\n\n    try:\n        if method == \"suite2p\":\n            from element_interface import suite2p_loader\n\n            suite2p_loader.Suite2p(output_dir)\n        elif method == \"caiman\":\n            from element_interface import caiman_loader\n\n            caiman_loader.CaImAn(output_dir)\n        elif method == \"extract\":\n            from element_interface import extract_loader\n\n            extract_loader.EXTRACT(output_dir)\n\n        else:\n            raise NotImplementedError(\n                \"Unknown/unimplemented method: {}\".format(method)\n            )\n    except FileNotFoundError:\n        task_mode = \"trigger\"\n    else:\n        task_mode = \"load\"\n\n    cls.insert1(\n        {\n            **key,\n            \"processing_output_dir\": output_dir.relative_to(\n                processed_dir\n            ).as_posix(),\n            \"task_mode\": task_mode,\n        }\n    )\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging/#element_calcium_imaging.imaging.Processing", "title": "<code>Processing</code>", "text": "<p>         Bases: <code>dj.Computed</code></p> <p>Perform the computation of an entry (task) defined in the ProcessingTask table. The computation is performed only on the scans with ScanInfo inserted.</p> <p>Attributes:</p> Name Type Description <code>ProcessingTask</code> <code>foreign key</code> <p>Primary key from ProcessingTask.</p> <code>processing_time</code> <code>datetime</code> <p>Process completion datetime.</p> <code>package_version</code> <code>str</code> <p>Version of the analysis package used in processing the data.</p> Source code in <code>element_calcium_imaging/imaging.py</code> <pre><code>@schema\nclass Processing(dj.Computed):\n\"\"\"Perform the computation of an entry (task) defined in the ProcessingTask table.\n    The computation is performed only on the scans with ScanInfo inserted.\n\n    Attributes:\n        ProcessingTask (foreign key): Primary key from ProcessingTask.\n        processing_time (datetime): Process completion datetime.\n        package_version (str, optional): Version of the analysis package used in\n            processing the data.\n    \"\"\"\n\n    definition = \"\"\"\n    -&gt; ProcessingTask\n    ---\n    processing_time     : datetime  # Time of generation of this set of processed, segmented results\n    package_version=''  : varchar(16)\n    \"\"\"\n\n    # Run processing only on Scan with ScanInfo inserted\n    @property\n    def key_source(self):\n\"\"\"Limit the Processing to Scans that have their metadata ingested to the\n        database.\"\"\"\n\n        return ProcessingTask &amp; scan.ScanInfo\n\n    def make(self, key):\n\"\"\"Execute the calcium imaging analysis defined by the ProcessingTask.\"\"\"\n\n        task_mode, output_dir = (ProcessingTask &amp; key).fetch1(\n            \"task_mode\", \"processing_output_dir\"\n        )\n\n        if not output_dir:\n            output_dir = ProcessingTask.infer_output_dir(key, relative=True, mkdir=True)\n            # update processing_output_dir\n            ProcessingTask.update1(\n                {**key, \"processing_output_dir\": output_dir.as_posix()}\n            )\n        output_dir = find_full_path(get_imaging_root_data_dir(), output_dir).as_posix()\n\n        if task_mode == \"load\":\n            method, imaging_dataset = get_loader_result(key, ProcessingTask)\n            if method == \"suite2p\":\n                if (scan.ScanInfo &amp; key).fetch1(\"nrois\") &gt; 0:\n                    raise NotImplementedError(\n                        \"Suite2p ingestion error - Unable to handle\"\n                        + \" ScanImage multi-ROI scanning mode yet\"\n                    )\n                suite2p_dataset = imaging_dataset\n                key = {**key, \"processing_time\": suite2p_dataset.creation_time}\n            elif method == \"caiman\":\n                caiman_dataset = imaging_dataset\n                key = {**key, \"processing_time\": caiman_dataset.creation_time}\n            elif method == \"extract\":\n                raise NotImplementedError(\n                    \"To use EXTRACT with this DataJoint Element please set `task_mode=trigger`\"\n                )\n            else:\n                raise NotImplementedError(\"Unknown method: {}\".format(method))\n        elif task_mode == \"trigger\":\n            method = (ProcessingParamSet * ProcessingTask &amp; key).fetch1(\n                \"processing_method\"\n            )\n\n            image_files = (scan.ScanInfo.ScanFile &amp; key).fetch(\"file_path\")\n            image_files = [\n                find_full_path(get_imaging_root_data_dir(), image_file)\n                for image_file in image_files\n            ]\n\n            if method == \"suite2p\":\n                import suite2p\n\n                suite2p_params = (ProcessingTask * ProcessingParamSet &amp; key).fetch1(\n                    \"params\"\n                )\n                suite2p_params[\"save_path0\"] = output_dir\n                (\n                    suite2p_params[\"fs\"],\n                    suite2p_params[\"nplanes\"],\n                    suite2p_params[\"nchannels\"],\n                ) = (scan.ScanInfo &amp; key).fetch1(\"fps\", \"ndepths\", \"nchannels\")\n\n                input_format = pathlib.Path(image_files[0]).suffix\n                suite2p_params[\"input_format\"] = input_format[1:]\n\n                suite2p_paths = {\n                    \"data_path\": [image_files[0].parent.as_posix()],\n                    \"tiff_list\": [f.as_posix() for f in image_files],\n                }\n\n                suite2p.run_s2p(ops=suite2p_params, db=suite2p_paths)  # Run suite2p\n\n                _, imaging_dataset = get_loader_result(key, ProcessingTask)\n                suite2p_dataset = imaging_dataset\n                key = {**key, \"processing_time\": suite2p_dataset.creation_time}\n\n            elif method == \"caiman\":\n                from element_interface.caiman_loader import _process_scanimage_tiff\n                from element_interface.run_caiman import run_caiman\n\n                caiman_params = (ProcessingTask * ProcessingParamSet &amp; key).fetch1(\n                    \"params\"\n                )\n                sampling_rate, ndepths, nchannels = (scan.ScanInfo &amp; key).fetch1(\n                    \"fps\", \"ndepths\", \"nchannels\"\n                )\n\n                is3D = bool(ndepths &gt; 1)\n                if is3D:\n                    raise NotImplementedError(\n                        \"Caiman pipeline is not yet capable of analyzing 3D scans.\"\n                    )\n\n                # handle multi-channel tiff image before running CaImAn\n                if nchannels &gt; 1:\n                    channel_idx = caiman_params.get(\"channel_to_process\", 0)\n                    tmp_dir = pathlib.Path(output_dir) / \"channel_separated_tif\"\n                    tmp_dir.mkdir(exist_ok=True)\n                    _process_scanimage_tiff(\n                        [f.as_posix() for f in image_files], output_dir=tmp_dir\n                    )\n                    image_files = tmp_dir.glob(f\"*_chn{channel_idx}.tif\")\n\n                run_caiman(\n                    file_paths=[f.as_posix() for f in image_files],\n                    parameters=caiman_params,\n                    sampling_rate=sampling_rate,\n                    output_dir=output_dir,\n                    is3D=is3D,\n                )\n\n                _, imaging_dataset = get_loader_result(key, ProcessingTask)\n                caiman_dataset = imaging_dataset\n                key[\"processing_time\"] = caiman_dataset.creation_time\n\n            elif method == \"extract\":\n                import suite2p\n                from element_interface.extract_trigger import EXTRACT_trigger\n                from scipy.io import savemat\n\n                # Motion Correction with Suite2p\n                params = (ProcessingTask * ProcessingParamSet &amp; key).fetch1(\"params\")\n\n                params[\"suite2p\"][\"save_path0\"] = output_dir\n                (\n                    params[\"suite2p\"][\"fs\"],\n                    params[\"suite2p\"][\"nplanes\"],\n                    params[\"suite2p\"][\"nchannels\"],\n                ) = (scan.ScanInfo &amp; key).fetch1(\"fps\", \"ndepths\", \"nchannels\")\n\n                input_format = pathlib.Path(image_files[0]).suffix\n                params[\"suite2p\"][\"input_format\"] = input_format[1:]\n\n                suite2p_paths = {\n                    \"data_path\": [image_files[0].parent.as_posix()],\n                    \"tiff_list\": [f.as_posix() for f in image_files],\n                }\n\n                suite2p.run_s2p(ops=params[\"suite2p\"], db=suite2p_paths)\n\n                # Convert data.bin to registered_scans.mat\n                scanfile_fullpath = pathlib.Path(output_dir) / \"suite2p/plane0/data.bin\"\n\n                data_shape = (scan.ScanInfo * scan.ScanInfo.Field &amp; key).fetch1(\n                    \"nframes\", \"px_height\", \"px_width\"\n                )\n                data = np.memmap(scanfile_fullpath, shape=data_shape, dtype=np.int16)\n\n                scan_matlab_fullpath = scanfile_fullpath.parent / \"registered_scan.mat\"\n\n                # Save the motion corrected movie (data.bin) in a .mat file\n                savemat(\n                    scan_matlab_fullpath,\n                    {\"M\": np.transpose(data, axes=[1, 2, 0])},\n                )\n\n                # Execute EXTRACT\n\n                ex = EXTRACT_trigger(\n                    scan_matlab_fullpath, params[\"extract\"], output_dir\n                )\n                ex.run()\n\n                _, extract_dataset = get_loader_result(key, ProcessingTask)\n                key[\"processing_time\"] = extract_dataset.creation_time\n\n        else:\n            raise ValueError(f\"Unknown task mode: {task_mode}\")\n\n        self.insert1({**key, \"package_version\": \"\"})\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging/#element_calcium_imaging.imaging.Processing.key_source", "title": "<code>key_source</code>  <code>property</code>", "text": "<p>Limit the Processing to Scans that have their metadata ingested to the database.</p>"}, {"location": "api/element_calcium_imaging/imaging/#element_calcium_imaging.imaging.Processing.make", "title": "<code>make(key)</code>", "text": "<p>Execute the calcium imaging analysis defined by the ProcessingTask.</p> Source code in <code>element_calcium_imaging/imaging.py</code> <pre><code>def make(self, key):\n\"\"\"Execute the calcium imaging analysis defined by the ProcessingTask.\"\"\"\n\n    task_mode, output_dir = (ProcessingTask &amp; key).fetch1(\n        \"task_mode\", \"processing_output_dir\"\n    )\n\n    if not output_dir:\n        output_dir = ProcessingTask.infer_output_dir(key, relative=True, mkdir=True)\n        # update processing_output_dir\n        ProcessingTask.update1(\n            {**key, \"processing_output_dir\": output_dir.as_posix()}\n        )\n    output_dir = find_full_path(get_imaging_root_data_dir(), output_dir).as_posix()\n\n    if task_mode == \"load\":\n        method, imaging_dataset = get_loader_result(key, ProcessingTask)\n        if method == \"suite2p\":\n            if (scan.ScanInfo &amp; key).fetch1(\"nrois\") &gt; 0:\n                raise NotImplementedError(\n                    \"Suite2p ingestion error - Unable to handle\"\n                    + \" ScanImage multi-ROI scanning mode yet\"\n                )\n            suite2p_dataset = imaging_dataset\n            key = {**key, \"processing_time\": suite2p_dataset.creation_time}\n        elif method == \"caiman\":\n            caiman_dataset = imaging_dataset\n            key = {**key, \"processing_time\": caiman_dataset.creation_time}\n        elif method == \"extract\":\n            raise NotImplementedError(\n                \"To use EXTRACT with this DataJoint Element please set `task_mode=trigger`\"\n            )\n        else:\n            raise NotImplementedError(\"Unknown method: {}\".format(method))\n    elif task_mode == \"trigger\":\n        method = (ProcessingParamSet * ProcessingTask &amp; key).fetch1(\n            \"processing_method\"\n        )\n\n        image_files = (scan.ScanInfo.ScanFile &amp; key).fetch(\"file_path\")\n        image_files = [\n            find_full_path(get_imaging_root_data_dir(), image_file)\n            for image_file in image_files\n        ]\n\n        if method == \"suite2p\":\n            import suite2p\n\n            suite2p_params = (ProcessingTask * ProcessingParamSet &amp; key).fetch1(\n                \"params\"\n            )\n            suite2p_params[\"save_path0\"] = output_dir\n            (\n                suite2p_params[\"fs\"],\n                suite2p_params[\"nplanes\"],\n                suite2p_params[\"nchannels\"],\n            ) = (scan.ScanInfo &amp; key).fetch1(\"fps\", \"ndepths\", \"nchannels\")\n\n            input_format = pathlib.Path(image_files[0]).suffix\n            suite2p_params[\"input_format\"] = input_format[1:]\n\n            suite2p_paths = {\n                \"data_path\": [image_files[0].parent.as_posix()],\n                \"tiff_list\": [f.as_posix() for f in image_files],\n            }\n\n            suite2p.run_s2p(ops=suite2p_params, db=suite2p_paths)  # Run suite2p\n\n            _, imaging_dataset = get_loader_result(key, ProcessingTask)\n            suite2p_dataset = imaging_dataset\n            key = {**key, \"processing_time\": suite2p_dataset.creation_time}\n\n        elif method == \"caiman\":\n            from element_interface.caiman_loader import _process_scanimage_tiff\n            from element_interface.run_caiman import run_caiman\n\n            caiman_params = (ProcessingTask * ProcessingParamSet &amp; key).fetch1(\n                \"params\"\n            )\n            sampling_rate, ndepths, nchannels = (scan.ScanInfo &amp; key).fetch1(\n                \"fps\", \"ndepths\", \"nchannels\"\n            )\n\n            is3D = bool(ndepths &gt; 1)\n            if is3D:\n                raise NotImplementedError(\n                    \"Caiman pipeline is not yet capable of analyzing 3D scans.\"\n                )\n\n            # handle multi-channel tiff image before running CaImAn\n            if nchannels &gt; 1:\n                channel_idx = caiman_params.get(\"channel_to_process\", 0)\n                tmp_dir = pathlib.Path(output_dir) / \"channel_separated_tif\"\n                tmp_dir.mkdir(exist_ok=True)\n                _process_scanimage_tiff(\n                    [f.as_posix() for f in image_files], output_dir=tmp_dir\n                )\n                image_files = tmp_dir.glob(f\"*_chn{channel_idx}.tif\")\n\n            run_caiman(\n                file_paths=[f.as_posix() for f in image_files],\n                parameters=caiman_params,\n                sampling_rate=sampling_rate,\n                output_dir=output_dir,\n                is3D=is3D,\n            )\n\n            _, imaging_dataset = get_loader_result(key, ProcessingTask)\n            caiman_dataset = imaging_dataset\n            key[\"processing_time\"] = caiman_dataset.creation_time\n\n        elif method == \"extract\":\n            import suite2p\n            from element_interface.extract_trigger import EXTRACT_trigger\n            from scipy.io import savemat\n\n            # Motion Correction with Suite2p\n            params = (ProcessingTask * ProcessingParamSet &amp; key).fetch1(\"params\")\n\n            params[\"suite2p\"][\"save_path0\"] = output_dir\n            (\n                params[\"suite2p\"][\"fs\"],\n                params[\"suite2p\"][\"nplanes\"],\n                params[\"suite2p\"][\"nchannels\"],\n            ) = (scan.ScanInfo &amp; key).fetch1(\"fps\", \"ndepths\", \"nchannels\")\n\n            input_format = pathlib.Path(image_files[0]).suffix\n            params[\"suite2p\"][\"input_format\"] = input_format[1:]\n\n            suite2p_paths = {\n                \"data_path\": [image_files[0].parent.as_posix()],\n                \"tiff_list\": [f.as_posix() for f in image_files],\n            }\n\n            suite2p.run_s2p(ops=params[\"suite2p\"], db=suite2p_paths)\n\n            # Convert data.bin to registered_scans.mat\n            scanfile_fullpath = pathlib.Path(output_dir) / \"suite2p/plane0/data.bin\"\n\n            data_shape = (scan.ScanInfo * scan.ScanInfo.Field &amp; key).fetch1(\n                \"nframes\", \"px_height\", \"px_width\"\n            )\n            data = np.memmap(scanfile_fullpath, shape=data_shape, dtype=np.int16)\n\n            scan_matlab_fullpath = scanfile_fullpath.parent / \"registered_scan.mat\"\n\n            # Save the motion corrected movie (data.bin) in a .mat file\n            savemat(\n                scan_matlab_fullpath,\n                {\"M\": np.transpose(data, axes=[1, 2, 0])},\n            )\n\n            # Execute EXTRACT\n\n            ex = EXTRACT_trigger(\n                scan_matlab_fullpath, params[\"extract\"], output_dir\n            )\n            ex.run()\n\n            _, extract_dataset = get_loader_result(key, ProcessingTask)\n            key[\"processing_time\"] = extract_dataset.creation_time\n\n    else:\n        raise ValueError(f\"Unknown task mode: {task_mode}\")\n\n    self.insert1({**key, \"package_version\": \"\"})\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging/#element_calcium_imaging.imaging.Curation", "title": "<code>Curation</code>", "text": "<p>         Bases: <code>dj.Manual</code></p> <p>Curated results</p> <p>If no curation is applied, the curation_output_dir can be set to the value of processing_output_dir.</p> <p>Attributes:</p> Name Type Description <code>Processing</code> <code>foreign key</code> <p>Primary key from Processing.</p> <code>curation_id</code> <code>int</code> <p>Unique curation ID.</p> <code>curation_time</code> <code>datetime</code> <p>Time of generation of this set of curated results.</p> <code>curation_output_dir</code> <code>str</code> <p>Output directory of the curated results, relative to root data directory.</p> <code>manual_curation</code> <code>bool</code> <p>If True, manual curation has been performed on this result.</p> <code>curation_note</code> <code>str</code> <p>Notes about the curation task.</p> Source code in <code>element_calcium_imaging/imaging.py</code> <pre><code>@schema\nclass Curation(dj.Manual):\n\"\"\"Curated results\n\n    If no curation is applied, the curation_output_dir can be set to\n    the value of processing_output_dir.\n\n    Attributes:\n        Processing (foreign key): Primary key from Processing.\n        curation_id (int): Unique curation ID.\n        curation_time (datetime): Time of generation of this set of curated results.\n        curation_output_dir (str): Output directory of the curated results, relative to\n            root data directory.\n        manual_curation (bool): If True, manual curation has been performed on this\n            result.\n        curation_note (str, optional): Notes about the curation task.\n    \"\"\"\n\n    definition = \"\"\"# Curation(s) results\n    -&gt; Processing\n    curation_id: int\n    ---\n    curation_time: datetime  # Time of generation of this set of curated results\n    curation_output_dir: varchar(255)  # Output directory of the curated results, relative to root data directory\n    manual_curation: bool  # Has manual curation been performed on this result?\n    curation_note='': varchar(2000)\n    \"\"\"\n\n    def create1_from_processing_task(self, key, is_curated=False, curation_note=\"\"):\n\"\"\"Create a Curation entry for a given ProcessingTask key.\n\n        Args:\n            key (dict): Primary key set of an entry in the ProcessingTask table.\n            is_curated (bool): When True, indicates a manual curation.\n            curation_note (str): User's note on the specifics of the curation.\n        \"\"\"\n        if key not in Processing():\n            raise ValueError(\n                f\"No corresponding entry in Processing available for: {key};\"\n                f\"Please run `Processing.populate(key)`\"\n            )\n\n        output_dir = (ProcessingTask &amp; key).fetch1(\"processing_output_dir\")\n        method, imaging_dataset = get_loader_result(key, ProcessingTask)\n\n        if method == \"suite2p\":\n            suite2p_dataset = imaging_dataset\n            curation_time = suite2p_dataset.creation_time\n        elif method == \"caiman\":\n            caiman_dataset = imaging_dataset\n            curation_time = caiman_dataset.creation_time\n        elif method == \"extract\":\n            extract_dataset = imaging_dataset\n            curation_time = extract_dataset.creation_time\n        else:\n            raise NotImplementedError(\"Unknown method: {}\".format(method))\n\n        # Synthesize curation_id\n        curation_id = (\n            dj.U().aggr(self &amp; key, n=\"ifnull(max(curation_id)+1,1)\").fetch1(\"n\")\n        )\n        self.insert1(\n            {\n                **key,\n                \"curation_id\": curation_id,\n                \"curation_time\": curation_time,\n                \"curation_output_dir\": output_dir,\n                \"manual_curation\": is_curated,\n                \"curation_note\": curation_note,\n            }\n        )\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging/#element_calcium_imaging.imaging.Curation.create1_from_processing_task", "title": "<code>create1_from_processing_task(key, is_curated=False, curation_note='')</code>", "text": "<p>Create a Curation entry for a given ProcessingTask key.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>dict</code> <p>Primary key set of an entry in the ProcessingTask table.</p> required <code>is_curated</code> <code>bool</code> <p>When True, indicates a manual curation.</p> <code>False</code> <code>curation_note</code> <code>str</code> <p>User's note on the specifics of the curation.</p> <code>''</code> Source code in <code>element_calcium_imaging/imaging.py</code> <pre><code>def create1_from_processing_task(self, key, is_curated=False, curation_note=\"\"):\n\"\"\"Create a Curation entry for a given ProcessingTask key.\n\n    Args:\n        key (dict): Primary key set of an entry in the ProcessingTask table.\n        is_curated (bool): When True, indicates a manual curation.\n        curation_note (str): User's note on the specifics of the curation.\n    \"\"\"\n    if key not in Processing():\n        raise ValueError(\n            f\"No corresponding entry in Processing available for: {key};\"\n            f\"Please run `Processing.populate(key)`\"\n        )\n\n    output_dir = (ProcessingTask &amp; key).fetch1(\"processing_output_dir\")\n    method, imaging_dataset = get_loader_result(key, ProcessingTask)\n\n    if method == \"suite2p\":\n        suite2p_dataset = imaging_dataset\n        curation_time = suite2p_dataset.creation_time\n    elif method == \"caiman\":\n        caiman_dataset = imaging_dataset\n        curation_time = caiman_dataset.creation_time\n    elif method == \"extract\":\n        extract_dataset = imaging_dataset\n        curation_time = extract_dataset.creation_time\n    else:\n        raise NotImplementedError(\"Unknown method: {}\".format(method))\n\n    # Synthesize curation_id\n    curation_id = (\n        dj.U().aggr(self &amp; key, n=\"ifnull(max(curation_id)+1,1)\").fetch1(\"n\")\n    )\n    self.insert1(\n        {\n            **key,\n            \"curation_id\": curation_id,\n            \"curation_time\": curation_time,\n            \"curation_output_dir\": output_dir,\n            \"manual_curation\": is_curated,\n            \"curation_note\": curation_note,\n        }\n    )\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging/#element_calcium_imaging.imaging.MotionCorrection", "title": "<code>MotionCorrection</code>", "text": "<p>         Bases: <code>dj.Imported</code></p> <p>Results of motion correction shifts performed on the imaging data.</p> <p>Attributes:</p> Name Type Description <code>Curation</code> <code>foreign key</code> <p>Primary key from Curation.</p> <code>scan.Channel.proj(motion_correct_channel='channel')</code> <code>int</code> <p>Channel used for motion correction in this processing task.</p> Source code in <code>element_calcium_imaging/imaging.py</code> <pre><code>@schema\nclass MotionCorrection(dj.Imported):\n\"\"\"Results of motion correction shifts performed on the imaging data.\n\n    Attributes:\n        Curation (foreign key): Primary key from Curation.\n        scan.Channel.proj(motion_correct_channel='channel') (int): Channel used for\n            motion correction in this processing task.\n    \"\"\"\n\n    definition = \"\"\"# Results of motion correction\n    -&gt; Curation\n    ---\n    -&gt; scan.Channel.proj(motion_correct_channel='channel') # channel used for motion correction in this processing task\n    \"\"\"\n\n    class RigidMotionCorrection(dj.Part):\n\"\"\"Details of rigid motion correction performed on the imaging data.\n\n        Attributes:\n            MotionCorrection (foreign key): Primary key from MotionCorrection.\n            outlier_frames (longblob): Mask with true for frames with outlier shifts\n                (already corrected).\n            y_shifts (longblob): y motion correction shifts (pixels).\n            x_shifts (longblob): x motion correction shifts (pixels).\n            z_shifts (longblob, optional): z motion correction shifts (z-drift, pixels).\n            y_std (float): standard deviation of y shifts across all frames (pixels).\n            x_std (float): standard deviation of x shifts across all frames (pixels).\n            z_std (float, optional): standard deviation of z shifts across all frames\n                (pixels).\n        \"\"\"\n\n        definition = \"\"\"# Details of rigid motion correction performed on the imaging data\n        -&gt; master\n        ---\n        outlier_frames=null : longblob  # mask with true for frames with outlier shifts (already corrected)\n        y_shifts            : longblob  # (pixels) y motion correction shifts\n        x_shifts            : longblob  # (pixels) x motion correction shifts\n        z_shifts=null       : longblob  # (pixels) z motion correction shifts (z-drift)\n        y_std               : float     # (pixels) standard deviation of y shifts across all frames\n        x_std               : float     # (pixels) standard deviation of x shifts across all frames\n        z_std=null          : float     # (pixels) standard deviation of z shifts across all frames\n        \"\"\"\n\n    class NonRigidMotionCorrection(dj.Part):\n\"\"\"Piece-wise rigid motion correction - tile the FOV into multiple 3D\n        blocks/patches.\n\n        Attributes:\n            MotionCorrection (foreign key): Primary key from MotionCorrection.\n            outlier_frames (longblob, null): Mask with true for frames with outlier\n                shifts (already corrected).\n            block_height (int): Block height in pixels.\n            block_width (int): Block width in pixels.\n            block_depth (int): Block depth in pixels.\n            block_count_y (int): Number of blocks tiled in the y direction.\n            block_count_x (int): Number of blocks tiled in the x direction.\n            block_count_z (int): Number of blocks tiled in the z direction.\n        \"\"\"\n\n        definition = \"\"\"# Details of non-rigid motion correction performed on the imaging data\n        -&gt; master\n        ---\n        outlier_frames=null : longblob # mask with true for frames with outlier shifts (already corrected)\n        block_height        : int      # (pixels)\n        block_width         : int      # (pixels)\n        block_depth         : int      # (pixels)\n        block_count_y       : int      # number of blocks tiled in the y direction\n        block_count_x       : int      # number of blocks tiled in the x direction\n        block_count_z       : int      # number of blocks tiled in the z direction\n        \"\"\"\n\n    class Block(dj.Part):\n\"\"\"FOV-tiled blocks used for non-rigid motion correction.\n\n        Attributes:\n            NonRigidMotionCorrection (foreign key): Primary key from\n                NonRigidMotionCorrection.\n            block_id (int): Unique block ID.\n            block_y (longblob): y_start and y_end in pixels for this block\n            block_x (longblob): x_start and x_end in pixels for this block\n            block_z (longblob): z_start and z_end in pixels for this block\n            y_shifts (longblob): y motion correction shifts for every frame in pixels\n            x_shifts (longblob): x motion correction shifts for every frame in pixels\n            z_shift=null (longblob, optional): x motion correction shifts for every frame\n                in pixels\n            y_std (float): standard deviation of y shifts across all frames in pixels\n            x_std (float): standard deviation of x shifts across all frames in pixels\n            z_std=null (float, optional): standard deviation of z shifts across all frames\n                in pixels\n        \"\"\"\n\n        definition = \"\"\"# FOV-tiled blocks used for non-rigid motion correction\n        -&gt; master.NonRigidMotionCorrection\n        block_id        : int\n        ---\n        block_y         : longblob  # (y_start, y_end) in pixel of this block\n        block_x         : longblob  # (x_start, x_end) in pixel of this block\n        block_z         : longblob  # (z_start, z_end) in pixel of this block\n        y_shifts        : longblob  # (pixels) y motion correction shifts for every frame\n        x_shifts        : longblob  # (pixels) x motion correction shifts for every frame\n        z_shifts=null   : longblob  # (pixels) x motion correction shifts for every frame\n        y_std           : float     # (pixels) standard deviation of y shifts across all frames\n        x_std           : float     # (pixels) standard deviation of x shifts across all frames\n        z_std=null      : float     # (pixels) standard deviation of z shifts across all frames\n        \"\"\"\n\n    class Summary(dj.Part):\n\"\"\"Summary images for each field and channel after corrections.\n\n        Attributes:\n            MotionCorrection (foreign key): Primary key from MotionCorrection.\n            scan.ScanInfo.Field (foreign key): Primary key from scan.ScanInfo.Field.\n            ref_image (longblob): Image used as alignment template.\n            average_image (longblob): Mean of registered frames.\n            correlation_image (longblob, optional): Correlation map (computed during\n                cell detection).\n            max_proj_image (longblob, optional): Max of registered frames.\n        \"\"\"\n\n        definition = \"\"\"# Summary images for each field and channel after corrections\n        -&gt; master\n        -&gt; scan.ScanInfo.Field\n        ---\n        ref_image               : longblob  # image used as alignment template\n        average_image           : longblob  # mean of registered frames\n        correlation_image=null  : longblob  # correlation map (computed during cell detection)\n        max_proj_image=null     : longblob  # max of registered frames\n        \"\"\"\n\n    def make(self, key):\n\"\"\"Populate MotionCorrection with results parsed from analysis outputs\"\"\"\n\n        method, imaging_dataset = get_loader_result(key, Curation)\n\n        field_keys, _ = (scan.ScanInfo.Field &amp; key).fetch(\n            \"KEY\", \"field_z\", order_by=\"field_z\"\n        )\n\n        if method in [\"suite2p\", \"extract\"]:\n            suite2p_dataset = imaging_dataset\n\n            motion_correct_channel = suite2p_dataset.planes[0].alignment_channel\n\n            # ---- iterate through all s2p plane outputs ----\n            rigid_correction, nonrigid_correction, nonrigid_blocks = {}, {}, {}\n            summary_images = []\n            for idx, (plane, s2p) in enumerate(suite2p_dataset.planes.items()):\n                # -- rigid motion correction --\n                if idx == 0:\n                    rigid_correction = {\n                        **key,\n                        \"y_shifts\": s2p.ops[\"yoff\"],\n                        \"x_shifts\": s2p.ops[\"xoff\"],\n                        \"z_shifts\": np.full_like(s2p.ops[\"xoff\"], 0),\n                        \"y_std\": np.nanstd(s2p.ops[\"yoff\"]),\n                        \"x_std\": np.nanstd(s2p.ops[\"xoff\"]),\n                        \"z_std\": np.nan,\n                        \"outlier_frames\": s2p.ops[\"badframes\"],\n                    }\n                else:\n                    rigid_correction[\"y_shifts\"] = np.vstack(\n                        [rigid_correction[\"y_shifts\"], s2p.ops[\"yoff\"]]\n                    )\n                    rigid_correction[\"y_std\"] = np.nanstd(\n                        rigid_correction[\"y_shifts\"].flatten()\n                    )\n                    rigid_correction[\"x_shifts\"] = np.vstack(\n                        [rigid_correction[\"x_shifts\"], s2p.ops[\"xoff\"]]\n                    )\n                    rigid_correction[\"x_std\"] = np.nanstd(\n                        rigid_correction[\"x_shifts\"].flatten()\n                    )\n                    rigid_correction[\"outlier_frames\"] = np.logical_or(\n                        rigid_correction[\"outlier_frames\"], s2p.ops[\"badframes\"]\n                    )\n                # -- non-rigid motion correction --\n                if s2p.ops[\"nonrigid\"]:\n                    if idx == 0:\n                        nonrigid_correction = {\n                            **key,\n                            \"block_height\": s2p.ops[\"block_size\"][0],\n                            \"block_width\": s2p.ops[\"block_size\"][1],\n                            \"block_depth\": 1,\n                            \"block_count_y\": s2p.ops[\"nblocks\"][0],\n                            \"block_count_x\": s2p.ops[\"nblocks\"][1],\n                            \"block_count_z\": len(suite2p_dataset.planes),\n                            \"outlier_frames\": s2p.ops[\"badframes\"],\n                        }\n                    else:\n                        nonrigid_correction[\"outlier_frames\"] = np.logical_or(\n                            nonrigid_correction[\"outlier_frames\"],\n                            s2p.ops[\"badframes\"],\n                        )\n                    for b_id, (b_y, b_x, bshift_y, bshift_x) in enumerate(\n                        zip(\n                            s2p.ops[\"xblock\"],\n                            s2p.ops[\"yblock\"],\n                            s2p.ops[\"yoff1\"].T,\n                            s2p.ops[\"xoff1\"].T,\n                        )\n                    ):\n                        if b_id in nonrigid_blocks:\n                            nonrigid_blocks[b_id][\"y_shifts\"] = np.vstack(\n                                [nonrigid_blocks[b_id][\"y_shifts\"], bshift_y]\n                            )\n                            nonrigid_blocks[b_id][\"y_std\"] = np.nanstd(\n                                nonrigid_blocks[b_id][\"y_shifts\"].flatten()\n                            )\n                            nonrigid_blocks[b_id][\"x_shifts\"] = np.vstack(\n                                [nonrigid_blocks[b_id][\"x_shifts\"], bshift_x]\n                            )\n                            nonrigid_blocks[b_id][\"x_std\"] = np.nanstd(\n                                nonrigid_blocks[b_id][\"x_shifts\"].flatten()\n                            )\n                        else:\n                            nonrigid_blocks[b_id] = {\n                                **key,\n                                \"block_id\": b_id,\n                                \"block_y\": b_y,\n                                \"block_x\": b_x,\n                                \"block_z\": np.full_like(b_x, plane),\n                                \"y_shifts\": bshift_y,\n                                \"x_shifts\": bshift_x,\n                                \"z_shifts\": np.full(\n                                    (\n                                        len(suite2p_dataset.planes),\n                                        len(bshift_x),\n                                    ),\n                                    0,\n                                ),\n                                \"y_std\": np.nanstd(bshift_y),\n                                \"x_std\": np.nanstd(bshift_x),\n                                \"z_std\": np.nan,\n                            }\n\n                # -- summary images --\n                motion_correction_key = (\n                    scan.ScanInfo.Field * Curation &amp; key &amp; field_keys[plane]\n                ).fetch1(\"KEY\")\n                summary_images.append(\n                    {\n                        **motion_correction_key,\n                        \"ref_image\": s2p.ref_image,\n                        \"average_image\": s2p.mean_image,\n                        \"correlation_image\": s2p.correlation_map,\n                        \"max_proj_image\": s2p.max_proj_image,\n                    }\n                )\n\n            self.insert1({**key, \"motion_correct_channel\": motion_correct_channel})\n            if rigid_correction:\n                self.RigidMotionCorrection.insert1(rigid_correction)\n            if nonrigid_correction:\n                self.NonRigidMotionCorrection.insert1(nonrigid_correction)\n                self.Block.insert(nonrigid_blocks.values())\n            self.Summary.insert(summary_images)\n        elif method == \"caiman\":\n            caiman_dataset = imaging_dataset\n\n            self.insert1(\n                {\n                    **key,\n                    \"motion_correct_channel\": caiman_dataset.alignment_channel,\n                }\n            )\n\n            is3D = caiman_dataset.params.motion[\"is3D\"]\n            if not caiman_dataset.params.motion[\"pw_rigid\"]:\n                # -- rigid motion correction --\n                rigid_correction = {\n                    **key,\n                    \"x_shifts\": caiman_dataset.motion_correction[\"shifts_rig\"][:, 0],\n                    \"y_shifts\": caiman_dataset.motion_correction[\"shifts_rig\"][:, 1],\n                    \"z_shifts\": (\n                        caiman_dataset.motion_correction[\"shifts_rig\"][:, 2]\n                        if is3D\n                        else np.full_like(\n                            caiman_dataset.motion_correction[\"shifts_rig\"][:, 0],\n                            0,\n                        )\n                    ),\n                    \"x_std\": np.nanstd(\n                        caiman_dataset.motion_correction[\"shifts_rig\"][:, 0]\n                    ),\n                    \"y_std\": np.nanstd(\n                        caiman_dataset.motion_correction[\"shifts_rig\"][:, 1]\n                    ),\n                    \"z_std\": (\n                        np.nanstd(caiman_dataset.motion_correction[\"shifts_rig\"][:, 2])\n                        if is3D\n                        else np.nan\n                    ),\n                    \"outlier_frames\": None,\n                }\n\n                self.RigidMotionCorrection.insert1(rigid_correction)\n            else:\n                # -- non-rigid motion correction --\n                nonrigid_correction = {\n                    **key,\n                    \"block_height\": (\n                        caiman_dataset.params.motion[\"strides\"][0]\n                        + caiman_dataset.params.motion[\"overlaps\"][0]\n                    ),\n                    \"block_width\": (\n                        caiman_dataset.params.motion[\"strides\"][1]\n                        + caiman_dataset.params.motion[\"overlaps\"][1]\n                    ),\n                    \"block_depth\": (\n                        caiman_dataset.params.motion[\"strides\"][2]\n                        + caiman_dataset.params.motion[\"overlaps\"][2]\n                        if is3D\n                        else 1\n                    ),\n                    \"block_count_x\": len(\n                        set(caiman_dataset.motion_correction[\"coord_shifts_els\"][:, 0])\n                    ),\n                    \"block_count_y\": len(\n                        set(caiman_dataset.motion_correction[\"coord_shifts_els\"][:, 2])\n                    ),\n                    \"block_count_z\": (\n                        len(\n                            set(\n                                caiman_dataset.motion_correction[\"coord_shifts_els\"][\n                                    :, 4\n                                ]\n                            )\n                        )\n                        if is3D\n                        else 1\n                    ),\n                    \"outlier_frames\": None,\n                }\n\n                nonrigid_blocks = []\n                for b_id in range(\n                    len(caiman_dataset.motion_correction[\"x_shifts_els\"][0, :])\n                ):\n                    nonrigid_blocks.append(\n                        {\n                            **key,\n                            \"block_id\": b_id,\n                            \"block_x\": np.arange(\n                                *caiman_dataset.motion_correction[\"coord_shifts_els\"][\n                                    b_id, 0:2\n                                ]\n                            ),\n                            \"block_y\": np.arange(\n                                *caiman_dataset.motion_correction[\"coord_shifts_els\"][\n                                    b_id, 2:4\n                                ]\n                            ),\n                            \"block_z\": (\n                                np.arange(\n                                    *caiman_dataset.motion_correction[\n                                        \"coord_shifts_els\"\n                                    ][b_id, 4:6]\n                                )\n                                if is3D\n                                else np.full_like(\n                                    np.arange(\n                                        *caiman_dataset.motion_correction[\n                                            \"coord_shifts_els\"\n                                        ][b_id, 0:2]\n                                    ),\n                                    0,\n                                )\n                            ),\n                            \"x_shifts\": caiman_dataset.motion_correction[\n                                \"x_shifts_els\"\n                            ][:, b_id],\n                            \"y_shifts\": caiman_dataset.motion_correction[\n                                \"y_shifts_els\"\n                            ][:, b_id],\n                            \"z_shifts\": (\n                                caiman_dataset.motion_correction[\"z_shifts_els\"][\n                                    :, b_id\n                                ]\n                                if is3D\n                                else np.full_like(\n                                    caiman_dataset.motion_correction[\"x_shifts_els\"][\n                                        :, b_id\n                                    ],\n                                    0,\n                                )\n                            ),\n                            \"x_std\": np.nanstd(\n                                caiman_dataset.motion_correction[\"x_shifts_els\"][\n                                    :, b_id\n                                ]\n                            ),\n                            \"y_std\": np.nanstd(\n                                caiman_dataset.motion_correction[\"y_shifts_els\"][\n                                    :, b_id\n                                ]\n                            ),\n                            \"z_std\": (\n                                np.nanstd(\n                                    caiman_dataset.motion_correction[\"z_shifts_els\"][\n                                        :, b_id\n                                    ]\n                                )\n                                if is3D\n                                else np.nan\n                            ),\n                        }\n                    )\n\n                self.NonRigidMotionCorrection.insert1(nonrigid_correction)\n                self.Block.insert(nonrigid_blocks)\n\n            # -- summary images --\n            summary_images = [\n                {\n                    **key,\n                    **fkey,\n                    \"ref_image\": ref_image,\n                    \"average_image\": ave_img,\n                    \"correlation_image\": corr_img,\n                    \"max_proj_image\": max_img,\n                }\n                for fkey, ref_image, ave_img, corr_img, max_img in zip(\n                    field_keys,\n                    caiman_dataset.motion_correction[\"reference_image\"].transpose(\n                        2, 0, 1\n                    )\n                    if is3D\n                    else caiman_dataset.motion_correction[\"reference_image\"][...][\n                        np.newaxis, ...\n                    ],\n                    caiman_dataset.motion_correction[\"average_image\"].transpose(2, 0, 1)\n                    if is3D\n                    else caiman_dataset.motion_correction[\"average_image\"][...][\n                        np.newaxis, ...\n                    ],\n                    caiman_dataset.motion_correction[\"correlation_image\"].transpose(\n                        2, 0, 1\n                    )\n                    if is3D\n                    else caiman_dataset.motion_correction[\"correlation_image\"][...][\n                        np.newaxis, ...\n                    ],\n                    caiman_dataset.motion_correction[\"max_image\"].transpose(2, 0, 1)\n                    if is3D\n                    else caiman_dataset.motion_correction[\"max_image\"][...][\n                        np.newaxis, ...\n                    ],\n                )\n            ]\n            self.Summary.insert(summary_images)\n        else:\n            raise NotImplementedError(\"Unknown/unimplemented method: {}\".format(method))\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging/#element_calcium_imaging.imaging.MotionCorrection.RigidMotionCorrection", "title": "<code>RigidMotionCorrection</code>", "text": "<p>         Bases: <code>dj.Part</code></p> <p>Details of rigid motion correction performed on the imaging data.</p> <p>Attributes:</p> Name Type Description <code>MotionCorrection</code> <code>foreign key</code> <p>Primary key from MotionCorrection.</p> <code>outlier_frames</code> <code>longblob</code> <p>Mask with true for frames with outlier shifts (already corrected).</p> <code>y_shifts</code> <code>longblob</code> <p>y motion correction shifts (pixels).</p> <code>x_shifts</code> <code>longblob</code> <p>x motion correction shifts (pixels).</p> <code>z_shifts</code> <code>longblob</code> <p>z motion correction shifts (z-drift, pixels).</p> <code>y_std</code> <code>float</code> <p>standard deviation of y shifts across all frames (pixels).</p> <code>x_std</code> <code>float</code> <p>standard deviation of x shifts across all frames (pixels).</p> <code>z_std</code> <code>float</code> <p>standard deviation of z shifts across all frames (pixels).</p> Source code in <code>element_calcium_imaging/imaging.py</code> <pre><code>class RigidMotionCorrection(dj.Part):\n\"\"\"Details of rigid motion correction performed on the imaging data.\n\n    Attributes:\n        MotionCorrection (foreign key): Primary key from MotionCorrection.\n        outlier_frames (longblob): Mask with true for frames with outlier shifts\n            (already corrected).\n        y_shifts (longblob): y motion correction shifts (pixels).\n        x_shifts (longblob): x motion correction shifts (pixels).\n        z_shifts (longblob, optional): z motion correction shifts (z-drift, pixels).\n        y_std (float): standard deviation of y shifts across all frames (pixels).\n        x_std (float): standard deviation of x shifts across all frames (pixels).\n        z_std (float, optional): standard deviation of z shifts across all frames\n            (pixels).\n    \"\"\"\n\n    definition = \"\"\"# Details of rigid motion correction performed on the imaging data\n    -&gt; master\n    ---\n    outlier_frames=null : longblob  # mask with true for frames with outlier shifts (already corrected)\n    y_shifts            : longblob  # (pixels) y motion correction shifts\n    x_shifts            : longblob  # (pixels) x motion correction shifts\n    z_shifts=null       : longblob  # (pixels) z motion correction shifts (z-drift)\n    y_std               : float     # (pixels) standard deviation of y shifts across all frames\n    x_std               : float     # (pixels) standard deviation of x shifts across all frames\n    z_std=null          : float     # (pixels) standard deviation of z shifts across all frames\n    \"\"\"\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging/#element_calcium_imaging.imaging.MotionCorrection.NonRigidMotionCorrection", "title": "<code>NonRigidMotionCorrection</code>", "text": "<p>         Bases: <code>dj.Part</code></p> <p>Piece-wise rigid motion correction - tile the FOV into multiple 3D blocks/patches.</p> <p>Attributes:</p> Name Type Description <code>MotionCorrection</code> <code>foreign key</code> <p>Primary key from MotionCorrection.</p> <code>outlier_frames</code> <code>longblob, null</code> <p>Mask with true for frames with outlier shifts (already corrected).</p> <code>block_height</code> <code>int</code> <p>Block height in pixels.</p> <code>block_width</code> <code>int</code> <p>Block width in pixels.</p> <code>block_depth</code> <code>int</code> <p>Block depth in pixels.</p> <code>block_count_y</code> <code>int</code> <p>Number of blocks tiled in the y direction.</p> <code>block_count_x</code> <code>int</code> <p>Number of blocks tiled in the x direction.</p> <code>block_count_z</code> <code>int</code> <p>Number of blocks tiled in the z direction.</p> Source code in <code>element_calcium_imaging/imaging.py</code> <pre><code>class NonRigidMotionCorrection(dj.Part):\n\"\"\"Piece-wise rigid motion correction - tile the FOV into multiple 3D\n    blocks/patches.\n\n    Attributes:\n        MotionCorrection (foreign key): Primary key from MotionCorrection.\n        outlier_frames (longblob, null): Mask with true for frames with outlier\n            shifts (already corrected).\n        block_height (int): Block height in pixels.\n        block_width (int): Block width in pixels.\n        block_depth (int): Block depth in pixels.\n        block_count_y (int): Number of blocks tiled in the y direction.\n        block_count_x (int): Number of blocks tiled in the x direction.\n        block_count_z (int): Number of blocks tiled in the z direction.\n    \"\"\"\n\n    definition = \"\"\"# Details of non-rigid motion correction performed on the imaging data\n    -&gt; master\n    ---\n    outlier_frames=null : longblob # mask with true for frames with outlier shifts (already corrected)\n    block_height        : int      # (pixels)\n    block_width         : int      # (pixels)\n    block_depth         : int      # (pixels)\n    block_count_y       : int      # number of blocks tiled in the y direction\n    block_count_x       : int      # number of blocks tiled in the x direction\n    block_count_z       : int      # number of blocks tiled in the z direction\n    \"\"\"\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging/#element_calcium_imaging.imaging.MotionCorrection.Block", "title": "<code>Block</code>", "text": "<p>         Bases: <code>dj.Part</code></p> <p>FOV-tiled blocks used for non-rigid motion correction.</p> <p>Attributes:</p> Name Type Description <code>NonRigidMotionCorrection</code> <code>foreign key</code> <p>Primary key from NonRigidMotionCorrection.</p> <code>block_id</code> <code>int</code> <p>Unique block ID.</p> <code>block_y</code> <code>longblob</code> <p>y_start and y_end in pixels for this block</p> <code>block_x</code> <code>longblob</code> <p>x_start and x_end in pixels for this block</p> <code>block_z</code> <code>longblob</code> <p>z_start and z_end in pixels for this block</p> <code>y_shifts</code> <code>longblob</code> <p>y motion correction shifts for every frame in pixels</p> <code>x_shifts</code> <code>longblob</code> <p>x motion correction shifts for every frame in pixels</p> <code>z_shift=null</code> <code>longblob</code> <p>x motion correction shifts for every frame in pixels</p> <code>y_std</code> <code>float</code> <p>standard deviation of y shifts across all frames in pixels</p> <code>x_std</code> <code>float</code> <p>standard deviation of x shifts across all frames in pixels</p> <code>z_std=null</code> <code>float</code> <p>standard deviation of z shifts across all frames in pixels</p> Source code in <code>element_calcium_imaging/imaging.py</code> <pre><code>class Block(dj.Part):\n\"\"\"FOV-tiled blocks used for non-rigid motion correction.\n\n    Attributes:\n        NonRigidMotionCorrection (foreign key): Primary key from\n            NonRigidMotionCorrection.\n        block_id (int): Unique block ID.\n        block_y (longblob): y_start and y_end in pixels for this block\n        block_x (longblob): x_start and x_end in pixels for this block\n        block_z (longblob): z_start and z_end in pixels for this block\n        y_shifts (longblob): y motion correction shifts for every frame in pixels\n        x_shifts (longblob): x motion correction shifts for every frame in pixels\n        z_shift=null (longblob, optional): x motion correction shifts for every frame\n            in pixels\n        y_std (float): standard deviation of y shifts across all frames in pixels\n        x_std (float): standard deviation of x shifts across all frames in pixels\n        z_std=null (float, optional): standard deviation of z shifts across all frames\n            in pixels\n    \"\"\"\n\n    definition = \"\"\"# FOV-tiled blocks used for non-rigid motion correction\n    -&gt; master.NonRigidMotionCorrection\n    block_id        : int\n    ---\n    block_y         : longblob  # (y_start, y_end) in pixel of this block\n    block_x         : longblob  # (x_start, x_end) in pixel of this block\n    block_z         : longblob  # (z_start, z_end) in pixel of this block\n    y_shifts        : longblob  # (pixels) y motion correction shifts for every frame\n    x_shifts        : longblob  # (pixels) x motion correction shifts for every frame\n    z_shifts=null   : longblob  # (pixels) x motion correction shifts for every frame\n    y_std           : float     # (pixels) standard deviation of y shifts across all frames\n    x_std           : float     # (pixels) standard deviation of x shifts across all frames\n    z_std=null      : float     # (pixels) standard deviation of z shifts across all frames\n    \"\"\"\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging/#element_calcium_imaging.imaging.MotionCorrection.Summary", "title": "<code>Summary</code>", "text": "<p>         Bases: <code>dj.Part</code></p> <p>Summary images for each field and channel after corrections.</p> <p>Attributes:</p> Name Type Description <code>MotionCorrection</code> <code>foreign key</code> <p>Primary key from MotionCorrection.</p> <code>scan.ScanInfo.Field</code> <code>foreign key</code> <p>Primary key from scan.ScanInfo.Field.</p> <code>ref_image</code> <code>longblob</code> <p>Image used as alignment template.</p> <code>average_image</code> <code>longblob</code> <p>Mean of registered frames.</p> <code>correlation_image</code> <code>longblob</code> <p>Correlation map (computed during cell detection).</p> <code>max_proj_image</code> <code>longblob</code> <p>Max of registered frames.</p> Source code in <code>element_calcium_imaging/imaging.py</code> <pre><code>class Summary(dj.Part):\n\"\"\"Summary images for each field and channel after corrections.\n\n    Attributes:\n        MotionCorrection (foreign key): Primary key from MotionCorrection.\n        scan.ScanInfo.Field (foreign key): Primary key from scan.ScanInfo.Field.\n        ref_image (longblob): Image used as alignment template.\n        average_image (longblob): Mean of registered frames.\n        correlation_image (longblob, optional): Correlation map (computed during\n            cell detection).\n        max_proj_image (longblob, optional): Max of registered frames.\n    \"\"\"\n\n    definition = \"\"\"# Summary images for each field and channel after corrections\n    -&gt; master\n    -&gt; scan.ScanInfo.Field\n    ---\n    ref_image               : longblob  # image used as alignment template\n    average_image           : longblob  # mean of registered frames\n    correlation_image=null  : longblob  # correlation map (computed during cell detection)\n    max_proj_image=null     : longblob  # max of registered frames\n    \"\"\"\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging/#element_calcium_imaging.imaging.MotionCorrection.make", "title": "<code>make(key)</code>", "text": "<p>Populate MotionCorrection with results parsed from analysis outputs</p> Source code in <code>element_calcium_imaging/imaging.py</code> <pre><code>def make(self, key):\n\"\"\"Populate MotionCorrection with results parsed from analysis outputs\"\"\"\n\n    method, imaging_dataset = get_loader_result(key, Curation)\n\n    field_keys, _ = (scan.ScanInfo.Field &amp; key).fetch(\n        \"KEY\", \"field_z\", order_by=\"field_z\"\n    )\n\n    if method in [\"suite2p\", \"extract\"]:\n        suite2p_dataset = imaging_dataset\n\n        motion_correct_channel = suite2p_dataset.planes[0].alignment_channel\n\n        # ---- iterate through all s2p plane outputs ----\n        rigid_correction, nonrigid_correction, nonrigid_blocks = {}, {}, {}\n        summary_images = []\n        for idx, (plane, s2p) in enumerate(suite2p_dataset.planes.items()):\n            # -- rigid motion correction --\n            if idx == 0:\n                rigid_correction = {\n                    **key,\n                    \"y_shifts\": s2p.ops[\"yoff\"],\n                    \"x_shifts\": s2p.ops[\"xoff\"],\n                    \"z_shifts\": np.full_like(s2p.ops[\"xoff\"], 0),\n                    \"y_std\": np.nanstd(s2p.ops[\"yoff\"]),\n                    \"x_std\": np.nanstd(s2p.ops[\"xoff\"]),\n                    \"z_std\": np.nan,\n                    \"outlier_frames\": s2p.ops[\"badframes\"],\n                }\n            else:\n                rigid_correction[\"y_shifts\"] = np.vstack(\n                    [rigid_correction[\"y_shifts\"], s2p.ops[\"yoff\"]]\n                )\n                rigid_correction[\"y_std\"] = np.nanstd(\n                    rigid_correction[\"y_shifts\"].flatten()\n                )\n                rigid_correction[\"x_shifts\"] = np.vstack(\n                    [rigid_correction[\"x_shifts\"], s2p.ops[\"xoff\"]]\n                )\n                rigid_correction[\"x_std\"] = np.nanstd(\n                    rigid_correction[\"x_shifts\"].flatten()\n                )\n                rigid_correction[\"outlier_frames\"] = np.logical_or(\n                    rigid_correction[\"outlier_frames\"], s2p.ops[\"badframes\"]\n                )\n            # -- non-rigid motion correction --\n            if s2p.ops[\"nonrigid\"]:\n                if idx == 0:\n                    nonrigid_correction = {\n                        **key,\n                        \"block_height\": s2p.ops[\"block_size\"][0],\n                        \"block_width\": s2p.ops[\"block_size\"][1],\n                        \"block_depth\": 1,\n                        \"block_count_y\": s2p.ops[\"nblocks\"][0],\n                        \"block_count_x\": s2p.ops[\"nblocks\"][1],\n                        \"block_count_z\": len(suite2p_dataset.planes),\n                        \"outlier_frames\": s2p.ops[\"badframes\"],\n                    }\n                else:\n                    nonrigid_correction[\"outlier_frames\"] = np.logical_or(\n                        nonrigid_correction[\"outlier_frames\"],\n                        s2p.ops[\"badframes\"],\n                    )\n                for b_id, (b_y, b_x, bshift_y, bshift_x) in enumerate(\n                    zip(\n                        s2p.ops[\"xblock\"],\n                        s2p.ops[\"yblock\"],\n                        s2p.ops[\"yoff1\"].T,\n                        s2p.ops[\"xoff1\"].T,\n                    )\n                ):\n                    if b_id in nonrigid_blocks:\n                        nonrigid_blocks[b_id][\"y_shifts\"] = np.vstack(\n                            [nonrigid_blocks[b_id][\"y_shifts\"], bshift_y]\n                        )\n                        nonrigid_blocks[b_id][\"y_std\"] = np.nanstd(\n                            nonrigid_blocks[b_id][\"y_shifts\"].flatten()\n                        )\n                        nonrigid_blocks[b_id][\"x_shifts\"] = np.vstack(\n                            [nonrigid_blocks[b_id][\"x_shifts\"], bshift_x]\n                        )\n                        nonrigid_blocks[b_id][\"x_std\"] = np.nanstd(\n                            nonrigid_blocks[b_id][\"x_shifts\"].flatten()\n                        )\n                    else:\n                        nonrigid_blocks[b_id] = {\n                            **key,\n                            \"block_id\": b_id,\n                            \"block_y\": b_y,\n                            \"block_x\": b_x,\n                            \"block_z\": np.full_like(b_x, plane),\n                            \"y_shifts\": bshift_y,\n                            \"x_shifts\": bshift_x,\n                            \"z_shifts\": np.full(\n                                (\n                                    len(suite2p_dataset.planes),\n                                    len(bshift_x),\n                                ),\n                                0,\n                            ),\n                            \"y_std\": np.nanstd(bshift_y),\n                            \"x_std\": np.nanstd(bshift_x),\n                            \"z_std\": np.nan,\n                        }\n\n            # -- summary images --\n            motion_correction_key = (\n                scan.ScanInfo.Field * Curation &amp; key &amp; field_keys[plane]\n            ).fetch1(\"KEY\")\n            summary_images.append(\n                {\n                    **motion_correction_key,\n                    \"ref_image\": s2p.ref_image,\n                    \"average_image\": s2p.mean_image,\n                    \"correlation_image\": s2p.correlation_map,\n                    \"max_proj_image\": s2p.max_proj_image,\n                }\n            )\n\n        self.insert1({**key, \"motion_correct_channel\": motion_correct_channel})\n        if rigid_correction:\n            self.RigidMotionCorrection.insert1(rigid_correction)\n        if nonrigid_correction:\n            self.NonRigidMotionCorrection.insert1(nonrigid_correction)\n            self.Block.insert(nonrigid_blocks.values())\n        self.Summary.insert(summary_images)\n    elif method == \"caiman\":\n        caiman_dataset = imaging_dataset\n\n        self.insert1(\n            {\n                **key,\n                \"motion_correct_channel\": caiman_dataset.alignment_channel,\n            }\n        )\n\n        is3D = caiman_dataset.params.motion[\"is3D\"]\n        if not caiman_dataset.params.motion[\"pw_rigid\"]:\n            # -- rigid motion correction --\n            rigid_correction = {\n                **key,\n                \"x_shifts\": caiman_dataset.motion_correction[\"shifts_rig\"][:, 0],\n                \"y_shifts\": caiman_dataset.motion_correction[\"shifts_rig\"][:, 1],\n                \"z_shifts\": (\n                    caiman_dataset.motion_correction[\"shifts_rig\"][:, 2]\n                    if is3D\n                    else np.full_like(\n                        caiman_dataset.motion_correction[\"shifts_rig\"][:, 0],\n                        0,\n                    )\n                ),\n                \"x_std\": np.nanstd(\n                    caiman_dataset.motion_correction[\"shifts_rig\"][:, 0]\n                ),\n                \"y_std\": np.nanstd(\n                    caiman_dataset.motion_correction[\"shifts_rig\"][:, 1]\n                ),\n                \"z_std\": (\n                    np.nanstd(caiman_dataset.motion_correction[\"shifts_rig\"][:, 2])\n                    if is3D\n                    else np.nan\n                ),\n                \"outlier_frames\": None,\n            }\n\n            self.RigidMotionCorrection.insert1(rigid_correction)\n        else:\n            # -- non-rigid motion correction --\n            nonrigid_correction = {\n                **key,\n                \"block_height\": (\n                    caiman_dataset.params.motion[\"strides\"][0]\n                    + caiman_dataset.params.motion[\"overlaps\"][0]\n                ),\n                \"block_width\": (\n                    caiman_dataset.params.motion[\"strides\"][1]\n                    + caiman_dataset.params.motion[\"overlaps\"][1]\n                ),\n                \"block_depth\": (\n                    caiman_dataset.params.motion[\"strides\"][2]\n                    + caiman_dataset.params.motion[\"overlaps\"][2]\n                    if is3D\n                    else 1\n                ),\n                \"block_count_x\": len(\n                    set(caiman_dataset.motion_correction[\"coord_shifts_els\"][:, 0])\n                ),\n                \"block_count_y\": len(\n                    set(caiman_dataset.motion_correction[\"coord_shifts_els\"][:, 2])\n                ),\n                \"block_count_z\": (\n                    len(\n                        set(\n                            caiman_dataset.motion_correction[\"coord_shifts_els\"][\n                                :, 4\n                            ]\n                        )\n                    )\n                    if is3D\n                    else 1\n                ),\n                \"outlier_frames\": None,\n            }\n\n            nonrigid_blocks = []\n            for b_id in range(\n                len(caiman_dataset.motion_correction[\"x_shifts_els\"][0, :])\n            ):\n                nonrigid_blocks.append(\n                    {\n                        **key,\n                        \"block_id\": b_id,\n                        \"block_x\": np.arange(\n                            *caiman_dataset.motion_correction[\"coord_shifts_els\"][\n                                b_id, 0:2\n                            ]\n                        ),\n                        \"block_y\": np.arange(\n                            *caiman_dataset.motion_correction[\"coord_shifts_els\"][\n                                b_id, 2:4\n                            ]\n                        ),\n                        \"block_z\": (\n                            np.arange(\n                                *caiman_dataset.motion_correction[\n                                    \"coord_shifts_els\"\n                                ][b_id, 4:6]\n                            )\n                            if is3D\n                            else np.full_like(\n                                np.arange(\n                                    *caiman_dataset.motion_correction[\n                                        \"coord_shifts_els\"\n                                    ][b_id, 0:2]\n                                ),\n                                0,\n                            )\n                        ),\n                        \"x_shifts\": caiman_dataset.motion_correction[\n                            \"x_shifts_els\"\n                        ][:, b_id],\n                        \"y_shifts\": caiman_dataset.motion_correction[\n                            \"y_shifts_els\"\n                        ][:, b_id],\n                        \"z_shifts\": (\n                            caiman_dataset.motion_correction[\"z_shifts_els\"][\n                                :, b_id\n                            ]\n                            if is3D\n                            else np.full_like(\n                                caiman_dataset.motion_correction[\"x_shifts_els\"][\n                                    :, b_id\n                                ],\n                                0,\n                            )\n                        ),\n                        \"x_std\": np.nanstd(\n                            caiman_dataset.motion_correction[\"x_shifts_els\"][\n                                :, b_id\n                            ]\n                        ),\n                        \"y_std\": np.nanstd(\n                            caiman_dataset.motion_correction[\"y_shifts_els\"][\n                                :, b_id\n                            ]\n                        ),\n                        \"z_std\": (\n                            np.nanstd(\n                                caiman_dataset.motion_correction[\"z_shifts_els\"][\n                                    :, b_id\n                                ]\n                            )\n                            if is3D\n                            else np.nan\n                        ),\n                    }\n                )\n\n            self.NonRigidMotionCorrection.insert1(nonrigid_correction)\n            self.Block.insert(nonrigid_blocks)\n\n        # -- summary images --\n        summary_images = [\n            {\n                **key,\n                **fkey,\n                \"ref_image\": ref_image,\n                \"average_image\": ave_img,\n                \"correlation_image\": corr_img,\n                \"max_proj_image\": max_img,\n            }\n            for fkey, ref_image, ave_img, corr_img, max_img in zip(\n                field_keys,\n                caiman_dataset.motion_correction[\"reference_image\"].transpose(\n                    2, 0, 1\n                )\n                if is3D\n                else caiman_dataset.motion_correction[\"reference_image\"][...][\n                    np.newaxis, ...\n                ],\n                caiman_dataset.motion_correction[\"average_image\"].transpose(2, 0, 1)\n                if is3D\n                else caiman_dataset.motion_correction[\"average_image\"][...][\n                    np.newaxis, ...\n                ],\n                caiman_dataset.motion_correction[\"correlation_image\"].transpose(\n                    2, 0, 1\n                )\n                if is3D\n                else caiman_dataset.motion_correction[\"correlation_image\"][...][\n                    np.newaxis, ...\n                ],\n                caiman_dataset.motion_correction[\"max_image\"].transpose(2, 0, 1)\n                if is3D\n                else caiman_dataset.motion_correction[\"max_image\"][...][\n                    np.newaxis, ...\n                ],\n            )\n        ]\n        self.Summary.insert(summary_images)\n    else:\n        raise NotImplementedError(\"Unknown/unimplemented method: {}\".format(method))\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging/#element_calcium_imaging.imaging.Segmentation", "title": "<code>Segmentation</code>", "text": "<p>         Bases: <code>dj.Computed</code></p> <p>Result of the Segmentation process.</p> <p>Attributes:</p> Name Type Description <code>Curation</code> <code>foreign key</code> <p>Primary key from Curation.</p> Source code in <code>element_calcium_imaging/imaging.py</code> <pre><code>@schema\nclass Segmentation(dj.Computed):\n\"\"\"Result of the Segmentation process.\n\n    Attributes:\n        Curation (foreign key): Primary key from Curation.\n    \"\"\"\n\n    definition = \"\"\"# Different mask segmentations.\n    -&gt; Curation\n    \"\"\"\n\n    class Mask(dj.Part):\n\"\"\"Details of the masks identified from the Segmentation procedure.\n\n        Attributes:\n            Segmentation (foreign key): Primary key from Segmentation.\n            mask (int): Unique mask ID.\n            scan.Channel.proj(segmentation_channel='channel') (foreign key): Channel\n                used for segmentation.\n            mask_npix (int): Number of pixels in ROIs.\n            mask_center_x (int): Center x coordinate in pixel.\n            mask_center_y (int): Center y coordinate in pixel.\n            mask_center_z (int): Center z coordinate in pixel.\n            mask_xpix (longblob): X coordinates in pixels.\n            mask_ypix (longblob): Y coordinates in pixels.\n            mask_zpix (longblob): Z coordinates in pixels.\n            mask_weights (longblob): Weights of the mask at the indices above.\n        \"\"\"\n\n        definition = \"\"\" # A mask produced by segmentation.\n        -&gt; master\n        mask               : smallint\n        ---\n        -&gt; scan.Channel.proj(segmentation_channel='channel')  # channel used for segmentation\n        mask_npix          : int       # number of pixels in ROIs\n        mask_center_x      : int       # center x coordinate in pixel\n        mask_center_y      : int       # center y coordinate in pixel\n        mask_center_z=null : int       # center z coordinate in pixel\n        mask_xpix          : longblob  # x coordinates in pixels\n        mask_ypix          : longblob  # y coordinates in pixels\n        mask_zpix=null     : longblob  # z coordinates in pixels\n        mask_weights       : longblob  # weights of the mask at the indices above\n        \"\"\"\n\n    def make(self, key):\n\"\"\"Populate the Segmentation with the results parsed from analysis outputs.\"\"\"\n\n        method, imaging_dataset = get_loader_result(key, Curation)\n\n        if method == \"suite2p\":\n            suite2p_dataset = imaging_dataset\n\n            # ---- iterate through all s2p plane outputs ----\n            masks, cells = [], []\n            for plane, s2p in suite2p_dataset.planes.items():\n                mask_count = len(masks)  # increment mask id from all \"plane\"\n                for mask_idx, (is_cell, cell_prob, mask_stat) in enumerate(\n                    zip(s2p.iscell, s2p.cell_prob, s2p.stat)\n                ):\n                    masks.append(\n                        {\n                            **key,\n                            \"mask\": mask_idx + mask_count,\n                            \"segmentation_channel\": s2p.segmentation_channel,\n                            \"mask_npix\": mask_stat[\"npix\"],\n                            \"mask_center_x\": mask_stat[\"med\"][1],\n                            \"mask_center_y\": mask_stat[\"med\"][0],\n                            \"mask_center_z\": mask_stat.get(\"iplane\", plane),\n                            \"mask_xpix\": mask_stat[\"xpix\"],\n                            \"mask_ypix\": mask_stat[\"ypix\"],\n                            \"mask_zpix\": np.full(\n                                mask_stat[\"npix\"],\n                                mask_stat.get(\"iplane\", plane),\n                            ),\n                            \"mask_weights\": mask_stat[\"lam\"],\n                        }\n                    )\n                    if is_cell:\n                        cells.append(\n                            {\n                                **key,\n                                \"mask_classification_method\": \"suite2p_default_classifier\",\n                                \"mask\": mask_idx + mask_count,\n                                \"mask_type\": \"soma\",\n                                \"confidence\": cell_prob,\n                            }\n                        )\n\n            self.insert1(key)\n            self.Mask.insert(masks, ignore_extra_fields=True)\n\n            if cells:\n                MaskClassification.insert1(\n                    {\n                        **key,\n                        \"mask_classification_method\": \"suite2p_default_classifier\",\n                    },\n                    allow_direct_insert=True,\n                )\n                MaskClassification.MaskType.insert(\n                    cells, ignore_extra_fields=True, allow_direct_insert=True\n                )\n        elif method == \"caiman\":\n            caiman_dataset = imaging_dataset\n\n            # infer \"segmentation_channel\" - from params if available, else from caiman loader\n            params = (ProcessingParamSet * ProcessingTask &amp; key).fetch1(\"params\")\n            segmentation_channel = params.get(\n                \"segmentation_channel\", caiman_dataset.segmentation_channel\n            )\n\n            masks, cells = [], []\n            for mask in caiman_dataset.masks:\n                masks.append(\n                    {\n                        **key,\n                        \"segmentation_channel\": segmentation_channel,\n                        \"mask\": mask[\"mask_id\"],\n                        \"mask_npix\": mask[\"mask_npix\"],\n                        \"mask_center_x\": mask[\"mask_center_x\"],\n                        \"mask_center_y\": mask[\"mask_center_y\"],\n                        \"mask_center_z\": mask[\"mask_center_z\"],\n                        \"mask_xpix\": mask[\"mask_xpix\"],\n                        \"mask_ypix\": mask[\"mask_ypix\"],\n                        \"mask_zpix\": mask[\"mask_zpix\"],\n                        \"mask_weights\": mask[\"mask_weights\"],\n                    }\n                )\n                if caiman_dataset.cnmf.estimates.idx_components is not None:\n                    if mask[\"mask_id\"] in caiman_dataset.cnmf.estimates.idx_components:\n                        cells.append(\n                            {\n                                **key,\n                                \"mask_classification_method\": \"caiman_default_classifier\",\n                                \"mask\": mask[\"mask_id\"],\n                                \"mask_type\": \"soma\",\n                            }\n                        )\n\n            self.insert1(key)\n            self.Mask.insert(masks, ignore_extra_fields=True)\n\n            if cells:\n                MaskClassification.insert1(\n                    {\n                        **key,\n                        \"mask_classification_method\": \"caiman_default_classifier\",\n                    },\n                    allow_direct_insert=True,\n                )\n                MaskClassification.MaskType.insert(\n                    cells, ignore_extra_fields=True, allow_direct_insert=True\n                )\n        elif method == \"extract\":\n            extract_dataset = imaging_dataset\n            masks = [\n                dict(\n                    **key,\n                    segmentation_channel=0,\n                    mask=mask[\"mask_id\"],\n                    mask_npix=mask[\"mask_npix\"],\n                    mask_center_x=mask[\"mask_center_x\"],\n                    mask_center_y=mask[\"mask_center_y\"],\n                    mask_center_z=mask[\"mask_center_z\"],\n                    mask_xpix=mask[\"mask_xpix\"],\n                    mask_ypix=mask[\"mask_ypix\"],\n                    mask_zpix=mask[\"mask_zpix\"],\n                    mask_weights=mask[\"mask_weights\"],\n                )\n                for mask in extract_dataset.load_results()\n            ]\n\n            self.insert1(key)\n            self.Mask.insert(masks, ignore_extra_fields=True)\n        else:\n            raise NotImplementedError(f\"Unknown/unimplemented method: {method}\")\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging/#element_calcium_imaging.imaging.Segmentation.Mask", "title": "<code>Mask</code>", "text": "<p>         Bases: <code>dj.Part</code></p> <p>Details of the masks identified from the Segmentation procedure.</p> <p>Attributes:</p> Name Type Description <code>Segmentation</code> <code>foreign key</code> <p>Primary key from Segmentation.</p> <code>mask</code> <code>int</code> <p>Unique mask ID.</p> <code>scan.Channel.proj(segmentation_channel='channel')</code> <code>foreign key</code> <p>Channel used for segmentation.</p> <code>mask_npix</code> <code>int</code> <p>Number of pixels in ROIs.</p> <code>mask_center_x</code> <code>int</code> <p>Center x coordinate in pixel.</p> <code>mask_center_y</code> <code>int</code> <p>Center y coordinate in pixel.</p> <code>mask_center_z</code> <code>int</code> <p>Center z coordinate in pixel.</p> <code>mask_xpix</code> <code>longblob</code> <p>X coordinates in pixels.</p> <code>mask_ypix</code> <code>longblob</code> <p>Y coordinates in pixels.</p> <code>mask_zpix</code> <code>longblob</code> <p>Z coordinates in pixels.</p> <code>mask_weights</code> <code>longblob</code> <p>Weights of the mask at the indices above.</p> Source code in <code>element_calcium_imaging/imaging.py</code> <pre><code>class Mask(dj.Part):\n\"\"\"Details of the masks identified from the Segmentation procedure.\n\n    Attributes:\n        Segmentation (foreign key): Primary key from Segmentation.\n        mask (int): Unique mask ID.\n        scan.Channel.proj(segmentation_channel='channel') (foreign key): Channel\n            used for segmentation.\n        mask_npix (int): Number of pixels in ROIs.\n        mask_center_x (int): Center x coordinate in pixel.\n        mask_center_y (int): Center y coordinate in pixel.\n        mask_center_z (int): Center z coordinate in pixel.\n        mask_xpix (longblob): X coordinates in pixels.\n        mask_ypix (longblob): Y coordinates in pixels.\n        mask_zpix (longblob): Z coordinates in pixels.\n        mask_weights (longblob): Weights of the mask at the indices above.\n    \"\"\"\n\n    definition = \"\"\" # A mask produced by segmentation.\n    -&gt; master\n    mask               : smallint\n    ---\n    -&gt; scan.Channel.proj(segmentation_channel='channel')  # channel used for segmentation\n    mask_npix          : int       # number of pixels in ROIs\n    mask_center_x      : int       # center x coordinate in pixel\n    mask_center_y      : int       # center y coordinate in pixel\n    mask_center_z=null : int       # center z coordinate in pixel\n    mask_xpix          : longblob  # x coordinates in pixels\n    mask_ypix          : longblob  # y coordinates in pixels\n    mask_zpix=null     : longblob  # z coordinates in pixels\n    mask_weights       : longblob  # weights of the mask at the indices above\n    \"\"\"\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging/#element_calcium_imaging.imaging.Segmentation.make", "title": "<code>make(key)</code>", "text": "<p>Populate the Segmentation with the results parsed from analysis outputs.</p> Source code in <code>element_calcium_imaging/imaging.py</code> <pre><code>def make(self, key):\n\"\"\"Populate the Segmentation with the results parsed from analysis outputs.\"\"\"\n\n    method, imaging_dataset = get_loader_result(key, Curation)\n\n    if method == \"suite2p\":\n        suite2p_dataset = imaging_dataset\n\n        # ---- iterate through all s2p plane outputs ----\n        masks, cells = [], []\n        for plane, s2p in suite2p_dataset.planes.items():\n            mask_count = len(masks)  # increment mask id from all \"plane\"\n            for mask_idx, (is_cell, cell_prob, mask_stat) in enumerate(\n                zip(s2p.iscell, s2p.cell_prob, s2p.stat)\n            ):\n                masks.append(\n                    {\n                        **key,\n                        \"mask\": mask_idx + mask_count,\n                        \"segmentation_channel\": s2p.segmentation_channel,\n                        \"mask_npix\": mask_stat[\"npix\"],\n                        \"mask_center_x\": mask_stat[\"med\"][1],\n                        \"mask_center_y\": mask_stat[\"med\"][0],\n                        \"mask_center_z\": mask_stat.get(\"iplane\", plane),\n                        \"mask_xpix\": mask_stat[\"xpix\"],\n                        \"mask_ypix\": mask_stat[\"ypix\"],\n                        \"mask_zpix\": np.full(\n                            mask_stat[\"npix\"],\n                            mask_stat.get(\"iplane\", plane),\n                        ),\n                        \"mask_weights\": mask_stat[\"lam\"],\n                    }\n                )\n                if is_cell:\n                    cells.append(\n                        {\n                            **key,\n                            \"mask_classification_method\": \"suite2p_default_classifier\",\n                            \"mask\": mask_idx + mask_count,\n                            \"mask_type\": \"soma\",\n                            \"confidence\": cell_prob,\n                        }\n                    )\n\n        self.insert1(key)\n        self.Mask.insert(masks, ignore_extra_fields=True)\n\n        if cells:\n            MaskClassification.insert1(\n                {\n                    **key,\n                    \"mask_classification_method\": \"suite2p_default_classifier\",\n                },\n                allow_direct_insert=True,\n            )\n            MaskClassification.MaskType.insert(\n                cells, ignore_extra_fields=True, allow_direct_insert=True\n            )\n    elif method == \"caiman\":\n        caiman_dataset = imaging_dataset\n\n        # infer \"segmentation_channel\" - from params if available, else from caiman loader\n        params = (ProcessingParamSet * ProcessingTask &amp; key).fetch1(\"params\")\n        segmentation_channel = params.get(\n            \"segmentation_channel\", caiman_dataset.segmentation_channel\n        )\n\n        masks, cells = [], []\n        for mask in caiman_dataset.masks:\n            masks.append(\n                {\n                    **key,\n                    \"segmentation_channel\": segmentation_channel,\n                    \"mask\": mask[\"mask_id\"],\n                    \"mask_npix\": mask[\"mask_npix\"],\n                    \"mask_center_x\": mask[\"mask_center_x\"],\n                    \"mask_center_y\": mask[\"mask_center_y\"],\n                    \"mask_center_z\": mask[\"mask_center_z\"],\n                    \"mask_xpix\": mask[\"mask_xpix\"],\n                    \"mask_ypix\": mask[\"mask_ypix\"],\n                    \"mask_zpix\": mask[\"mask_zpix\"],\n                    \"mask_weights\": mask[\"mask_weights\"],\n                }\n            )\n            if caiman_dataset.cnmf.estimates.idx_components is not None:\n                if mask[\"mask_id\"] in caiman_dataset.cnmf.estimates.idx_components:\n                    cells.append(\n                        {\n                            **key,\n                            \"mask_classification_method\": \"caiman_default_classifier\",\n                            \"mask\": mask[\"mask_id\"],\n                            \"mask_type\": \"soma\",\n                        }\n                    )\n\n        self.insert1(key)\n        self.Mask.insert(masks, ignore_extra_fields=True)\n\n        if cells:\n            MaskClassification.insert1(\n                {\n                    **key,\n                    \"mask_classification_method\": \"caiman_default_classifier\",\n                },\n                allow_direct_insert=True,\n            )\n            MaskClassification.MaskType.insert(\n                cells, ignore_extra_fields=True, allow_direct_insert=True\n            )\n    elif method == \"extract\":\n        extract_dataset = imaging_dataset\n        masks = [\n            dict(\n                **key,\n                segmentation_channel=0,\n                mask=mask[\"mask_id\"],\n                mask_npix=mask[\"mask_npix\"],\n                mask_center_x=mask[\"mask_center_x\"],\n                mask_center_y=mask[\"mask_center_y\"],\n                mask_center_z=mask[\"mask_center_z\"],\n                mask_xpix=mask[\"mask_xpix\"],\n                mask_ypix=mask[\"mask_ypix\"],\n                mask_zpix=mask[\"mask_zpix\"],\n                mask_weights=mask[\"mask_weights\"],\n            )\n            for mask in extract_dataset.load_results()\n        ]\n\n        self.insert1(key)\n        self.Mask.insert(masks, ignore_extra_fields=True)\n    else:\n        raise NotImplementedError(f\"Unknown/unimplemented method: {method}\")\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging/#element_calcium_imaging.imaging.MaskClassificationMethod", "title": "<code>MaskClassificationMethod</code>", "text": "<p>         Bases: <code>dj.Lookup</code></p> <p>Available mask classification methods.</p> <p>Attributes:</p> Name Type Description <code>mask_classification_method</code> <code>str</code> <p>Mask classification method.</p> Source code in <code>element_calcium_imaging/imaging.py</code> <pre><code>@schema\nclass MaskClassificationMethod(dj.Lookup):\n\"\"\"Available mask classification methods.\n\n    Attributes:\n        mask_classification_method (str): Mask classification method.\n    \"\"\"\n\n    definition = \"\"\"\n    mask_classification_method: varchar(48)\n    \"\"\"\n\n    contents = zip([\"suite2p_default_classifier\", \"caiman_default_classifier\"])\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging/#element_calcium_imaging.imaging.MaskClassification", "title": "<code>MaskClassification</code>", "text": "<p>         Bases: <code>dj.Computed</code></p> <p>Classes assigned to each mask.</p> <p>Attributes:</p> Name Type Description <code>Segmentation</code> <code>foreign key</code> <p>Primary key from Segmentation.</p> <code>MaskClassificationMethod</code> <code>foreign key</code> <p>Primary key from MaskClassificationMethod.</p> Source code in <code>element_calcium_imaging/imaging.py</code> <pre><code>@schema\nclass MaskClassification(dj.Computed):\n\"\"\"Classes assigned to each mask.\n\n    Attributes:\n        Segmentation (foreign key): Primary key from Segmentation.\n        MaskClassificationMethod (foreign key): Primary key from\n            MaskClassificationMethod.\n    \"\"\"\n\n    definition = \"\"\"\n    -&gt; Segmentation\n    -&gt; MaskClassificationMethod\n    \"\"\"\n\n    class MaskType(dj.Part):\n\"\"\"Type assigned to each mask.\n\n        Attributes:\n            MaskClassification (foreign key): Primary key from MaskClassification.\n            Segmentation.Mask (foreign key): Primary key from Segmentation.Mask.\n            MaskType: Primary key from MaskType.\n            confidence (float, optional): Confidence level of the mask classification.\n        \"\"\"\n\n        definition = \"\"\"\n        -&gt; master\n        -&gt; Segmentation.Mask\n        ---\n        -&gt; MaskType\n        confidence=null: float\n        \"\"\"\n\n    def make(self, key):\n        pass\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging/#element_calcium_imaging.imaging.MaskClassification.MaskType", "title": "<code>MaskType</code>", "text": "<p>         Bases: <code>dj.Part</code></p> <p>Type assigned to each mask.</p> <p>Attributes:</p> Name Type Description <code>MaskClassification</code> <code>foreign key</code> <p>Primary key from MaskClassification.</p> <code>Segmentation.Mask</code> <code>foreign key</code> <p>Primary key from Segmentation.Mask.</p> <code>MaskType</code> <code>foreign key</code> <p>Primary key from MaskType.</p> <code>confidence</code> <code>float</code> <p>Confidence level of the mask classification.</p> Source code in <code>element_calcium_imaging/imaging.py</code> <pre><code>class MaskType(dj.Part):\n\"\"\"Type assigned to each mask.\n\n    Attributes:\n        MaskClassification (foreign key): Primary key from MaskClassification.\n        Segmentation.Mask (foreign key): Primary key from Segmentation.Mask.\n        MaskType: Primary key from MaskType.\n        confidence (float, optional): Confidence level of the mask classification.\n    \"\"\"\n\n    definition = \"\"\"\n    -&gt; master\n    -&gt; Segmentation.Mask\n    ---\n    -&gt; MaskType\n    confidence=null: float\n    \"\"\"\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging/#element_calcium_imaging.imaging.Fluorescence", "title": "<code>Fluorescence</code>", "text": "<p>         Bases: <code>dj.Computed</code></p> <p>Fluorescence traces.</p> <p>Attributes:</p> Name Type Description <code>Segmentation</code> <code>foreign key</code> <p>Primary key from Segmentation.</p> Source code in <code>element_calcium_imaging/imaging.py</code> <pre><code>@schema\nclass Fluorescence(dj.Computed):\n\"\"\"Fluorescence traces.\n\n    Attributes:\n        Segmentation (foreign key): Primary key from Segmentation.\n    \"\"\"\n\n    definition = \"\"\"# Fluorescence traces before spike extraction or filtering\n    -&gt; Segmentation\n    \"\"\"\n\n    class Trace(dj.Part):\n\"\"\"Traces obtained from segmented region of interests.\n\n        Attributes:\n            Fluorescence (foreign key): Primary key from Fluorescence.\n            Segmentation.Mask (foreign key): Primary key from Segmentation.Mask.\n            scan.Channel.proj(fluo_channel='channel') (int): The channel that this trace\n                comes from.\n            fluorescence (longblob): Fluorescence trace associated with this mask.\n            neuropil_fluorescence (longblob, optional): Neuropil fluorescence trace.\n        \"\"\"\n\n        definition = \"\"\"\n        -&gt; master\n        -&gt; Segmentation.Mask\n        -&gt; scan.Channel.proj(fluo_channel='channel')  # The channel that this trace comes from\n        ---\n        fluorescence                : longblob  # Fluorescence trace associated with this mask\n        neuropil_fluorescence=null  : longblob  # Neuropil fluorescence trace\n        \"\"\"\n\n    def make(self, key):\n\"\"\"Populate the Fluorescence with the results parsed from analysis outputs.\"\"\"\n\n        method, imaging_dataset = get_loader_result(key, Curation)\n\n        if method == \"suite2p\":\n            suite2p_dataset = imaging_dataset\n\n            # ---- iterate through all s2p plane outputs ----\n            fluo_traces, fluo_chn2_traces = [], []\n            for s2p in suite2p_dataset.planes.values():\n                mask_count = len(fluo_traces)  # increment mask id from all \"plane\"\n                for mask_idx, (f, fneu) in enumerate(zip(s2p.F, s2p.Fneu)):\n                    fluo_traces.append(\n                        {\n                            **key,\n                            \"mask\": mask_idx + mask_count,\n                            \"fluo_channel\": 0,\n                            \"fluorescence\": f,\n                            \"neuropil_fluorescence\": fneu,\n                        }\n                    )\n                if len(s2p.F_chan2):\n                    mask_chn2_count = len(\n                        fluo_chn2_traces\n                    )  # increment mask id from all planes\n                    for mask_idx, (f2, fneu2) in enumerate(\n                        zip(s2p.F_chan2, s2p.Fneu_chan2)\n                    ):\n                        fluo_chn2_traces.append(\n                            {\n                                **key,\n                                \"mask\": mask_idx + mask_chn2_count,\n                                \"fluo_channel\": 1,\n                                \"fluorescence\": f2,\n                                \"neuropil_fluorescence\": fneu2,\n                            }\n                        )\n\n            self.insert1(key)\n            self.Trace.insert(fluo_traces + fluo_chn2_traces)\n        elif method == \"caiman\":\n            caiman_dataset = imaging_dataset\n\n            # infer \"segmentation_channel\" - from params if available, else from caiman loader\n            params = (ProcessingParamSet * ProcessingTask &amp; key).fetch1(\"params\")\n            segmentation_channel = params.get(\n                \"segmentation_channel\", caiman_dataset.segmentation_channel\n            )\n\n            fluo_traces = []\n            for mask in caiman_dataset.masks:\n                fluo_traces.append(\n                    {\n                        **key,\n                        \"mask\": mask[\"mask_id\"],\n                        \"fluo_channel\": segmentation_channel,\n                        \"fluorescence\": mask[\"inferred_trace\"],\n                    }\n                )\n\n            self.insert1(key)\n            self.Trace.insert(fluo_traces)\n        elif method == \"extract\":\n            extract_dataset = imaging_dataset\n\n            fluo_traces = [\n                {\n                    **key,\n                    \"mask\": mask_id,\n                    \"fluo_channel\": 0,\n                    \"fluorescence\": fluorescence,\n                }\n                for mask_id, fluorescence in enumerate(extract_dataset.T)\n            ]\n\n            self.insert1(key)\n            self.Trace.insert(fluo_traces)\n\n        else:\n            raise NotImplementedError(\"Unknown/unimplemented method: {}\".format(method))\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging/#element_calcium_imaging.imaging.Fluorescence.Trace", "title": "<code>Trace</code>", "text": "<p>         Bases: <code>dj.Part</code></p> <p>Traces obtained from segmented region of interests.</p> <p>Attributes:</p> Name Type Description <code>Fluorescence</code> <code>foreign key</code> <p>Primary key from Fluorescence.</p> <code>Segmentation.Mask</code> <code>foreign key</code> <p>Primary key from Segmentation.Mask.</p> <code>scan.Channel.proj(fluo_channel='channel')</code> <code>int</code> <p>The channel that this trace comes from.</p> <code>fluorescence</code> <code>longblob</code> <p>Fluorescence trace associated with this mask.</p> <code>neuropil_fluorescence</code> <code>longblob</code> <p>Neuropil fluorescence trace.</p> Source code in <code>element_calcium_imaging/imaging.py</code> <pre><code>class Trace(dj.Part):\n\"\"\"Traces obtained from segmented region of interests.\n\n    Attributes:\n        Fluorescence (foreign key): Primary key from Fluorescence.\n        Segmentation.Mask (foreign key): Primary key from Segmentation.Mask.\n        scan.Channel.proj(fluo_channel='channel') (int): The channel that this trace\n            comes from.\n        fluorescence (longblob): Fluorescence trace associated with this mask.\n        neuropil_fluorescence (longblob, optional): Neuropil fluorescence trace.\n    \"\"\"\n\n    definition = \"\"\"\n    -&gt; master\n    -&gt; Segmentation.Mask\n    -&gt; scan.Channel.proj(fluo_channel='channel')  # The channel that this trace comes from\n    ---\n    fluorescence                : longblob  # Fluorescence trace associated with this mask\n    neuropil_fluorescence=null  : longblob  # Neuropil fluorescence trace\n    \"\"\"\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging/#element_calcium_imaging.imaging.Fluorescence.make", "title": "<code>make(key)</code>", "text": "<p>Populate the Fluorescence with the results parsed from analysis outputs.</p> Source code in <code>element_calcium_imaging/imaging.py</code> <pre><code>def make(self, key):\n\"\"\"Populate the Fluorescence with the results parsed from analysis outputs.\"\"\"\n\n    method, imaging_dataset = get_loader_result(key, Curation)\n\n    if method == \"suite2p\":\n        suite2p_dataset = imaging_dataset\n\n        # ---- iterate through all s2p plane outputs ----\n        fluo_traces, fluo_chn2_traces = [], []\n        for s2p in suite2p_dataset.planes.values():\n            mask_count = len(fluo_traces)  # increment mask id from all \"plane\"\n            for mask_idx, (f, fneu) in enumerate(zip(s2p.F, s2p.Fneu)):\n                fluo_traces.append(\n                    {\n                        **key,\n                        \"mask\": mask_idx + mask_count,\n                        \"fluo_channel\": 0,\n                        \"fluorescence\": f,\n                        \"neuropil_fluorescence\": fneu,\n                    }\n                )\n            if len(s2p.F_chan2):\n                mask_chn2_count = len(\n                    fluo_chn2_traces\n                )  # increment mask id from all planes\n                for mask_idx, (f2, fneu2) in enumerate(\n                    zip(s2p.F_chan2, s2p.Fneu_chan2)\n                ):\n                    fluo_chn2_traces.append(\n                        {\n                            **key,\n                            \"mask\": mask_idx + mask_chn2_count,\n                            \"fluo_channel\": 1,\n                            \"fluorescence\": f2,\n                            \"neuropil_fluorescence\": fneu2,\n                        }\n                    )\n\n        self.insert1(key)\n        self.Trace.insert(fluo_traces + fluo_chn2_traces)\n    elif method == \"caiman\":\n        caiman_dataset = imaging_dataset\n\n        # infer \"segmentation_channel\" - from params if available, else from caiman loader\n        params = (ProcessingParamSet * ProcessingTask &amp; key).fetch1(\"params\")\n        segmentation_channel = params.get(\n            \"segmentation_channel\", caiman_dataset.segmentation_channel\n        )\n\n        fluo_traces = []\n        for mask in caiman_dataset.masks:\n            fluo_traces.append(\n                {\n                    **key,\n                    \"mask\": mask[\"mask_id\"],\n                    \"fluo_channel\": segmentation_channel,\n                    \"fluorescence\": mask[\"inferred_trace\"],\n                }\n            )\n\n        self.insert1(key)\n        self.Trace.insert(fluo_traces)\n    elif method == \"extract\":\n        extract_dataset = imaging_dataset\n\n        fluo_traces = [\n            {\n                **key,\n                \"mask\": mask_id,\n                \"fluo_channel\": 0,\n                \"fluorescence\": fluorescence,\n            }\n            for mask_id, fluorescence in enumerate(extract_dataset.T)\n        ]\n\n        self.insert1(key)\n        self.Trace.insert(fluo_traces)\n\n    else:\n        raise NotImplementedError(\"Unknown/unimplemented method: {}\".format(method))\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging/#element_calcium_imaging.imaging.ActivityExtractionMethod", "title": "<code>ActivityExtractionMethod</code>", "text": "<p>         Bases: <code>dj.Lookup</code></p> <p>Available activity extraction methods.</p> <p>Attributes:</p> Name Type Description <code>extraction_method</code> <code>str</code> <p>Extraction method.</p> Source code in <code>element_calcium_imaging/imaging.py</code> <pre><code>@schema\nclass ActivityExtractionMethod(dj.Lookup):\n\"\"\"Available activity extraction methods.\n\n    Attributes:\n        extraction_method (str): Extraction method.\n    \"\"\"\n\n    definition = \"\"\"# Activity extraction method\n    extraction_method: varchar(32)\n    \"\"\"\n\n    contents = zip([\"suite2p_deconvolution\", \"caiman_deconvolution\", \"caiman_dff\"])\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging/#element_calcium_imaging.imaging.Activity", "title": "<code>Activity</code>", "text": "<p>         Bases: <code>dj.Computed</code></p> <p>Inferred neural activity from fluorescence trace (e.g. dff, spikes, etc.).</p> <p>Attributes:</p> Name Type Description <code>Fluorescence</code> <code>foreign key</code> <p>Primary key from Fluorescence.</p> <code>ActivityExtractionMethod</code> <code>foreign key</code> <p>Primary key from ActivityExtractionMethod.</p> Source code in <code>element_calcium_imaging/imaging.py</code> <pre><code>@schema\nclass Activity(dj.Computed):\n\"\"\"Inferred neural activity from fluorescence trace (e.g. dff, spikes, etc.).\n\n    Attributes:\n        Fluorescence (foreign key): Primary key from Fluorescence.\n        ActivityExtractionMethod (foreign key): Primary key from\n            ActivityExtractionMethod.\n    \"\"\"\n\n    definition = \"\"\"# Neural Activity\n    -&gt; Fluorescence\n    -&gt; ActivityExtractionMethod\n    \"\"\"\n\n    class Trace(dj.Part):\n\"\"\"Trace(s) for each mask.\n\n        Attributes:\n            Activity (foreign key): Primary key from Activity.\n            Fluorescence.Trace (foreign key): Fluorescence.Trace.\n            activity_trace (longblob): Neural activity from fluorescence trace.\n        \"\"\"\n\n        definition = \"\"\"\n        -&gt; master\n        -&gt; Fluorescence.Trace\n        ---\n        activity_trace: longblob\n        \"\"\"\n\n    @property\n    def key_source(self):\n        suite2p_key_source = (\n            Fluorescence\n            * ActivityExtractionMethod\n            * ProcessingParamSet.proj(\"processing_method\")\n            &amp; 'processing_method = \"suite2p\"'\n            &amp; 'extraction_method LIKE \"suite2p%\"'\n        )\n        caiman_key_source = (\n            Fluorescence\n            * ActivityExtractionMethod\n            * ProcessingParamSet.proj(\"processing_method\")\n            &amp; 'processing_method = \"caiman\"'\n            &amp; 'extraction_method LIKE \"caiman%\"'\n        )\n        return suite2p_key_source.proj() + caiman_key_source.proj()\n\n    def make(self, key):\n\"\"\"Populate the Activity with the results parsed from analysis outputs.\"\"\"\n\n        method, imaging_dataset = get_loader_result(key, Curation)\n\n        if method == \"suite2p\":\n            if key[\"extraction_method\"] == \"suite2p_deconvolution\":\n                suite2p_dataset = imaging_dataset\n                # ---- iterate through all s2p plane outputs ----\n                spikes = [\n                    dict(\n                        key,\n                        mask=mask_idx,\n                        fluo_channel=0,\n                        activity_trace=spks,\n                    )\n                    for mask_idx, spks in enumerate(\n                        s\n                        for plane in suite2p_dataset.planes.values()\n                        for s in plane.spks\n                    )\n                ]\n\n                self.insert1(key)\n                self.Trace.insert(spikes)\n        elif method == \"caiman\":\n            caiman_dataset = imaging_dataset\n\n            if key[\"extraction_method\"] in (\n                \"caiman_deconvolution\",\n                \"caiman_dff\",\n            ):\n                attr_mapper = {\n                    \"caiman_deconvolution\": \"spikes\",\n                    \"caiman_dff\": \"dff\",\n                }\n\n                # infer \"segmentation_channel\" - from params if available, else from caiman loader\n                params = (ProcessingParamSet * ProcessingTask &amp; key).fetch1(\"params\")\n                segmentation_channel = params.get(\n                    \"segmentation_channel\", caiman_dataset.segmentation_channel\n                )\n\n                self.insert1(key)\n                self.Trace.insert(\n                    dict(\n                        key,\n                        mask=mask[\"mask_id\"],\n                        fluo_channel=segmentation_channel,\n                        activity_trace=mask[attr_mapper[key[\"extraction_method\"]]],\n                    )\n                    for mask in caiman_dataset.masks\n                )\n        else:\n            raise NotImplementedError(\"Unknown/unimplemented method: {}\".format(method))\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging/#element_calcium_imaging.imaging.Activity.Trace", "title": "<code>Trace</code>", "text": "<p>         Bases: <code>dj.Part</code></p> <p>Trace(s) for each mask.</p> <p>Attributes:</p> Name Type Description <code>Activity</code> <code>foreign key</code> <p>Primary key from Activity.</p> <code>Fluorescence.Trace</code> <code>foreign key</code> <p>Fluorescence.Trace.</p> <code>activity_trace</code> <code>longblob</code> <p>Neural activity from fluorescence trace.</p> Source code in <code>element_calcium_imaging/imaging.py</code> <pre><code>class Trace(dj.Part):\n\"\"\"Trace(s) for each mask.\n\n    Attributes:\n        Activity (foreign key): Primary key from Activity.\n        Fluorescence.Trace (foreign key): Fluorescence.Trace.\n        activity_trace (longblob): Neural activity from fluorescence trace.\n    \"\"\"\n\n    definition = \"\"\"\n    -&gt; master\n    -&gt; Fluorescence.Trace\n    ---\n    activity_trace: longblob\n    \"\"\"\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging/#element_calcium_imaging.imaging.Activity.make", "title": "<code>make(key)</code>", "text": "<p>Populate the Activity with the results parsed from analysis outputs.</p> Source code in <code>element_calcium_imaging/imaging.py</code> <pre><code>def make(self, key):\n\"\"\"Populate the Activity with the results parsed from analysis outputs.\"\"\"\n\n    method, imaging_dataset = get_loader_result(key, Curation)\n\n    if method == \"suite2p\":\n        if key[\"extraction_method\"] == \"suite2p_deconvolution\":\n            suite2p_dataset = imaging_dataset\n            # ---- iterate through all s2p plane outputs ----\n            spikes = [\n                dict(\n                    key,\n                    mask=mask_idx,\n                    fluo_channel=0,\n                    activity_trace=spks,\n                )\n                for mask_idx, spks in enumerate(\n                    s\n                    for plane in suite2p_dataset.planes.values()\n                    for s in plane.spks\n                )\n            ]\n\n            self.insert1(key)\n            self.Trace.insert(spikes)\n    elif method == \"caiman\":\n        caiman_dataset = imaging_dataset\n\n        if key[\"extraction_method\"] in (\n            \"caiman_deconvolution\",\n            \"caiman_dff\",\n        ):\n            attr_mapper = {\n                \"caiman_deconvolution\": \"spikes\",\n                \"caiman_dff\": \"dff\",\n            }\n\n            # infer \"segmentation_channel\" - from params if available, else from caiman loader\n            params = (ProcessingParamSet * ProcessingTask &amp; key).fetch1(\"params\")\n            segmentation_channel = params.get(\n                \"segmentation_channel\", caiman_dataset.segmentation_channel\n            )\n\n            self.insert1(key)\n            self.Trace.insert(\n                dict(\n                    key,\n                    mask=mask[\"mask_id\"],\n                    fluo_channel=segmentation_channel,\n                    activity_trace=mask[attr_mapper[key[\"extraction_method\"]]],\n                )\n                for mask in caiman_dataset.masks\n            )\n    else:\n        raise NotImplementedError(\"Unknown/unimplemented method: {}\".format(method))\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging/#element_calcium_imaging.imaging.ProcessingQualityMetrics", "title": "<code>ProcessingQualityMetrics</code>", "text": "<p>         Bases: <code>dj.Computed</code></p> <p>Quality metrics used to evaluate the results of the calcium imaging analysis pipeline.</p> <p>Attributes:</p> Name Type Description <code>Fluorescence</code> <code>foreign key</code> <p>Primary key from Fluorescence.</p> Source code in <code>element_calcium_imaging/imaging.py</code> <pre><code>@schema\nclass ProcessingQualityMetrics(dj.Computed):\n\"\"\"Quality metrics used to evaluate the results of the calcium imaging analysis pipeline.\n\n    Attributes:\n        Fluorescence (foreign key): Primary key from Fluorescence.\n    \"\"\"\n\n    definition = \"\"\"\n    -&gt; Fluorescence\n    \"\"\"\n\n    class Mask(dj.Part):\n\"\"\"Quality metrics used to evaluate the masks.\n\n        Attributes:\n            Fluorescence (foreign key): Primary key from Fluorescence.\n            Segmentation.Mask (foreign key): Primary key from Segmentation.Mask.\n            mask_area (float): Mask area in square micrometer.\n            roundness (float): Roundness between 0 and 1. Values closer to 1 are rounder.\n        \"\"\"\n\n        definition = \"\"\"\n        -&gt; master\n        -&gt; Segmentation.Mask\n        ---\n        mask_area=null: float  # Mask area in square micrometer.\n        roundness: float       # Roundness between 0 and 1. Values closer to 1 are rounder.\n        \"\"\"\n\n    class Trace(dj.Part):\n\"\"\"Quality metrics used to evaluate the fluorescence traces.\n\n        Attributes:\n            Fluorescence (foreign key): Primary key from Fluorescence.\n            Fluorescence.Trace (foreign key): Primary key from Fluorescence.Trace.\n            skewness (float): Skewness of the fluorescence trace.\n            variance (float): Variance of the fluorescence trace.\n        \"\"\"\n\n        definition = \"\"\"\n        -&gt; master\n        -&gt; Fluorescence.Trace\n        ---\n        skewness: float   # Skewness of the fluorescence trace.\n        variance: float   # Variance of the fluorescence trace.\n        \"\"\"\n\n    def make(self, key):\n\"\"\"Populate the ProcessingQualityMetrics table and its part tables.\"\"\"\n        from scipy.stats import skew\n\n        (\n            mask_xpixs,\n            mask_ypixs,\n            mask_weights,\n            fluorescence,\n            fluo_channels,\n            mask_ids,\n            mask_npix,\n            px_height,\n            px_width,\n            um_height,\n            um_width,\n        ) = (Segmentation.Mask * scan.ScanInfo.Field * Fluorescence.Trace &amp; key).fetch(\n            \"mask_xpix\",\n            \"mask_ypix\",\n            \"mask_weights\",\n            \"fluorescence\",\n            \"fluo_channel\",\n            \"mask\",\n            \"mask_npix\",\n            \"px_height\",\n            \"px_width\",\n            \"um_height\",\n            \"um_width\",\n        )\n\n        norm_mean = lambda x: x.mean() / x.max()\n        roundnesses = [\n            norm_mean(np.linalg.eigvals(np.cov(x, y, aweights=w)))\n            for x, y, w in zip(mask_xpixs, mask_ypixs, mask_weights)\n        ]\n\n        fluorescence = np.stack(fluorescence)\n\n        self.insert1(key)\n\n        self.Mask.insert(\n            dict(key, mask=mask_id, mask_area=mask_area, roundness=roundness)\n            for mask_id, mask_area, roundness in zip(\n                mask_ids,\n                mask_npix * (um_height / px_height) * (um_width / px_width),\n                roundnesses,\n            )\n        )\n\n        self.Trace.insert(\n            dict(\n                key,\n                fluo_channel=fluo_channel,\n                mask=mask_id,\n                skewness=skewness,\n                variance=variance,\n            )\n            for fluo_channel, mask_id, skewness, variance in zip(\n                fluo_channels,\n                mask_ids,\n                skew(fluorescence, axis=1),\n                fluorescence.std(axis=1),\n            )\n        )\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging/#element_calcium_imaging.imaging.ProcessingQualityMetrics.Mask", "title": "<code>Mask</code>", "text": "<p>         Bases: <code>dj.Part</code></p> <p>Quality metrics used to evaluate the masks.</p> <p>Attributes:</p> Name Type Description <code>Fluorescence</code> <code>foreign key</code> <p>Primary key from Fluorescence.</p> <code>Segmentation.Mask</code> <code>foreign key</code> <p>Primary key from Segmentation.Mask.</p> <code>mask_area</code> <code>float</code> <p>Mask area in square micrometer.</p> <code>roundness</code> <code>float</code> <p>Roundness between 0 and 1. Values closer to 1 are rounder.</p> Source code in <code>element_calcium_imaging/imaging.py</code> <pre><code>class Mask(dj.Part):\n\"\"\"Quality metrics used to evaluate the masks.\n\n    Attributes:\n        Fluorescence (foreign key): Primary key from Fluorescence.\n        Segmentation.Mask (foreign key): Primary key from Segmentation.Mask.\n        mask_area (float): Mask area in square micrometer.\n        roundness (float): Roundness between 0 and 1. Values closer to 1 are rounder.\n    \"\"\"\n\n    definition = \"\"\"\n    -&gt; master\n    -&gt; Segmentation.Mask\n    ---\n    mask_area=null: float  # Mask area in square micrometer.\n    roundness: float       # Roundness between 0 and 1. Values closer to 1 are rounder.\n    \"\"\"\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging/#element_calcium_imaging.imaging.ProcessingQualityMetrics.Trace", "title": "<code>Trace</code>", "text": "<p>         Bases: <code>dj.Part</code></p> <p>Quality metrics used to evaluate the fluorescence traces.</p> <p>Attributes:</p> Name Type Description <code>Fluorescence</code> <code>foreign key</code> <p>Primary key from Fluorescence.</p> <code>Fluorescence.Trace</code> <code>foreign key</code> <p>Primary key from Fluorescence.Trace.</p> <code>skewness</code> <code>float</code> <p>Skewness of the fluorescence trace.</p> <code>variance</code> <code>float</code> <p>Variance of the fluorescence trace.</p> Source code in <code>element_calcium_imaging/imaging.py</code> <pre><code>class Trace(dj.Part):\n\"\"\"Quality metrics used to evaluate the fluorescence traces.\n\n    Attributes:\n        Fluorescence (foreign key): Primary key from Fluorescence.\n        Fluorescence.Trace (foreign key): Primary key from Fluorescence.Trace.\n        skewness (float): Skewness of the fluorescence trace.\n        variance (float): Variance of the fluorescence trace.\n    \"\"\"\n\n    definition = \"\"\"\n    -&gt; master\n    -&gt; Fluorescence.Trace\n    ---\n    skewness: float   # Skewness of the fluorescence trace.\n    variance: float   # Variance of the fluorescence trace.\n    \"\"\"\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging/#element_calcium_imaging.imaging.ProcessingQualityMetrics.make", "title": "<code>make(key)</code>", "text": "<p>Populate the ProcessingQualityMetrics table and its part tables.</p> Source code in <code>element_calcium_imaging/imaging.py</code> <pre><code>def make(self, key):\n\"\"\"Populate the ProcessingQualityMetrics table and its part tables.\"\"\"\n    from scipy.stats import skew\n\n    (\n        mask_xpixs,\n        mask_ypixs,\n        mask_weights,\n        fluorescence,\n        fluo_channels,\n        mask_ids,\n        mask_npix,\n        px_height,\n        px_width,\n        um_height,\n        um_width,\n    ) = (Segmentation.Mask * scan.ScanInfo.Field * Fluorescence.Trace &amp; key).fetch(\n        \"mask_xpix\",\n        \"mask_ypix\",\n        \"mask_weights\",\n        \"fluorescence\",\n        \"fluo_channel\",\n        \"mask\",\n        \"mask_npix\",\n        \"px_height\",\n        \"px_width\",\n        \"um_height\",\n        \"um_width\",\n    )\n\n    norm_mean = lambda x: x.mean() / x.max()\n    roundnesses = [\n        norm_mean(np.linalg.eigvals(np.cov(x, y, aweights=w)))\n        for x, y, w in zip(mask_xpixs, mask_ypixs, mask_weights)\n    ]\n\n    fluorescence = np.stack(fluorescence)\n\n    self.insert1(key)\n\n    self.Mask.insert(\n        dict(key, mask=mask_id, mask_area=mask_area, roundness=roundness)\n        for mask_id, mask_area, roundness in zip(\n            mask_ids,\n            mask_npix * (um_height / px_height) * (um_width / px_width),\n            roundnesses,\n        )\n    )\n\n    self.Trace.insert(\n        dict(\n            key,\n            fluo_channel=fluo_channel,\n            mask=mask_id,\n            skewness=skewness,\n            variance=variance,\n        )\n        for fluo_channel, mask_id, skewness, variance in zip(\n            fluo_channels,\n            mask_ids,\n            skew(fluorescence, axis=1),\n            fluorescence.std(axis=1),\n        )\n    )\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging/#element_calcium_imaging.imaging.get_loader_result", "title": "<code>get_loader_result(key, table)</code>", "text": "<p>Retrieve the processed imaging results from a suite2p or caiman loader.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>dict</code> <p>The <code>key</code> to one entry of ProcessingTask or Curation</p> required <code>table</code> <code>dj.Table</code> <p>A datajoint table to retrieve the loaded results from (e.g. ProcessingTask, Curation)</p> required <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If the processing_method is different than 'suite2p' or 'caiman'.</p> <p>Returns:</p> Type Description <code>Callable</code> <p>A loader object of the loaded results (e.g. suite2p.Suite2p or caiman.CaImAn,</p> <code>Callable</code> <p>see element-interface for more information on the loaders.)</p> Source code in <code>element_calcium_imaging/imaging.py</code> <pre><code>def get_loader_result(key: dict, table: dj.Table) -&gt; Callable:\n\"\"\"Retrieve the processed imaging results from a suite2p or caiman loader.\n\n    Args:\n        key (dict): The `key` to one entry of ProcessingTask or Curation\n        table (dj.Table): A datajoint table to retrieve the loaded results from (e.g.\n            ProcessingTask, Curation)\n\n    Raises:\n        NotImplementedError: If the processing_method is different than 'suite2p' or\n            'caiman'.\n\n    Returns:\n        A loader object of the loaded results (e.g. suite2p.Suite2p or caiman.CaImAn,\n        see element-interface for more information on the loaders.)\n    \"\"\"\n    method, output_dir = (ProcessingParamSet * table &amp; key).fetch1(\n        \"processing_method\", _table_attribute_mapper[table.__name__]\n    )\n\n    output_path = find_full_path(get_imaging_root_data_dir(), output_dir)\n\n    if method == \"suite2p\" or (\n        method == \"extract\" and table.__name__ == \"MotionCorrection\"\n    ):\n        from element_interface import suite2p_loader\n\n        loaded_dataset = suite2p_loader.Suite2p(output_path)\n    elif method == \"caiman\":\n        from element_interface import caiman_loader\n\n        loaded_dataset = caiman_loader.CaImAn(output_path)\n    elif method == \"extract\":\n        from element_interface import extract_loader\n\n        loaded_dataset = extract_loader.EXTRACT(output_path)\n    else:\n        raise NotImplementedError(\"Unknown/unimplemented method: {}\".format(method))\n\n    return method, loaded_dataset\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_no_curation/", "title": "imaging_no_curation.py", "text": ""}, {"location": "api/element_calcium_imaging/imaging_no_curation/#element_calcium_imaging.imaging_no_curation.activate", "title": "<code>activate(imaging_schema_name, scan_schema_name=None, *, create_schema=True, create_tables=True, linking_module=None)</code>", "text": "<p>Activate this schema.</p> <p>Parameters:</p> Name Type Description Default <code>imaging_schema_name</code> <code>str</code> <p>Schema name on the database server to activate the <code>imaging</code> module.</p> required <code>scan_schema_name</code> <code>str</code> <p>Schema name on the database server to activate the <code>scan</code> module. Omitted, if the <code>scan</code> module is already activated.</p> <code>None</code> <code>create_schema</code> <code>bool</code> <p>When True (default), create schema in the database if it does not yet exist.</p> <code>True</code> <code>create_tables</code> <code>bool</code> <p>When True (default), create tables in the database if they do not yet exist.</p> <code>True</code> <code>linking_module</code> <code>str</code> <p>A module name or a module containing the required dependencies to activate the <code>imaging</code> module: + all that are required by the <code>scan</code> module.</p> <code>None</code> <p>Dependencies:</p> Upstream tables <ul> <li>Session: A parent table to Scan, identifying a scanning session.</li> <li>Equipment: A parent table to Scan, identifying a scanning device.</li> </ul> Source code in <code>element_calcium_imaging/imaging_no_curation.py</code> <pre><code>def activate(\n    imaging_schema_name: str,\n    scan_schema_name: str = None,\n    *,\n    create_schema: bool = True,\n    create_tables: bool = True,\n    linking_module: str = None,\n):\n\"\"\"Activate this schema.\n\n    Args:\n        imaging_schema_name (str): Schema name on the database server to activate the\n            `imaging` module.\n        scan_schema_name (str): Schema name on the database server to activate the\n            `scan` module. Omitted, if the `scan` module is already activated.\n        create_schema (bool): When True (default), create schema in the database if it\n            does not yet exist.\n        create_tables (bool): When True (default), create tables in the database if they\n            do not yet exist.\n        linking_module (str): A module name or a module containing the required\n            dependencies to activate the `imaging` module: + all that are required by\n            the `scan` module.\n\n    Dependencies:\n    Upstream tables:\n        + Session: A parent table to Scan, identifying a scanning session.\n        + Equipment: A parent table to Scan, identifying a scanning device.\n    \"\"\"\n\n    if isinstance(linking_module, str):\n        linking_module = importlib.import_module(linking_module)\n    assert inspect.ismodule(\n        linking_module\n    ), \"The argument 'dependency' must be a module's name or a module\"\n\n    global _linking_module\n    _linking_module = linking_module\n\n    scan.activate(\n        scan_schema_name,\n        create_schema=create_schema,\n        create_tables=create_tables,\n        linking_module=linking_module,\n    )\n    schema.activate(\n        imaging_schema_name,\n        create_schema=create_schema,\n        create_tables=create_tables,\n        add_objects=_linking_module.__dict__,\n    )\n    imaging_report.activate(f\"{imaging_schema_name}_report\", imaging_schema_name)\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_no_curation/#element_calcium_imaging.imaging_no_curation.get_imaging_root_data_dir", "title": "<code>get_imaging_root_data_dir()</code>", "text": "<p>Return imaging root data director(y/ies)</p> <p>Retrieve the root data director(y/ies) containing the imaging data for all subjects/sessions (e.g. acquired ScanImage raw files, output files from processing routines, etc.). All data paths and directories in DataJoint Elements are recommended to be stored as relative paths (posix format), with respect to some user-configured \"root\" directory, which varies from machine to machine (e.g. different mounted drive locations).</p> <p>Returns:</p> Name Type Description <code>dirs</code> <code>list</code> <p>A list of string(s) or Path(s) for the absolute paths of the imaging root data director(y/ies).</p> Source code in <code>element_calcium_imaging/scan.py</code> <pre><code>def get_imaging_root_data_dir() -&gt; list:\n\"\"\"Return imaging root data director(y/ies)\n\n    Retrieve the root data director(y/ies) containing the imaging data\n    for all subjects/sessions (e.g. acquired ScanImage raw files, output files from\n    processing routines, etc.). All data paths and directories in DataJoint Elements are\n    recommended to be stored as relative paths (posix format), with respect to some\n    user-configured \"root\" directory, which varies from machine to machine\n    (e.g. different mounted drive locations).\n\n    Returns:\n        dirs (list): A list of string(s) or Path(s) for the absolute paths of the imaging root data\n            director(y/ies).\n    \"\"\"\n\n    root_directories = _linking_module.get_imaging_root_data_dir()\n    if isinstance(root_directories, (str, pathlib.Path)):\n        root_directories = [root_directories]\n\n    if hasattr(_linking_module, \"get_processed_root_data_dir\"):\n        root_directories.append(_linking_module.get_processed_root_data_dir())\n\n    return root_directories\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_no_curation/#element_calcium_imaging.imaging_no_curation.ProcessingMethod", "title": "<code>ProcessingMethod</code>", "text": "<p>         Bases: <code>dj.Lookup</code></p> <p>Package used for processing of calcium imaging data (e.g. Suite2p, CaImAn, etc.).</p> <p>Attributes:</p> Name Type Description <code>processing_method</code> <code>str</code> <p>Processing method.</p> <code>processing_method_desc</code> <code>str</code> <p>Processing method description.</p> Source code in <code>element_calcium_imaging/imaging_no_curation.py</code> <pre><code>@schema\nclass ProcessingMethod(dj.Lookup):\n\"\"\"Package used for processing of calcium imaging data (e.g. Suite2p, CaImAn, etc.).\n\n    Attributes:\n        processing_method (str): Processing method.\n        processing_method_desc (str): Processing method description.\n    \"\"\"\n\n    definition = \"\"\"# Package used for processing of calcium imaging data (e.g. Suite2p, CaImAn, etc.).\n    processing_method: char(8)\n    ---\n    processing_method_desc: varchar(1000)  # Processing method description\n    \"\"\"\n\n    contents = [\n        (\"suite2p\", \"suite2p analysis suite\"),\n        (\"caiman\", \"caiman analysis suite\"),\n        (\"extract\", \"extract analysis suite\"),\n    ]\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_no_curation/#element_calcium_imaging.imaging_no_curation.get_processed_root_data_dir", "title": "<code>get_processed_root_data_dir()</code>", "text": "<p>Retrieve the root directory for all processed data.</p> <p>All data paths and directories in DataJoint Elements are recommended to be stored as relative paths (posix format), with respect to some user-configured \"root\" directory, which varies from machine to machine (e.g. different mounted drive locations).</p> <p>Returns:</p> Name Type Description <code>dir</code> <code>str | pathlib.Path</code> <p>Absolute path of the processed imaging root data directory.</p> Source code in <code>element_calcium_imaging/scan.py</code> <pre><code>def get_processed_root_data_dir() -&gt; Union[str, pathlib.Path]:\n\"\"\"Retrieve the root directory for all processed data.\n\n    All data paths and directories in DataJoint Elements are recommended to be stored as\n    relative paths (posix format), with respect to some user-configured \"root\"\n    directory, which varies from machine to machine (e.g. different mounted drive\n    locations).\n\n    Returns:\n        dir (str| pathlib.Path): Absolute path of the processed imaging root data\n            directory.\n    \"\"\"\n\n    if hasattr(_linking_module, \"get_processed_root_data_dir\"):\n        return _linking_module.get_processed_root_data_dir()\n    else:\n        return get_imaging_root_data_dir()[0]\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_no_curation/#element_calcium_imaging.imaging_no_curation.ProcessingParamSet", "title": "<code>ProcessingParamSet</code>", "text": "<p>         Bases: <code>dj.Lookup</code></p> <p>Parameter set used for the processing of the calcium imaging scans, including both the analysis suite and its respective input parameters.</p> <p>A hash of the parameters of the analysis suite is also stored in order to avoid duplicated entries.</p> <p>Attributes:</p> Name Type Description <code>paramset_idx</code> <code>int</code> <p>Unique parameter set ID.</p> <code>ProcessingMethod</code> <code>foreign key</code> <p>A primary key from ProcessingMethod.</p> <code>paramset_desc</code> <code>str</code> <p>Parameter set description.</p> <code>param_set_hash</code> <code>uuid</code> <p>A universally unique identifier for the parameter set.</p> <code>params</code> <code>longblob</code> <p>Parameter Set, a dictionary of all applicable parameters to the analysis suite.</p> Source code in <code>element_calcium_imaging/imaging_no_curation.py</code> <pre><code>@schema\nclass ProcessingParamSet(dj.Lookup):\n\"\"\"Parameter set used for the processing of the calcium imaging scans,\n    including both the analysis suite and its respective input parameters.\n\n    A hash of the parameters of the analysis suite is also stored in order\n    to avoid duplicated entries.\n\n    Attributes:\n        paramset_idx (int): Unique parameter set ID.\n        ProcessingMethod (foreign key): A primary key from ProcessingMethod.\n        paramset_desc (str): Parameter set description.\n        param_set_hash (uuid): A universally unique identifier for the parameter set.\n        params (longblob): Parameter Set, a dictionary of all applicable parameters to\n            the analysis suite.\n    \"\"\"\n\n    definition = \"\"\"# Processing Parameter Set\n    paramset_idx: smallint  # Unique parameter set ID.\n    ---\n    -&gt; ProcessingMethod\n    paramset_desc: varchar(1280)  # Parameter-set description\n    param_set_hash: uuid  # A universally unique identifier for the parameter set\n    unique index (param_set_hash)\n    params: longblob  # Parameter Set, a dictionary of all applicable parameters to the analysis suite.\n    \"\"\"\n\n    @classmethod\n    def insert_new_params(\n        cls,\n        processing_method: str,\n        paramset_idx: int,\n        paramset_desc: str,\n        params: dict,\n    ):\n\"\"\"Insert a parameter set into ProcessingParamSet table.\n\n        This function automates the parameter set hashing and avoids insertion of an\n            existing parameter set.\n\n        Attributes:\n            processing_method (str): Processing method/package used for processing of\n                calcium imaging.\n            paramset_idx (int): Unique parameter set ID.\n            paramset_desc (str): Parameter set description.\n            params (dict): Parameter Set, all applicable parameters to the analysis\n                suite.\n        \"\"\"\n        if processing_method == \"extract\":\n            assert (\n                params.get(\"extract\") is not None and params.get(\"suite2p\") is not None\n            ), ValueError(\n                \"Please provide the processing parameters in the {'suite2p': {...}, 'extract': {...}} dictionary format.\"\n            )\n\n            # Force Suite2p to only run motion correction.\n            params[\"suite2p\"][\"do_registration\"] = True\n            params[\"suite2p\"][\"roidetect\"] = False\n\n        param_dict = {\n            \"processing_method\": processing_method,\n            \"paramset_idx\": paramset_idx,\n            \"paramset_desc\": paramset_desc,\n            \"params\": params,\n            \"param_set_hash\": dict_to_uuid(params),\n        }\n        q_param = cls &amp; {\"param_set_hash\": param_dict[\"param_set_hash\"]}\n\n        if q_param:  # If the specified param-set already exists\n            p_name = q_param.fetch1(\"paramset_idx\")\n            if p_name == paramset_idx:  # If the existed set has the same name: job done\n                return\n            else:  # If not same name: human error, trying to add the same paramset with different name\n                raise dj.DataJointError(\n                    \"The specified param-set already exists - name: {}\".format(p_name)\n                )\n        else:\n            cls.insert1(param_dict)\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_no_curation/#element_calcium_imaging.imaging_no_curation.ProcessingParamSet.insert_new_params", "title": "<code>insert_new_params(processing_method, paramset_idx, paramset_desc, params)</code>  <code>classmethod</code>", "text": "<p>Insert a parameter set into ProcessingParamSet table.</p> <p>This function automates the parameter set hashing and avoids insertion of an     existing parameter set.</p> <p>Attributes:</p> Name Type Description <code>processing_method</code> <code>str</code> <p>Processing method/package used for processing of calcium imaging.</p> <code>paramset_idx</code> <code>int</code> <p>Unique parameter set ID.</p> <code>paramset_desc</code> <code>str</code> <p>Parameter set description.</p> <code>params</code> <code>dict</code> <p>Parameter Set, all applicable parameters to the analysis suite.</p> Source code in <code>element_calcium_imaging/imaging_no_curation.py</code> <pre><code>@classmethod\ndef insert_new_params(\n    cls,\n    processing_method: str,\n    paramset_idx: int,\n    paramset_desc: str,\n    params: dict,\n):\n\"\"\"Insert a parameter set into ProcessingParamSet table.\n\n    This function automates the parameter set hashing and avoids insertion of an\n        existing parameter set.\n\n    Attributes:\n        processing_method (str): Processing method/package used for processing of\n            calcium imaging.\n        paramset_idx (int): Unique parameter set ID.\n        paramset_desc (str): Parameter set description.\n        params (dict): Parameter Set, all applicable parameters to the analysis\n            suite.\n    \"\"\"\n    if processing_method == \"extract\":\n        assert (\n            params.get(\"extract\") is not None and params.get(\"suite2p\") is not None\n        ), ValueError(\n            \"Please provide the processing parameters in the {'suite2p': {...}, 'extract': {...}} dictionary format.\"\n        )\n\n        # Force Suite2p to only run motion correction.\n        params[\"suite2p\"][\"do_registration\"] = True\n        params[\"suite2p\"][\"roidetect\"] = False\n\n    param_dict = {\n        \"processing_method\": processing_method,\n        \"paramset_idx\": paramset_idx,\n        \"paramset_desc\": paramset_desc,\n        \"params\": params,\n        \"param_set_hash\": dict_to_uuid(params),\n    }\n    q_param = cls &amp; {\"param_set_hash\": param_dict[\"param_set_hash\"]}\n\n    if q_param:  # If the specified param-set already exists\n        p_name = q_param.fetch1(\"paramset_idx\")\n        if p_name == paramset_idx:  # If the existed set has the same name: job done\n            return\n        else:  # If not same name: human error, trying to add the same paramset with different name\n            raise dj.DataJointError(\n                \"The specified param-set already exists - name: {}\".format(p_name)\n            )\n    else:\n        cls.insert1(param_dict)\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_no_curation/#element_calcium_imaging.imaging_no_curation.get_image_files", "title": "<code>get_image_files(scan_key, file_type)</code>", "text": "<p>Retrieve the list of image files associated with a given Scan.</p> <p>Parameters:</p> Name Type Description Default <code>scan_key</code> <code>dict</code> <p>Primary key of a Scan entry.</p> required <p>Returns:</p> Type Description <code>list</code> <p>A list of full file paths.</p> Source code in <code>element_calcium_imaging/scan.py</code> <pre><code>def get_image_files(scan_key: dict, file_type: str) -&gt; list:\n\"\"\"Retrieve the list of image files associated with a given Scan.\n\n    Args:\n        scan_key: Primary key of a Scan entry.\n\n    Returns:\n        A list of full file paths.\n    \"\"\"\n    return _linking_module.get_image_files(scan_key, file_type)\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_no_curation/#element_calcium_imaging.imaging_no_curation.CellCompartment", "title": "<code>CellCompartment</code>", "text": "<p>         Bases: <code>dj.Lookup</code></p> <p>Cell compartments that can be imaged (e.g. 'axon', 'soma', etc.)</p> <p>Attributes:</p> Name Type Description <code>cell_compartment</code> <code>str</code> <p>Cell compartment.</p> Source code in <code>element_calcium_imaging/imaging_no_curation.py</code> <pre><code>@schema\nclass CellCompartment(dj.Lookup):\n\"\"\"Cell compartments that can be imaged (e.g. 'axon', 'soma', etc.)\n\n    Attributes:\n        cell_compartment (str): Cell compartment.\n    \"\"\"\n\n    definition = \"\"\"# Cell compartments\n    cell_compartment: char(16)\n    \"\"\"\n\n    contents = zip([\"axon\", \"soma\", \"bouton\"])\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_no_curation/#element_calcium_imaging.imaging_no_curation.MaskType", "title": "<code>MaskType</code>", "text": "<p>         Bases: <code>dj.Lookup</code></p> <p>Available labels for segmented masks (e.g. 'soma', 'axon', 'dendrite', 'neuropil').</p> <p>Attributes:</p> Name Type Description <code>mask_type</code> <code>str</code> <p>Mask type.</p> Source code in <code>element_calcium_imaging/imaging_no_curation.py</code> <pre><code>@schema\nclass MaskType(dj.Lookup):\n\"\"\"Available labels for segmented masks (e.g. 'soma', 'axon', 'dendrite', 'neuropil').\n\n    Attributes:\n        mask_type (str): Mask type.\n    \"\"\"\n\n    definition = \"\"\"# Possible types of a segmented mask\n    mask_type: varchar(16)\n    \"\"\"\n\n    contents = zip([\"soma\", \"axon\", \"dendrite\", \"neuropil\", \"artefact\", \"unknown\"])\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_no_curation/#element_calcium_imaging.imaging_no_curation.ProcessingTask", "title": "<code>ProcessingTask</code>", "text": "<p>         Bases: <code>dj.Manual</code></p> <p>A pairing of processing params and scans to be loaded or triggered</p> <p>This table defines a calcium imaging processing task for a combination of a <code>Scan</code> and a <code>ProcessingParamSet</code> entries, including all the inputs (scan, method, method's parameters). The task defined here is then run in the downstream table <code>Processing</code>. This table supports definitions of both loading of pre-generated results and the triggering of new analysis for all supported analysis methods.</p> <p>Attributes:</p> Name Type Description <code>scan.Scan</code> <code>foreign key</code> <p>Primary key from scan.Scan.</p> <code>ProcessingParamSet</code> <code>foreign key</code> <p>Primary key from ProcessingParamSet.</p> <code>processing_output_dir</code> <code>str</code> <p>Output directory of the processed scan relative to the root data directory.</p> <code>task_mode</code> <code>str</code> <p>One of 'load' (load computed analysis results) or 'trigger' (trigger computation).</p> Source code in <code>element_calcium_imaging/imaging_no_curation.py</code> <pre><code>@schema\nclass ProcessingTask(dj.Manual):\n\"\"\"A pairing of processing params and scans to be loaded or triggered\n\n    This table defines a calcium imaging processing task for a combination of a\n    `Scan` and a `ProcessingParamSet` entries, including all the inputs (scan, method,\n    method's parameters). The task defined here is then run in the downstream table\n    `Processing`. This table supports definitions of both loading of pre-generated results\n    and the triggering of new analysis for all supported analysis methods.\n\n    Attributes:\n        scan.Scan (foreign key): Primary key from scan.Scan.\n        ProcessingParamSet (foreign key): Primary key from ProcessingParamSet.\n        processing_output_dir (str): Output directory of the processed scan relative to the root data directory.\n        task_mode (str): One of 'load' (load computed analysis results) or 'trigger'\n            (trigger computation).\n    \"\"\"\n\n    definition = \"\"\"# Manual table for defining a processing task ready to be run\n    -&gt; scan.Scan\n    -&gt; ProcessingParamSet\n    ---\n    processing_output_dir: varchar(255)  #  Output directory of the processed scan relative to root data directory\n    task_mode='load': enum('load', 'trigger')  # 'load': load computed analysis results, 'trigger': trigger computation\n    \"\"\"\n\n    @classmethod\n    def infer_output_dir(cls, key, relative=False, mkdir=False):\n\"\"\"Infer an output directory for an entry in ProcessingTask table.\n\n        Args:\n            key (dict): Primary key from the ProcessingTask table.\n            relative (bool): If True, processing_output_dir is returned relative to\n                imaging_root_dir. Default False.\n            mkdir (bool): If True, create the processing_output_dir directory.\n                Default True.\n\n        Returns:\n            dir (str): A default output directory for the processed results (processed_output_dir\n                in ProcessingTask) based on the following convention:\n                processed_dir / scan_dir / {processing_method}_{paramset_idx}\n                e.g.: sub4/sess1/scan0/suite2p_0\n        \"\"\"\n        acq_software = (scan.Scan &amp; key).fetch1(\"acq_software\")\n        filetypes = dict(\n            ScanImage=\"*.tif\", Scanbox=\"*.sbx\", NIS=\"*.nd2\", PrairieView=\"*.tif\"\n        )\n\n        scan_dir = find_full_path(\n            get_imaging_root_data_dir(),\n            get_image_files(key, filetypes[acq_software])[0],\n        ).parent\n        root_dir = find_root_directory(get_imaging_root_data_dir(), scan_dir)\n\n        method = (\n            (ProcessingParamSet &amp; key).fetch1(\"processing_method\").replace(\".\", \"-\")\n        )\n\n        processed_dir = pathlib.Path(get_processed_root_data_dir())\n        output_dir = (\n            processed_dir\n            / scan_dir.relative_to(root_dir)\n            / f'{method}_{key[\"paramset_idx\"]}'\n        )\n\n        if mkdir:\n            output_dir.mkdir(parents=True, exist_ok=True)\n\n        return output_dir.relative_to(processed_dir) if relative else output_dir\n\n    @classmethod\n    def generate(cls, scan_key, paramset_idx=0):\n\"\"\"Generate a ProcessingTask for a Scan using an parameter ProcessingParamSet\n\n        Generate an entry in the ProcessingTask table for a particular scan using an\n        existing parameter set from the ProcessingParamSet table.\n\n        Args:\n            scan_key (dict): Primary key from Scan table.\n            paramset_idx (int): Unique parameter set ID.\n        \"\"\"\n        key = {**scan_key, \"paramset_idx\": paramset_idx}\n\n        processed_dir = get_processed_root_data_dir()\n        output_dir = cls.infer_output_dir(key, relative=False, mkdir=True)\n\n        method = (ProcessingParamSet &amp; {\"paramset_idx\": paramset_idx}).fetch1(\n            \"processing_method\"\n        )\n\n        try:\n            if method == \"suite2p\":\n                from element_interface import suite2p_loader\n\n                suite2p_loader.Suite2p(output_dir)\n            elif method == \"caiman\":\n                from element_interface import caiman_loader\n\n                caiman_loader.CaImAn(output_dir)\n            elif method == \"extract\":\n                from element_interface import extract_loader\n\n                extract_loader.EXTRACT(output_dir)\n\n            else:\n                raise NotImplementedError(\n                    \"Unknown/unimplemented method: {}\".format(method)\n                )\n        except FileNotFoundError:\n            task_mode = \"trigger\"\n        else:\n            task_mode = \"load\"\n\n        cls.insert1(\n            {\n                **key,\n                \"processing_output_dir\": output_dir.relative_to(\n                    processed_dir\n                ).as_posix(),\n                \"task_mode\": task_mode,\n            }\n        )\n\n    auto_generate_entries = generate\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_no_curation/#element_calcium_imaging.imaging_no_curation.ProcessingTask.infer_output_dir", "title": "<code>infer_output_dir(key, relative=False, mkdir=False)</code>  <code>classmethod</code>", "text": "<p>Infer an output directory for an entry in ProcessingTask table.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>dict</code> <p>Primary key from the ProcessingTask table.</p> required <code>relative</code> <code>bool</code> <p>If True, processing_output_dir is returned relative to imaging_root_dir. Default False.</p> <code>False</code> <code>mkdir</code> <code>bool</code> <p>If True, create the processing_output_dir directory. Default True.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>dir</code> <code>str</code> <p>A default output directory for the processed results (processed_output_dir in ProcessingTask) based on the following convention: processed_dir / scan_dir / {processing_method}_{paramset_idx} e.g.: sub4/sess1/scan0/suite2p_0</p> Source code in <code>element_calcium_imaging/imaging_no_curation.py</code> <pre><code>@classmethod\ndef infer_output_dir(cls, key, relative=False, mkdir=False):\n\"\"\"Infer an output directory for an entry in ProcessingTask table.\n\n    Args:\n        key (dict): Primary key from the ProcessingTask table.\n        relative (bool): If True, processing_output_dir is returned relative to\n            imaging_root_dir. Default False.\n        mkdir (bool): If True, create the processing_output_dir directory.\n            Default True.\n\n    Returns:\n        dir (str): A default output directory for the processed results (processed_output_dir\n            in ProcessingTask) based on the following convention:\n            processed_dir / scan_dir / {processing_method}_{paramset_idx}\n            e.g.: sub4/sess1/scan0/suite2p_0\n    \"\"\"\n    acq_software = (scan.Scan &amp; key).fetch1(\"acq_software\")\n    filetypes = dict(\n        ScanImage=\"*.tif\", Scanbox=\"*.sbx\", NIS=\"*.nd2\", PrairieView=\"*.tif\"\n    )\n\n    scan_dir = find_full_path(\n        get_imaging_root_data_dir(),\n        get_image_files(key, filetypes[acq_software])[0],\n    ).parent\n    root_dir = find_root_directory(get_imaging_root_data_dir(), scan_dir)\n\n    method = (\n        (ProcessingParamSet &amp; key).fetch1(\"processing_method\").replace(\".\", \"-\")\n    )\n\n    processed_dir = pathlib.Path(get_processed_root_data_dir())\n    output_dir = (\n        processed_dir\n        / scan_dir.relative_to(root_dir)\n        / f'{method}_{key[\"paramset_idx\"]}'\n    )\n\n    if mkdir:\n        output_dir.mkdir(parents=True, exist_ok=True)\n\n    return output_dir.relative_to(processed_dir) if relative else output_dir\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_no_curation/#element_calcium_imaging.imaging_no_curation.ProcessingTask.generate", "title": "<code>generate(scan_key, paramset_idx=0)</code>  <code>classmethod</code>", "text": "<p>Generate a ProcessingTask for a Scan using an parameter ProcessingParamSet</p> <p>Generate an entry in the ProcessingTask table for a particular scan using an existing parameter set from the ProcessingParamSet table.</p> <p>Parameters:</p> Name Type Description Default <code>scan_key</code> <code>dict</code> <p>Primary key from Scan table.</p> required <code>paramset_idx</code> <code>int</code> <p>Unique parameter set ID.</p> <code>0</code> Source code in <code>element_calcium_imaging/imaging_no_curation.py</code> <pre><code>@classmethod\ndef generate(cls, scan_key, paramset_idx=0):\n\"\"\"Generate a ProcessingTask for a Scan using an parameter ProcessingParamSet\n\n    Generate an entry in the ProcessingTask table for a particular scan using an\n    existing parameter set from the ProcessingParamSet table.\n\n    Args:\n        scan_key (dict): Primary key from Scan table.\n        paramset_idx (int): Unique parameter set ID.\n    \"\"\"\n    key = {**scan_key, \"paramset_idx\": paramset_idx}\n\n    processed_dir = get_processed_root_data_dir()\n    output_dir = cls.infer_output_dir(key, relative=False, mkdir=True)\n\n    method = (ProcessingParamSet &amp; {\"paramset_idx\": paramset_idx}).fetch1(\n        \"processing_method\"\n    )\n\n    try:\n        if method == \"suite2p\":\n            from element_interface import suite2p_loader\n\n            suite2p_loader.Suite2p(output_dir)\n        elif method == \"caiman\":\n            from element_interface import caiman_loader\n\n            caiman_loader.CaImAn(output_dir)\n        elif method == \"extract\":\n            from element_interface import extract_loader\n\n            extract_loader.EXTRACT(output_dir)\n\n        else:\n            raise NotImplementedError(\n                \"Unknown/unimplemented method: {}\".format(method)\n            )\n    except FileNotFoundError:\n        task_mode = \"trigger\"\n    else:\n        task_mode = \"load\"\n\n    cls.insert1(\n        {\n            **key,\n            \"processing_output_dir\": output_dir.relative_to(\n                processed_dir\n            ).as_posix(),\n            \"task_mode\": task_mode,\n        }\n    )\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_no_curation/#element_calcium_imaging.imaging_no_curation.Processing", "title": "<code>Processing</code>", "text": "<p>         Bases: <code>dj.Computed</code></p> <p>Perform the computation of an entry (task) defined in the ProcessingTask table. The computation is performed only on the scans with ScanInfo inserted.</p> <p>Attributes:</p> Name Type Description <code>ProcessingTask</code> <code>foreign key</code> <p>Primary key from ProcessingTask.</p> <code>processing_time</code> <code>datetime</code> <p>Process completion datetime.</p> <code>package_version</code> <code>str</code> <p>Version of the analysis package used in processing the data.</p> Source code in <code>element_calcium_imaging/imaging_no_curation.py</code> <pre><code>@schema\nclass Processing(dj.Computed):\n\"\"\"Perform the computation of an entry (task) defined in the ProcessingTask table.\n    The computation is performed only on the scans with ScanInfo inserted.\n\n    Attributes:\n        ProcessingTask (foreign key): Primary key from ProcessingTask.\n        processing_time (datetime): Process completion datetime.\n        package_version (str, optional): Version of the analysis package used in\n            processing the data.\n    \"\"\"\n\n    definition = \"\"\"\n    -&gt; ProcessingTask\n    ---\n    processing_time     : datetime  # Time of generation of this set of processed, segmented results\n    package_version=''  : varchar(16)\n    \"\"\"\n\n    # Run processing only on Scan with ScanInfo inserted\n    @property\n    def key_source(self):\n\"\"\"Limit the Processing to Scans that have their metadata ingested to the\n        database.\"\"\"\n\n        return ProcessingTask &amp; scan.ScanInfo\n\n    def make(self, key):\n\"\"\"Execute the calcium imaging analysis defined by the ProcessingTask.\"\"\"\n\n        task_mode, output_dir = (ProcessingTask &amp; key).fetch1(\n            \"task_mode\", \"processing_output_dir\"\n        )\n\n        if not output_dir:\n            output_dir = ProcessingTask.infer_output_dir(key, relative=True, mkdir=True)\n            # update processing_output_dir\n            ProcessingTask.update1(\n                {**key, \"processing_output_dir\": output_dir.as_posix()}\n            )\n        output_dir = find_full_path(get_imaging_root_data_dir(), output_dir).as_posix()\n\n        if task_mode == \"load\":\n            method, imaging_dataset = get_loader_result(key, ProcessingTask)\n            if method == \"suite2p\":\n                if (scan.ScanInfo &amp; key).fetch1(\"nrois\") &gt; 0:\n                    raise NotImplementedError(\n                        \"Suite2p ingestion error - Unable to handle\"\n                        + \" ScanImage multi-ROI scanning mode yet\"\n                    )\n                suite2p_dataset = imaging_dataset\n                key = {**key, \"processing_time\": suite2p_dataset.creation_time}\n            elif method == \"caiman\":\n                caiman_dataset = imaging_dataset\n                key = {**key, \"processing_time\": caiman_dataset.creation_time}\n            elif method == \"extract\":\n                raise NotImplementedError(\n                    \"To use EXTRACT with this DataJoint Element please set `task_mode=trigger`\"\n                )\n            else:\n                raise NotImplementedError(\"Unknown method: {}\".format(method))\n        elif task_mode == \"trigger\":\n            method = (ProcessingParamSet * ProcessingTask &amp; key).fetch1(\n                \"processing_method\"\n            )\n\n            image_files = (scan.ScanInfo.ScanFile &amp; key).fetch(\"file_path\")\n            image_files = [\n                find_full_path(get_imaging_root_data_dir(), image_file)\n                for image_file in image_files\n            ]\n\n            if method == \"suite2p\":\n                import suite2p\n\n                suite2p_params = (ProcessingTask * ProcessingParamSet &amp; key).fetch1(\n                    \"params\"\n                )\n                suite2p_params[\"save_path0\"] = output_dir\n                (\n                    suite2p_params[\"fs\"],\n                    suite2p_params[\"nplanes\"],\n                    suite2p_params[\"nchannels\"],\n                ) = (scan.ScanInfo &amp; key).fetch1(\"fps\", \"ndepths\", \"nchannels\")\n\n                input_format = pathlib.Path(image_files[0]).suffix\n                suite2p_params[\"input_format\"] = input_format[1:]\n\n                suite2p_paths = {\n                    \"data_path\": [image_files[0].parent.as_posix()],\n                    \"tiff_list\": [f.as_posix() for f in image_files],\n                }\n\n                suite2p.run_s2p(ops=suite2p_params, db=suite2p_paths)  # Run suite2p\n\n                _, imaging_dataset = get_loader_result(key, ProcessingTask)\n                suite2p_dataset = imaging_dataset\n                key = {**key, \"processing_time\": suite2p_dataset.creation_time}\n\n            elif method == \"caiman\":\n                from element_interface.caiman_loader import _process_scanimage_tiff\n                from element_interface.run_caiman import run_caiman\n\n                caiman_params = (ProcessingTask * ProcessingParamSet &amp; key).fetch1(\n                    \"params\"\n                )\n                sampling_rate, ndepths, nchannels = (scan.ScanInfo &amp; key).fetch1(\n                    \"fps\", \"ndepths\", \"nchannels\"\n                )\n\n                is3D = bool(ndepths &gt; 1)\n                if is3D:\n                    raise NotImplementedError(\n                        \"Caiman pipeline is not yet capable of analyzing 3D scans.\"\n                    )\n\n                # handle multi-channel tiff image before running CaImAn\n                if nchannels &gt; 1:\n                    channel_idx = caiman_params.get(\"channel_to_process\", 0)\n                    tmp_dir = pathlib.Path(output_dir) / \"channel_separated_tif\"\n                    tmp_dir.mkdir(exist_ok=True)\n                    _process_scanimage_tiff(\n                        [f.as_posix() for f in image_files], output_dir=tmp_dir\n                    )\n                    image_files = tmp_dir.glob(f\"*_chn{channel_idx}.tif\")\n\n                run_caiman(\n                    file_paths=[f.as_posix() for f in image_files],\n                    parameters=caiman_params,\n                    sampling_rate=sampling_rate,\n                    output_dir=output_dir,\n                    is3D=is3D,\n                )\n\n                _, imaging_dataset = get_loader_result(key, ProcessingTask)\n                caiman_dataset = imaging_dataset\n                key[\"processing_time\"] = caiman_dataset.creation_time\n\n            elif method == \"extract\":\n                import suite2p\n                from element_interface.extract_trigger import EXTRACT_trigger\n                from scipy.io import savemat\n\n                # Motion Correction with Suite2p\n                params = (ProcessingTask * ProcessingParamSet &amp; key).fetch1(\"params\")\n\n                params[\"suite2p\"][\"save_path0\"] = output_dir\n                (\n                    params[\"suite2p\"][\"fs\"],\n                    params[\"suite2p\"][\"nplanes\"],\n                    params[\"suite2p\"][\"nchannels\"],\n                ) = (scan.ScanInfo &amp; key).fetch1(\"fps\", \"ndepths\", \"nchannels\")\n\n                input_format = pathlib.Path(image_files[0]).suffix\n                params[\"suite2p\"][\"input_format\"] = input_format[1:]\n\n                suite2p_paths = {\n                    \"data_path\": [image_files[0].parent.as_posix()],\n                    \"tiff_list\": [f.as_posix() for f in image_files],\n                }\n\n                suite2p.run_s2p(ops=params[\"suite2p\"], db=suite2p_paths)\n\n                # Convert data.bin to registered_scans.mat\n                scanfile_fullpath = pathlib.Path(output_dir) / \"suite2p/plane0/data.bin\"\n\n                data_shape = (scan.ScanInfo * scan.ScanInfo.Field &amp; key).fetch1(\n                    \"nframes\", \"px_height\", \"px_width\"\n                )\n                data = np.memmap(scanfile_fullpath, shape=data_shape, dtype=np.int16)\n\n                scan_matlab_fullpath = scanfile_fullpath.parent / \"registered_scan.mat\"\n\n                # Save the motion corrected movie (data.bin) in a .mat file\n                savemat(\n                    scan_matlab_fullpath,\n                    {\"M\": np.transpose(data, axes=[1, 2, 0])},\n                )\n\n                # Execute EXTRACT\n\n                ex = EXTRACT_trigger(\n                    scan_matlab_fullpath, params[\"extract\"], output_dir\n                )\n                ex.run()\n\n                _, extract_dataset = get_loader_result(key, ProcessingTask)\n                key[\"processing_time\"] = extract_dataset.creation_time\n\n        else:\n            raise ValueError(f\"Unknown task mode: {task_mode}\")\n\n        self.insert1({**key, \"package_version\": \"\"})\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_no_curation/#element_calcium_imaging.imaging_no_curation.Processing.key_source", "title": "<code>key_source</code>  <code>property</code>", "text": "<p>Limit the Processing to Scans that have their metadata ingested to the database.</p>"}, {"location": "api/element_calcium_imaging/imaging_no_curation/#element_calcium_imaging.imaging_no_curation.Processing.make", "title": "<code>make(key)</code>", "text": "<p>Execute the calcium imaging analysis defined by the ProcessingTask.</p> Source code in <code>element_calcium_imaging/imaging_no_curation.py</code> <pre><code>def make(self, key):\n\"\"\"Execute the calcium imaging analysis defined by the ProcessingTask.\"\"\"\n\n    task_mode, output_dir = (ProcessingTask &amp; key).fetch1(\n        \"task_mode\", \"processing_output_dir\"\n    )\n\n    if not output_dir:\n        output_dir = ProcessingTask.infer_output_dir(key, relative=True, mkdir=True)\n        # update processing_output_dir\n        ProcessingTask.update1(\n            {**key, \"processing_output_dir\": output_dir.as_posix()}\n        )\n    output_dir = find_full_path(get_imaging_root_data_dir(), output_dir).as_posix()\n\n    if task_mode == \"load\":\n        method, imaging_dataset = get_loader_result(key, ProcessingTask)\n        if method == \"suite2p\":\n            if (scan.ScanInfo &amp; key).fetch1(\"nrois\") &gt; 0:\n                raise NotImplementedError(\n                    \"Suite2p ingestion error - Unable to handle\"\n                    + \" ScanImage multi-ROI scanning mode yet\"\n                )\n            suite2p_dataset = imaging_dataset\n            key = {**key, \"processing_time\": suite2p_dataset.creation_time}\n        elif method == \"caiman\":\n            caiman_dataset = imaging_dataset\n            key = {**key, \"processing_time\": caiman_dataset.creation_time}\n        elif method == \"extract\":\n            raise NotImplementedError(\n                \"To use EXTRACT with this DataJoint Element please set `task_mode=trigger`\"\n            )\n        else:\n            raise NotImplementedError(\"Unknown method: {}\".format(method))\n    elif task_mode == \"trigger\":\n        method = (ProcessingParamSet * ProcessingTask &amp; key).fetch1(\n            \"processing_method\"\n        )\n\n        image_files = (scan.ScanInfo.ScanFile &amp; key).fetch(\"file_path\")\n        image_files = [\n            find_full_path(get_imaging_root_data_dir(), image_file)\n            for image_file in image_files\n        ]\n\n        if method == \"suite2p\":\n            import suite2p\n\n            suite2p_params = (ProcessingTask * ProcessingParamSet &amp; key).fetch1(\n                \"params\"\n            )\n            suite2p_params[\"save_path0\"] = output_dir\n            (\n                suite2p_params[\"fs\"],\n                suite2p_params[\"nplanes\"],\n                suite2p_params[\"nchannels\"],\n            ) = (scan.ScanInfo &amp; key).fetch1(\"fps\", \"ndepths\", \"nchannels\")\n\n            input_format = pathlib.Path(image_files[0]).suffix\n            suite2p_params[\"input_format\"] = input_format[1:]\n\n            suite2p_paths = {\n                \"data_path\": [image_files[0].parent.as_posix()],\n                \"tiff_list\": [f.as_posix() for f in image_files],\n            }\n\n            suite2p.run_s2p(ops=suite2p_params, db=suite2p_paths)  # Run suite2p\n\n            _, imaging_dataset = get_loader_result(key, ProcessingTask)\n            suite2p_dataset = imaging_dataset\n            key = {**key, \"processing_time\": suite2p_dataset.creation_time}\n\n        elif method == \"caiman\":\n            from element_interface.caiman_loader import _process_scanimage_tiff\n            from element_interface.run_caiman import run_caiman\n\n            caiman_params = (ProcessingTask * ProcessingParamSet &amp; key).fetch1(\n                \"params\"\n            )\n            sampling_rate, ndepths, nchannels = (scan.ScanInfo &amp; key).fetch1(\n                \"fps\", \"ndepths\", \"nchannels\"\n            )\n\n            is3D = bool(ndepths &gt; 1)\n            if is3D:\n                raise NotImplementedError(\n                    \"Caiman pipeline is not yet capable of analyzing 3D scans.\"\n                )\n\n            # handle multi-channel tiff image before running CaImAn\n            if nchannels &gt; 1:\n                channel_idx = caiman_params.get(\"channel_to_process\", 0)\n                tmp_dir = pathlib.Path(output_dir) / \"channel_separated_tif\"\n                tmp_dir.mkdir(exist_ok=True)\n                _process_scanimage_tiff(\n                    [f.as_posix() for f in image_files], output_dir=tmp_dir\n                )\n                image_files = tmp_dir.glob(f\"*_chn{channel_idx}.tif\")\n\n            run_caiman(\n                file_paths=[f.as_posix() for f in image_files],\n                parameters=caiman_params,\n                sampling_rate=sampling_rate,\n                output_dir=output_dir,\n                is3D=is3D,\n            )\n\n            _, imaging_dataset = get_loader_result(key, ProcessingTask)\n            caiman_dataset = imaging_dataset\n            key[\"processing_time\"] = caiman_dataset.creation_time\n\n        elif method == \"extract\":\n            import suite2p\n            from element_interface.extract_trigger import EXTRACT_trigger\n            from scipy.io import savemat\n\n            # Motion Correction with Suite2p\n            params = (ProcessingTask * ProcessingParamSet &amp; key).fetch1(\"params\")\n\n            params[\"suite2p\"][\"save_path0\"] = output_dir\n            (\n                params[\"suite2p\"][\"fs\"],\n                params[\"suite2p\"][\"nplanes\"],\n                params[\"suite2p\"][\"nchannels\"],\n            ) = (scan.ScanInfo &amp; key).fetch1(\"fps\", \"ndepths\", \"nchannels\")\n\n            input_format = pathlib.Path(image_files[0]).suffix\n            params[\"suite2p\"][\"input_format\"] = input_format[1:]\n\n            suite2p_paths = {\n                \"data_path\": [image_files[0].parent.as_posix()],\n                \"tiff_list\": [f.as_posix() for f in image_files],\n            }\n\n            suite2p.run_s2p(ops=params[\"suite2p\"], db=suite2p_paths)\n\n            # Convert data.bin to registered_scans.mat\n            scanfile_fullpath = pathlib.Path(output_dir) / \"suite2p/plane0/data.bin\"\n\n            data_shape = (scan.ScanInfo * scan.ScanInfo.Field &amp; key).fetch1(\n                \"nframes\", \"px_height\", \"px_width\"\n            )\n            data = np.memmap(scanfile_fullpath, shape=data_shape, dtype=np.int16)\n\n            scan_matlab_fullpath = scanfile_fullpath.parent / \"registered_scan.mat\"\n\n            # Save the motion corrected movie (data.bin) in a .mat file\n            savemat(\n                scan_matlab_fullpath,\n                {\"M\": np.transpose(data, axes=[1, 2, 0])},\n            )\n\n            # Execute EXTRACT\n\n            ex = EXTRACT_trigger(\n                scan_matlab_fullpath, params[\"extract\"], output_dir\n            )\n            ex.run()\n\n            _, extract_dataset = get_loader_result(key, ProcessingTask)\n            key[\"processing_time\"] = extract_dataset.creation_time\n\n    else:\n        raise ValueError(f\"Unknown task mode: {task_mode}\")\n\n    self.insert1({**key, \"package_version\": \"\"})\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_no_curation/#element_calcium_imaging.imaging_no_curation.MotionCorrection", "title": "<code>MotionCorrection</code>", "text": "<p>         Bases: <code>dj.Imported</code></p> <p>Results of motion correction shifts performed on the imaging data.</p> <p>Attributes:</p> Name Type Description <code>Processing</code> <code>foreign key</code> <p>Primary key from Processing.</p> <code>scan.Channel.proj(motion_correct_channel='channel')</code> <code>int</code> <p>Channel used for motion correction in this processing task.</p> Source code in <code>element_calcium_imaging/imaging_no_curation.py</code> <pre><code>@schema\nclass MotionCorrection(dj.Imported):\n\"\"\"Results of motion correction shifts performed on the imaging data.\n\n    Attributes:\n        Processing (foreign key): Primary key from Processing.\n        scan.Channel.proj(motion_correct_channel='channel') (int): Channel used for\n            motion correction in this processing task.\n    \"\"\"\n\n    definition = \"\"\"# Results of motion correction\n    -&gt; Processing\n    ---\n    -&gt; scan.Channel.proj(motion_correct_channel='channel') # channel used for motion correction in this processing task\n    \"\"\"\n\n    class RigidMotionCorrection(dj.Part):\n\"\"\"Details of rigid motion correction performed on the imaging data.\n\n        Attributes:\n            MotionCorrection (foreign key): Primary key from MotionCorrection.\n            outlier_frames (longblob): Mask with true for frames with outlier shifts\n                (already corrected).\n            y_shifts (longblob): y motion correction shifts (pixels).\n            x_shifts (longblob): x motion correction shifts (pixels).\n            z_shifts (longblob, optional): z motion correction shifts (z-drift, pixels).\n            y_std (float): standard deviation of y shifts across all frames (pixels).\n            x_std (float): standard deviation of x shifts across all frames (pixels).\n            z_std (float, optional): standard deviation of z shifts across all frames\n                (pixels).\n        \"\"\"\n\n        definition = \"\"\"# Details of rigid motion correction performed on the imaging data\n        -&gt; master\n        ---\n        outlier_frames=null : longblob  # mask with true for frames with outlier shifts (already corrected)\n        y_shifts            : longblob  # (pixels) y motion correction shifts\n        x_shifts            : longblob  # (pixels) x motion correction shifts\n        z_shifts=null       : longblob  # (pixels) z motion correction shifts (z-drift)\n        y_std               : float     # (pixels) standard deviation of y shifts across all frames\n        x_std               : float     # (pixels) standard deviation of x shifts across all frames\n        z_std=null          : float     # (pixels) standard deviation of z shifts across all frames\n        \"\"\"\n\n    class NonRigidMotionCorrection(dj.Part):\n\"\"\"Piece-wise rigid motion correction - tile the FOV into multiple 3D\n        blocks/patches.\n\n        Attributes:\n            MotionCorrection (foreign key): Primary key from MotionCorrection.\n            outlier_frames (longblob, null): Mask with true for frames with outlier\n                shifts (already corrected).\n            block_height (int): Block height in pixels.\n            block_width (int): Block width in pixels.\n            block_depth (int): Block depth in pixels.\n            block_count_y (int): Number of blocks tiled in the y direction.\n            block_count_x (int): Number of blocks tiled in the x direction.\n            block_count_z (int): Number of blocks tiled in the z direction.\n        \"\"\"\n\n        definition = \"\"\"# Details of non-rigid motion correction performed on the imaging data\n        -&gt; master\n        ---\n        outlier_frames=null : longblob # mask with true for frames with outlier shifts (already corrected)\n        block_height        : int      # (pixels)\n        block_width         : int      # (pixels)\n        block_depth         : int      # (pixels)\n        block_count_y       : int      # number of blocks tiled in the y direction\n        block_count_x       : int      # number of blocks tiled in the x direction\n        block_count_z       : int      # number of blocks tiled in the z direction\n        \"\"\"\n\n    class Block(dj.Part):\n\"\"\"FOV-tiled blocks used for non-rigid motion correction.\n\n        Attributes:\n            NonRigidMotionCorrection (foreign key): Primary key from\n                NonRigidMotionCorrection.\n            block_id (int): Unique block ID.\n            block_y (longblob): y_start and y_end in pixels for this block\n            block_x (longblob): x_start and x_end in pixels for this block\n            block_z (longblob): z_start and z_end in pixels for this block\n            y_shifts (longblob): y motion correction shifts for every frame in pixels\n            x_shifts (longblob): x motion correction shifts for every frame in pixels\n            z_shift=null (longblob, optional): x motion correction shifts for every frame\n                in pixels\n            y_std (float): standard deviation of y shifts across all frames in pixels\n            x_std (float): standard deviation of x shifts across all frames in pixels\n            z_std=null (float, optional): standard deviation of z shifts across all frames\n                in pixels\n        \"\"\"\n\n        definition = \"\"\"# FOV-tiled blocks used for non-rigid motion correction\n        -&gt; master.NonRigidMotionCorrection\n        block_id        : int\n        ---\n        block_y         : longblob  # (y_start, y_end) in pixel of this block\n        block_x         : longblob  # (x_start, x_end) in pixel of this block\n        block_z         : longblob  # (z_start, z_end) in pixel of this block\n        y_shifts        : longblob  # (pixels) y motion correction shifts for every frame\n        x_shifts        : longblob  # (pixels) x motion correction shifts for every frame\n        z_shifts=null   : longblob  # (pixels) x motion correction shifts for every frame\n        y_std           : float     # (pixels) standard deviation of y shifts across all frames\n        x_std           : float     # (pixels) standard deviation of x shifts across all frames\n        z_std=null      : float     # (pixels) standard deviation of z shifts across all frames\n        \"\"\"\n\n    class Summary(dj.Part):\n\"\"\"Summary images for each field and channel after corrections.\n\n        Attributes:\n            MotionCorrection (foreign key): Primary key from MotionCorrection.\n            scan.ScanInfo.Field (foreign key): Primary key from scan.ScanInfo.Field.\n            ref_image (longblob): Image used as alignment template.\n            average_image (longblob): Mean of registered frames.\n            correlation_image (longblob, optional): Correlation map (computed during\n                cell detection).\n            max_proj_image (longblob, optional): Max of registered frames.\n        \"\"\"\n\n        definition = \"\"\"# Summary images for each field and channel after corrections\n        -&gt; master\n        -&gt; scan.ScanInfo.Field\n        ---\n        ref_image               : longblob  # image used as alignment template\n        average_image           : longblob  # mean of registered frames\n        correlation_image=null  : longblob  # correlation map (computed during cell detection)\n        max_proj_image=null     : longblob  # max of registered frames\n        \"\"\"\n\n    def make(self, key):\n\"\"\"Populate MotionCorrection with results parsed from analysis outputs\"\"\"\n\n        method, imaging_dataset = get_loader_result(key, ProcessingTask)\n\n        field_keys, _ = (scan.ScanInfo.Field &amp; key).fetch(\n            \"KEY\", \"field_z\", order_by=\"field_z\"\n        )\n\n        if method in [\"suite2p\", \"extract\"]:\n            suite2p_dataset = imaging_dataset\n\n            motion_correct_channel = suite2p_dataset.planes[0].alignment_channel\n\n            # ---- iterate through all s2p plane outputs ----\n            rigid_correction, nonrigid_correction, nonrigid_blocks = {}, {}, {}\n            summary_images = []\n            for idx, (plane, s2p) in enumerate(suite2p_dataset.planes.items()):\n                # -- rigid motion correction --\n                if idx == 0:\n                    rigid_correction = {\n                        **key,\n                        \"y_shifts\": s2p.ops[\"yoff\"],\n                        \"x_shifts\": s2p.ops[\"xoff\"],\n                        \"z_shifts\": np.full_like(s2p.ops[\"xoff\"], 0),\n                        \"y_std\": np.nanstd(s2p.ops[\"yoff\"]),\n                        \"x_std\": np.nanstd(s2p.ops[\"xoff\"]),\n                        \"z_std\": np.nan,\n                        \"outlier_frames\": s2p.ops[\"badframes\"],\n                    }\n                else:\n                    rigid_correction[\"y_shifts\"] = np.vstack(\n                        [rigid_correction[\"y_shifts\"], s2p.ops[\"yoff\"]]\n                    )\n                    rigid_correction[\"y_std\"] = np.nanstd(\n                        rigid_correction[\"y_shifts\"].flatten()\n                    )\n                    rigid_correction[\"x_shifts\"] = np.vstack(\n                        [rigid_correction[\"x_shifts\"], s2p.ops[\"xoff\"]]\n                    )\n                    rigid_correction[\"x_std\"] = np.nanstd(\n                        rigid_correction[\"x_shifts\"].flatten()\n                    )\n                    rigid_correction[\"outlier_frames\"] = np.logical_or(\n                        rigid_correction[\"outlier_frames\"], s2p.ops[\"badframes\"]\n                    )\n                # -- non-rigid motion correction --\n                if s2p.ops[\"nonrigid\"]:\n                    if idx == 0:\n                        nonrigid_correction = {\n                            **key,\n                            \"block_height\": s2p.ops[\"block_size\"][0],\n                            \"block_width\": s2p.ops[\"block_size\"][1],\n                            \"block_depth\": 1,\n                            \"block_count_y\": s2p.ops[\"nblocks\"][0],\n                            \"block_count_x\": s2p.ops[\"nblocks\"][1],\n                            \"block_count_z\": len(suite2p_dataset.planes),\n                            \"outlier_frames\": s2p.ops[\"badframes\"],\n                        }\n                    else:\n                        nonrigid_correction[\"outlier_frames\"] = np.logical_or(\n                            nonrigid_correction[\"outlier_frames\"],\n                            s2p.ops[\"badframes\"],\n                        )\n                    for b_id, (b_y, b_x, bshift_y, bshift_x) in enumerate(\n                        zip(\n                            s2p.ops[\"xblock\"],\n                            s2p.ops[\"yblock\"],\n                            s2p.ops[\"yoff1\"].T,\n                            s2p.ops[\"xoff1\"].T,\n                        )\n                    ):\n                        if b_id in nonrigid_blocks:\n                            nonrigid_blocks[b_id][\"y_shifts\"] = np.vstack(\n                                [nonrigid_blocks[b_id][\"y_shifts\"], bshift_y]\n                            )\n                            nonrigid_blocks[b_id][\"y_std\"] = np.nanstd(\n                                nonrigid_blocks[b_id][\"y_shifts\"].flatten()\n                            )\n                            nonrigid_blocks[b_id][\"x_shifts\"] = np.vstack(\n                                [nonrigid_blocks[b_id][\"x_shifts\"], bshift_x]\n                            )\n                            nonrigid_blocks[b_id][\"x_std\"] = np.nanstd(\n                                nonrigid_blocks[b_id][\"x_shifts\"].flatten()\n                            )\n                        else:\n                            nonrigid_blocks[b_id] = {\n                                **key,\n                                \"block_id\": b_id,\n                                \"block_y\": b_y,\n                                \"block_x\": b_x,\n                                \"block_z\": np.full_like(b_x, plane),\n                                \"y_shifts\": bshift_y,\n                                \"x_shifts\": bshift_x,\n                                \"z_shifts\": np.full(\n                                    (\n                                        len(suite2p_dataset.planes),\n                                        len(bshift_x),\n                                    ),\n                                    0,\n                                ),\n                                \"y_std\": np.nanstd(bshift_y),\n                                \"x_std\": np.nanstd(bshift_x),\n                                \"z_std\": np.nan,\n                            }\n\n                # -- summary images --\n                motion_correction_key = (\n                    scan.ScanInfo.Field * Processing &amp; key &amp; field_keys[plane]\n                ).fetch1(\"KEY\")\n                summary_images.append(\n                    {\n                        **motion_correction_key,\n                        \"ref_image\": s2p.ref_image,\n                        \"average_image\": s2p.mean_image,\n                        \"correlation_image\": s2p.correlation_map,\n                        \"max_proj_image\": s2p.max_proj_image,\n                    }\n                )\n\n            self.insert1({**key, \"motion_correct_channel\": motion_correct_channel})\n            if rigid_correction:\n                self.RigidMotionCorrection.insert1(rigid_correction)\n            if nonrigid_correction:\n                self.NonRigidMotionCorrection.insert1(nonrigid_correction)\n                self.Block.insert(nonrigid_blocks.values())\n            self.Summary.insert(summary_images)\n        elif method == \"caiman\":\n            caiman_dataset = imaging_dataset\n\n            self.insert1(\n                {\n                    **key,\n                    \"motion_correct_channel\": caiman_dataset.alignment_channel,\n                }\n            )\n\n            is3D = caiman_dataset.params.motion[\"is3D\"]\n            if not caiman_dataset.params.motion[\"pw_rigid\"]:\n                # -- rigid motion correction --\n                rigid_correction = {\n                    **key,\n                    \"x_shifts\": caiman_dataset.motion_correction[\"shifts_rig\"][:, 0],\n                    \"y_shifts\": caiman_dataset.motion_correction[\"shifts_rig\"][:, 1],\n                    \"z_shifts\": (\n                        caiman_dataset.motion_correction[\"shifts_rig\"][:, 2]\n                        if is3D\n                        else np.full_like(\n                            caiman_dataset.motion_correction[\"shifts_rig\"][:, 0],\n                            0,\n                        )\n                    ),\n                    \"x_std\": np.nanstd(\n                        caiman_dataset.motion_correction[\"shifts_rig\"][:, 0]\n                    ),\n                    \"y_std\": np.nanstd(\n                        caiman_dataset.motion_correction[\"shifts_rig\"][:, 1]\n                    ),\n                    \"z_std\": (\n                        np.nanstd(caiman_dataset.motion_correction[\"shifts_rig\"][:, 2])\n                        if is3D\n                        else np.nan\n                    ),\n                    \"outlier_frames\": None,\n                }\n\n                self.RigidMotionCorrection.insert1(rigid_correction)\n            else:\n                # -- non-rigid motion correction --\n                nonrigid_correction = {\n                    **key,\n                    \"block_height\": (\n                        caiman_dataset.params.motion[\"strides\"][0]\n                        + caiman_dataset.params.motion[\"overlaps\"][0]\n                    ),\n                    \"block_width\": (\n                        caiman_dataset.params.motion[\"strides\"][1]\n                        + caiman_dataset.params.motion[\"overlaps\"][1]\n                    ),\n                    \"block_depth\": (\n                        caiman_dataset.params.motion[\"strides\"][2]\n                        + caiman_dataset.params.motion[\"overlaps\"][2]\n                        if is3D\n                        else 1\n                    ),\n                    \"block_count_x\": len(\n                        set(caiman_dataset.motion_correction[\"coord_shifts_els\"][:, 0])\n                    ),\n                    \"block_count_y\": len(\n                        set(caiman_dataset.motion_correction[\"coord_shifts_els\"][:, 2])\n                    ),\n                    \"block_count_z\": (\n                        len(\n                            set(\n                                caiman_dataset.motion_correction[\"coord_shifts_els\"][\n                                    :, 4\n                                ]\n                            )\n                        )\n                        if is3D\n                        else 1\n                    ),\n                    \"outlier_frames\": None,\n                }\n\n                nonrigid_blocks = []\n                for b_id in range(\n                    len(caiman_dataset.motion_correction[\"x_shifts_els\"][0, :])\n                ):\n                    nonrigid_blocks.append(\n                        {\n                            **key,\n                            \"block_id\": b_id,\n                            \"block_x\": np.arange(\n                                *caiman_dataset.motion_correction[\"coord_shifts_els\"][\n                                    b_id, 0:2\n                                ]\n                            ),\n                            \"block_y\": np.arange(\n                                *caiman_dataset.motion_correction[\"coord_shifts_els\"][\n                                    b_id, 2:4\n                                ]\n                            ),\n                            \"block_z\": (\n                                np.arange(\n                                    *caiman_dataset.motion_correction[\n                                        \"coord_shifts_els\"\n                                    ][b_id, 4:6]\n                                )\n                                if is3D\n                                else np.full_like(\n                                    np.arange(\n                                        *caiman_dataset.motion_correction[\n                                            \"coord_shifts_els\"\n                                        ][b_id, 0:2]\n                                    ),\n                                    0,\n                                )\n                            ),\n                            \"x_shifts\": caiman_dataset.motion_correction[\n                                \"x_shifts_els\"\n                            ][:, b_id],\n                            \"y_shifts\": caiman_dataset.motion_correction[\n                                \"y_shifts_els\"\n                            ][:, b_id],\n                            \"z_shifts\": (\n                                caiman_dataset.motion_correction[\"z_shifts_els\"][\n                                    :, b_id\n                                ]\n                                if is3D\n                                else np.full_like(\n                                    caiman_dataset.motion_correction[\"x_shifts_els\"][\n                                        :, b_id\n                                    ],\n                                    0,\n                                )\n                            ),\n                            \"x_std\": np.nanstd(\n                                caiman_dataset.motion_correction[\"x_shifts_els\"][\n                                    :, b_id\n                                ]\n                            ),\n                            \"y_std\": np.nanstd(\n                                caiman_dataset.motion_correction[\"y_shifts_els\"][\n                                    :, b_id\n                                ]\n                            ),\n                            \"z_std\": (\n                                np.nanstd(\n                                    caiman_dataset.motion_correction[\"z_shifts_els\"][\n                                        :, b_id\n                                    ]\n                                )\n                                if is3D\n                                else np.nan\n                            ),\n                        }\n                    )\n\n                self.NonRigidMotionCorrection.insert1(nonrigid_correction)\n                self.Block.insert(nonrigid_blocks)\n\n            # -- summary images --\n            summary_images = [\n                {\n                    **key,\n                    **fkey,\n                    \"ref_image\": ref_image,\n                    \"average_image\": ave_img,\n                    \"correlation_image\": corr_img,\n                    \"max_proj_image\": max_img,\n                }\n                for fkey, ref_image, ave_img, corr_img, max_img in zip(\n                    field_keys,\n                    caiman_dataset.motion_correction[\"reference_image\"].transpose(\n                        2, 0, 1\n                    )\n                    if is3D\n                    else caiman_dataset.motion_correction[\"reference_image\"][...][\n                        np.newaxis, ...\n                    ],\n                    caiman_dataset.motion_correction[\"average_image\"].transpose(2, 0, 1)\n                    if is3D\n                    else caiman_dataset.motion_correction[\"average_image\"][...][\n                        np.newaxis, ...\n                    ],\n                    caiman_dataset.motion_correction[\"correlation_image\"].transpose(\n                        2, 0, 1\n                    )\n                    if is3D\n                    else caiman_dataset.motion_correction[\"correlation_image\"][...][\n                        np.newaxis, ...\n                    ],\n                    caiman_dataset.motion_correction[\"max_image\"].transpose(2, 0, 1)\n                    if is3D\n                    else caiman_dataset.motion_correction[\"max_image\"][...][\n                        np.newaxis, ...\n                    ],\n                )\n            ]\n            self.Summary.insert(summary_images)\n        else:\n            raise NotImplementedError(\"Unknown/unimplemented method: {}\".format(method))\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_no_curation/#element_calcium_imaging.imaging_no_curation.MotionCorrection.RigidMotionCorrection", "title": "<code>RigidMotionCorrection</code>", "text": "<p>         Bases: <code>dj.Part</code></p> <p>Details of rigid motion correction performed on the imaging data.</p> <p>Attributes:</p> Name Type Description <code>MotionCorrection</code> <code>foreign key</code> <p>Primary key from MotionCorrection.</p> <code>outlier_frames</code> <code>longblob</code> <p>Mask with true for frames with outlier shifts (already corrected).</p> <code>y_shifts</code> <code>longblob</code> <p>y motion correction shifts (pixels).</p> <code>x_shifts</code> <code>longblob</code> <p>x motion correction shifts (pixels).</p> <code>z_shifts</code> <code>longblob</code> <p>z motion correction shifts (z-drift, pixels).</p> <code>y_std</code> <code>float</code> <p>standard deviation of y shifts across all frames (pixels).</p> <code>x_std</code> <code>float</code> <p>standard deviation of x shifts across all frames (pixels).</p> <code>z_std</code> <code>float</code> <p>standard deviation of z shifts across all frames (pixels).</p> Source code in <code>element_calcium_imaging/imaging_no_curation.py</code> <pre><code>class RigidMotionCorrection(dj.Part):\n\"\"\"Details of rigid motion correction performed on the imaging data.\n\n    Attributes:\n        MotionCorrection (foreign key): Primary key from MotionCorrection.\n        outlier_frames (longblob): Mask with true for frames with outlier shifts\n            (already corrected).\n        y_shifts (longblob): y motion correction shifts (pixels).\n        x_shifts (longblob): x motion correction shifts (pixels).\n        z_shifts (longblob, optional): z motion correction shifts (z-drift, pixels).\n        y_std (float): standard deviation of y shifts across all frames (pixels).\n        x_std (float): standard deviation of x shifts across all frames (pixels).\n        z_std (float, optional): standard deviation of z shifts across all frames\n            (pixels).\n    \"\"\"\n\n    definition = \"\"\"# Details of rigid motion correction performed on the imaging data\n    -&gt; master\n    ---\n    outlier_frames=null : longblob  # mask with true for frames with outlier shifts (already corrected)\n    y_shifts            : longblob  # (pixels) y motion correction shifts\n    x_shifts            : longblob  # (pixels) x motion correction shifts\n    z_shifts=null       : longblob  # (pixels) z motion correction shifts (z-drift)\n    y_std               : float     # (pixels) standard deviation of y shifts across all frames\n    x_std               : float     # (pixels) standard deviation of x shifts across all frames\n    z_std=null          : float     # (pixels) standard deviation of z shifts across all frames\n    \"\"\"\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_no_curation/#element_calcium_imaging.imaging_no_curation.MotionCorrection.NonRigidMotionCorrection", "title": "<code>NonRigidMotionCorrection</code>", "text": "<p>         Bases: <code>dj.Part</code></p> <p>Piece-wise rigid motion correction - tile the FOV into multiple 3D blocks/patches.</p> <p>Attributes:</p> Name Type Description <code>MotionCorrection</code> <code>foreign key</code> <p>Primary key from MotionCorrection.</p> <code>outlier_frames</code> <code>longblob, null</code> <p>Mask with true for frames with outlier shifts (already corrected).</p> <code>block_height</code> <code>int</code> <p>Block height in pixels.</p> <code>block_width</code> <code>int</code> <p>Block width in pixels.</p> <code>block_depth</code> <code>int</code> <p>Block depth in pixels.</p> <code>block_count_y</code> <code>int</code> <p>Number of blocks tiled in the y direction.</p> <code>block_count_x</code> <code>int</code> <p>Number of blocks tiled in the x direction.</p> <code>block_count_z</code> <code>int</code> <p>Number of blocks tiled in the z direction.</p> Source code in <code>element_calcium_imaging/imaging_no_curation.py</code> <pre><code>class NonRigidMotionCorrection(dj.Part):\n\"\"\"Piece-wise rigid motion correction - tile the FOV into multiple 3D\n    blocks/patches.\n\n    Attributes:\n        MotionCorrection (foreign key): Primary key from MotionCorrection.\n        outlier_frames (longblob, null): Mask with true for frames with outlier\n            shifts (already corrected).\n        block_height (int): Block height in pixels.\n        block_width (int): Block width in pixels.\n        block_depth (int): Block depth in pixels.\n        block_count_y (int): Number of blocks tiled in the y direction.\n        block_count_x (int): Number of blocks tiled in the x direction.\n        block_count_z (int): Number of blocks tiled in the z direction.\n    \"\"\"\n\n    definition = \"\"\"# Details of non-rigid motion correction performed on the imaging data\n    -&gt; master\n    ---\n    outlier_frames=null : longblob # mask with true for frames with outlier shifts (already corrected)\n    block_height        : int      # (pixels)\n    block_width         : int      # (pixels)\n    block_depth         : int      # (pixels)\n    block_count_y       : int      # number of blocks tiled in the y direction\n    block_count_x       : int      # number of blocks tiled in the x direction\n    block_count_z       : int      # number of blocks tiled in the z direction\n    \"\"\"\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_no_curation/#element_calcium_imaging.imaging_no_curation.MotionCorrection.Block", "title": "<code>Block</code>", "text": "<p>         Bases: <code>dj.Part</code></p> <p>FOV-tiled blocks used for non-rigid motion correction.</p> <p>Attributes:</p> Name Type Description <code>NonRigidMotionCorrection</code> <code>foreign key</code> <p>Primary key from NonRigidMotionCorrection.</p> <code>block_id</code> <code>int</code> <p>Unique block ID.</p> <code>block_y</code> <code>longblob</code> <p>y_start and y_end in pixels for this block</p> <code>block_x</code> <code>longblob</code> <p>x_start and x_end in pixels for this block</p> <code>block_z</code> <code>longblob</code> <p>z_start and z_end in pixels for this block</p> <code>y_shifts</code> <code>longblob</code> <p>y motion correction shifts for every frame in pixels</p> <code>x_shifts</code> <code>longblob</code> <p>x motion correction shifts for every frame in pixels</p> <code>z_shift=null</code> <code>longblob</code> <p>x motion correction shifts for every frame in pixels</p> <code>y_std</code> <code>float</code> <p>standard deviation of y shifts across all frames in pixels</p> <code>x_std</code> <code>float</code> <p>standard deviation of x shifts across all frames in pixels</p> <code>z_std=null</code> <code>float</code> <p>standard deviation of z shifts across all frames in pixels</p> Source code in <code>element_calcium_imaging/imaging_no_curation.py</code> <pre><code>class Block(dj.Part):\n\"\"\"FOV-tiled blocks used for non-rigid motion correction.\n\n    Attributes:\n        NonRigidMotionCorrection (foreign key): Primary key from\n            NonRigidMotionCorrection.\n        block_id (int): Unique block ID.\n        block_y (longblob): y_start and y_end in pixels for this block\n        block_x (longblob): x_start and x_end in pixels for this block\n        block_z (longblob): z_start and z_end in pixels for this block\n        y_shifts (longblob): y motion correction shifts for every frame in pixels\n        x_shifts (longblob): x motion correction shifts for every frame in pixels\n        z_shift=null (longblob, optional): x motion correction shifts for every frame\n            in pixels\n        y_std (float): standard deviation of y shifts across all frames in pixels\n        x_std (float): standard deviation of x shifts across all frames in pixels\n        z_std=null (float, optional): standard deviation of z shifts across all frames\n            in pixels\n    \"\"\"\n\n    definition = \"\"\"# FOV-tiled blocks used for non-rigid motion correction\n    -&gt; master.NonRigidMotionCorrection\n    block_id        : int\n    ---\n    block_y         : longblob  # (y_start, y_end) in pixel of this block\n    block_x         : longblob  # (x_start, x_end) in pixel of this block\n    block_z         : longblob  # (z_start, z_end) in pixel of this block\n    y_shifts        : longblob  # (pixels) y motion correction shifts for every frame\n    x_shifts        : longblob  # (pixels) x motion correction shifts for every frame\n    z_shifts=null   : longblob  # (pixels) x motion correction shifts for every frame\n    y_std           : float     # (pixels) standard deviation of y shifts across all frames\n    x_std           : float     # (pixels) standard deviation of x shifts across all frames\n    z_std=null      : float     # (pixels) standard deviation of z shifts across all frames\n    \"\"\"\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_no_curation/#element_calcium_imaging.imaging_no_curation.MotionCorrection.Summary", "title": "<code>Summary</code>", "text": "<p>         Bases: <code>dj.Part</code></p> <p>Summary images for each field and channel after corrections.</p> <p>Attributes:</p> Name Type Description <code>MotionCorrection</code> <code>foreign key</code> <p>Primary key from MotionCorrection.</p> <code>scan.ScanInfo.Field</code> <code>foreign key</code> <p>Primary key from scan.ScanInfo.Field.</p> <code>ref_image</code> <code>longblob</code> <p>Image used as alignment template.</p> <code>average_image</code> <code>longblob</code> <p>Mean of registered frames.</p> <code>correlation_image</code> <code>longblob</code> <p>Correlation map (computed during cell detection).</p> <code>max_proj_image</code> <code>longblob</code> <p>Max of registered frames.</p> Source code in <code>element_calcium_imaging/imaging_no_curation.py</code> <pre><code>class Summary(dj.Part):\n\"\"\"Summary images for each field and channel after corrections.\n\n    Attributes:\n        MotionCorrection (foreign key): Primary key from MotionCorrection.\n        scan.ScanInfo.Field (foreign key): Primary key from scan.ScanInfo.Field.\n        ref_image (longblob): Image used as alignment template.\n        average_image (longblob): Mean of registered frames.\n        correlation_image (longblob, optional): Correlation map (computed during\n            cell detection).\n        max_proj_image (longblob, optional): Max of registered frames.\n    \"\"\"\n\n    definition = \"\"\"# Summary images for each field and channel after corrections\n    -&gt; master\n    -&gt; scan.ScanInfo.Field\n    ---\n    ref_image               : longblob  # image used as alignment template\n    average_image           : longblob  # mean of registered frames\n    correlation_image=null  : longblob  # correlation map (computed during cell detection)\n    max_proj_image=null     : longblob  # max of registered frames\n    \"\"\"\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_no_curation/#element_calcium_imaging.imaging_no_curation.MotionCorrection.make", "title": "<code>make(key)</code>", "text": "<p>Populate MotionCorrection with results parsed from analysis outputs</p> Source code in <code>element_calcium_imaging/imaging_no_curation.py</code> <pre><code>def make(self, key):\n\"\"\"Populate MotionCorrection with results parsed from analysis outputs\"\"\"\n\n    method, imaging_dataset = get_loader_result(key, ProcessingTask)\n\n    field_keys, _ = (scan.ScanInfo.Field &amp; key).fetch(\n        \"KEY\", \"field_z\", order_by=\"field_z\"\n    )\n\n    if method in [\"suite2p\", \"extract\"]:\n        suite2p_dataset = imaging_dataset\n\n        motion_correct_channel = suite2p_dataset.planes[0].alignment_channel\n\n        # ---- iterate through all s2p plane outputs ----\n        rigid_correction, nonrigid_correction, nonrigid_blocks = {}, {}, {}\n        summary_images = []\n        for idx, (plane, s2p) in enumerate(suite2p_dataset.planes.items()):\n            # -- rigid motion correction --\n            if idx == 0:\n                rigid_correction = {\n                    **key,\n                    \"y_shifts\": s2p.ops[\"yoff\"],\n                    \"x_shifts\": s2p.ops[\"xoff\"],\n                    \"z_shifts\": np.full_like(s2p.ops[\"xoff\"], 0),\n                    \"y_std\": np.nanstd(s2p.ops[\"yoff\"]),\n                    \"x_std\": np.nanstd(s2p.ops[\"xoff\"]),\n                    \"z_std\": np.nan,\n                    \"outlier_frames\": s2p.ops[\"badframes\"],\n                }\n            else:\n                rigid_correction[\"y_shifts\"] = np.vstack(\n                    [rigid_correction[\"y_shifts\"], s2p.ops[\"yoff\"]]\n                )\n                rigid_correction[\"y_std\"] = np.nanstd(\n                    rigid_correction[\"y_shifts\"].flatten()\n                )\n                rigid_correction[\"x_shifts\"] = np.vstack(\n                    [rigid_correction[\"x_shifts\"], s2p.ops[\"xoff\"]]\n                )\n                rigid_correction[\"x_std\"] = np.nanstd(\n                    rigid_correction[\"x_shifts\"].flatten()\n                )\n                rigid_correction[\"outlier_frames\"] = np.logical_or(\n                    rigid_correction[\"outlier_frames\"], s2p.ops[\"badframes\"]\n                )\n            # -- non-rigid motion correction --\n            if s2p.ops[\"nonrigid\"]:\n                if idx == 0:\n                    nonrigid_correction = {\n                        **key,\n                        \"block_height\": s2p.ops[\"block_size\"][0],\n                        \"block_width\": s2p.ops[\"block_size\"][1],\n                        \"block_depth\": 1,\n                        \"block_count_y\": s2p.ops[\"nblocks\"][0],\n                        \"block_count_x\": s2p.ops[\"nblocks\"][1],\n                        \"block_count_z\": len(suite2p_dataset.planes),\n                        \"outlier_frames\": s2p.ops[\"badframes\"],\n                    }\n                else:\n                    nonrigid_correction[\"outlier_frames\"] = np.logical_or(\n                        nonrigid_correction[\"outlier_frames\"],\n                        s2p.ops[\"badframes\"],\n                    )\n                for b_id, (b_y, b_x, bshift_y, bshift_x) in enumerate(\n                    zip(\n                        s2p.ops[\"xblock\"],\n                        s2p.ops[\"yblock\"],\n                        s2p.ops[\"yoff1\"].T,\n                        s2p.ops[\"xoff1\"].T,\n                    )\n                ):\n                    if b_id in nonrigid_blocks:\n                        nonrigid_blocks[b_id][\"y_shifts\"] = np.vstack(\n                            [nonrigid_blocks[b_id][\"y_shifts\"], bshift_y]\n                        )\n                        nonrigid_blocks[b_id][\"y_std\"] = np.nanstd(\n                            nonrigid_blocks[b_id][\"y_shifts\"].flatten()\n                        )\n                        nonrigid_blocks[b_id][\"x_shifts\"] = np.vstack(\n                            [nonrigid_blocks[b_id][\"x_shifts\"], bshift_x]\n                        )\n                        nonrigid_blocks[b_id][\"x_std\"] = np.nanstd(\n                            nonrigid_blocks[b_id][\"x_shifts\"].flatten()\n                        )\n                    else:\n                        nonrigid_blocks[b_id] = {\n                            **key,\n                            \"block_id\": b_id,\n                            \"block_y\": b_y,\n                            \"block_x\": b_x,\n                            \"block_z\": np.full_like(b_x, plane),\n                            \"y_shifts\": bshift_y,\n                            \"x_shifts\": bshift_x,\n                            \"z_shifts\": np.full(\n                                (\n                                    len(suite2p_dataset.planes),\n                                    len(bshift_x),\n                                ),\n                                0,\n                            ),\n                            \"y_std\": np.nanstd(bshift_y),\n                            \"x_std\": np.nanstd(bshift_x),\n                            \"z_std\": np.nan,\n                        }\n\n            # -- summary images --\n            motion_correction_key = (\n                scan.ScanInfo.Field * Processing &amp; key &amp; field_keys[plane]\n            ).fetch1(\"KEY\")\n            summary_images.append(\n                {\n                    **motion_correction_key,\n                    \"ref_image\": s2p.ref_image,\n                    \"average_image\": s2p.mean_image,\n                    \"correlation_image\": s2p.correlation_map,\n                    \"max_proj_image\": s2p.max_proj_image,\n                }\n            )\n\n        self.insert1({**key, \"motion_correct_channel\": motion_correct_channel})\n        if rigid_correction:\n            self.RigidMotionCorrection.insert1(rigid_correction)\n        if nonrigid_correction:\n            self.NonRigidMotionCorrection.insert1(nonrigid_correction)\n            self.Block.insert(nonrigid_blocks.values())\n        self.Summary.insert(summary_images)\n    elif method == \"caiman\":\n        caiman_dataset = imaging_dataset\n\n        self.insert1(\n            {\n                **key,\n                \"motion_correct_channel\": caiman_dataset.alignment_channel,\n            }\n        )\n\n        is3D = caiman_dataset.params.motion[\"is3D\"]\n        if not caiman_dataset.params.motion[\"pw_rigid\"]:\n            # -- rigid motion correction --\n            rigid_correction = {\n                **key,\n                \"x_shifts\": caiman_dataset.motion_correction[\"shifts_rig\"][:, 0],\n                \"y_shifts\": caiman_dataset.motion_correction[\"shifts_rig\"][:, 1],\n                \"z_shifts\": (\n                    caiman_dataset.motion_correction[\"shifts_rig\"][:, 2]\n                    if is3D\n                    else np.full_like(\n                        caiman_dataset.motion_correction[\"shifts_rig\"][:, 0],\n                        0,\n                    )\n                ),\n                \"x_std\": np.nanstd(\n                    caiman_dataset.motion_correction[\"shifts_rig\"][:, 0]\n                ),\n                \"y_std\": np.nanstd(\n                    caiman_dataset.motion_correction[\"shifts_rig\"][:, 1]\n                ),\n                \"z_std\": (\n                    np.nanstd(caiman_dataset.motion_correction[\"shifts_rig\"][:, 2])\n                    if is3D\n                    else np.nan\n                ),\n                \"outlier_frames\": None,\n            }\n\n            self.RigidMotionCorrection.insert1(rigid_correction)\n        else:\n            # -- non-rigid motion correction --\n            nonrigid_correction = {\n                **key,\n                \"block_height\": (\n                    caiman_dataset.params.motion[\"strides\"][0]\n                    + caiman_dataset.params.motion[\"overlaps\"][0]\n                ),\n                \"block_width\": (\n                    caiman_dataset.params.motion[\"strides\"][1]\n                    + caiman_dataset.params.motion[\"overlaps\"][1]\n                ),\n                \"block_depth\": (\n                    caiman_dataset.params.motion[\"strides\"][2]\n                    + caiman_dataset.params.motion[\"overlaps\"][2]\n                    if is3D\n                    else 1\n                ),\n                \"block_count_x\": len(\n                    set(caiman_dataset.motion_correction[\"coord_shifts_els\"][:, 0])\n                ),\n                \"block_count_y\": len(\n                    set(caiman_dataset.motion_correction[\"coord_shifts_els\"][:, 2])\n                ),\n                \"block_count_z\": (\n                    len(\n                        set(\n                            caiman_dataset.motion_correction[\"coord_shifts_els\"][\n                                :, 4\n                            ]\n                        )\n                    )\n                    if is3D\n                    else 1\n                ),\n                \"outlier_frames\": None,\n            }\n\n            nonrigid_blocks = []\n            for b_id in range(\n                len(caiman_dataset.motion_correction[\"x_shifts_els\"][0, :])\n            ):\n                nonrigid_blocks.append(\n                    {\n                        **key,\n                        \"block_id\": b_id,\n                        \"block_x\": np.arange(\n                            *caiman_dataset.motion_correction[\"coord_shifts_els\"][\n                                b_id, 0:2\n                            ]\n                        ),\n                        \"block_y\": np.arange(\n                            *caiman_dataset.motion_correction[\"coord_shifts_els\"][\n                                b_id, 2:4\n                            ]\n                        ),\n                        \"block_z\": (\n                            np.arange(\n                                *caiman_dataset.motion_correction[\n                                    \"coord_shifts_els\"\n                                ][b_id, 4:6]\n                            )\n                            if is3D\n                            else np.full_like(\n                                np.arange(\n                                    *caiman_dataset.motion_correction[\n                                        \"coord_shifts_els\"\n                                    ][b_id, 0:2]\n                                ),\n                                0,\n                            )\n                        ),\n                        \"x_shifts\": caiman_dataset.motion_correction[\n                            \"x_shifts_els\"\n                        ][:, b_id],\n                        \"y_shifts\": caiman_dataset.motion_correction[\n                            \"y_shifts_els\"\n                        ][:, b_id],\n                        \"z_shifts\": (\n                            caiman_dataset.motion_correction[\"z_shifts_els\"][\n                                :, b_id\n                            ]\n                            if is3D\n                            else np.full_like(\n                                caiman_dataset.motion_correction[\"x_shifts_els\"][\n                                    :, b_id\n                                ],\n                                0,\n                            )\n                        ),\n                        \"x_std\": np.nanstd(\n                            caiman_dataset.motion_correction[\"x_shifts_els\"][\n                                :, b_id\n                            ]\n                        ),\n                        \"y_std\": np.nanstd(\n                            caiman_dataset.motion_correction[\"y_shifts_els\"][\n                                :, b_id\n                            ]\n                        ),\n                        \"z_std\": (\n                            np.nanstd(\n                                caiman_dataset.motion_correction[\"z_shifts_els\"][\n                                    :, b_id\n                                ]\n                            )\n                            if is3D\n                            else np.nan\n                        ),\n                    }\n                )\n\n            self.NonRigidMotionCorrection.insert1(nonrigid_correction)\n            self.Block.insert(nonrigid_blocks)\n\n        # -- summary images --\n        summary_images = [\n            {\n                **key,\n                **fkey,\n                \"ref_image\": ref_image,\n                \"average_image\": ave_img,\n                \"correlation_image\": corr_img,\n                \"max_proj_image\": max_img,\n            }\n            for fkey, ref_image, ave_img, corr_img, max_img in zip(\n                field_keys,\n                caiman_dataset.motion_correction[\"reference_image\"].transpose(\n                    2, 0, 1\n                )\n                if is3D\n                else caiman_dataset.motion_correction[\"reference_image\"][...][\n                    np.newaxis, ...\n                ],\n                caiman_dataset.motion_correction[\"average_image\"].transpose(2, 0, 1)\n                if is3D\n                else caiman_dataset.motion_correction[\"average_image\"][...][\n                    np.newaxis, ...\n                ],\n                caiman_dataset.motion_correction[\"correlation_image\"].transpose(\n                    2, 0, 1\n                )\n                if is3D\n                else caiman_dataset.motion_correction[\"correlation_image\"][...][\n                    np.newaxis, ...\n                ],\n                caiman_dataset.motion_correction[\"max_image\"].transpose(2, 0, 1)\n                if is3D\n                else caiman_dataset.motion_correction[\"max_image\"][...][\n                    np.newaxis, ...\n                ],\n            )\n        ]\n        self.Summary.insert(summary_images)\n    else:\n        raise NotImplementedError(\"Unknown/unimplemented method: {}\".format(method))\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_no_curation/#element_calcium_imaging.imaging_no_curation.Segmentation", "title": "<code>Segmentation</code>", "text": "<p>         Bases: <code>dj.Computed</code></p> <p>Result of the Segmentation process.</p> <p>Attributes:</p> Name Type Description <code>Processing</code> <code>foreign key</code> <p>Primary key from Processing.</p> Source code in <code>element_calcium_imaging/imaging_no_curation.py</code> <pre><code>@schema\nclass Segmentation(dj.Computed):\n\"\"\"Result of the Segmentation process.\n\n    Attributes:\n        Processing (foreign key): Primary key from Processing.\n    \"\"\"\n\n    definition = \"\"\"# Different mask segmentations.\n    -&gt; Processing\n    \"\"\"\n\n    class Mask(dj.Part):\n\"\"\"Details of the masks identified from the Segmentation procedure.\n\n        Attributes:\n            Segmentation (foreign key): Primary key from Segmentation.\n            mask (int): Unique mask ID.\n            scan.Channel.proj(segmentation_channel='channel') (foreign key): Channel\n                used for segmentation.\n            mask_npix (int): Number of pixels in ROIs.\n            mask_center_x (int): Center x coordinate in pixel.\n            mask_center_y (int): Center y coordinate in pixel.\n            mask_center_z (int): Center z coordinate in pixel.\n            mask_xpix (longblob): X coordinates in pixels.\n            mask_ypix (longblob): Y coordinates in pixels.\n            mask_zpix (longblob): Z coordinates in pixels.\n            mask_weights (longblob): Weights of the mask at the indices above.\n        \"\"\"\n\n        definition = \"\"\" # A mask produced by segmentation.\n        -&gt; master\n        mask               : smallint\n        ---\n        -&gt; scan.Channel.proj(segmentation_channel='channel')  # channel used for segmentation\n        mask_npix          : int       # number of pixels in ROIs\n        mask_center_x      : int       # center x coordinate in pixel\n        mask_center_y      : int       # center y coordinate in pixel\n        mask_center_z=null : int       # center z coordinate in pixel\n        mask_xpix          : longblob  # x coordinates in pixels\n        mask_ypix          : longblob  # y coordinates in pixels\n        mask_zpix=null     : longblob  # z coordinates in pixels\n        mask_weights       : longblob  # weights of the mask at the indices above\n        \"\"\"\n\n    def make(self, key):\n\"\"\"Populate the Segmentation with the results parsed from analysis outputs.\"\"\"\n\n        method, imaging_dataset = get_loader_result(key, ProcessingTask)\n\n        if method == \"suite2p\":\n            suite2p_dataset = imaging_dataset\n\n            # ---- iterate through all s2p plane outputs ----\n            masks, cells = [], []\n            for plane, s2p in suite2p_dataset.planes.items():\n                mask_count = len(masks)  # increment mask id from all \"plane\"\n                for mask_idx, (is_cell, cell_prob, mask_stat) in enumerate(\n                    zip(s2p.iscell, s2p.cell_prob, s2p.stat)\n                ):\n                    masks.append(\n                        {\n                            **key,\n                            \"mask\": mask_idx + mask_count,\n                            \"segmentation_channel\": s2p.segmentation_channel,\n                            \"mask_npix\": mask_stat[\"npix\"],\n                            \"mask_center_x\": mask_stat[\"med\"][1],\n                            \"mask_center_y\": mask_stat[\"med\"][0],\n                            \"mask_center_z\": mask_stat.get(\"iplane\", plane),\n                            \"mask_xpix\": mask_stat[\"xpix\"],\n                            \"mask_ypix\": mask_stat[\"ypix\"],\n                            \"mask_zpix\": np.full(\n                                mask_stat[\"npix\"],\n                                mask_stat.get(\"iplane\", plane),\n                            ),\n                            \"mask_weights\": mask_stat[\"lam\"],\n                        }\n                    )\n                    if is_cell:\n                        cells.append(\n                            {\n                                **key,\n                                \"mask_classification_method\": \"suite2p_default_classifier\",\n                                \"mask\": mask_idx + mask_count,\n                                \"mask_type\": \"soma\",\n                                \"confidence\": cell_prob,\n                            }\n                        )\n\n            self.insert1(key)\n            self.Mask.insert(masks, ignore_extra_fields=True)\n\n            if cells:\n                MaskClassification.insert1(\n                    {\n                        **key,\n                        \"mask_classification_method\": \"suite2p_default_classifier\",\n                    },\n                    allow_direct_insert=True,\n                )\n                MaskClassification.MaskType.insert(\n                    cells, ignore_extra_fields=True, allow_direct_insert=True\n                )\n        elif method == \"caiman\":\n            caiman_dataset = imaging_dataset\n\n            # infer \"segmentation_channel\" - from params if available, else from caiman loader\n            params = (ProcessingParamSet * ProcessingTask &amp; key).fetch1(\"params\")\n            segmentation_channel = params.get(\n                \"segmentation_channel\", caiman_dataset.segmentation_channel\n            )\n\n            masks, cells = [], []\n            for mask in caiman_dataset.masks:\n                masks.append(\n                    {\n                        **key,\n                        \"segmentation_channel\": segmentation_channel,\n                        \"mask\": mask[\"mask_id\"],\n                        \"mask_npix\": mask[\"mask_npix\"],\n                        \"mask_center_x\": mask[\"mask_center_x\"],\n                        \"mask_center_y\": mask[\"mask_center_y\"],\n                        \"mask_center_z\": mask[\"mask_center_z\"],\n                        \"mask_xpix\": mask[\"mask_xpix\"],\n                        \"mask_ypix\": mask[\"mask_ypix\"],\n                        \"mask_zpix\": mask[\"mask_zpix\"],\n                        \"mask_weights\": mask[\"mask_weights\"],\n                    }\n                )\n                if caiman_dataset.cnmf.estimates.idx_components is not None:\n                    if mask[\"mask_id\"] in caiman_dataset.cnmf.estimates.idx_components:\n                        cells.append(\n                            {\n                                **key,\n                                \"mask_classification_method\": \"caiman_default_classifier\",\n                                \"mask\": mask[\"mask_id\"],\n                                \"mask_type\": \"soma\",\n                            }\n                        )\n\n            self.insert1(key)\n            self.Mask.insert(masks, ignore_extra_fields=True)\n\n            if cells:\n                MaskClassification.insert1(\n                    {\n                        **key,\n                        \"mask_classification_method\": \"caiman_default_classifier\",\n                    },\n                    allow_direct_insert=True,\n                )\n                MaskClassification.MaskType.insert(\n                    cells, ignore_extra_fields=True, allow_direct_insert=True\n                )\n        elif method == \"extract\":\n            extract_dataset = imaging_dataset\n            masks = [\n                dict(\n                    **key,\n                    segmentation_channel=0,\n                    mask=mask[\"mask_id\"],\n                    mask_npix=mask[\"mask_npix\"],\n                    mask_center_x=mask[\"mask_center_x\"],\n                    mask_center_y=mask[\"mask_center_y\"],\n                    mask_center_z=mask[\"mask_center_z\"],\n                    mask_xpix=mask[\"mask_xpix\"],\n                    mask_ypix=mask[\"mask_ypix\"],\n                    mask_zpix=mask[\"mask_zpix\"],\n                    mask_weights=mask[\"mask_weights\"],\n                )\n                for mask in extract_dataset.load_results()\n            ]\n\n            self.insert1(key)\n            self.Mask.insert(masks, ignore_extra_fields=True)\n        else:\n            raise NotImplementedError(f\"Unknown/unimplemented method: {method}\")\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_no_curation/#element_calcium_imaging.imaging_no_curation.Segmentation.Mask", "title": "<code>Mask</code>", "text": "<p>         Bases: <code>dj.Part</code></p> <p>Details of the masks identified from the Segmentation procedure.</p> <p>Attributes:</p> Name Type Description <code>Segmentation</code> <code>foreign key</code> <p>Primary key from Segmentation.</p> <code>mask</code> <code>int</code> <p>Unique mask ID.</p> <code>scan.Channel.proj(segmentation_channel='channel')</code> <code>foreign key</code> <p>Channel used for segmentation.</p> <code>mask_npix</code> <code>int</code> <p>Number of pixels in ROIs.</p> <code>mask_center_x</code> <code>int</code> <p>Center x coordinate in pixel.</p> <code>mask_center_y</code> <code>int</code> <p>Center y coordinate in pixel.</p> <code>mask_center_z</code> <code>int</code> <p>Center z coordinate in pixel.</p> <code>mask_xpix</code> <code>longblob</code> <p>X coordinates in pixels.</p> <code>mask_ypix</code> <code>longblob</code> <p>Y coordinates in pixels.</p> <code>mask_zpix</code> <code>longblob</code> <p>Z coordinates in pixels.</p> <code>mask_weights</code> <code>longblob</code> <p>Weights of the mask at the indices above.</p> Source code in <code>element_calcium_imaging/imaging_no_curation.py</code> <pre><code>class Mask(dj.Part):\n\"\"\"Details of the masks identified from the Segmentation procedure.\n\n    Attributes:\n        Segmentation (foreign key): Primary key from Segmentation.\n        mask (int): Unique mask ID.\n        scan.Channel.proj(segmentation_channel='channel') (foreign key): Channel\n            used for segmentation.\n        mask_npix (int): Number of pixels in ROIs.\n        mask_center_x (int): Center x coordinate in pixel.\n        mask_center_y (int): Center y coordinate in pixel.\n        mask_center_z (int): Center z coordinate in pixel.\n        mask_xpix (longblob): X coordinates in pixels.\n        mask_ypix (longblob): Y coordinates in pixels.\n        mask_zpix (longblob): Z coordinates in pixels.\n        mask_weights (longblob): Weights of the mask at the indices above.\n    \"\"\"\n\n    definition = \"\"\" # A mask produced by segmentation.\n    -&gt; master\n    mask               : smallint\n    ---\n    -&gt; scan.Channel.proj(segmentation_channel='channel')  # channel used for segmentation\n    mask_npix          : int       # number of pixels in ROIs\n    mask_center_x      : int       # center x coordinate in pixel\n    mask_center_y      : int       # center y coordinate in pixel\n    mask_center_z=null : int       # center z coordinate in pixel\n    mask_xpix          : longblob  # x coordinates in pixels\n    mask_ypix          : longblob  # y coordinates in pixels\n    mask_zpix=null     : longblob  # z coordinates in pixels\n    mask_weights       : longblob  # weights of the mask at the indices above\n    \"\"\"\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_no_curation/#element_calcium_imaging.imaging_no_curation.Segmentation.make", "title": "<code>make(key)</code>", "text": "<p>Populate the Segmentation with the results parsed from analysis outputs.</p> Source code in <code>element_calcium_imaging/imaging_no_curation.py</code> <pre><code>def make(self, key):\n\"\"\"Populate the Segmentation with the results parsed from analysis outputs.\"\"\"\n\n    method, imaging_dataset = get_loader_result(key, ProcessingTask)\n\n    if method == \"suite2p\":\n        suite2p_dataset = imaging_dataset\n\n        # ---- iterate through all s2p plane outputs ----\n        masks, cells = [], []\n        for plane, s2p in suite2p_dataset.planes.items():\n            mask_count = len(masks)  # increment mask id from all \"plane\"\n            for mask_idx, (is_cell, cell_prob, mask_stat) in enumerate(\n                zip(s2p.iscell, s2p.cell_prob, s2p.stat)\n            ):\n                masks.append(\n                    {\n                        **key,\n                        \"mask\": mask_idx + mask_count,\n                        \"segmentation_channel\": s2p.segmentation_channel,\n                        \"mask_npix\": mask_stat[\"npix\"],\n                        \"mask_center_x\": mask_stat[\"med\"][1],\n                        \"mask_center_y\": mask_stat[\"med\"][0],\n                        \"mask_center_z\": mask_stat.get(\"iplane\", plane),\n                        \"mask_xpix\": mask_stat[\"xpix\"],\n                        \"mask_ypix\": mask_stat[\"ypix\"],\n                        \"mask_zpix\": np.full(\n                            mask_stat[\"npix\"],\n                            mask_stat.get(\"iplane\", plane),\n                        ),\n                        \"mask_weights\": mask_stat[\"lam\"],\n                    }\n                )\n                if is_cell:\n                    cells.append(\n                        {\n                            **key,\n                            \"mask_classification_method\": \"suite2p_default_classifier\",\n                            \"mask\": mask_idx + mask_count,\n                            \"mask_type\": \"soma\",\n                            \"confidence\": cell_prob,\n                        }\n                    )\n\n        self.insert1(key)\n        self.Mask.insert(masks, ignore_extra_fields=True)\n\n        if cells:\n            MaskClassification.insert1(\n                {\n                    **key,\n                    \"mask_classification_method\": \"suite2p_default_classifier\",\n                },\n                allow_direct_insert=True,\n            )\n            MaskClassification.MaskType.insert(\n                cells, ignore_extra_fields=True, allow_direct_insert=True\n            )\n    elif method == \"caiman\":\n        caiman_dataset = imaging_dataset\n\n        # infer \"segmentation_channel\" - from params if available, else from caiman loader\n        params = (ProcessingParamSet * ProcessingTask &amp; key).fetch1(\"params\")\n        segmentation_channel = params.get(\n            \"segmentation_channel\", caiman_dataset.segmentation_channel\n        )\n\n        masks, cells = [], []\n        for mask in caiman_dataset.masks:\n            masks.append(\n                {\n                    **key,\n                    \"segmentation_channel\": segmentation_channel,\n                    \"mask\": mask[\"mask_id\"],\n                    \"mask_npix\": mask[\"mask_npix\"],\n                    \"mask_center_x\": mask[\"mask_center_x\"],\n                    \"mask_center_y\": mask[\"mask_center_y\"],\n                    \"mask_center_z\": mask[\"mask_center_z\"],\n                    \"mask_xpix\": mask[\"mask_xpix\"],\n                    \"mask_ypix\": mask[\"mask_ypix\"],\n                    \"mask_zpix\": mask[\"mask_zpix\"],\n                    \"mask_weights\": mask[\"mask_weights\"],\n                }\n            )\n            if caiman_dataset.cnmf.estimates.idx_components is not None:\n                if mask[\"mask_id\"] in caiman_dataset.cnmf.estimates.idx_components:\n                    cells.append(\n                        {\n                            **key,\n                            \"mask_classification_method\": \"caiman_default_classifier\",\n                            \"mask\": mask[\"mask_id\"],\n                            \"mask_type\": \"soma\",\n                        }\n                    )\n\n        self.insert1(key)\n        self.Mask.insert(masks, ignore_extra_fields=True)\n\n        if cells:\n            MaskClassification.insert1(\n                {\n                    **key,\n                    \"mask_classification_method\": \"caiman_default_classifier\",\n                },\n                allow_direct_insert=True,\n            )\n            MaskClassification.MaskType.insert(\n                cells, ignore_extra_fields=True, allow_direct_insert=True\n            )\n    elif method == \"extract\":\n        extract_dataset = imaging_dataset\n        masks = [\n            dict(\n                **key,\n                segmentation_channel=0,\n                mask=mask[\"mask_id\"],\n                mask_npix=mask[\"mask_npix\"],\n                mask_center_x=mask[\"mask_center_x\"],\n                mask_center_y=mask[\"mask_center_y\"],\n                mask_center_z=mask[\"mask_center_z\"],\n                mask_xpix=mask[\"mask_xpix\"],\n                mask_ypix=mask[\"mask_ypix\"],\n                mask_zpix=mask[\"mask_zpix\"],\n                mask_weights=mask[\"mask_weights\"],\n            )\n            for mask in extract_dataset.load_results()\n        ]\n\n        self.insert1(key)\n        self.Mask.insert(masks, ignore_extra_fields=True)\n    else:\n        raise NotImplementedError(f\"Unknown/unimplemented method: {method}\")\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_no_curation/#element_calcium_imaging.imaging_no_curation.MaskClassificationMethod", "title": "<code>MaskClassificationMethod</code>", "text": "<p>         Bases: <code>dj.Lookup</code></p> <p>Available mask classification methods.</p> <p>Attributes:</p> Name Type Description <code>mask_classification_method</code> <code>str</code> <p>Mask classification method.</p> Source code in <code>element_calcium_imaging/imaging_no_curation.py</code> <pre><code>@schema\nclass MaskClassificationMethod(dj.Lookup):\n\"\"\"Available mask classification methods.\n\n    Attributes:\n        mask_classification_method (str): Mask classification method.\n    \"\"\"\n\n    definition = \"\"\"\n    mask_classification_method: varchar(48)\n    \"\"\"\n\n    contents = zip([\"suite2p_default_classifier\", \"caiman_default_classifier\"])\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_no_curation/#element_calcium_imaging.imaging_no_curation.MaskClassification", "title": "<code>MaskClassification</code>", "text": "<p>         Bases: <code>dj.Computed</code></p> <p>Classes assigned to each mask.</p> <p>Attributes:</p> Name Type Description <code>Segmentation</code> <code>foreign key</code> <p>Primary key from Segmentation.</p> <code>MaskClassificationMethod</code> <code>foreign key</code> <p>Primary key from MaskClassificationMethod.</p> Source code in <code>element_calcium_imaging/imaging_no_curation.py</code> <pre><code>@schema\nclass MaskClassification(dj.Computed):\n\"\"\"Classes assigned to each mask.\n\n    Attributes:\n        Segmentation (foreign key): Primary key from Segmentation.\n        MaskClassificationMethod (foreign key): Primary key from\n            MaskClassificationMethod.\n    \"\"\"\n\n    definition = \"\"\"\n    -&gt; Segmentation\n    -&gt; MaskClassificationMethod\n    \"\"\"\n\n    class MaskType(dj.Part):\n\"\"\"Type assigned to each mask.\n\n        Attributes:\n            MaskClassification (foreign key): Primary key from MaskClassification.\n            Segmentation.Mask (foreign key): Primary key from Segmentation.Mask.\n            MaskType: Primary key from MaskType.\n            confidence (float, optional): Confidence level of the mask classification.\n        \"\"\"\n\n        definition = \"\"\"\n        -&gt; master\n        -&gt; Segmentation.Mask\n        ---\n        -&gt; MaskType\n        confidence=null: float\n        \"\"\"\n\n    def make(self, key):\n        pass\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_no_curation/#element_calcium_imaging.imaging_no_curation.MaskClassification.MaskType", "title": "<code>MaskType</code>", "text": "<p>         Bases: <code>dj.Part</code></p> <p>Type assigned to each mask.</p> <p>Attributes:</p> Name Type Description <code>MaskClassification</code> <code>foreign key</code> <p>Primary key from MaskClassification.</p> <code>Segmentation.Mask</code> <code>foreign key</code> <p>Primary key from Segmentation.Mask.</p> <code>MaskType</code> <code>foreign key</code> <p>Primary key from MaskType.</p> <code>confidence</code> <code>float</code> <p>Confidence level of the mask classification.</p> Source code in <code>element_calcium_imaging/imaging_no_curation.py</code> <pre><code>class MaskType(dj.Part):\n\"\"\"Type assigned to each mask.\n\n    Attributes:\n        MaskClassification (foreign key): Primary key from MaskClassification.\n        Segmentation.Mask (foreign key): Primary key from Segmentation.Mask.\n        MaskType: Primary key from MaskType.\n        confidence (float, optional): Confidence level of the mask classification.\n    \"\"\"\n\n    definition = \"\"\"\n    -&gt; master\n    -&gt; Segmentation.Mask\n    ---\n    -&gt; MaskType\n    confidence=null: float\n    \"\"\"\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_no_curation/#element_calcium_imaging.imaging_no_curation.Fluorescence", "title": "<code>Fluorescence</code>", "text": "<p>         Bases: <code>dj.Computed</code></p> <p>Fluorescence traces.</p> <p>Attributes:</p> Name Type Description <code>Segmentation</code> <code>foreign key</code> <p>Primary key from Segmentation.</p> Source code in <code>element_calcium_imaging/imaging_no_curation.py</code> <pre><code>@schema\nclass Fluorescence(dj.Computed):\n\"\"\"Fluorescence traces.\n\n    Attributes:\n        Segmentation (foreign key): Primary key from Segmentation.\n    \"\"\"\n\n    definition = \"\"\"# Fluorescence traces before spike extraction or filtering\n    -&gt; Segmentation\n    \"\"\"\n\n    class Trace(dj.Part):\n\"\"\"Traces obtained from segmented region of interests.\n\n        Attributes:\n            Fluorescence (foreign key): Primary key from Fluorescence.\n            Segmentation.Mask (foreign key): Primary key from Segmentation.Mask.\n            scan.Channel.proj(fluo_channel='channel') (int): The channel that this trace\n                comes from.\n            fluorescence (longblob): Fluorescence trace associated with this mask.\n            neuropil_fluorescence (longblob, optional): Neuropil fluorescence trace.\n        \"\"\"\n\n        definition = \"\"\"\n        -&gt; master\n        -&gt; Segmentation.Mask\n        -&gt; scan.Channel.proj(fluo_channel='channel')  # The channel that this trace comes from\n        ---\n        fluorescence                : longblob  # Fluorescence trace associated with this mask\n        neuropil_fluorescence=null  : longblob  # Neuropil fluorescence trace\n        \"\"\"\n\n    def make(self, key):\n\"\"\"Populate the Fluorescence with the results parsed from analysis outputs.\"\"\"\n\n        method, imaging_dataset = get_loader_result(key, ProcessingTask)\n\n        if method == \"suite2p\":\n            suite2p_dataset = imaging_dataset\n\n            # ---- iterate through all s2p plane outputs ----\n            fluo_traces, fluo_chn2_traces = [], []\n            for s2p in suite2p_dataset.planes.values():\n                mask_count = len(fluo_traces)  # increment mask id from all \"plane\"\n                for mask_idx, (f, fneu) in enumerate(zip(s2p.F, s2p.Fneu)):\n                    fluo_traces.append(\n                        {\n                            **key,\n                            \"mask\": mask_idx + mask_count,\n                            \"fluo_channel\": 0,\n                            \"fluorescence\": f,\n                            \"neuropil_fluorescence\": fneu,\n                        }\n                    )\n                if len(s2p.F_chan2):\n                    mask_chn2_count = len(\n                        fluo_chn2_traces\n                    )  # increment mask id from all planes\n                    for mask_idx, (f2, fneu2) in enumerate(\n                        zip(s2p.F_chan2, s2p.Fneu_chan2)\n                    ):\n                        fluo_chn2_traces.append(\n                            {\n                                **key,\n                                \"mask\": mask_idx + mask_chn2_count,\n                                \"fluo_channel\": 1,\n                                \"fluorescence\": f2,\n                                \"neuropil_fluorescence\": fneu2,\n                            }\n                        )\n\n            self.insert1(key)\n            self.Trace.insert(fluo_traces + fluo_chn2_traces)\n        elif method == \"caiman\":\n            caiman_dataset = imaging_dataset\n\n            # infer \"segmentation_channel\" - from params if available, else from caiman loader\n            params = (ProcessingParamSet * ProcessingTask &amp; key).fetch1(\"params\")\n            segmentation_channel = params.get(\n                \"segmentation_channel\", caiman_dataset.segmentation_channel\n            )\n\n            fluo_traces = []\n            for mask in caiman_dataset.masks:\n                fluo_traces.append(\n                    {\n                        **key,\n                        \"mask\": mask[\"mask_id\"],\n                        \"fluo_channel\": segmentation_channel,\n                        \"fluorescence\": mask[\"inferred_trace\"],\n                    }\n                )\n\n            self.insert1(key)\n            self.Trace.insert(fluo_traces)\n        elif method == \"extract\":\n            extract_dataset = imaging_dataset\n\n            fluo_traces = [\n                {\n                    **key,\n                    \"mask\": mask_id,\n                    \"fluo_channel\": 0,\n                    \"fluorescence\": fluorescence,\n                }\n                for mask_id, fluorescence in enumerate(extract_dataset.T)\n            ]\n\n            self.insert1(key)\n            self.Trace.insert(fluo_traces)\n\n        else:\n            raise NotImplementedError(\"Unknown/unimplemented method: {}\".format(method))\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_no_curation/#element_calcium_imaging.imaging_no_curation.Fluorescence.Trace", "title": "<code>Trace</code>", "text": "<p>         Bases: <code>dj.Part</code></p> <p>Traces obtained from segmented region of interests.</p> <p>Attributes:</p> Name Type Description <code>Fluorescence</code> <code>foreign key</code> <p>Primary key from Fluorescence.</p> <code>Segmentation.Mask</code> <code>foreign key</code> <p>Primary key from Segmentation.Mask.</p> <code>scan.Channel.proj(fluo_channel='channel')</code> <code>int</code> <p>The channel that this trace comes from.</p> <code>fluorescence</code> <code>longblob</code> <p>Fluorescence trace associated with this mask.</p> <code>neuropil_fluorescence</code> <code>longblob</code> <p>Neuropil fluorescence trace.</p> Source code in <code>element_calcium_imaging/imaging_no_curation.py</code> <pre><code>class Trace(dj.Part):\n\"\"\"Traces obtained from segmented region of interests.\n\n    Attributes:\n        Fluorescence (foreign key): Primary key from Fluorescence.\n        Segmentation.Mask (foreign key): Primary key from Segmentation.Mask.\n        scan.Channel.proj(fluo_channel='channel') (int): The channel that this trace\n            comes from.\n        fluorescence (longblob): Fluorescence trace associated with this mask.\n        neuropil_fluorescence (longblob, optional): Neuropil fluorescence trace.\n    \"\"\"\n\n    definition = \"\"\"\n    -&gt; master\n    -&gt; Segmentation.Mask\n    -&gt; scan.Channel.proj(fluo_channel='channel')  # The channel that this trace comes from\n    ---\n    fluorescence                : longblob  # Fluorescence trace associated with this mask\n    neuropil_fluorescence=null  : longblob  # Neuropil fluorescence trace\n    \"\"\"\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_no_curation/#element_calcium_imaging.imaging_no_curation.Fluorescence.make", "title": "<code>make(key)</code>", "text": "<p>Populate the Fluorescence with the results parsed from analysis outputs.</p> Source code in <code>element_calcium_imaging/imaging_no_curation.py</code> <pre><code>def make(self, key):\n\"\"\"Populate the Fluorescence with the results parsed from analysis outputs.\"\"\"\n\n    method, imaging_dataset = get_loader_result(key, ProcessingTask)\n\n    if method == \"suite2p\":\n        suite2p_dataset = imaging_dataset\n\n        # ---- iterate through all s2p plane outputs ----\n        fluo_traces, fluo_chn2_traces = [], []\n        for s2p in suite2p_dataset.planes.values():\n            mask_count = len(fluo_traces)  # increment mask id from all \"plane\"\n            for mask_idx, (f, fneu) in enumerate(zip(s2p.F, s2p.Fneu)):\n                fluo_traces.append(\n                    {\n                        **key,\n                        \"mask\": mask_idx + mask_count,\n                        \"fluo_channel\": 0,\n                        \"fluorescence\": f,\n                        \"neuropil_fluorescence\": fneu,\n                    }\n                )\n            if len(s2p.F_chan2):\n                mask_chn2_count = len(\n                    fluo_chn2_traces\n                )  # increment mask id from all planes\n                for mask_idx, (f2, fneu2) in enumerate(\n                    zip(s2p.F_chan2, s2p.Fneu_chan2)\n                ):\n                    fluo_chn2_traces.append(\n                        {\n                            **key,\n                            \"mask\": mask_idx + mask_chn2_count,\n                            \"fluo_channel\": 1,\n                            \"fluorescence\": f2,\n                            \"neuropil_fluorescence\": fneu2,\n                        }\n                    )\n\n        self.insert1(key)\n        self.Trace.insert(fluo_traces + fluo_chn2_traces)\n    elif method == \"caiman\":\n        caiman_dataset = imaging_dataset\n\n        # infer \"segmentation_channel\" - from params if available, else from caiman loader\n        params = (ProcessingParamSet * ProcessingTask &amp; key).fetch1(\"params\")\n        segmentation_channel = params.get(\n            \"segmentation_channel\", caiman_dataset.segmentation_channel\n        )\n\n        fluo_traces = []\n        for mask in caiman_dataset.masks:\n            fluo_traces.append(\n                {\n                    **key,\n                    \"mask\": mask[\"mask_id\"],\n                    \"fluo_channel\": segmentation_channel,\n                    \"fluorescence\": mask[\"inferred_trace\"],\n                }\n            )\n\n        self.insert1(key)\n        self.Trace.insert(fluo_traces)\n    elif method == \"extract\":\n        extract_dataset = imaging_dataset\n\n        fluo_traces = [\n            {\n                **key,\n                \"mask\": mask_id,\n                \"fluo_channel\": 0,\n                \"fluorescence\": fluorescence,\n            }\n            for mask_id, fluorescence in enumerate(extract_dataset.T)\n        ]\n\n        self.insert1(key)\n        self.Trace.insert(fluo_traces)\n\n    else:\n        raise NotImplementedError(\"Unknown/unimplemented method: {}\".format(method))\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_no_curation/#element_calcium_imaging.imaging_no_curation.ActivityExtractionMethod", "title": "<code>ActivityExtractionMethod</code>", "text": "<p>         Bases: <code>dj.Lookup</code></p> <p>Available activity extraction methods.</p> <p>Attributes:</p> Name Type Description <code>extraction_method</code> <code>str</code> <p>Extraction method.</p> Source code in <code>element_calcium_imaging/imaging_no_curation.py</code> <pre><code>@schema\nclass ActivityExtractionMethod(dj.Lookup):\n\"\"\"Available activity extraction methods.\n\n    Attributes:\n        extraction_method (str): Extraction method.\n    \"\"\"\n\n    definition = \"\"\"# Activity extraction method\n    extraction_method: varchar(32)\n    \"\"\"\n\n    contents = zip([\"suite2p_deconvolution\", \"caiman_deconvolution\", \"caiman_dff\"])\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_no_curation/#element_calcium_imaging.imaging_no_curation.Activity", "title": "<code>Activity</code>", "text": "<p>         Bases: <code>dj.Computed</code></p> <p>Inferred neural activity from fluorescence trace (e.g. dff, spikes, etc.).</p> <p>Attributes:</p> Name Type Description <code>Fluorescence</code> <code>foreign key</code> <p>Primary key from Fluorescence.</p> <code>ActivityExtractionMethod</code> <code>foreign key</code> <p>Primary key from ActivityExtractionMethod.</p> Source code in <code>element_calcium_imaging/imaging_no_curation.py</code> <pre><code>@schema\nclass Activity(dj.Computed):\n\"\"\"Inferred neural activity from fluorescence trace (e.g. dff, spikes, etc.).\n\n    Attributes:\n        Fluorescence (foreign key): Primary key from Fluorescence.\n        ActivityExtractionMethod (foreign key): Primary key from\n            ActivityExtractionMethod.\n    \"\"\"\n\n    definition = \"\"\"# Neural Activity\n    -&gt; Fluorescence\n    -&gt; ActivityExtractionMethod\n    \"\"\"\n\n    class Trace(dj.Part):\n\"\"\"Trace(s) for each mask.\n\n        Attributes:\n            Activity (foreign key): Primary key from Activity.\n            Fluorescence.Trace (foreign key): Fluorescence.Trace.\n            activity_trace (longblob): Neural activity from fluorescence trace.\n        \"\"\"\n\n        definition = \"\"\"\n        -&gt; master\n        -&gt; Fluorescence.Trace\n        ---\n        activity_trace: longblob\n        \"\"\"\n\n    @property\n    def key_source(self):\n        suite2p_key_source = (\n            Fluorescence\n            * ActivityExtractionMethod\n            * ProcessingParamSet.proj(\"processing_method\")\n            &amp; 'processing_method = \"suite2p\"'\n            &amp; 'extraction_method LIKE \"suite2p%\"'\n        )\n        caiman_key_source = (\n            Fluorescence\n            * ActivityExtractionMethod\n            * ProcessingParamSet.proj(\"processing_method\")\n            &amp; 'processing_method = \"caiman\"'\n            &amp; 'extraction_method LIKE \"caiman%\"'\n        )\n        return suite2p_key_source.proj() + caiman_key_source.proj()\n\n    def make(self, key):\n\"\"\"Populate the Activity with the results parsed from analysis outputs.\"\"\"\n\n        method, imaging_dataset = get_loader_result(key, ProcessingTask)\n\n        if method == \"suite2p\":\n            if key[\"extraction_method\"] == \"suite2p_deconvolution\":\n                suite2p_dataset = imaging_dataset\n                # ---- iterate through all s2p plane outputs ----\n                spikes = [\n                    dict(\n                        key,\n                        mask=mask_idx,\n                        fluo_channel=0,\n                        activity_trace=spks,\n                    )\n                    for mask_idx, spks in enumerate(\n                        s\n                        for plane in suite2p_dataset.planes.values()\n                        for s in plane.spks\n                    )\n                ]\n\n                self.insert1(key)\n                self.Trace.insert(spikes)\n        elif method == \"caiman\":\n            caiman_dataset = imaging_dataset\n\n            if key[\"extraction_method\"] in (\n                \"caiman_deconvolution\",\n                \"caiman_dff\",\n            ):\n                attr_mapper = {\n                    \"caiman_deconvolution\": \"spikes\",\n                    \"caiman_dff\": \"dff\",\n                }\n\n                # infer \"segmentation_channel\" - from params if available, else from caiman loader\n                params = (ProcessingParamSet * ProcessingTask &amp; key).fetch1(\"params\")\n                segmentation_channel = params.get(\n                    \"segmentation_channel\", caiman_dataset.segmentation_channel\n                )\n\n                self.insert1(key)\n                self.Trace.insert(\n                    dict(\n                        key,\n                        mask=mask[\"mask_id\"],\n                        fluo_channel=segmentation_channel,\n                        activity_trace=mask[attr_mapper[key[\"extraction_method\"]]],\n                    )\n                    for mask in caiman_dataset.masks\n                )\n        else:\n            raise NotImplementedError(\"Unknown/unimplemented method: {}\".format(method))\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_no_curation/#element_calcium_imaging.imaging_no_curation.Activity.Trace", "title": "<code>Trace</code>", "text": "<p>         Bases: <code>dj.Part</code></p> <p>Trace(s) for each mask.</p> <p>Attributes:</p> Name Type Description <code>Activity</code> <code>foreign key</code> <p>Primary key from Activity.</p> <code>Fluorescence.Trace</code> <code>foreign key</code> <p>Fluorescence.Trace.</p> <code>activity_trace</code> <code>longblob</code> <p>Neural activity from fluorescence trace.</p> Source code in <code>element_calcium_imaging/imaging_no_curation.py</code> <pre><code>class Trace(dj.Part):\n\"\"\"Trace(s) for each mask.\n\n    Attributes:\n        Activity (foreign key): Primary key from Activity.\n        Fluorescence.Trace (foreign key): Fluorescence.Trace.\n        activity_trace (longblob): Neural activity from fluorescence trace.\n    \"\"\"\n\n    definition = \"\"\"\n    -&gt; master\n    -&gt; Fluorescence.Trace\n    ---\n    activity_trace: longblob\n    \"\"\"\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_no_curation/#element_calcium_imaging.imaging_no_curation.Activity.make", "title": "<code>make(key)</code>", "text": "<p>Populate the Activity with the results parsed from analysis outputs.</p> Source code in <code>element_calcium_imaging/imaging_no_curation.py</code> <pre><code>def make(self, key):\n\"\"\"Populate the Activity with the results parsed from analysis outputs.\"\"\"\n\n    method, imaging_dataset = get_loader_result(key, ProcessingTask)\n\n    if method == \"suite2p\":\n        if key[\"extraction_method\"] == \"suite2p_deconvolution\":\n            suite2p_dataset = imaging_dataset\n            # ---- iterate through all s2p plane outputs ----\n            spikes = [\n                dict(\n                    key,\n                    mask=mask_idx,\n                    fluo_channel=0,\n                    activity_trace=spks,\n                )\n                for mask_idx, spks in enumerate(\n                    s\n                    for plane in suite2p_dataset.planes.values()\n                    for s in plane.spks\n                )\n            ]\n\n            self.insert1(key)\n            self.Trace.insert(spikes)\n    elif method == \"caiman\":\n        caiman_dataset = imaging_dataset\n\n        if key[\"extraction_method\"] in (\n            \"caiman_deconvolution\",\n            \"caiman_dff\",\n        ):\n            attr_mapper = {\n                \"caiman_deconvolution\": \"spikes\",\n                \"caiman_dff\": \"dff\",\n            }\n\n            # infer \"segmentation_channel\" - from params if available, else from caiman loader\n            params = (ProcessingParamSet * ProcessingTask &amp; key).fetch1(\"params\")\n            segmentation_channel = params.get(\n                \"segmentation_channel\", caiman_dataset.segmentation_channel\n            )\n\n            self.insert1(key)\n            self.Trace.insert(\n                dict(\n                    key,\n                    mask=mask[\"mask_id\"],\n                    fluo_channel=segmentation_channel,\n                    activity_trace=mask[attr_mapper[key[\"extraction_method\"]]],\n                )\n                for mask in caiman_dataset.masks\n            )\n    else:\n        raise NotImplementedError(\"Unknown/unimplemented method: {}\".format(method))\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_no_curation/#element_calcium_imaging.imaging_no_curation.ProcessingQualityMetrics", "title": "<code>ProcessingQualityMetrics</code>", "text": "<p>         Bases: <code>dj.Computed</code></p> <p>Quality metrics used to evaluate the results of the calcium imaging analysis pipeline.</p> <p>Attributes:</p> Name Type Description <code>Fluorescence</code> <code>foreign key</code> <p>Primary key from Fluorescence.</p> Source code in <code>element_calcium_imaging/imaging_no_curation.py</code> <pre><code>@schema\nclass ProcessingQualityMetrics(dj.Computed):\n\"\"\"Quality metrics used to evaluate the results of the calcium imaging analysis pipeline.\n\n    Attributes:\n        Fluorescence (foreign key): Primary key from Fluorescence.\n    \"\"\"\n\n    definition = \"\"\"\n    -&gt; Fluorescence\n    \"\"\"\n\n    class Mask(dj.Part):\n\"\"\"Quality metrics used to evaluate the masks.\n\n        Attributes:\n            Fluorescence (foreign key): Primary key from Fluorescence.\n            Segmentation.Mask (foreign key): Primary key from Segmentation.Mask.\n            mask_area (float): Mask area in square micrometer.\n            roundness (float): Roundness between 0 and 1. Values closer to 1 are rounder.\n        \"\"\"\n\n        definition = \"\"\"\n        -&gt; master\n        -&gt; Segmentation.Mask\n        ---\n        mask_area=null: float  # Mask area in square micrometer.\n        roundness: float       # Roundness between 0 and 1. Values closer to 1 are rounder.\n        \"\"\"\n\n    class Trace(dj.Part):\n\"\"\"Quality metrics used to evaluate the fluorescence traces.\n\n        Attributes:\n            Fluorescence (foreign key): Primary key from Fluorescence.\n            Fluorescence.Trace (foreign key): Primary key from Fluorescence.Trace.\n            skewness (float): Skewness of the fluorescence trace.\n            variance (float): Variance of the fluorescence trace.\n        \"\"\"\n\n        definition = \"\"\"\n        -&gt; master\n        -&gt; Fluorescence.Trace\n        ---\n        skewness: float   # Skewness of the fluorescence trace.\n        variance: float   # Variance of the fluorescence trace.\n        \"\"\"\n\n    def make(self, key):\n\"\"\"Populate the ProcessingQualityMetrics table and its part tables.\"\"\"\n        from scipy.stats import skew\n\n        (\n            mask_xpixs,\n            mask_ypixs,\n            mask_weights,\n            fluorescence,\n            fluo_channels,\n            mask_ids,\n            mask_npix,\n            px_height,\n            px_width,\n            um_height,\n            um_width,\n        ) = (Segmentation.Mask * scan.ScanInfo.Field * Fluorescence.Trace &amp; key).fetch(\n            \"mask_xpix\",\n            \"mask_ypix\",\n            \"mask_weights\",\n            \"fluorescence\",\n            \"fluo_channel\",\n            \"mask\",\n            \"mask_npix\",\n            \"px_height\",\n            \"px_width\",\n            \"um_height\",\n            \"um_width\",\n        )\n\n        norm_mean = lambda x: x.mean() / x.max()\n        roundnesses = [\n            norm_mean(np.linalg.eigvals(np.cov(x, y, aweights=w)))\n            for x, y, w in zip(mask_xpixs, mask_ypixs, mask_weights)\n        ]\n\n        fluorescence = np.stack(fluorescence)\n\n        self.insert1(key)\n\n        self.Mask.insert(\n            dict(key, mask=mask_id, mask_area=mask_area, roundness=roundness)\n            for mask_id, mask_area, roundness in zip(\n                mask_ids,\n                mask_npix * (um_height / px_height) * (um_width / px_width),\n                roundnesses,\n            )\n        )\n\n        self.Trace.insert(\n            dict(\n                key,\n                fluo_channel=fluo_channel,\n                mask=mask_id,\n                skewness=skewness,\n                variance=variance,\n            )\n            for fluo_channel, mask_id, skewness, variance in zip(\n                fluo_channels,\n                mask_ids,\n                skew(fluorescence, axis=1),\n                fluorescence.std(axis=1),\n            )\n        )\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_no_curation/#element_calcium_imaging.imaging_no_curation.ProcessingQualityMetrics.Mask", "title": "<code>Mask</code>", "text": "<p>         Bases: <code>dj.Part</code></p> <p>Quality metrics used to evaluate the masks.</p> <p>Attributes:</p> Name Type Description <code>Fluorescence</code> <code>foreign key</code> <p>Primary key from Fluorescence.</p> <code>Segmentation.Mask</code> <code>foreign key</code> <p>Primary key from Segmentation.Mask.</p> <code>mask_area</code> <code>float</code> <p>Mask area in square micrometer.</p> <code>roundness</code> <code>float</code> <p>Roundness between 0 and 1. Values closer to 1 are rounder.</p> Source code in <code>element_calcium_imaging/imaging_no_curation.py</code> <pre><code>class Mask(dj.Part):\n\"\"\"Quality metrics used to evaluate the masks.\n\n    Attributes:\n        Fluorescence (foreign key): Primary key from Fluorescence.\n        Segmentation.Mask (foreign key): Primary key from Segmentation.Mask.\n        mask_area (float): Mask area in square micrometer.\n        roundness (float): Roundness between 0 and 1. Values closer to 1 are rounder.\n    \"\"\"\n\n    definition = \"\"\"\n    -&gt; master\n    -&gt; Segmentation.Mask\n    ---\n    mask_area=null: float  # Mask area in square micrometer.\n    roundness: float       # Roundness between 0 and 1. Values closer to 1 are rounder.\n    \"\"\"\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_no_curation/#element_calcium_imaging.imaging_no_curation.ProcessingQualityMetrics.Trace", "title": "<code>Trace</code>", "text": "<p>         Bases: <code>dj.Part</code></p> <p>Quality metrics used to evaluate the fluorescence traces.</p> <p>Attributes:</p> Name Type Description <code>Fluorescence</code> <code>foreign key</code> <p>Primary key from Fluorescence.</p> <code>Fluorescence.Trace</code> <code>foreign key</code> <p>Primary key from Fluorescence.Trace.</p> <code>skewness</code> <code>float</code> <p>Skewness of the fluorescence trace.</p> <code>variance</code> <code>float</code> <p>Variance of the fluorescence trace.</p> Source code in <code>element_calcium_imaging/imaging_no_curation.py</code> <pre><code>class Trace(dj.Part):\n\"\"\"Quality metrics used to evaluate the fluorescence traces.\n\n    Attributes:\n        Fluorescence (foreign key): Primary key from Fluorescence.\n        Fluorescence.Trace (foreign key): Primary key from Fluorescence.Trace.\n        skewness (float): Skewness of the fluorescence trace.\n        variance (float): Variance of the fluorescence trace.\n    \"\"\"\n\n    definition = \"\"\"\n    -&gt; master\n    -&gt; Fluorescence.Trace\n    ---\n    skewness: float   # Skewness of the fluorescence trace.\n    variance: float   # Variance of the fluorescence trace.\n    \"\"\"\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_no_curation/#element_calcium_imaging.imaging_no_curation.ProcessingQualityMetrics.make", "title": "<code>make(key)</code>", "text": "<p>Populate the ProcessingQualityMetrics table and its part tables.</p> Source code in <code>element_calcium_imaging/imaging_no_curation.py</code> <pre><code>def make(self, key):\n\"\"\"Populate the ProcessingQualityMetrics table and its part tables.\"\"\"\n    from scipy.stats import skew\n\n    (\n        mask_xpixs,\n        mask_ypixs,\n        mask_weights,\n        fluorescence,\n        fluo_channels,\n        mask_ids,\n        mask_npix,\n        px_height,\n        px_width,\n        um_height,\n        um_width,\n    ) = (Segmentation.Mask * scan.ScanInfo.Field * Fluorescence.Trace &amp; key).fetch(\n        \"mask_xpix\",\n        \"mask_ypix\",\n        \"mask_weights\",\n        \"fluorescence\",\n        \"fluo_channel\",\n        \"mask\",\n        \"mask_npix\",\n        \"px_height\",\n        \"px_width\",\n        \"um_height\",\n        \"um_width\",\n    )\n\n    norm_mean = lambda x: x.mean() / x.max()\n    roundnesses = [\n        norm_mean(np.linalg.eigvals(np.cov(x, y, aweights=w)))\n        for x, y, w in zip(mask_xpixs, mask_ypixs, mask_weights)\n    ]\n\n    fluorescence = np.stack(fluorescence)\n\n    self.insert1(key)\n\n    self.Mask.insert(\n        dict(key, mask=mask_id, mask_area=mask_area, roundness=roundness)\n        for mask_id, mask_area, roundness in zip(\n            mask_ids,\n            mask_npix * (um_height / px_height) * (um_width / px_width),\n            roundnesses,\n        )\n    )\n\n    self.Trace.insert(\n        dict(\n            key,\n            fluo_channel=fluo_channel,\n            mask=mask_id,\n            skewness=skewness,\n            variance=variance,\n        )\n        for fluo_channel, mask_id, skewness, variance in zip(\n            fluo_channels,\n            mask_ids,\n            skew(fluorescence, axis=1),\n            fluorescence.std(axis=1),\n        )\n    )\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_no_curation/#element_calcium_imaging.imaging_no_curation.get_loader_result", "title": "<code>get_loader_result(key, table)</code>", "text": "<p>Retrieve the processed imaging results from a suite2p or caiman loader.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>dict</code> <p>The <code>key</code> to one entry of ProcessingTask or Curation</p> required <code>table</code> <code>dj.Table</code> <p>A datajoint table to retrieve the loaded results from (e.g. ProcessingTask, Curation)</p> required <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If the processing_method is different than 'suite2p' or 'caiman'.</p> <p>Returns:</p> Type Description <code>Callable</code> <p>A loader object of the loaded results (e.g. suite2p.Suite2p or caiman.CaImAn,</p> <code>Callable</code> <p>see element-interface for more information on the loaders.)</p> Source code in <code>element_calcium_imaging/imaging_no_curation.py</code> <pre><code>def get_loader_result(key: dict, table: dj.Table) -&gt; Callable:\n\"\"\"Retrieve the processed imaging results from a suite2p or caiman loader.\n\n    Args:\n        key (dict): The `key` to one entry of ProcessingTask or Curation\n        table (dj.Table): A datajoint table to retrieve the loaded results from (e.g.\n            ProcessingTask, Curation)\n\n    Raises:\n        NotImplementedError: If the processing_method is different than 'suite2p' or\n            'caiman'.\n\n    Returns:\n        A loader object of the loaded results (e.g. suite2p.Suite2p or caiman.CaImAn,\n        see element-interface for more information on the loaders.)\n    \"\"\"\n    method, output_dir = (ProcessingParamSet * table &amp; key).fetch1(\n        \"processing_method\", _table_attribute_mapper[table.__name__]\n    )\n\n    output_path = find_full_path(get_imaging_root_data_dir(), output_dir)\n\n    if method == \"suite2p\" or (\n        method == \"extract\" and table.__name__ == \"MotionCorrection\"\n    ):\n        from element_interface import suite2p_loader\n\n        loaded_dataset = suite2p_loader.Suite2p(output_path)\n    elif method == \"caiman\":\n        from element_interface import caiman_loader\n\n        loaded_dataset = caiman_loader.CaImAn(output_path)\n    elif method == \"extract\":\n        from element_interface import extract_loader\n\n        loaded_dataset = extract_loader.EXTRACT(output_path)\n    else:\n        raise NotImplementedError(\"Unknown/unimplemented method: {}\".format(method))\n\n    return method, loaded_dataset\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_preprocess/", "title": "imaging_preprocess.py", "text": ""}, {"location": "api/element_calcium_imaging/imaging_preprocess/#element_calcium_imaging.imaging_preprocess.activate", "title": "<code>activate(imaging_schema_name, scan_schema_name=None, *, create_schema=True, create_tables=True, linking_module=None)</code>", "text": "<p>Activate this schema.</p> <p>Parameters:</p> Name Type Description Default <code>imaging_schema_name</code> <code>str</code> <p>Schema name on the database server to activate the <code>imaging</code> module.</p> required <code>scan_schema_name</code> <code>str</code> <p>Schema name on the database server to activate the <code>scan</code> module. Omitted, if the <code>scan</code> module is already activated.</p> <code>None</code> <code>create_schema</code> <code>bool</code> <p>When True (default), create schema in the database if it does not yet exist.</p> <code>True</code> <code>create_tables</code> <code>bool</code> <p>When True (default), create tables in the database if they do not yet exist.</p> <code>True</code> <code>linking_module</code> <code>str</code> <p>A module name or a module containing the required dependencies to activate the <code>imaging</code> module: + all that are required by the <code>scan</code> module.</p> <code>None</code> <p>Dependencies:</p> Upstream tables <ul> <li>Session: A parent table to Scan, identifying a scanning session.</li> <li>Equipment: A parent table to Scan, identifying a scanning device.</li> </ul> Source code in <code>element_calcium_imaging/imaging_preprocess.py</code> <pre><code>def activate(\n    imaging_schema_name: str,\n    scan_schema_name: str = None,\n    *,\n    create_schema: bool = True,\n    create_tables: bool = True,\n    linking_module: str = None,\n):\n\"\"\"Activate this schema.\n\n    Args:\n        imaging_schema_name (str): Schema name on the database server to activate the\n            `imaging` module.\n        scan_schema_name (str): Schema name on the database server to activate the\n            `scan` module. Omitted, if the `scan` module is already activated.\n        create_schema (bool): When True (default), create schema in the database if it\n            does not yet exist.\n        create_tables (bool): When True (default), create tables in the database if they\n            do not yet exist.\n        linking_module (str): A module name or a module containing the required\n            dependencies to activate the `imaging` module: + all that are required by\n            the `scan` module.\n\n    Dependencies:\n    Upstream tables:\n        + Session: A parent table to Scan, identifying a scanning session.\n        + Equipment: A parent table to Scan, identifying a scanning device.\n    \"\"\"\n\n    if isinstance(linking_module, str):\n        linking_module = importlib.import_module(linking_module)\n    assert inspect.ismodule(\n        linking_module\n    ), \"The argument 'dependency' must be a module's name or a module\"\n\n    global _linking_module\n    _linking_module = linking_module\n\n    scan.activate(\n        scan_schema_name,\n        create_schema=create_schema,\n        create_tables=create_tables,\n        linking_module=linking_module,\n    )\n    schema.activate(\n        imaging_schema_name,\n        create_schema=create_schema,\n        create_tables=create_tables,\n        add_objects=_linking_module.__dict__,\n    )\n    imaging_report.activate(f\"{imaging_schema_name}_report\", imaging_schema_name)\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_preprocess/#element_calcium_imaging.imaging_preprocess.get_imaging_root_data_dir", "title": "<code>get_imaging_root_data_dir()</code>", "text": "<p>Return imaging root data director(y/ies)</p> <p>Retrieve the root data director(y/ies) containing the imaging data for all subjects/sessions (e.g. acquired ScanImage raw files, output files from processing routines, etc.). All data paths and directories in DataJoint Elements are recommended to be stored as relative paths (posix format), with respect to some user-configured \"root\" directory, which varies from machine to machine (e.g. different mounted drive locations).</p> <p>Returns:</p> Name Type Description <code>dirs</code> <code>list</code> <p>A list of string(s) or Path(s) for the absolute paths of the imaging root data director(y/ies).</p> Source code in <code>element_calcium_imaging/scan.py</code> <pre><code>def get_imaging_root_data_dir() -&gt; list:\n\"\"\"Return imaging root data director(y/ies)\n\n    Retrieve the root data director(y/ies) containing the imaging data\n    for all subjects/sessions (e.g. acquired ScanImage raw files, output files from\n    processing routines, etc.). All data paths and directories in DataJoint Elements are\n    recommended to be stored as relative paths (posix format), with respect to some\n    user-configured \"root\" directory, which varies from machine to machine\n    (e.g. different mounted drive locations).\n\n    Returns:\n        dirs (list): A list of string(s) or Path(s) for the absolute paths of the imaging root data\n            director(y/ies).\n    \"\"\"\n\n    root_directories = _linking_module.get_imaging_root_data_dir()\n    if isinstance(root_directories, (str, pathlib.Path)):\n        root_directories = [root_directories]\n\n    if hasattr(_linking_module, \"get_processed_root_data_dir\"):\n        root_directories.append(_linking_module.get_processed_root_data_dir())\n\n    return root_directories\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_preprocess/#element_calcium_imaging.imaging_preprocess.PreprocessMethod", "title": "<code>PreprocessMethod</code>", "text": "<p>         Bases: <code>dj.Lookup</code></p> <p>Method(s) used for preprocessing of calcium imaging data.</p> <p>Attributes:</p> Name Type Description <code>preprocess_method</code> <code>str</code> <p>Preprocessing method.</p> <code>preprocess_method_desc</code> <code>str</code> <p>Processing method description.</p> Source code in <code>element_calcium_imaging/imaging_preprocess.py</code> <pre><code>@schema\nclass PreprocessMethod(dj.Lookup):\n\"\"\"Method(s) used for preprocessing of calcium imaging data.\n\n    Attributes:\n        preprocess_method (str): Preprocessing method.\n        preprocess_method_desc (str): Processing method description.\n    \"\"\"\n\n    definition = \"\"\"  #  Method/package used for pre-processing\n    preprocess_method: varchar(16)\n    ---\n    preprocess_method_desc: varchar(1000)\n    \"\"\"\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_preprocess/#element_calcium_imaging.imaging_preprocess.get_processed_root_data_dir", "title": "<code>get_processed_root_data_dir()</code>", "text": "<p>Retrieve the root directory for all processed data.</p> <p>All data paths and directories in DataJoint Elements are recommended to be stored as relative paths (posix format), with respect to some user-configured \"root\" directory, which varies from machine to machine (e.g. different mounted drive locations).</p> <p>Returns:</p> Name Type Description <code>dir</code> <code>str | pathlib.Path</code> <p>Absolute path of the processed imaging root data directory.</p> Source code in <code>element_calcium_imaging/scan.py</code> <pre><code>def get_processed_root_data_dir() -&gt; Union[str, pathlib.Path]:\n\"\"\"Retrieve the root directory for all processed data.\n\n    All data paths and directories in DataJoint Elements are recommended to be stored as\n    relative paths (posix format), with respect to some user-configured \"root\"\n    directory, which varies from machine to machine (e.g. different mounted drive\n    locations).\n\n    Returns:\n        dir (str| pathlib.Path): Absolute path of the processed imaging root data\n            directory.\n    \"\"\"\n\n    if hasattr(_linking_module, \"get_processed_root_data_dir\"):\n        return _linking_module.get_processed_root_data_dir()\n    else:\n        return get_imaging_root_data_dir()[0]\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_preprocess/#element_calcium_imaging.imaging_preprocess.PreprocessParamSet", "title": "<code>PreprocessParamSet</code>", "text": "<p>         Bases: <code>dj.Lookup</code></p> <p>Parameter set used for the preprocessing of the calcium imaging scans.</p> <p>A hash of the parameters of the analysis suite is also stored in order to avoid duplicated entries.</p> <p>Attributes:</p> Name Type Description <code>paramset_idx</code> <code>int</code> <p>Unique parameter set ID.</p> <code>PreprocessMethod</code> <code>foreign key</code> <p>A primary key from PreprocessMethod.</p> <code>paramset_desc</code> <code>str</code> <p>Parameter set description.</p> <code>param_set_hash</code> <code>uuid</code> <p>A universally unique identifier for the parameter set.</p> <code>params</code> <code>longblob</code> <p>Parameter Set, a dictionary of all applicable parameters to the analysis suite.</p> Source code in <code>element_calcium_imaging/imaging_preprocess.py</code> <pre><code>@schema\nclass PreprocessParamSet(dj.Lookup):\n\"\"\"Parameter set used for the preprocessing of the calcium imaging scans.\n\n    A hash of the parameters of the analysis suite is also stored in order\n    to avoid duplicated entries.\n\n    Attributes:\n        paramset_idx (int): Unique parameter set ID.\n        PreprocessMethod (foreign key): A primary key from PreprocessMethod.\n        paramset_desc (str): Parameter set description.\n        param_set_hash (uuid): A universally unique identifier for the parameter set.\n        params (longblob): Parameter Set, a dictionary of all applicable parameters to\n            the analysis suite.\n    \"\"\"\n\n    definition = \"\"\"  #  Parameter set used for pre-processing of calcium imaging data\n    paramset_idx:  smallint\n    ---\n    -&gt; PreprocessMethod\n    paramset_desc: varchar(128)\n    param_set_hash: uuid\n    unique index (param_set_hash)\n    params: longblob  # dictionary of all applicable parameters\n    \"\"\"\n\n    @classmethod\n    def insert_new_params(\n        cls,\n        preprocess_method: str,\n        paramset_idx: int,\n        paramset_desc: str,\n        params: dict,\n    ):\n\"\"\"Insert a parameter set into PreprocessParamSet table.\n        This function automates the parameter set hashing and avoids insertion of an\n            existing parameter set.\n\n        Attributes:\n            preprocess_method (str): Method used for processing of calcium imaging scans.\n            paramset_idx (int): Unique parameter set ID.\n            paramset_desc (str): Parameter set description.\n            params (dict): Parameter Set, all applicable parameters.\n        \"\"\"\n        param_dict = {\n            \"preprocess_method\": preprocess_method,\n            \"paramset_idx\": paramset_idx,\n            \"paramset_desc\": paramset_desc,\n            \"params\": params,\n            \"param_set_hash\": dict_to_uuid(params),\n        }\n        q_param = cls &amp; {\"param_set_hash\": param_dict[\"param_set_hash\"]}\n\n        if q_param:  # If the specified param-set already exists\n            p_name = q_param.fetch1(\"paramset_idx\")\n            if p_name == paramset_idx:  # If the existed set has the same name: job done\n                return\n            else:  # If not same name: human error, trying to add the same paramset with different name\n                raise dj.DataJointError(\n                    \"The specified param-set already exists - name: {}\".format(p_name)\n                )\n        else:\n            cls.insert1(param_dict)\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_preprocess/#element_calcium_imaging.imaging_preprocess.PreprocessParamSet.insert_new_params", "title": "<code>insert_new_params(preprocess_method, paramset_idx, paramset_desc, params)</code>  <code>classmethod</code>", "text": "<p>Insert a parameter set into PreprocessParamSet table. This function automates the parameter set hashing and avoids insertion of an     existing parameter set.</p> <p>Attributes:</p> Name Type Description <code>preprocess_method</code> <code>str</code> <p>Method used for processing of calcium imaging scans.</p> <code>paramset_idx</code> <code>int</code> <p>Unique parameter set ID.</p> <code>paramset_desc</code> <code>str</code> <p>Parameter set description.</p> <code>params</code> <code>dict</code> <p>Parameter Set, all applicable parameters.</p> Source code in <code>element_calcium_imaging/imaging_preprocess.py</code> <pre><code>@classmethod\ndef insert_new_params(\n    cls,\n    preprocess_method: str,\n    paramset_idx: int,\n    paramset_desc: str,\n    params: dict,\n):\n\"\"\"Insert a parameter set into PreprocessParamSet table.\n    This function automates the parameter set hashing and avoids insertion of an\n        existing parameter set.\n\n    Attributes:\n        preprocess_method (str): Method used for processing of calcium imaging scans.\n        paramset_idx (int): Unique parameter set ID.\n        paramset_desc (str): Parameter set description.\n        params (dict): Parameter Set, all applicable parameters.\n    \"\"\"\n    param_dict = {\n        \"preprocess_method\": preprocess_method,\n        \"paramset_idx\": paramset_idx,\n        \"paramset_desc\": paramset_desc,\n        \"params\": params,\n        \"param_set_hash\": dict_to_uuid(params),\n    }\n    q_param = cls &amp; {\"param_set_hash\": param_dict[\"param_set_hash\"]}\n\n    if q_param:  # If the specified param-set already exists\n        p_name = q_param.fetch1(\"paramset_idx\")\n        if p_name == paramset_idx:  # If the existed set has the same name: job done\n            return\n        else:  # If not same name: human error, trying to add the same paramset with different name\n            raise dj.DataJointError(\n                \"The specified param-set already exists - name: {}\".format(p_name)\n            )\n    else:\n        cls.insert1(param_dict)\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_preprocess/#element_calcium_imaging.imaging_preprocess.get_image_files", "title": "<code>get_image_files(scan_key, file_type)</code>", "text": "<p>Retrieve the list of image files associated with a given Scan.</p> <p>Parameters:</p> Name Type Description Default <code>scan_key</code> <code>dict</code> <p>Primary key of a Scan entry.</p> required <p>Returns:</p> Type Description <code>list</code> <p>A list of full file paths.</p> Source code in <code>element_calcium_imaging/scan.py</code> <pre><code>def get_image_files(scan_key: dict, file_type: str) -&gt; list:\n\"\"\"Retrieve the list of image files associated with a given Scan.\n\n    Args:\n        scan_key: Primary key of a Scan entry.\n\n    Returns:\n        A list of full file paths.\n    \"\"\"\n    return _linking_module.get_image_files(scan_key, file_type)\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_preprocess/#element_calcium_imaging.imaging_preprocess.PreprocessParamSteps", "title": "<code>PreprocessParamSteps</code>", "text": "<p>         Bases: <code>dj.Manual</code></p> <p>Ordered list of paramset_idx that will be run.</p> <p>When pre-processing is not performed, do not create an entry in <code>Step</code> Part table</p> <p>Attributes:</p> Name Type Description <code>preprocess_param_steps_id</code> <code>int</code> <code>preprocess_param_steps_name</code> <code>str</code> <code>preprocess_param_steps_desc</code> <code>str</code> Source code in <code>element_calcium_imaging/imaging_preprocess.py</code> <pre><code>@schema\nclass PreprocessParamSteps(dj.Manual):\n\"\"\"Ordered list of paramset_idx that will be run.\n\n    When pre-processing is not performed, do not create an entry in `Step` Part table\n\n    Attributes:\n        preprocess_param_steps_id (int):\n        preprocess_param_steps_name (str):\n        preprocess_param_steps_desc (str):\n    \"\"\"\n\n    definition = \"\"\"\n    preprocess_param_steps_id: smallint\n    ---\n    preprocess_param_steps_name: varchar(32)\n    preprocess_param_steps_desc: varchar(128)\n    \"\"\"\n\n    class Step(dj.Part):\n\"\"\"ADD DEFINITION\n\n        Attributes:\n            PreprocessParamSteps (foreign key): A primary key from PreprocessParamSteps.\n            step_number (int):\n            PreprocessParamSet (foreign key): A primary key from PreprocessParamSet.\n        \"\"\"\n\n        definition = \"\"\"\n        -&gt; master\n        step_number: smallint                  # Order of operations\n        ---\n        -&gt; PreprocessParamSet\n        \"\"\"\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_preprocess/#element_calcium_imaging.imaging_preprocess.PreprocessParamSteps.Step", "title": "<code>Step</code>", "text": "<p>         Bases: <code>dj.Part</code></p> <p>ADD DEFINITION</p> <p>Attributes:</p> Name Type Description <code>PreprocessParamSteps</code> <code>foreign key</code> <p>A primary key from PreprocessParamSteps.</p> <code>step_number</code> <code>int</code> <code>PreprocessParamSet</code> <code>foreign key</code> <p>A primary key from PreprocessParamSet.</p> Source code in <code>element_calcium_imaging/imaging_preprocess.py</code> <pre><code>class Step(dj.Part):\n\"\"\"ADD DEFINITION\n\n    Attributes:\n        PreprocessParamSteps (foreign key): A primary key from PreprocessParamSteps.\n        step_number (int):\n        PreprocessParamSet (foreign key): A primary key from PreprocessParamSet.\n    \"\"\"\n\n    definition = \"\"\"\n    -&gt; master\n    step_number: smallint                  # Order of operations\n    ---\n    -&gt; PreprocessParamSet\n    \"\"\"\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_preprocess/#element_calcium_imaging.imaging_preprocess.PreprocessTask", "title": "<code>PreprocessTask</code>", "text": "<p>         Bases: <code>dj.Manual</code></p> <p>This table defines a calcium imaging preprocessing task for a combination of a <code>Scan</code> and a <code>PreprocessParamSteps</code> entries, including all the inputs (scan, method, steps). The task defined here is then run in the downstream table Preprocess. This table supports definitions of both loading of pre-generated, results, triggering of new analysis, or skipping of preprocessing step.</p> <p>Attributes:</p> Name Type Description <code>Scan</code> <code>foreign key</code> <p>A primary key from Scan.</p> <code>PreprocessParamSteps</code> <code>foreign key</code> <p>A primary key from PreprocessParamSteps.</p> <code>preprocess_output_dir</code> <code>str</code> <p>Output directory for the results of preprocessing.</p> <code>task_mode</code> <code>str</code> <p>One of 'load' (load computed analysis results), 'trigger' (trigger computation), 'none' (no pre-processing). Default none.</p> Source code in <code>element_calcium_imaging/imaging_preprocess.py</code> <pre><code>@schema\nclass PreprocessTask(dj.Manual):\n\"\"\"This table defines a calcium imaging preprocessing task for a combination of a\n    `Scan` and a `PreprocessParamSteps` entries, including all the inputs (scan, method,\n    steps). The task defined here is then run in the downstream table\n    Preprocess. This table supports definitions of both loading of pre-generated,\n    results, triggering of new analysis, or skipping of preprocessing step.\n\n    Attributes:\n        Scan (foreign key): A primary key from Scan.\n        PreprocessParamSteps (foreign key): A primary key from PreprocessParamSteps.\n        preprocess_output_dir (str): Output directory for the results of preprocessing.\n        task_mode (str, optional): One of 'load' (load computed analysis results), 'trigger'\n            (trigger computation), 'none' (no pre-processing). Default none.\n    \"\"\"\n\n    definition = \"\"\"\n    # Manual table for defining a pre-processing task ready to be run\n    -&gt; scan.Scan\n    -&gt; PreprocessParamSteps\n    ---\n    preprocess_output_dir: varchar(255)  # Pre-processing output directory relative\n                                         # to the root data directory\n    task_mode='none': enum('none','load', 'trigger') # 'none': no pre-processing\n                                                     # 'load': load analysis results\n                                                     # 'trigger': trigger computation\n    \"\"\"\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_preprocess/#element_calcium_imaging.imaging_preprocess.Preprocess", "title": "<code>Preprocess</code>", "text": "<p>         Bases: <code>dj.Imported</code></p> <p>Perform the computation of an entry (task) defined in the PreprocessTask table.</p> <ul> <li>If <code>task_mode == \"none\"</code>: no pre-processing performed</li> <li>If <code>task_mode == \"trigger\"</code>: Not implemented</li> <li>If <code>task_mode == \"load\"</code>: Not implemented</li> </ul> <p>Attributes:</p> Name Type Description <code>PreprocessTask</code> <code>foreign key</code> <code>preprocess_time</code> <code>datetime</code> <code>package_version</code> <code>str</code> <p>Version of the analysis package used in processing the data.</p> Source code in <code>element_calcium_imaging/imaging_preprocess.py</code> <pre><code>@schema\nclass Preprocess(dj.Imported):\n\"\"\"Perform the computation of an entry (task) defined in the PreprocessTask table.\n\n    + If `task_mode == \"none\"`: no pre-processing performed\n    + If `task_mode == \"trigger\"`: Not implemented\n    + If `task_mode == \"load\"`: Not implemented\n\n    Attributes:\n        PreprocessTask (foreign key):\n        preprocess_time (datetime, optional):\n        package_version (str, optional): Version of the analysis package used in\n            processing the data.\n    \"\"\"\n\n    definition = \"\"\"\n    -&gt; PreprocessTask\n    ---\n    preprocess_time=null: datetime  # Time of generation of pre-processing results\n    package_version='': varchar(16)\n    \"\"\"\n\n    def make(self, key):\n\"\"\"Execute the preprocessing analysis steps defined in PreprocessTask.\"\"\"\n\n        task_mode, output_dir = (PreprocessTask &amp; key).fetch1(\n            \"task_mode\", \"preprocess_output_dir\"\n        )\n        _ = find_full_path(get_imaging_root_data_dir(), output_dir)\n\n        if task_mode == \"none\":\n            print(f\"No pre-processing run on entry: {key}\")\n        elif task_mode in [\"load\", \"trigger\"]:\n            raise NotImplementedError(\n                \"Pre-processing steps are not implemented.\"\n                \"Please overwrite this `make` function with\"\n                \"desired pre-processing steps.\"\n            )\n        else:\n            raise ValueError(f\"Unknown task mode: {task_mode}\")\n\n        self.insert1({**key, \"package_version\": \"\"})\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_preprocess/#element_calcium_imaging.imaging_preprocess.Preprocess.make", "title": "<code>make(key)</code>", "text": "<p>Execute the preprocessing analysis steps defined in PreprocessTask.</p> Source code in <code>element_calcium_imaging/imaging_preprocess.py</code> <pre><code>def make(self, key):\n\"\"\"Execute the preprocessing analysis steps defined in PreprocessTask.\"\"\"\n\n    task_mode, output_dir = (PreprocessTask &amp; key).fetch1(\n        \"task_mode\", \"preprocess_output_dir\"\n    )\n    _ = find_full_path(get_imaging_root_data_dir(), output_dir)\n\n    if task_mode == \"none\":\n        print(f\"No pre-processing run on entry: {key}\")\n    elif task_mode in [\"load\", \"trigger\"]:\n        raise NotImplementedError(\n            \"Pre-processing steps are not implemented.\"\n            \"Please overwrite this `make` function with\"\n            \"desired pre-processing steps.\"\n        )\n    else:\n        raise ValueError(f\"Unknown task mode: {task_mode}\")\n\n    self.insert1({**key, \"package_version\": \"\"})\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_preprocess/#element_calcium_imaging.imaging_preprocess.ProcessingMethod", "title": "<code>ProcessingMethod</code>", "text": "<p>         Bases: <code>dj.Lookup</code></p> <p>Package used for processing of calcium imaging data (e.g. Suite2p, CaImAn, etc.).</p> <p>Attributes:</p> Name Type Description <code>processing_method</code> <code>str</code> <p>Processing method.</p> <code>processing_method_desc</code> <code>str</code> <p>Processing method description.</p> Source code in <code>element_calcium_imaging/imaging_preprocess.py</code> <pre><code>@schema\nclass ProcessingMethod(dj.Lookup):\n\"\"\"Package used for processing of calcium imaging data (e.g. Suite2p, CaImAn, etc.).\n\n    Attributes:\n        processing_method (str): Processing method.\n        processing_method_desc (str): Processing method description.\n    \"\"\"\n\n    definition = \"\"\"# Package used for processing of calcium imaging data (e.g. Suite2p, CaImAn, etc.).\n    processing_method: char(8)\n    ---\n    processing_method_desc: varchar(1000)  # Processing method description\n    \"\"\"\n\n    contents = [\n        (\"suite2p\", \"suite2p analysis suite\"),\n        (\"caiman\", \"caiman analysis suite\"),\n        (\"extract\", \"extract analysis suite\"),\n    ]\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_preprocess/#element_calcium_imaging.imaging_preprocess.ProcessingParamSet", "title": "<code>ProcessingParamSet</code>", "text": "<p>         Bases: <code>dj.Lookup</code></p> <p>Parameter set used for the processing of the calcium imaging scans, including both the analysis suite and its respective input parameters.</p> <p>A hash of the parameters of the analysis suite is also stored in order to avoid duplicated entries.</p> <p>Attributes:</p> Name Type Description <code>paramset_idx</code> <code>int</code> <p>Unique parameter set ID.</p> <code>ProcessingMethod</code> <code>foreign key</code> <p>A primary key from ProcessingMethod.</p> <code>paramset_desc</code> <code>str</code> <p>Parameter set description.</p> <code>param_set_hash</code> <code>uuid</code> <p>A universally unique identifier for the parameter set.</p> <code>params</code> <code>longblob</code> <p>Parameter Set, a dictionary of all applicable parameters to the analysis suite.</p> Source code in <code>element_calcium_imaging/imaging_preprocess.py</code> <pre><code>@schema\nclass ProcessingParamSet(dj.Lookup):\n\"\"\"Parameter set used for the processing of the calcium imaging scans,\n    including both the analysis suite and its respective input parameters.\n\n    A hash of the parameters of the analysis suite is also stored in order\n    to avoid duplicated entries.\n\n    Attributes:\n        paramset_idx (int): Unique parameter set ID.\n        ProcessingMethod (foreign key): A primary key from ProcessingMethod.\n        paramset_desc (str): Parameter set description.\n        param_set_hash (uuid): A universally unique identifier for the parameter set.\n        params (longblob): Parameter Set, a dictionary of all applicable parameters to\n            the analysis suite.\n    \"\"\"\n\n    definition = \"\"\"# Processing Parameter Set\n    paramset_idx: smallint  # Unique parameter set ID.\n    ---\n    -&gt; ProcessingMethod\n    paramset_desc: varchar(1280)  # Parameter-set description\n    param_set_hash: uuid  # A universally unique identifier for the parameter set\n    unique index (param_set_hash)\n    params: longblob  # Parameter Set, a dictionary of all applicable parameters to the analysis suite.\n    \"\"\"\n\n    @classmethod\n    def insert_new_params(\n        cls,\n        processing_method: str,\n        paramset_idx: int,\n        paramset_desc: str,\n        params: dict,\n    ):\n\"\"\"Insert a parameter set into ProcessingParamSet table.\n\n        This function automates the parameter set hashing and avoids insertion of an\n            existing parameter set.\n\n        Attributes:\n            processing_method (str): Processing method/package used for processing of\n                calcium imaging.\n            paramset_idx (int): Unique parameter set ID.\n            paramset_desc (str): Parameter set description.\n            params (dict): Parameter Set, all applicable parameters to the analysis\n                suite.\n        \"\"\"\n        if processing_method == \"extract\":\n            assert (\n                params.get(\"extract\") is not None and params.get(\"suite2p\") is not None\n            ), ValueError(\n                \"Please provide the processing parameters in the {'suite2p': {...}, 'extract': {...}} dictionary format.\"\n            )\n\n            # Force Suite2p to only run motion correction.\n            params[\"suite2p\"][\"do_registration\"] = True\n            params[\"suite2p\"][\"roidetect\"] = False\n\n        param_dict = {\n            \"processing_method\": processing_method,\n            \"paramset_idx\": paramset_idx,\n            \"paramset_desc\": paramset_desc,\n            \"params\": params,\n            \"param_set_hash\": dict_to_uuid(params),\n        }\n        q_param = cls &amp; {\"param_set_hash\": param_dict[\"param_set_hash\"]}\n\n        if q_param:  # If the specified param-set already exists\n            p_name = q_param.fetch1(\"paramset_idx\")\n            if p_name == paramset_idx:  # If the existed set has the same name: job done\n                return\n            else:  # If not same name: human error, trying to add the same paramset with different name\n                raise dj.DataJointError(\n                    \"The specified param-set already exists - name: {}\".format(p_name)\n                )\n        else:\n            cls.insert1(param_dict)\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_preprocess/#element_calcium_imaging.imaging_preprocess.ProcessingParamSet.insert_new_params", "title": "<code>insert_new_params(processing_method, paramset_idx, paramset_desc, params)</code>  <code>classmethod</code>", "text": "<p>Insert a parameter set into ProcessingParamSet table.</p> <p>This function automates the parameter set hashing and avoids insertion of an     existing parameter set.</p> <p>Attributes:</p> Name Type Description <code>processing_method</code> <code>str</code> <p>Processing method/package used for processing of calcium imaging.</p> <code>paramset_idx</code> <code>int</code> <p>Unique parameter set ID.</p> <code>paramset_desc</code> <code>str</code> <p>Parameter set description.</p> <code>params</code> <code>dict</code> <p>Parameter Set, all applicable parameters to the analysis suite.</p> Source code in <code>element_calcium_imaging/imaging_preprocess.py</code> <pre><code>@classmethod\ndef insert_new_params(\n    cls,\n    processing_method: str,\n    paramset_idx: int,\n    paramset_desc: str,\n    params: dict,\n):\n\"\"\"Insert a parameter set into ProcessingParamSet table.\n\n    This function automates the parameter set hashing and avoids insertion of an\n        existing parameter set.\n\n    Attributes:\n        processing_method (str): Processing method/package used for processing of\n            calcium imaging.\n        paramset_idx (int): Unique parameter set ID.\n        paramset_desc (str): Parameter set description.\n        params (dict): Parameter Set, all applicable parameters to the analysis\n            suite.\n    \"\"\"\n    if processing_method == \"extract\":\n        assert (\n            params.get(\"extract\") is not None and params.get(\"suite2p\") is not None\n        ), ValueError(\n            \"Please provide the processing parameters in the {'suite2p': {...}, 'extract': {...}} dictionary format.\"\n        )\n\n        # Force Suite2p to only run motion correction.\n        params[\"suite2p\"][\"do_registration\"] = True\n        params[\"suite2p\"][\"roidetect\"] = False\n\n    param_dict = {\n        \"processing_method\": processing_method,\n        \"paramset_idx\": paramset_idx,\n        \"paramset_desc\": paramset_desc,\n        \"params\": params,\n        \"param_set_hash\": dict_to_uuid(params),\n    }\n    q_param = cls &amp; {\"param_set_hash\": param_dict[\"param_set_hash\"]}\n\n    if q_param:  # If the specified param-set already exists\n        p_name = q_param.fetch1(\"paramset_idx\")\n        if p_name == paramset_idx:  # If the existed set has the same name: job done\n            return\n        else:  # If not same name: human error, trying to add the same paramset with different name\n            raise dj.DataJointError(\n                \"The specified param-set already exists - name: {}\".format(p_name)\n            )\n    else:\n        cls.insert1(param_dict)\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_preprocess/#element_calcium_imaging.imaging_preprocess.CellCompartment", "title": "<code>CellCompartment</code>", "text": "<p>         Bases: <code>dj.Lookup</code></p> <p>Cell compartments that can be imaged (e.g. 'axon', 'soma', etc.)</p> <p>Attributes:</p> Name Type Description <code>cell_compartment</code> <code>str</code> <p>Cell compartment.</p> Source code in <code>element_calcium_imaging/imaging_preprocess.py</code> <pre><code>@schema\nclass CellCompartment(dj.Lookup):\n\"\"\"Cell compartments that can be imaged (e.g. 'axon', 'soma', etc.)\n\n    Attributes:\n        cell_compartment (str): Cell compartment.\n    \"\"\"\n\n    definition = \"\"\"# Cell compartments\n    cell_compartment: char(16)\n    \"\"\"\n\n    contents = zip([\"axon\", \"soma\", \"bouton\"])\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_preprocess/#element_calcium_imaging.imaging_preprocess.MaskType", "title": "<code>MaskType</code>", "text": "<p>         Bases: <code>dj.Lookup</code></p> <p>Available labels for segmented masks (e.g. 'soma', 'axon', 'dendrite', 'neuropil').</p> <p>Attributes:</p> Name Type Description <code>mask_type</code> <code>str</code> <p>Mask type.</p> Source code in <code>element_calcium_imaging/imaging_preprocess.py</code> <pre><code>@schema\nclass MaskType(dj.Lookup):\n\"\"\"Available labels for segmented masks (e.g. 'soma', 'axon', 'dendrite', 'neuropil').\n\n    Attributes:\n        mask_type (str): Mask type.\n    \"\"\"\n\n    definition = \"\"\"# Possible types of a segmented mask\n    mask_type: varchar(16)\n    \"\"\"\n\n    contents = zip([\"soma\", \"axon\", \"dendrite\", \"neuropil\", \"artefact\", \"unknown\"])\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_preprocess/#element_calcium_imaging.imaging_preprocess.ProcessingTask", "title": "<code>ProcessingTask</code>", "text": "<p>         Bases: <code>dj.Manual</code></p> <p>A pairing of processing params and scans to be loaded or triggered</p> <p>This table defines a calcium imaging processing task for a combination of a <code>Scan</code> and a <code>ProcessingParamSet</code> entries, including all the inputs (scan, method, method's parameters). The task defined here is then run in the downstream table <code>Processing</code>. This table supports definitions of both loading of pre-generated results and the triggering of new analysis for all supported analysis methods.</p> <p>Attributes:</p> Name Type Description <code>Preprocess</code> <code>foreign key</code> <p>Primary key from Preprocess.</p> <code>ProcessingParamSet</code> <code>foreign key</code> <p>Primary key from ProcessingParamSet.</p> <code>processing_output_dir</code> <code>str</code> <p>Output directory of the processed scan relative to the root data directory.</p> <code>task_mode</code> <code>str</code> <p>One of 'load' (load computed analysis results) or 'trigger' (trigger computation).</p> Source code in <code>element_calcium_imaging/imaging_preprocess.py</code> <pre><code>@schema\nclass ProcessingTask(dj.Manual):\n\"\"\"A pairing of processing params and scans to be loaded or triggered\n\n    This table defines a calcium imaging processing task for a combination of a\n    `Scan` and a `ProcessingParamSet` entries, including all the inputs (scan, method,\n    method's parameters). The task defined here is then run in the downstream table\n    `Processing`. This table supports definitions of both loading of pre-generated results\n    and the triggering of new analysis for all supported analysis methods.\n\n    Attributes:\n        Preprocess (foreign key): Primary key from Preprocess.\n        ProcessingParamSet (foreign key): Primary key from ProcessingParamSet.\n        processing_output_dir (str): Output directory of the processed scan relative to the root data directory.\n        task_mode (str): One of 'load' (load computed analysis results) or 'trigger'\n            (trigger computation).\n    \"\"\"\n\n    definition = \"\"\"# Manual table for defining a processing task ready to be run\n    -&gt; Preprocess\n    -&gt; ProcessingParamSet\n    ---\n    processing_output_dir: varchar(255)  #  Output directory of the processed scan relative to root data directory\n    task_mode='load': enum('load', 'trigger')  # 'load': load computed analysis results, 'trigger': trigger computation\n    \"\"\"\n\n    @classmethod\n    def infer_output_dir(cls, key, relative=False, mkdir=False):\n\"\"\"Infer an output directory for an entry in ProcessingTask table.\n\n        Args:\n            key (dict): Primary key from the ProcessingTask table.\n            relative (bool): If True, processing_output_dir is returned relative to\n                imaging_root_dir. Default False.\n            mkdir (bool): If True, create the processing_output_dir directory.\n                Default True.\n\n        Returns:\n            dir (str): A default output directory for the processed results (processed_output_dir\n                in ProcessingTask) based on the following convention:\n                processed_dir / scan_dir / {processing_method}_{paramset_idx}\n                e.g.: sub4/sess1/scan0/suite2p_0\n        \"\"\"\n        acq_software = (scan.Scan &amp; key).fetch1(\"acq_software\")\n        filetypes = dict(\n            ScanImage=\"*.tif\", Scanbox=\"*.sbx\", NIS=\"*.nd2\", PrairieView=\"*.tif\"\n        )\n\n        scan_dir = find_full_path(\n            get_imaging_root_data_dir(),\n            get_image_files(key, filetypes[acq_software])[0],\n        ).parent\n        root_dir = find_root_directory(get_imaging_root_data_dir(), scan_dir)\n\n        method = (\n            (ProcessingParamSet &amp; key).fetch1(\"processing_method\").replace(\".\", \"-\")\n        )\n\n        processed_dir = pathlib.Path(get_processed_root_data_dir())\n        output_dir = (\n            processed_dir\n            / scan_dir.relative_to(root_dir)\n            / f'{method}_{key[\"paramset_idx\"]}'\n        )\n\n        if mkdir:\n            output_dir.mkdir(parents=True, exist_ok=True)\n\n        return output_dir.relative_to(processed_dir) if relative else output_dir\n\n    @classmethod\n    def generate(cls, scan_key, paramset_idx=0):\n\"\"\"Generate a ProcessingTask for a Scan using an parameter ProcessingParamSet\n\n        Generate an entry in the ProcessingTask table for a particular scan using an\n        existing parameter set from the ProcessingParamSet table.\n\n        Args:\n            scan_key (dict): Primary key from Scan table.\n            paramset_idx (int): Unique parameter set ID.\n        \"\"\"\n        key = {**scan_key, \"paramset_idx\": paramset_idx}\n\n        processed_dir = get_processed_root_data_dir()\n        output_dir = cls.infer_output_dir(key, relative=False, mkdir=True)\n\n        method = (ProcessingParamSet &amp; {\"paramset_idx\": paramset_idx}).fetch1(\n            \"processing_method\"\n        )\n\n        try:\n            if method == \"suite2p\":\n                from element_interface import suite2p_loader\n\n                suite2p_loader.Suite2p(output_dir)\n            elif method == \"caiman\":\n                from element_interface import caiman_loader\n\n                caiman_loader.CaImAn(output_dir)\n            elif method == \"extract\":\n                from element_interface import extract_loader\n\n                extract_loader.EXTRACT(output_dir)\n\n            else:\n                raise NotImplementedError(\n                    \"Unknown/unimplemented method: {}\".format(method)\n                )\n        except FileNotFoundError:\n            task_mode = \"trigger\"\n        else:\n            task_mode = \"load\"\n\n        cls.insert1(\n            {\n                **key,\n                \"processing_output_dir\": output_dir.relative_to(\n                    processed_dir\n                ).as_posix(),\n                \"task_mode\": task_mode,\n            }\n        )\n\n    auto_generate_entries = generate\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_preprocess/#element_calcium_imaging.imaging_preprocess.ProcessingTask.infer_output_dir", "title": "<code>infer_output_dir(key, relative=False, mkdir=False)</code>  <code>classmethod</code>", "text": "<p>Infer an output directory for an entry in ProcessingTask table.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>dict</code> <p>Primary key from the ProcessingTask table.</p> required <code>relative</code> <code>bool</code> <p>If True, processing_output_dir is returned relative to imaging_root_dir. Default False.</p> <code>False</code> <code>mkdir</code> <code>bool</code> <p>If True, create the processing_output_dir directory. Default True.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>dir</code> <code>str</code> <p>A default output directory for the processed results (processed_output_dir in ProcessingTask) based on the following convention: processed_dir / scan_dir / {processing_method}_{paramset_idx} e.g.: sub4/sess1/scan0/suite2p_0</p> Source code in <code>element_calcium_imaging/imaging_preprocess.py</code> <pre><code>@classmethod\ndef infer_output_dir(cls, key, relative=False, mkdir=False):\n\"\"\"Infer an output directory for an entry in ProcessingTask table.\n\n    Args:\n        key (dict): Primary key from the ProcessingTask table.\n        relative (bool): If True, processing_output_dir is returned relative to\n            imaging_root_dir. Default False.\n        mkdir (bool): If True, create the processing_output_dir directory.\n            Default True.\n\n    Returns:\n        dir (str): A default output directory for the processed results (processed_output_dir\n            in ProcessingTask) based on the following convention:\n            processed_dir / scan_dir / {processing_method}_{paramset_idx}\n            e.g.: sub4/sess1/scan0/suite2p_0\n    \"\"\"\n    acq_software = (scan.Scan &amp; key).fetch1(\"acq_software\")\n    filetypes = dict(\n        ScanImage=\"*.tif\", Scanbox=\"*.sbx\", NIS=\"*.nd2\", PrairieView=\"*.tif\"\n    )\n\n    scan_dir = find_full_path(\n        get_imaging_root_data_dir(),\n        get_image_files(key, filetypes[acq_software])[0],\n    ).parent\n    root_dir = find_root_directory(get_imaging_root_data_dir(), scan_dir)\n\n    method = (\n        (ProcessingParamSet &amp; key).fetch1(\"processing_method\").replace(\".\", \"-\")\n    )\n\n    processed_dir = pathlib.Path(get_processed_root_data_dir())\n    output_dir = (\n        processed_dir\n        / scan_dir.relative_to(root_dir)\n        / f'{method}_{key[\"paramset_idx\"]}'\n    )\n\n    if mkdir:\n        output_dir.mkdir(parents=True, exist_ok=True)\n\n    return output_dir.relative_to(processed_dir) if relative else output_dir\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_preprocess/#element_calcium_imaging.imaging_preprocess.ProcessingTask.generate", "title": "<code>generate(scan_key, paramset_idx=0)</code>  <code>classmethod</code>", "text": "<p>Generate a ProcessingTask for a Scan using an parameter ProcessingParamSet</p> <p>Generate an entry in the ProcessingTask table for a particular scan using an existing parameter set from the ProcessingParamSet table.</p> <p>Parameters:</p> Name Type Description Default <code>scan_key</code> <code>dict</code> <p>Primary key from Scan table.</p> required <code>paramset_idx</code> <code>int</code> <p>Unique parameter set ID.</p> <code>0</code> Source code in <code>element_calcium_imaging/imaging_preprocess.py</code> <pre><code>@classmethod\ndef generate(cls, scan_key, paramset_idx=0):\n\"\"\"Generate a ProcessingTask for a Scan using an parameter ProcessingParamSet\n\n    Generate an entry in the ProcessingTask table for a particular scan using an\n    existing parameter set from the ProcessingParamSet table.\n\n    Args:\n        scan_key (dict): Primary key from Scan table.\n        paramset_idx (int): Unique parameter set ID.\n    \"\"\"\n    key = {**scan_key, \"paramset_idx\": paramset_idx}\n\n    processed_dir = get_processed_root_data_dir()\n    output_dir = cls.infer_output_dir(key, relative=False, mkdir=True)\n\n    method = (ProcessingParamSet &amp; {\"paramset_idx\": paramset_idx}).fetch1(\n        \"processing_method\"\n    )\n\n    try:\n        if method == \"suite2p\":\n            from element_interface import suite2p_loader\n\n            suite2p_loader.Suite2p(output_dir)\n        elif method == \"caiman\":\n            from element_interface import caiman_loader\n\n            caiman_loader.CaImAn(output_dir)\n        elif method == \"extract\":\n            from element_interface import extract_loader\n\n            extract_loader.EXTRACT(output_dir)\n\n        else:\n            raise NotImplementedError(\n                \"Unknown/unimplemented method: {}\".format(method)\n            )\n    except FileNotFoundError:\n        task_mode = \"trigger\"\n    else:\n        task_mode = \"load\"\n\n    cls.insert1(\n        {\n            **key,\n            \"processing_output_dir\": output_dir.relative_to(\n                processed_dir\n            ).as_posix(),\n            \"task_mode\": task_mode,\n        }\n    )\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_preprocess/#element_calcium_imaging.imaging_preprocess.Processing", "title": "<code>Processing</code>", "text": "<p>         Bases: <code>dj.Computed</code></p> <p>Perform the computation of an entry (task) defined in the ProcessingTask table. The computation is performed only on the scans with ScanInfo inserted.</p> <p>Attributes:</p> Name Type Description <code>ProcessingTask</code> <code>foreign key</code> <p>Primary key from ProcessingTask.</p> <code>processing_time</code> <code>datetime</code> <p>Process completion datetime.</p> <code>package_version</code> <code>str</code> <p>Version of the analysis package used in processing the data.</p> Source code in <code>element_calcium_imaging/imaging_preprocess.py</code> <pre><code>@schema\nclass Processing(dj.Computed):\n\"\"\"Perform the computation of an entry (task) defined in the ProcessingTask table.\n    The computation is performed only on the scans with ScanInfo inserted.\n\n    Attributes:\n        ProcessingTask (foreign key): Primary key from ProcessingTask.\n        processing_time (datetime): Process completion datetime.\n        package_version (str, optional): Version of the analysis package used in\n            processing the data.\n    \"\"\"\n\n    definition = \"\"\"\n    -&gt; ProcessingTask\n    ---\n    processing_time     : datetime  # Time of generation of this set of processed, segmented results\n    package_version=''  : varchar(16)\n    \"\"\"\n\n    # Run processing only on Scan with ScanInfo inserted\n    @property\n    def key_source(self):\n\"\"\"Limit the Processing to Scans that have their metadata ingested to the\n        database.\"\"\"\n\n        return ProcessingTask &amp; scan.ScanInfo\n\n    def make(self, key):\n\"\"\"Execute the calcium imaging analysis defined by the ProcessingTask.\"\"\"\n\n        task_mode, output_dir = (ProcessingTask &amp; key).fetch1(\n            \"task_mode\", \"processing_output_dir\"\n        )\n\n        if not output_dir:\n            output_dir = ProcessingTask.infer_output_dir(key, relative=True, mkdir=True)\n            # update processing_output_dir\n            ProcessingTask.update1(\n                {**key, \"processing_output_dir\": output_dir.as_posix()}\n            )\n        output_dir = find_full_path(get_imaging_root_data_dir(), output_dir).as_posix()\n\n        if task_mode == \"load\":\n            method, imaging_dataset = get_loader_result(key, ProcessingTask)\n            if method == \"suite2p\":\n                if (scan.ScanInfo &amp; key).fetch1(\"nrois\") &gt; 0:\n                    raise NotImplementedError(\n                        \"Suite2p ingestion error - Unable to handle\"\n                        + \" ScanImage multi-ROI scanning mode yet\"\n                    )\n                suite2p_dataset = imaging_dataset\n                key = {**key, \"processing_time\": suite2p_dataset.creation_time}\n            elif method == \"caiman\":\n                caiman_dataset = imaging_dataset\n                key = {**key, \"processing_time\": caiman_dataset.creation_time}\n            elif method == \"extract\":\n                raise NotImplementedError(\n                    \"To use EXTRACT with this DataJoint Element please set `task_mode=trigger`\"\n                )\n            else:\n                raise NotImplementedError(\"Unknown method: {}\".format(method))\n        elif task_mode == \"trigger\":\n            method = (ProcessingParamSet * ProcessingTask &amp; key).fetch1(\n                \"processing_method\"\n            )\n\n            preprocess_paramsets = (\n                PreprocessParamSteps.Step()\n                &amp; dict(preprocess_param_steps_id=key[\"preprocess_param_steps_id\"])\n            ).fetch(\"paramset_idx\")\n\n            if len(preprocess_paramsets) == 0:\n                # No pre-processing steps were performed on the acquired dataset, so process the raw/acquired files.\n                image_files = (scan.ScanInfo.ScanFile &amp; key).fetch(\"file_path\")\n                image_files = [\n                    find_full_path(get_imaging_root_data_dir(), image_file)\n                    for image_file in image_files\n                ]\n\n            else:\n                preprocess_output_dir = (PreprocessTask &amp; key).fetch1(\n                    \"preprocess_output_dir\"\n                )\n\n                preprocess_output_dir = find_full_path(\n                    get_imaging_root_data_dir(), preprocess_output_dir\n                )\n\n                if not preprocess_output_dir.exists():\n                    raise FileNotFoundError(\n                        f\"Pre-processed output directory not found ({preprocess_output_dir})\"\n                    )\n\n                image_files = list(preprocess_output_dir.glob(\"*.tif\"))\n\n            if method == \"suite2p\":\n                import suite2p\n\n                suite2p_params = (ProcessingTask * ProcessingParamSet &amp; key).fetch1(\n                    \"params\"\n                )\n                suite2p_params[\"save_path0\"] = output_dir\n                (\n                    suite2p_params[\"fs\"],\n                    suite2p_params[\"nplanes\"],\n                    suite2p_params[\"nchannels\"],\n                ) = (scan.ScanInfo &amp; key).fetch1(\"fps\", \"ndepths\", \"nchannels\")\n\n                input_format = pathlib.Path(image_files[0]).suffix\n                suite2p_params[\"input_format\"] = input_format[1:]\n\n                suite2p_paths = {\n                    \"data_path\": [image_files[0].parent.as_posix()],\n                    \"tiff_list\": [f.as_posix() for f in image_files],\n                }\n\n                suite2p.run_s2p(ops=suite2p_params, db=suite2p_paths)  # Run suite2p\n\n                _, imaging_dataset = get_loader_result(key, ProcessingTask)\n                suite2p_dataset = imaging_dataset\n                key = {**key, \"processing_time\": suite2p_dataset.creation_time}\n\n            elif method == \"caiman\":\n                from element_interface.caiman_loader import _process_scanimage_tiff\n                from element_interface.run_caiman import run_caiman\n\n                caiman_params = (ProcessingTask * ProcessingParamSet &amp; key).fetch1(\n                    \"params\"\n                )\n                sampling_rate, ndepths, nchannels = (scan.ScanInfo &amp; key).fetch1(\n                    \"fps\", \"ndepths\", \"nchannels\"\n                )\n\n                is3D = bool(ndepths &gt; 1)\n                if is3D:\n                    raise NotImplementedError(\n                        \"Caiman pipeline is not yet capable of analyzing 3D scans.\"\n                    )\n\n                # handle multi-channel tiff image before running CaImAn\n                if nchannels &gt; 1:\n                    channel_idx = caiman_params.get(\"channel_to_process\", 0)\n                    tmp_dir = pathlib.Path(output_dir) / \"channel_separated_tif\"\n                    tmp_dir.mkdir(exist_ok=True)\n                    _process_scanimage_tiff(\n                        [f.as_posix() for f in image_files], output_dir=tmp_dir\n                    )\n                    image_files = tmp_dir.glob(f\"*_chn{channel_idx}.tif\")\n\n                run_caiman(\n                    file_paths=[f.as_posix() for f in image_files],\n                    parameters=caiman_params,\n                    sampling_rate=sampling_rate,\n                    output_dir=output_dir,\n                    is3D=is3D,\n                )\n\n                _, imaging_dataset = get_loader_result(key, ProcessingTask)\n                caiman_dataset = imaging_dataset\n                key[\"processing_time\"] = caiman_dataset.creation_time\n\n            elif method == \"extract\":\n                import suite2p\n                from element_interface.extract_trigger import EXTRACT_trigger\n                from scipy.io import savemat\n\n                # Motion Correction with Suite2p\n                params = (ProcessingTask * ProcessingParamSet &amp; key).fetch1(\"params\")\n\n                params[\"suite2p\"][\"save_path0\"] = output_dir\n                (\n                    params[\"suite2p\"][\"fs\"],\n                    params[\"suite2p\"][\"nplanes\"],\n                    params[\"suite2p\"][\"nchannels\"],\n                ) = (scan.ScanInfo &amp; key).fetch1(\"fps\", \"ndepths\", \"nchannels\")\n\n                input_format = pathlib.Path(image_files[0]).suffix\n                params[\"suite2p\"][\"input_format\"] = input_format[1:]\n\n                suite2p_paths = {\n                    \"data_path\": [image_files[0].parent.as_posix()],\n                    \"tiff_list\": [f.as_posix() for f in image_files],\n                }\n\n                suite2p.run_s2p(ops=params[\"suite2p\"], db=suite2p_paths)\n\n                # Convert data.bin to registered_scans.mat\n                scanfile_fullpath = pathlib.Path(output_dir) / \"suite2p/plane0/data.bin\"\n\n                data_shape = (scan.ScanInfo * scan.ScanInfo.Field &amp; key).fetch1(\n                    \"nframes\", \"px_height\", \"px_width\"\n                )\n                data = np.memmap(scanfile_fullpath, shape=data_shape, dtype=np.int16)\n\n                scan_matlab_fullpath = scanfile_fullpath.parent / \"registered_scan.mat\"\n\n                # Save the motion corrected movie (data.bin) in a .mat file\n                savemat(\n                    scan_matlab_fullpath,\n                    {\"M\": np.transpose(data, axes=[1, 2, 0])},\n                )\n\n                # Execute EXTRACT\n\n                ex = EXTRACT_trigger(\n                    scan_matlab_fullpath, params[\"extract\"], output_dir\n                )\n                ex.run()\n\n                _, extract_dataset = get_loader_result(key, ProcessingTask)\n                key[\"processing_time\"] = extract_dataset.creation_time\n\n        else:\n            raise ValueError(f\"Unknown task mode: {task_mode}\")\n\n        self.insert1({**key, \"package_version\": \"\"})\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_preprocess/#element_calcium_imaging.imaging_preprocess.Processing.key_source", "title": "<code>key_source</code>  <code>property</code>", "text": "<p>Limit the Processing to Scans that have their metadata ingested to the database.</p>"}, {"location": "api/element_calcium_imaging/imaging_preprocess/#element_calcium_imaging.imaging_preprocess.Processing.make", "title": "<code>make(key)</code>", "text": "<p>Execute the calcium imaging analysis defined by the ProcessingTask.</p> Source code in <code>element_calcium_imaging/imaging_preprocess.py</code> <pre><code>def make(self, key):\n\"\"\"Execute the calcium imaging analysis defined by the ProcessingTask.\"\"\"\n\n    task_mode, output_dir = (ProcessingTask &amp; key).fetch1(\n        \"task_mode\", \"processing_output_dir\"\n    )\n\n    if not output_dir:\n        output_dir = ProcessingTask.infer_output_dir(key, relative=True, mkdir=True)\n        # update processing_output_dir\n        ProcessingTask.update1(\n            {**key, \"processing_output_dir\": output_dir.as_posix()}\n        )\n    output_dir = find_full_path(get_imaging_root_data_dir(), output_dir).as_posix()\n\n    if task_mode == \"load\":\n        method, imaging_dataset = get_loader_result(key, ProcessingTask)\n        if method == \"suite2p\":\n            if (scan.ScanInfo &amp; key).fetch1(\"nrois\") &gt; 0:\n                raise NotImplementedError(\n                    \"Suite2p ingestion error - Unable to handle\"\n                    + \" ScanImage multi-ROI scanning mode yet\"\n                )\n            suite2p_dataset = imaging_dataset\n            key = {**key, \"processing_time\": suite2p_dataset.creation_time}\n        elif method == \"caiman\":\n            caiman_dataset = imaging_dataset\n            key = {**key, \"processing_time\": caiman_dataset.creation_time}\n        elif method == \"extract\":\n            raise NotImplementedError(\n                \"To use EXTRACT with this DataJoint Element please set `task_mode=trigger`\"\n            )\n        else:\n            raise NotImplementedError(\"Unknown method: {}\".format(method))\n    elif task_mode == \"trigger\":\n        method = (ProcessingParamSet * ProcessingTask &amp; key).fetch1(\n            \"processing_method\"\n        )\n\n        preprocess_paramsets = (\n            PreprocessParamSteps.Step()\n            &amp; dict(preprocess_param_steps_id=key[\"preprocess_param_steps_id\"])\n        ).fetch(\"paramset_idx\")\n\n        if len(preprocess_paramsets) == 0:\n            # No pre-processing steps were performed on the acquired dataset, so process the raw/acquired files.\n            image_files = (scan.ScanInfo.ScanFile &amp; key).fetch(\"file_path\")\n            image_files = [\n                find_full_path(get_imaging_root_data_dir(), image_file)\n                for image_file in image_files\n            ]\n\n        else:\n            preprocess_output_dir = (PreprocessTask &amp; key).fetch1(\n                \"preprocess_output_dir\"\n            )\n\n            preprocess_output_dir = find_full_path(\n                get_imaging_root_data_dir(), preprocess_output_dir\n            )\n\n            if not preprocess_output_dir.exists():\n                raise FileNotFoundError(\n                    f\"Pre-processed output directory not found ({preprocess_output_dir})\"\n                )\n\n            image_files = list(preprocess_output_dir.glob(\"*.tif\"))\n\n        if method == \"suite2p\":\n            import suite2p\n\n            suite2p_params = (ProcessingTask * ProcessingParamSet &amp; key).fetch1(\n                \"params\"\n            )\n            suite2p_params[\"save_path0\"] = output_dir\n            (\n                suite2p_params[\"fs\"],\n                suite2p_params[\"nplanes\"],\n                suite2p_params[\"nchannels\"],\n            ) = (scan.ScanInfo &amp; key).fetch1(\"fps\", \"ndepths\", \"nchannels\")\n\n            input_format = pathlib.Path(image_files[0]).suffix\n            suite2p_params[\"input_format\"] = input_format[1:]\n\n            suite2p_paths = {\n                \"data_path\": [image_files[0].parent.as_posix()],\n                \"tiff_list\": [f.as_posix() for f in image_files],\n            }\n\n            suite2p.run_s2p(ops=suite2p_params, db=suite2p_paths)  # Run suite2p\n\n            _, imaging_dataset = get_loader_result(key, ProcessingTask)\n            suite2p_dataset = imaging_dataset\n            key = {**key, \"processing_time\": suite2p_dataset.creation_time}\n\n        elif method == \"caiman\":\n            from element_interface.caiman_loader import _process_scanimage_tiff\n            from element_interface.run_caiman import run_caiman\n\n            caiman_params = (ProcessingTask * ProcessingParamSet &amp; key).fetch1(\n                \"params\"\n            )\n            sampling_rate, ndepths, nchannels = (scan.ScanInfo &amp; key).fetch1(\n                \"fps\", \"ndepths\", \"nchannels\"\n            )\n\n            is3D = bool(ndepths &gt; 1)\n            if is3D:\n                raise NotImplementedError(\n                    \"Caiman pipeline is not yet capable of analyzing 3D scans.\"\n                )\n\n            # handle multi-channel tiff image before running CaImAn\n            if nchannels &gt; 1:\n                channel_idx = caiman_params.get(\"channel_to_process\", 0)\n                tmp_dir = pathlib.Path(output_dir) / \"channel_separated_tif\"\n                tmp_dir.mkdir(exist_ok=True)\n                _process_scanimage_tiff(\n                    [f.as_posix() for f in image_files], output_dir=tmp_dir\n                )\n                image_files = tmp_dir.glob(f\"*_chn{channel_idx}.tif\")\n\n            run_caiman(\n                file_paths=[f.as_posix() for f in image_files],\n                parameters=caiman_params,\n                sampling_rate=sampling_rate,\n                output_dir=output_dir,\n                is3D=is3D,\n            )\n\n            _, imaging_dataset = get_loader_result(key, ProcessingTask)\n            caiman_dataset = imaging_dataset\n            key[\"processing_time\"] = caiman_dataset.creation_time\n\n        elif method == \"extract\":\n            import suite2p\n            from element_interface.extract_trigger import EXTRACT_trigger\n            from scipy.io import savemat\n\n            # Motion Correction with Suite2p\n            params = (ProcessingTask * ProcessingParamSet &amp; key).fetch1(\"params\")\n\n            params[\"suite2p\"][\"save_path0\"] = output_dir\n            (\n                params[\"suite2p\"][\"fs\"],\n                params[\"suite2p\"][\"nplanes\"],\n                params[\"suite2p\"][\"nchannels\"],\n            ) = (scan.ScanInfo &amp; key).fetch1(\"fps\", \"ndepths\", \"nchannels\")\n\n            input_format = pathlib.Path(image_files[0]).suffix\n            params[\"suite2p\"][\"input_format\"] = input_format[1:]\n\n            suite2p_paths = {\n                \"data_path\": [image_files[0].parent.as_posix()],\n                \"tiff_list\": [f.as_posix() for f in image_files],\n            }\n\n            suite2p.run_s2p(ops=params[\"suite2p\"], db=suite2p_paths)\n\n            # Convert data.bin to registered_scans.mat\n            scanfile_fullpath = pathlib.Path(output_dir) / \"suite2p/plane0/data.bin\"\n\n            data_shape = (scan.ScanInfo * scan.ScanInfo.Field &amp; key).fetch1(\n                \"nframes\", \"px_height\", \"px_width\"\n            )\n            data = np.memmap(scanfile_fullpath, shape=data_shape, dtype=np.int16)\n\n            scan_matlab_fullpath = scanfile_fullpath.parent / \"registered_scan.mat\"\n\n            # Save the motion corrected movie (data.bin) in a .mat file\n            savemat(\n                scan_matlab_fullpath,\n                {\"M\": np.transpose(data, axes=[1, 2, 0])},\n            )\n\n            # Execute EXTRACT\n\n            ex = EXTRACT_trigger(\n                scan_matlab_fullpath, params[\"extract\"], output_dir\n            )\n            ex.run()\n\n            _, extract_dataset = get_loader_result(key, ProcessingTask)\n            key[\"processing_time\"] = extract_dataset.creation_time\n\n    else:\n        raise ValueError(f\"Unknown task mode: {task_mode}\")\n\n    self.insert1({**key, \"package_version\": \"\"})\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_preprocess/#element_calcium_imaging.imaging_preprocess.Curation", "title": "<code>Curation</code>", "text": "<p>         Bases: <code>dj.Manual</code></p> <p>Curated results</p> <p>If no curation is applied, the curation_output_dir can be set to the value of processing_output_dir.</p> <p>Attributes:</p> Name Type Description <code>Processing</code> <code>foreign key</code> <p>Primary key from Processing.</p> <code>curation_id</code> <code>int</code> <p>Unique curation ID.</p> <code>curation_time</code> <code>datetime</code> <p>Time of generation of this set of curated results.</p> <code>curation_output_dir</code> <code>str</code> <p>Output directory of the curated results, relative to root data directory.</p> <code>manual_curation</code> <code>bool</code> <p>If True, manual curation has been performed on this result.</p> <code>curation_note</code> <code>str</code> <p>Notes about the curation task.</p> Source code in <code>element_calcium_imaging/imaging_preprocess.py</code> <pre><code>@schema\nclass Curation(dj.Manual):\n\"\"\"Curated results\n\n    If no curation is applied, the curation_output_dir can be set to\n    the value of processing_output_dir.\n\n    Attributes:\n        Processing (foreign key): Primary key from Processing.\n        curation_id (int): Unique curation ID.\n        curation_time (datetime): Time of generation of this set of curated results.\n        curation_output_dir (str): Output directory of the curated results, relative to\n            root data directory.\n        manual_curation (bool): If True, manual curation has been performed on this\n            result.\n        curation_note (str, optional): Notes about the curation task.\n    \"\"\"\n\n    definition = \"\"\"# Curation(s) results\n    -&gt; Processing\n    curation_id: int\n    ---\n    curation_time: datetime  # Time of generation of this set of curated results\n    curation_output_dir: varchar(255)  # Output directory of the curated results, relative to root data directory\n    manual_curation: bool  # Has manual curation been performed on this result?\n    curation_note='': varchar(2000)\n    \"\"\"\n\n    def create1_from_processing_task(self, key, is_curated=False, curation_note=\"\"):\n\"\"\"Create a Curation entry for a given ProcessingTask key.\n\n        Args:\n            key (dict): Primary key set of an entry in the ProcessingTask table.\n            is_curated (bool): When True, indicates a manual curation.\n            curation_note (str): User's note on the specifics of the curation.\n        \"\"\"\n        if key not in Processing():\n            raise ValueError(\n                f\"No corresponding entry in Processing available for: {key};\"\n                f\"Please run `Processing.populate(key)`\"\n            )\n\n        output_dir = (ProcessingTask &amp; key).fetch1(\"processing_output_dir\")\n        method, imaging_dataset = get_loader_result(key, ProcessingTask)\n\n        if method == \"suite2p\":\n            suite2p_dataset = imaging_dataset\n            curation_time = suite2p_dataset.creation_time\n        elif method == \"caiman\":\n            caiman_dataset = imaging_dataset\n            curation_time = caiman_dataset.creation_time\n        elif method == \"extract\":\n            extract_dataset = imaging_dataset\n            curation_time = extract_dataset.creation_time\n        else:\n            raise NotImplementedError(\"Unknown method: {}\".format(method))\n\n        # Synthesize curation_id\n        curation_id = (\n            dj.U().aggr(self &amp; key, n=\"ifnull(max(curation_id)+1,1)\").fetch1(\"n\")\n        )\n        self.insert1(\n            {\n                **key,\n                \"curation_id\": curation_id,\n                \"curation_time\": curation_time,\n                \"curation_output_dir\": output_dir,\n                \"manual_curation\": is_curated,\n                \"curation_note\": curation_note,\n            }\n        )\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_preprocess/#element_calcium_imaging.imaging_preprocess.Curation.create1_from_processing_task", "title": "<code>create1_from_processing_task(key, is_curated=False, curation_note='')</code>", "text": "<p>Create a Curation entry for a given ProcessingTask key.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>dict</code> <p>Primary key set of an entry in the ProcessingTask table.</p> required <code>is_curated</code> <code>bool</code> <p>When True, indicates a manual curation.</p> <code>False</code> <code>curation_note</code> <code>str</code> <p>User's note on the specifics of the curation.</p> <code>''</code> Source code in <code>element_calcium_imaging/imaging_preprocess.py</code> <pre><code>def create1_from_processing_task(self, key, is_curated=False, curation_note=\"\"):\n\"\"\"Create a Curation entry for a given ProcessingTask key.\n\n    Args:\n        key (dict): Primary key set of an entry in the ProcessingTask table.\n        is_curated (bool): When True, indicates a manual curation.\n        curation_note (str): User's note on the specifics of the curation.\n    \"\"\"\n    if key not in Processing():\n        raise ValueError(\n            f\"No corresponding entry in Processing available for: {key};\"\n            f\"Please run `Processing.populate(key)`\"\n        )\n\n    output_dir = (ProcessingTask &amp; key).fetch1(\"processing_output_dir\")\n    method, imaging_dataset = get_loader_result(key, ProcessingTask)\n\n    if method == \"suite2p\":\n        suite2p_dataset = imaging_dataset\n        curation_time = suite2p_dataset.creation_time\n    elif method == \"caiman\":\n        caiman_dataset = imaging_dataset\n        curation_time = caiman_dataset.creation_time\n    elif method == \"extract\":\n        extract_dataset = imaging_dataset\n        curation_time = extract_dataset.creation_time\n    else:\n        raise NotImplementedError(\"Unknown method: {}\".format(method))\n\n    # Synthesize curation_id\n    curation_id = (\n        dj.U().aggr(self &amp; key, n=\"ifnull(max(curation_id)+1,1)\").fetch1(\"n\")\n    )\n    self.insert1(\n        {\n            **key,\n            \"curation_id\": curation_id,\n            \"curation_time\": curation_time,\n            \"curation_output_dir\": output_dir,\n            \"manual_curation\": is_curated,\n            \"curation_note\": curation_note,\n        }\n    )\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_preprocess/#element_calcium_imaging.imaging_preprocess.MotionCorrection", "title": "<code>MotionCorrection</code>", "text": "<p>         Bases: <code>dj.Imported</code></p> <p>Results of motion correction shifts performed on the imaging data.</p> <p>Attributes:</p> Name Type Description <code>Curation</code> <code>foreign key</code> <p>Primary key from Curation.</p> <code>scan.Channel.proj(motion_correct_channel='channel')</code> <code>int</code> <p>Channel used for motion correction in this processing task.</p> Source code in <code>element_calcium_imaging/imaging_preprocess.py</code> <pre><code>@schema\nclass MotionCorrection(dj.Imported):\n\"\"\"Results of motion correction shifts performed on the imaging data.\n\n    Attributes:\n        Curation (foreign key): Primary key from Curation.\n        scan.Channel.proj(motion_correct_channel='channel') (int): Channel used for\n            motion correction in this processing task.\n    \"\"\"\n\n    definition = \"\"\"# Results of motion correction\n    -&gt; Curation\n    ---\n    -&gt; scan.Channel.proj(motion_correct_channel='channel') # channel used for motion correction in this processing task\n    \"\"\"\n\n    class RigidMotionCorrection(dj.Part):\n\"\"\"Details of rigid motion correction performed on the imaging data.\n\n        Attributes:\n            MotionCorrection (foreign key): Primary key from MotionCorrection.\n            outlier_frames (longblob): Mask with true for frames with outlier shifts\n                (already corrected).\n            y_shifts (longblob): y motion correction shifts (pixels).\n            x_shifts (longblob): x motion correction shifts (pixels).\n            z_shifts (longblob, optional): z motion correction shifts (z-drift, pixels).\n            y_std (float): standard deviation of y shifts across all frames (pixels).\n            x_std (float): standard deviation of x shifts across all frames (pixels).\n            z_std (float, optional): standard deviation of z shifts across all frames\n                (pixels).\n        \"\"\"\n\n        definition = \"\"\"# Details of rigid motion correction performed on the imaging data\n        -&gt; master\n        ---\n        outlier_frames=null : longblob  # mask with true for frames with outlier shifts (already corrected)\n        y_shifts            : longblob  # (pixels) y motion correction shifts\n        x_shifts            : longblob  # (pixels) x motion correction shifts\n        z_shifts=null       : longblob  # (pixels) z motion correction shifts (z-drift)\n        y_std               : float     # (pixels) standard deviation of y shifts across all frames\n        x_std               : float     # (pixels) standard deviation of x shifts across all frames\n        z_std=null          : float     # (pixels) standard deviation of z shifts across all frames\n        \"\"\"\n\n    class NonRigidMotionCorrection(dj.Part):\n\"\"\"Piece-wise rigid motion correction - tile the FOV into multiple 3D\n        blocks/patches.\n\n        Attributes:\n            MotionCorrection (foreign key): Primary key from MotionCorrection.\n            outlier_frames (longblob, null): Mask with true for frames with outlier\n                shifts (already corrected).\n            block_height (int): Block height in pixels.\n            block_width (int): Block width in pixels.\n            block_depth (int): Block depth in pixels.\n            block_count_y (int): Number of blocks tiled in the y direction.\n            block_count_x (int): Number of blocks tiled in the x direction.\n            block_count_z (int): Number of blocks tiled in the z direction.\n        \"\"\"\n\n        definition = \"\"\"# Details of non-rigid motion correction performed on the imaging data\n        -&gt; master\n        ---\n        outlier_frames=null : longblob # mask with true for frames with outlier shifts (already corrected)\n        block_height        : int      # (pixels)\n        block_width         : int      # (pixels)\n        block_depth         : int      # (pixels)\n        block_count_y       : int      # number of blocks tiled in the y direction\n        block_count_x       : int      # number of blocks tiled in the x direction\n        block_count_z       : int      # number of blocks tiled in the z direction\n        \"\"\"\n\n    class Block(dj.Part):\n\"\"\"FOV-tiled blocks used for non-rigid motion correction.\n\n        Attributes:\n            NonRigidMotionCorrection (foreign key): Primary key from\n                NonRigidMotionCorrection.\n            block_id (int): Unique block ID.\n            block_y (longblob): y_start and y_end in pixels for this block\n            block_x (longblob): x_start and x_end in pixels for this block\n            block_z (longblob): z_start and z_end in pixels for this block\n            y_shifts (longblob): y motion correction shifts for every frame in pixels\n            x_shifts (longblob): x motion correction shifts for every frame in pixels\n            z_shift=null (longblob, optional): x motion correction shifts for every frame\n                in pixels\n            y_std (float): standard deviation of y shifts across all frames in pixels\n            x_std (float): standard deviation of x shifts across all frames in pixels\n            z_std=null (float, optional): standard deviation of z shifts across all frames\n                in pixels\n        \"\"\"\n\n        definition = \"\"\"# FOV-tiled blocks used for non-rigid motion correction\n        -&gt; master.NonRigidMotionCorrection\n        block_id        : int\n        ---\n        block_y         : longblob  # (y_start, y_end) in pixel of this block\n        block_x         : longblob  # (x_start, x_end) in pixel of this block\n        block_z         : longblob  # (z_start, z_end) in pixel of this block\n        y_shifts        : longblob  # (pixels) y motion correction shifts for every frame\n        x_shifts        : longblob  # (pixels) x motion correction shifts for every frame\n        z_shifts=null   : longblob  # (pixels) x motion correction shifts for every frame\n        y_std           : float     # (pixels) standard deviation of y shifts across all frames\n        x_std           : float     # (pixels) standard deviation of x shifts across all frames\n        z_std=null      : float     # (pixels) standard deviation of z shifts across all frames\n        \"\"\"\n\n    class Summary(dj.Part):\n\"\"\"Summary images for each field and channel after corrections.\n\n        Attributes:\n            MotionCorrection (foreign key): Primary key from MotionCorrection.\n            scan.ScanInfo.Field (foreign key): Primary key from scan.ScanInfo.Field.\n            ref_image (longblob): Image used as alignment template.\n            average_image (longblob): Mean of registered frames.\n            correlation_image (longblob, optional): Correlation map (computed during\n                cell detection).\n            max_proj_image (longblob, optional): Max of registered frames.\n        \"\"\"\n\n        definition = \"\"\"# Summary images for each field and channel after corrections\n        -&gt; master\n        -&gt; scan.ScanInfo.Field\n        ---\n        ref_image               : longblob  # image used as alignment template\n        average_image           : longblob  # mean of registered frames\n        correlation_image=null  : longblob  # correlation map (computed during cell detection)\n        max_proj_image=null     : longblob  # max of registered frames\n        \"\"\"\n\n    def make(self, key):\n\"\"\"Populate MotionCorrection with results parsed from analysis outputs\"\"\"\n\n        method, imaging_dataset = get_loader_result(key, Curation)\n\n        field_keys, _ = (scan.ScanInfo.Field &amp; key).fetch(\n            \"KEY\", \"field_z\", order_by=\"field_z\"\n        )\n\n        if method in [\"suite2p\", \"extract\"]:\n            suite2p_dataset = imaging_dataset\n\n            motion_correct_channel = suite2p_dataset.planes[0].alignment_channel\n\n            # ---- iterate through all s2p plane outputs ----\n            rigid_correction, nonrigid_correction, nonrigid_blocks = {}, {}, {}\n            summary_images = []\n            for idx, (plane, s2p) in enumerate(suite2p_dataset.planes.items()):\n                # -- rigid motion correction --\n                if idx == 0:\n                    rigid_correction = {\n                        **key,\n                        \"y_shifts\": s2p.ops[\"yoff\"],\n                        \"x_shifts\": s2p.ops[\"xoff\"],\n                        \"z_shifts\": np.full_like(s2p.ops[\"xoff\"], 0),\n                        \"y_std\": np.nanstd(s2p.ops[\"yoff\"]),\n                        \"x_std\": np.nanstd(s2p.ops[\"xoff\"]),\n                        \"z_std\": np.nan,\n                        \"outlier_frames\": s2p.ops[\"badframes\"],\n                    }\n                else:\n                    rigid_correction[\"y_shifts\"] = np.vstack(\n                        [rigid_correction[\"y_shifts\"], s2p.ops[\"yoff\"]]\n                    )\n                    rigid_correction[\"y_std\"] = np.nanstd(\n                        rigid_correction[\"y_shifts\"].flatten()\n                    )\n                    rigid_correction[\"x_shifts\"] = np.vstack(\n                        [rigid_correction[\"x_shifts\"], s2p.ops[\"xoff\"]]\n                    )\n                    rigid_correction[\"x_std\"] = np.nanstd(\n                        rigid_correction[\"x_shifts\"].flatten()\n                    )\n                    rigid_correction[\"outlier_frames\"] = np.logical_or(\n                        rigid_correction[\"outlier_frames\"], s2p.ops[\"badframes\"]\n                    )\n                # -- non-rigid motion correction --\n                if s2p.ops[\"nonrigid\"]:\n                    if idx == 0:\n                        nonrigid_correction = {\n                            **key,\n                            \"block_height\": s2p.ops[\"block_size\"][0],\n                            \"block_width\": s2p.ops[\"block_size\"][1],\n                            \"block_depth\": 1,\n                            \"block_count_y\": s2p.ops[\"nblocks\"][0],\n                            \"block_count_x\": s2p.ops[\"nblocks\"][1],\n                            \"block_count_z\": len(suite2p_dataset.planes),\n                            \"outlier_frames\": s2p.ops[\"badframes\"],\n                        }\n                    else:\n                        nonrigid_correction[\"outlier_frames\"] = np.logical_or(\n                            nonrigid_correction[\"outlier_frames\"],\n                            s2p.ops[\"badframes\"],\n                        )\n                    for b_id, (b_y, b_x, bshift_y, bshift_x) in enumerate(\n                        zip(\n                            s2p.ops[\"xblock\"],\n                            s2p.ops[\"yblock\"],\n                            s2p.ops[\"yoff1\"].T,\n                            s2p.ops[\"xoff1\"].T,\n                        )\n                    ):\n                        if b_id in nonrigid_blocks:\n                            nonrigid_blocks[b_id][\"y_shifts\"] = np.vstack(\n                                [nonrigid_blocks[b_id][\"y_shifts\"], bshift_y]\n                            )\n                            nonrigid_blocks[b_id][\"y_std\"] = np.nanstd(\n                                nonrigid_blocks[b_id][\"y_shifts\"].flatten()\n                            )\n                            nonrigid_blocks[b_id][\"x_shifts\"] = np.vstack(\n                                [nonrigid_blocks[b_id][\"x_shifts\"], bshift_x]\n                            )\n                            nonrigid_blocks[b_id][\"x_std\"] = np.nanstd(\n                                nonrigid_blocks[b_id][\"x_shifts\"].flatten()\n                            )\n                        else:\n                            nonrigid_blocks[b_id] = {\n                                **key,\n                                \"block_id\": b_id,\n                                \"block_y\": b_y,\n                                \"block_x\": b_x,\n                                \"block_z\": np.full_like(b_x, plane),\n                                \"y_shifts\": bshift_y,\n                                \"x_shifts\": bshift_x,\n                                \"z_shifts\": np.full(\n                                    (\n                                        len(suite2p_dataset.planes),\n                                        len(bshift_x),\n                                    ),\n                                    0,\n                                ),\n                                \"y_std\": np.nanstd(bshift_y),\n                                \"x_std\": np.nanstd(bshift_x),\n                                \"z_std\": np.nan,\n                            }\n\n                # -- summary images --\n                motion_correction_key = (\n                    scan.ScanInfo.Field * Curation &amp; key &amp; field_keys[plane]\n                ).fetch1(\"KEY\")\n                summary_images.append(\n                    {\n                        **motion_correction_key,\n                        \"ref_image\": s2p.ref_image,\n                        \"average_image\": s2p.mean_image,\n                        \"correlation_image\": s2p.correlation_map,\n                        \"max_proj_image\": s2p.max_proj_image,\n                    }\n                )\n\n            self.insert1({**key, \"motion_correct_channel\": motion_correct_channel})\n            if rigid_correction:\n                self.RigidMotionCorrection.insert1(rigid_correction)\n            if nonrigid_correction:\n                self.NonRigidMotionCorrection.insert1(nonrigid_correction)\n                self.Block.insert(nonrigid_blocks.values())\n            self.Summary.insert(summary_images)\n        elif method == \"caiman\":\n            caiman_dataset = imaging_dataset\n\n            self.insert1(\n                {\n                    **key,\n                    \"motion_correct_channel\": caiman_dataset.alignment_channel,\n                }\n            )\n\n            is3D = caiman_dataset.params.motion[\"is3D\"]\n            if not caiman_dataset.params.motion[\"pw_rigid\"]:\n                # -- rigid motion correction --\n                rigid_correction = {\n                    **key,\n                    \"x_shifts\": caiman_dataset.motion_correction[\"shifts_rig\"][:, 0],\n                    \"y_shifts\": caiman_dataset.motion_correction[\"shifts_rig\"][:, 1],\n                    \"z_shifts\": (\n                        caiman_dataset.motion_correction[\"shifts_rig\"][:, 2]\n                        if is3D\n                        else np.full_like(\n                            caiman_dataset.motion_correction[\"shifts_rig\"][:, 0],\n                            0,\n                        )\n                    ),\n                    \"x_std\": np.nanstd(\n                        caiman_dataset.motion_correction[\"shifts_rig\"][:, 0]\n                    ),\n                    \"y_std\": np.nanstd(\n                        caiman_dataset.motion_correction[\"shifts_rig\"][:, 1]\n                    ),\n                    \"z_std\": (\n                        np.nanstd(caiman_dataset.motion_correction[\"shifts_rig\"][:, 2])\n                        if is3D\n                        else np.nan\n                    ),\n                    \"outlier_frames\": None,\n                }\n\n                self.RigidMotionCorrection.insert1(rigid_correction)\n            else:\n                # -- non-rigid motion correction --\n                nonrigid_correction = {\n                    **key,\n                    \"block_height\": (\n                        caiman_dataset.params.motion[\"strides\"][0]\n                        + caiman_dataset.params.motion[\"overlaps\"][0]\n                    ),\n                    \"block_width\": (\n                        caiman_dataset.params.motion[\"strides\"][1]\n                        + caiman_dataset.params.motion[\"overlaps\"][1]\n                    ),\n                    \"block_depth\": (\n                        caiman_dataset.params.motion[\"strides\"][2]\n                        + caiman_dataset.params.motion[\"overlaps\"][2]\n                        if is3D\n                        else 1\n                    ),\n                    \"block_count_x\": len(\n                        set(caiman_dataset.motion_correction[\"coord_shifts_els\"][:, 0])\n                    ),\n                    \"block_count_y\": len(\n                        set(caiman_dataset.motion_correction[\"coord_shifts_els\"][:, 2])\n                    ),\n                    \"block_count_z\": (\n                        len(\n                            set(\n                                caiman_dataset.motion_correction[\"coord_shifts_els\"][\n                                    :, 4\n                                ]\n                            )\n                        )\n                        if is3D\n                        else 1\n                    ),\n                    \"outlier_frames\": None,\n                }\n\n                nonrigid_blocks = []\n                for b_id in range(\n                    len(caiman_dataset.motion_correction[\"x_shifts_els\"][0, :])\n                ):\n                    nonrigid_blocks.append(\n                        {\n                            **key,\n                            \"block_id\": b_id,\n                            \"block_x\": np.arange(\n                                *caiman_dataset.motion_correction[\"coord_shifts_els\"][\n                                    b_id, 0:2\n                                ]\n                            ),\n                            \"block_y\": np.arange(\n                                *caiman_dataset.motion_correction[\"coord_shifts_els\"][\n                                    b_id, 2:4\n                                ]\n                            ),\n                            \"block_z\": (\n                                np.arange(\n                                    *caiman_dataset.motion_correction[\n                                        \"coord_shifts_els\"\n                                    ][b_id, 4:6]\n                                )\n                                if is3D\n                                else np.full_like(\n                                    np.arange(\n                                        *caiman_dataset.motion_correction[\n                                            \"coord_shifts_els\"\n                                        ][b_id, 0:2]\n                                    ),\n                                    0,\n                                )\n                            ),\n                            \"x_shifts\": caiman_dataset.motion_correction[\n                                \"x_shifts_els\"\n                            ][:, b_id],\n                            \"y_shifts\": caiman_dataset.motion_correction[\n                                \"y_shifts_els\"\n                            ][:, b_id],\n                            \"z_shifts\": (\n                                caiman_dataset.motion_correction[\"z_shifts_els\"][\n                                    :, b_id\n                                ]\n                                if is3D\n                                else np.full_like(\n                                    caiman_dataset.motion_correction[\"x_shifts_els\"][\n                                        :, b_id\n                                    ],\n                                    0,\n                                )\n                            ),\n                            \"x_std\": np.nanstd(\n                                caiman_dataset.motion_correction[\"x_shifts_els\"][\n                                    :, b_id\n                                ]\n                            ),\n                            \"y_std\": np.nanstd(\n                                caiman_dataset.motion_correction[\"y_shifts_els\"][\n                                    :, b_id\n                                ]\n                            ),\n                            \"z_std\": (\n                                np.nanstd(\n                                    caiman_dataset.motion_correction[\"z_shifts_els\"][\n                                        :, b_id\n                                    ]\n                                )\n                                if is3D\n                                else np.nan\n                            ),\n                        }\n                    )\n\n                self.NonRigidMotionCorrection.insert1(nonrigid_correction)\n                self.Block.insert(nonrigid_blocks)\n\n            # -- summary images --\n            summary_images = [\n                {\n                    **key,\n                    **fkey,\n                    \"ref_image\": ref_image,\n                    \"average_image\": ave_img,\n                    \"correlation_image\": corr_img,\n                    \"max_proj_image\": max_img,\n                }\n                for fkey, ref_image, ave_img, corr_img, max_img in zip(\n                    field_keys,\n                    caiman_dataset.motion_correction[\"reference_image\"].transpose(\n                        2, 0, 1\n                    )\n                    if is3D\n                    else caiman_dataset.motion_correction[\"reference_image\"][...][\n                        np.newaxis, ...\n                    ],\n                    caiman_dataset.motion_correction[\"average_image\"].transpose(2, 0, 1)\n                    if is3D\n                    else caiman_dataset.motion_correction[\"average_image\"][...][\n                        np.newaxis, ...\n                    ],\n                    caiman_dataset.motion_correction[\"correlation_image\"].transpose(\n                        2, 0, 1\n                    )\n                    if is3D\n                    else caiman_dataset.motion_correction[\"correlation_image\"][...][\n                        np.newaxis, ...\n                    ],\n                    caiman_dataset.motion_correction[\"max_image\"].transpose(2, 0, 1)\n                    if is3D\n                    else caiman_dataset.motion_correction[\"max_image\"][...][\n                        np.newaxis, ...\n                    ],\n                )\n            ]\n            self.Summary.insert(summary_images)\n        else:\n            raise NotImplementedError(\"Unknown/unimplemented method: {}\".format(method))\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_preprocess/#element_calcium_imaging.imaging_preprocess.MotionCorrection.RigidMotionCorrection", "title": "<code>RigidMotionCorrection</code>", "text": "<p>         Bases: <code>dj.Part</code></p> <p>Details of rigid motion correction performed on the imaging data.</p> <p>Attributes:</p> Name Type Description <code>MotionCorrection</code> <code>foreign key</code> <p>Primary key from MotionCorrection.</p> <code>outlier_frames</code> <code>longblob</code> <p>Mask with true for frames with outlier shifts (already corrected).</p> <code>y_shifts</code> <code>longblob</code> <p>y motion correction shifts (pixels).</p> <code>x_shifts</code> <code>longblob</code> <p>x motion correction shifts (pixels).</p> <code>z_shifts</code> <code>longblob</code> <p>z motion correction shifts (z-drift, pixels).</p> <code>y_std</code> <code>float</code> <p>standard deviation of y shifts across all frames (pixels).</p> <code>x_std</code> <code>float</code> <p>standard deviation of x shifts across all frames (pixels).</p> <code>z_std</code> <code>float</code> <p>standard deviation of z shifts across all frames (pixels).</p> Source code in <code>element_calcium_imaging/imaging_preprocess.py</code> <pre><code>class RigidMotionCorrection(dj.Part):\n\"\"\"Details of rigid motion correction performed on the imaging data.\n\n    Attributes:\n        MotionCorrection (foreign key): Primary key from MotionCorrection.\n        outlier_frames (longblob): Mask with true for frames with outlier shifts\n            (already corrected).\n        y_shifts (longblob): y motion correction shifts (pixels).\n        x_shifts (longblob): x motion correction shifts (pixels).\n        z_shifts (longblob, optional): z motion correction shifts (z-drift, pixels).\n        y_std (float): standard deviation of y shifts across all frames (pixels).\n        x_std (float): standard deviation of x shifts across all frames (pixels).\n        z_std (float, optional): standard deviation of z shifts across all frames\n            (pixels).\n    \"\"\"\n\n    definition = \"\"\"# Details of rigid motion correction performed on the imaging data\n    -&gt; master\n    ---\n    outlier_frames=null : longblob  # mask with true for frames with outlier shifts (already corrected)\n    y_shifts            : longblob  # (pixels) y motion correction shifts\n    x_shifts            : longblob  # (pixels) x motion correction shifts\n    z_shifts=null       : longblob  # (pixels) z motion correction shifts (z-drift)\n    y_std               : float     # (pixels) standard deviation of y shifts across all frames\n    x_std               : float     # (pixels) standard deviation of x shifts across all frames\n    z_std=null          : float     # (pixels) standard deviation of z shifts across all frames\n    \"\"\"\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_preprocess/#element_calcium_imaging.imaging_preprocess.MotionCorrection.NonRigidMotionCorrection", "title": "<code>NonRigidMotionCorrection</code>", "text": "<p>         Bases: <code>dj.Part</code></p> <p>Piece-wise rigid motion correction - tile the FOV into multiple 3D blocks/patches.</p> <p>Attributes:</p> Name Type Description <code>MotionCorrection</code> <code>foreign key</code> <p>Primary key from MotionCorrection.</p> <code>outlier_frames</code> <code>longblob, null</code> <p>Mask with true for frames with outlier shifts (already corrected).</p> <code>block_height</code> <code>int</code> <p>Block height in pixels.</p> <code>block_width</code> <code>int</code> <p>Block width in pixels.</p> <code>block_depth</code> <code>int</code> <p>Block depth in pixels.</p> <code>block_count_y</code> <code>int</code> <p>Number of blocks tiled in the y direction.</p> <code>block_count_x</code> <code>int</code> <p>Number of blocks tiled in the x direction.</p> <code>block_count_z</code> <code>int</code> <p>Number of blocks tiled in the z direction.</p> Source code in <code>element_calcium_imaging/imaging_preprocess.py</code> <pre><code>class NonRigidMotionCorrection(dj.Part):\n\"\"\"Piece-wise rigid motion correction - tile the FOV into multiple 3D\n    blocks/patches.\n\n    Attributes:\n        MotionCorrection (foreign key): Primary key from MotionCorrection.\n        outlier_frames (longblob, null): Mask with true for frames with outlier\n            shifts (already corrected).\n        block_height (int): Block height in pixels.\n        block_width (int): Block width in pixels.\n        block_depth (int): Block depth in pixels.\n        block_count_y (int): Number of blocks tiled in the y direction.\n        block_count_x (int): Number of blocks tiled in the x direction.\n        block_count_z (int): Number of blocks tiled in the z direction.\n    \"\"\"\n\n    definition = \"\"\"# Details of non-rigid motion correction performed on the imaging data\n    -&gt; master\n    ---\n    outlier_frames=null : longblob # mask with true for frames with outlier shifts (already corrected)\n    block_height        : int      # (pixels)\n    block_width         : int      # (pixels)\n    block_depth         : int      # (pixels)\n    block_count_y       : int      # number of blocks tiled in the y direction\n    block_count_x       : int      # number of blocks tiled in the x direction\n    block_count_z       : int      # number of blocks tiled in the z direction\n    \"\"\"\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_preprocess/#element_calcium_imaging.imaging_preprocess.MotionCorrection.Block", "title": "<code>Block</code>", "text": "<p>         Bases: <code>dj.Part</code></p> <p>FOV-tiled blocks used for non-rigid motion correction.</p> <p>Attributes:</p> Name Type Description <code>NonRigidMotionCorrection</code> <code>foreign key</code> <p>Primary key from NonRigidMotionCorrection.</p> <code>block_id</code> <code>int</code> <p>Unique block ID.</p> <code>block_y</code> <code>longblob</code> <p>y_start and y_end in pixels for this block</p> <code>block_x</code> <code>longblob</code> <p>x_start and x_end in pixels for this block</p> <code>block_z</code> <code>longblob</code> <p>z_start and z_end in pixels for this block</p> <code>y_shifts</code> <code>longblob</code> <p>y motion correction shifts for every frame in pixels</p> <code>x_shifts</code> <code>longblob</code> <p>x motion correction shifts for every frame in pixels</p> <code>z_shift=null</code> <code>longblob</code> <p>x motion correction shifts for every frame in pixels</p> <code>y_std</code> <code>float</code> <p>standard deviation of y shifts across all frames in pixels</p> <code>x_std</code> <code>float</code> <p>standard deviation of x shifts across all frames in pixels</p> <code>z_std=null</code> <code>float</code> <p>standard deviation of z shifts across all frames in pixels</p> Source code in <code>element_calcium_imaging/imaging_preprocess.py</code> <pre><code>class Block(dj.Part):\n\"\"\"FOV-tiled blocks used for non-rigid motion correction.\n\n    Attributes:\n        NonRigidMotionCorrection (foreign key): Primary key from\n            NonRigidMotionCorrection.\n        block_id (int): Unique block ID.\n        block_y (longblob): y_start and y_end in pixels for this block\n        block_x (longblob): x_start and x_end in pixels for this block\n        block_z (longblob): z_start and z_end in pixels for this block\n        y_shifts (longblob): y motion correction shifts for every frame in pixels\n        x_shifts (longblob): x motion correction shifts for every frame in pixels\n        z_shift=null (longblob, optional): x motion correction shifts for every frame\n            in pixels\n        y_std (float): standard deviation of y shifts across all frames in pixels\n        x_std (float): standard deviation of x shifts across all frames in pixels\n        z_std=null (float, optional): standard deviation of z shifts across all frames\n            in pixels\n    \"\"\"\n\n    definition = \"\"\"# FOV-tiled blocks used for non-rigid motion correction\n    -&gt; master.NonRigidMotionCorrection\n    block_id        : int\n    ---\n    block_y         : longblob  # (y_start, y_end) in pixel of this block\n    block_x         : longblob  # (x_start, x_end) in pixel of this block\n    block_z         : longblob  # (z_start, z_end) in pixel of this block\n    y_shifts        : longblob  # (pixels) y motion correction shifts for every frame\n    x_shifts        : longblob  # (pixels) x motion correction shifts for every frame\n    z_shifts=null   : longblob  # (pixels) x motion correction shifts for every frame\n    y_std           : float     # (pixels) standard deviation of y shifts across all frames\n    x_std           : float     # (pixels) standard deviation of x shifts across all frames\n    z_std=null      : float     # (pixels) standard deviation of z shifts across all frames\n    \"\"\"\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_preprocess/#element_calcium_imaging.imaging_preprocess.MotionCorrection.Summary", "title": "<code>Summary</code>", "text": "<p>         Bases: <code>dj.Part</code></p> <p>Summary images for each field and channel after corrections.</p> <p>Attributes:</p> Name Type Description <code>MotionCorrection</code> <code>foreign key</code> <p>Primary key from MotionCorrection.</p> <code>scan.ScanInfo.Field</code> <code>foreign key</code> <p>Primary key from scan.ScanInfo.Field.</p> <code>ref_image</code> <code>longblob</code> <p>Image used as alignment template.</p> <code>average_image</code> <code>longblob</code> <p>Mean of registered frames.</p> <code>correlation_image</code> <code>longblob</code> <p>Correlation map (computed during cell detection).</p> <code>max_proj_image</code> <code>longblob</code> <p>Max of registered frames.</p> Source code in <code>element_calcium_imaging/imaging_preprocess.py</code> <pre><code>class Summary(dj.Part):\n\"\"\"Summary images for each field and channel after corrections.\n\n    Attributes:\n        MotionCorrection (foreign key): Primary key from MotionCorrection.\n        scan.ScanInfo.Field (foreign key): Primary key from scan.ScanInfo.Field.\n        ref_image (longblob): Image used as alignment template.\n        average_image (longblob): Mean of registered frames.\n        correlation_image (longblob, optional): Correlation map (computed during\n            cell detection).\n        max_proj_image (longblob, optional): Max of registered frames.\n    \"\"\"\n\n    definition = \"\"\"# Summary images for each field and channel after corrections\n    -&gt; master\n    -&gt; scan.ScanInfo.Field\n    ---\n    ref_image               : longblob  # image used as alignment template\n    average_image           : longblob  # mean of registered frames\n    correlation_image=null  : longblob  # correlation map (computed during cell detection)\n    max_proj_image=null     : longblob  # max of registered frames\n    \"\"\"\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_preprocess/#element_calcium_imaging.imaging_preprocess.MotionCorrection.make", "title": "<code>make(key)</code>", "text": "<p>Populate MotionCorrection with results parsed from analysis outputs</p> Source code in <code>element_calcium_imaging/imaging_preprocess.py</code> <pre><code>def make(self, key):\n\"\"\"Populate MotionCorrection with results parsed from analysis outputs\"\"\"\n\n    method, imaging_dataset = get_loader_result(key, Curation)\n\n    field_keys, _ = (scan.ScanInfo.Field &amp; key).fetch(\n        \"KEY\", \"field_z\", order_by=\"field_z\"\n    )\n\n    if method in [\"suite2p\", \"extract\"]:\n        suite2p_dataset = imaging_dataset\n\n        motion_correct_channel = suite2p_dataset.planes[0].alignment_channel\n\n        # ---- iterate through all s2p plane outputs ----\n        rigid_correction, nonrigid_correction, nonrigid_blocks = {}, {}, {}\n        summary_images = []\n        for idx, (plane, s2p) in enumerate(suite2p_dataset.planes.items()):\n            # -- rigid motion correction --\n            if idx == 0:\n                rigid_correction = {\n                    **key,\n                    \"y_shifts\": s2p.ops[\"yoff\"],\n                    \"x_shifts\": s2p.ops[\"xoff\"],\n                    \"z_shifts\": np.full_like(s2p.ops[\"xoff\"], 0),\n                    \"y_std\": np.nanstd(s2p.ops[\"yoff\"]),\n                    \"x_std\": np.nanstd(s2p.ops[\"xoff\"]),\n                    \"z_std\": np.nan,\n                    \"outlier_frames\": s2p.ops[\"badframes\"],\n                }\n            else:\n                rigid_correction[\"y_shifts\"] = np.vstack(\n                    [rigid_correction[\"y_shifts\"], s2p.ops[\"yoff\"]]\n                )\n                rigid_correction[\"y_std\"] = np.nanstd(\n                    rigid_correction[\"y_shifts\"].flatten()\n                )\n                rigid_correction[\"x_shifts\"] = np.vstack(\n                    [rigid_correction[\"x_shifts\"], s2p.ops[\"xoff\"]]\n                )\n                rigid_correction[\"x_std\"] = np.nanstd(\n                    rigid_correction[\"x_shifts\"].flatten()\n                )\n                rigid_correction[\"outlier_frames\"] = np.logical_or(\n                    rigid_correction[\"outlier_frames\"], s2p.ops[\"badframes\"]\n                )\n            # -- non-rigid motion correction --\n            if s2p.ops[\"nonrigid\"]:\n                if idx == 0:\n                    nonrigid_correction = {\n                        **key,\n                        \"block_height\": s2p.ops[\"block_size\"][0],\n                        \"block_width\": s2p.ops[\"block_size\"][1],\n                        \"block_depth\": 1,\n                        \"block_count_y\": s2p.ops[\"nblocks\"][0],\n                        \"block_count_x\": s2p.ops[\"nblocks\"][1],\n                        \"block_count_z\": len(suite2p_dataset.planes),\n                        \"outlier_frames\": s2p.ops[\"badframes\"],\n                    }\n                else:\n                    nonrigid_correction[\"outlier_frames\"] = np.logical_or(\n                        nonrigid_correction[\"outlier_frames\"],\n                        s2p.ops[\"badframes\"],\n                    )\n                for b_id, (b_y, b_x, bshift_y, bshift_x) in enumerate(\n                    zip(\n                        s2p.ops[\"xblock\"],\n                        s2p.ops[\"yblock\"],\n                        s2p.ops[\"yoff1\"].T,\n                        s2p.ops[\"xoff1\"].T,\n                    )\n                ):\n                    if b_id in nonrigid_blocks:\n                        nonrigid_blocks[b_id][\"y_shifts\"] = np.vstack(\n                            [nonrigid_blocks[b_id][\"y_shifts\"], bshift_y]\n                        )\n                        nonrigid_blocks[b_id][\"y_std\"] = np.nanstd(\n                            nonrigid_blocks[b_id][\"y_shifts\"].flatten()\n                        )\n                        nonrigid_blocks[b_id][\"x_shifts\"] = np.vstack(\n                            [nonrigid_blocks[b_id][\"x_shifts\"], bshift_x]\n                        )\n                        nonrigid_blocks[b_id][\"x_std\"] = np.nanstd(\n                            nonrigid_blocks[b_id][\"x_shifts\"].flatten()\n                        )\n                    else:\n                        nonrigid_blocks[b_id] = {\n                            **key,\n                            \"block_id\": b_id,\n                            \"block_y\": b_y,\n                            \"block_x\": b_x,\n                            \"block_z\": np.full_like(b_x, plane),\n                            \"y_shifts\": bshift_y,\n                            \"x_shifts\": bshift_x,\n                            \"z_shifts\": np.full(\n                                (\n                                    len(suite2p_dataset.planes),\n                                    len(bshift_x),\n                                ),\n                                0,\n                            ),\n                            \"y_std\": np.nanstd(bshift_y),\n                            \"x_std\": np.nanstd(bshift_x),\n                            \"z_std\": np.nan,\n                        }\n\n            # -- summary images --\n            motion_correction_key = (\n                scan.ScanInfo.Field * Curation &amp; key &amp; field_keys[plane]\n            ).fetch1(\"KEY\")\n            summary_images.append(\n                {\n                    **motion_correction_key,\n                    \"ref_image\": s2p.ref_image,\n                    \"average_image\": s2p.mean_image,\n                    \"correlation_image\": s2p.correlation_map,\n                    \"max_proj_image\": s2p.max_proj_image,\n                }\n            )\n\n        self.insert1({**key, \"motion_correct_channel\": motion_correct_channel})\n        if rigid_correction:\n            self.RigidMotionCorrection.insert1(rigid_correction)\n        if nonrigid_correction:\n            self.NonRigidMotionCorrection.insert1(nonrigid_correction)\n            self.Block.insert(nonrigid_blocks.values())\n        self.Summary.insert(summary_images)\n    elif method == \"caiman\":\n        caiman_dataset = imaging_dataset\n\n        self.insert1(\n            {\n                **key,\n                \"motion_correct_channel\": caiman_dataset.alignment_channel,\n            }\n        )\n\n        is3D = caiman_dataset.params.motion[\"is3D\"]\n        if not caiman_dataset.params.motion[\"pw_rigid\"]:\n            # -- rigid motion correction --\n            rigid_correction = {\n                **key,\n                \"x_shifts\": caiman_dataset.motion_correction[\"shifts_rig\"][:, 0],\n                \"y_shifts\": caiman_dataset.motion_correction[\"shifts_rig\"][:, 1],\n                \"z_shifts\": (\n                    caiman_dataset.motion_correction[\"shifts_rig\"][:, 2]\n                    if is3D\n                    else np.full_like(\n                        caiman_dataset.motion_correction[\"shifts_rig\"][:, 0],\n                        0,\n                    )\n                ),\n                \"x_std\": np.nanstd(\n                    caiman_dataset.motion_correction[\"shifts_rig\"][:, 0]\n                ),\n                \"y_std\": np.nanstd(\n                    caiman_dataset.motion_correction[\"shifts_rig\"][:, 1]\n                ),\n                \"z_std\": (\n                    np.nanstd(caiman_dataset.motion_correction[\"shifts_rig\"][:, 2])\n                    if is3D\n                    else np.nan\n                ),\n                \"outlier_frames\": None,\n            }\n\n            self.RigidMotionCorrection.insert1(rigid_correction)\n        else:\n            # -- non-rigid motion correction --\n            nonrigid_correction = {\n                **key,\n                \"block_height\": (\n                    caiman_dataset.params.motion[\"strides\"][0]\n                    + caiman_dataset.params.motion[\"overlaps\"][0]\n                ),\n                \"block_width\": (\n                    caiman_dataset.params.motion[\"strides\"][1]\n                    + caiman_dataset.params.motion[\"overlaps\"][1]\n                ),\n                \"block_depth\": (\n                    caiman_dataset.params.motion[\"strides\"][2]\n                    + caiman_dataset.params.motion[\"overlaps\"][2]\n                    if is3D\n                    else 1\n                ),\n                \"block_count_x\": len(\n                    set(caiman_dataset.motion_correction[\"coord_shifts_els\"][:, 0])\n                ),\n                \"block_count_y\": len(\n                    set(caiman_dataset.motion_correction[\"coord_shifts_els\"][:, 2])\n                ),\n                \"block_count_z\": (\n                    len(\n                        set(\n                            caiman_dataset.motion_correction[\"coord_shifts_els\"][\n                                :, 4\n                            ]\n                        )\n                    )\n                    if is3D\n                    else 1\n                ),\n                \"outlier_frames\": None,\n            }\n\n            nonrigid_blocks = []\n            for b_id in range(\n                len(caiman_dataset.motion_correction[\"x_shifts_els\"][0, :])\n            ):\n                nonrigid_blocks.append(\n                    {\n                        **key,\n                        \"block_id\": b_id,\n                        \"block_x\": np.arange(\n                            *caiman_dataset.motion_correction[\"coord_shifts_els\"][\n                                b_id, 0:2\n                            ]\n                        ),\n                        \"block_y\": np.arange(\n                            *caiman_dataset.motion_correction[\"coord_shifts_els\"][\n                                b_id, 2:4\n                            ]\n                        ),\n                        \"block_z\": (\n                            np.arange(\n                                *caiman_dataset.motion_correction[\n                                    \"coord_shifts_els\"\n                                ][b_id, 4:6]\n                            )\n                            if is3D\n                            else np.full_like(\n                                np.arange(\n                                    *caiman_dataset.motion_correction[\n                                        \"coord_shifts_els\"\n                                    ][b_id, 0:2]\n                                ),\n                                0,\n                            )\n                        ),\n                        \"x_shifts\": caiman_dataset.motion_correction[\n                            \"x_shifts_els\"\n                        ][:, b_id],\n                        \"y_shifts\": caiman_dataset.motion_correction[\n                            \"y_shifts_els\"\n                        ][:, b_id],\n                        \"z_shifts\": (\n                            caiman_dataset.motion_correction[\"z_shifts_els\"][\n                                :, b_id\n                            ]\n                            if is3D\n                            else np.full_like(\n                                caiman_dataset.motion_correction[\"x_shifts_els\"][\n                                    :, b_id\n                                ],\n                                0,\n                            )\n                        ),\n                        \"x_std\": np.nanstd(\n                            caiman_dataset.motion_correction[\"x_shifts_els\"][\n                                :, b_id\n                            ]\n                        ),\n                        \"y_std\": np.nanstd(\n                            caiman_dataset.motion_correction[\"y_shifts_els\"][\n                                :, b_id\n                            ]\n                        ),\n                        \"z_std\": (\n                            np.nanstd(\n                                caiman_dataset.motion_correction[\"z_shifts_els\"][\n                                    :, b_id\n                                ]\n                            )\n                            if is3D\n                            else np.nan\n                        ),\n                    }\n                )\n\n            self.NonRigidMotionCorrection.insert1(nonrigid_correction)\n            self.Block.insert(nonrigid_blocks)\n\n        # -- summary images --\n        summary_images = [\n            {\n                **key,\n                **fkey,\n                \"ref_image\": ref_image,\n                \"average_image\": ave_img,\n                \"correlation_image\": corr_img,\n                \"max_proj_image\": max_img,\n            }\n            for fkey, ref_image, ave_img, corr_img, max_img in zip(\n                field_keys,\n                caiman_dataset.motion_correction[\"reference_image\"].transpose(\n                    2, 0, 1\n                )\n                if is3D\n                else caiman_dataset.motion_correction[\"reference_image\"][...][\n                    np.newaxis, ...\n                ],\n                caiman_dataset.motion_correction[\"average_image\"].transpose(2, 0, 1)\n                if is3D\n                else caiman_dataset.motion_correction[\"average_image\"][...][\n                    np.newaxis, ...\n                ],\n                caiman_dataset.motion_correction[\"correlation_image\"].transpose(\n                    2, 0, 1\n                )\n                if is3D\n                else caiman_dataset.motion_correction[\"correlation_image\"][...][\n                    np.newaxis, ...\n                ],\n                caiman_dataset.motion_correction[\"max_image\"].transpose(2, 0, 1)\n                if is3D\n                else caiman_dataset.motion_correction[\"max_image\"][...][\n                    np.newaxis, ...\n                ],\n            )\n        ]\n        self.Summary.insert(summary_images)\n    else:\n        raise NotImplementedError(\"Unknown/unimplemented method: {}\".format(method))\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_preprocess/#element_calcium_imaging.imaging_preprocess.Segmentation", "title": "<code>Segmentation</code>", "text": "<p>         Bases: <code>dj.Computed</code></p> <p>Result of the Segmentation process.</p> <p>Attributes:</p> Name Type Description <code>Curation</code> <code>foreign key</code> <p>Primary key from Curation.</p> Source code in <code>element_calcium_imaging/imaging_preprocess.py</code> <pre><code>@schema\nclass Segmentation(dj.Computed):\n\"\"\"Result of the Segmentation process.\n\n    Attributes:\n        Curation (foreign key): Primary key from Curation.\n    \"\"\"\n\n    definition = \"\"\"# Different mask segmentations.\n    -&gt; Curation\n    \"\"\"\n\n    class Mask(dj.Part):\n\"\"\"Details of the masks identified from the Segmentation procedure.\n\n        Attributes:\n            Segmentation (foreign key): Primary key from Segmentation.\n            mask (int): Unique mask ID.\n            scan.Channel.proj(segmentation_channel='channel') (foreign key): Channel\n                used for segmentation.\n            mask_npix (int): Number of pixels in ROIs.\n            mask_center_x (int): Center x coordinate in pixel.\n            mask_center_y (int): Center y coordinate in pixel.\n            mask_center_z (int): Center z coordinate in pixel.\n            mask_xpix (longblob): X coordinates in pixels.\n            mask_ypix (longblob): Y coordinates in pixels.\n            mask_zpix (longblob): Z coordinates in pixels.\n            mask_weights (longblob): Weights of the mask at the indices above.\n        \"\"\"\n\n        definition = \"\"\" # A mask produced by segmentation.\n        -&gt; master\n        mask               : smallint\n        ---\n        -&gt; scan.Channel.proj(segmentation_channel='channel')  # channel used for segmentation\n        mask_npix          : int       # number of pixels in ROIs\n        mask_center_x      : int       # center x coordinate in pixel\n        mask_center_y      : int       # center y coordinate in pixel\n        mask_center_z=null : int       # center z coordinate in pixel\n        mask_xpix          : longblob  # x coordinates in pixels\n        mask_ypix          : longblob  # y coordinates in pixels\n        mask_zpix=null     : longblob  # z coordinates in pixels\n        mask_weights       : longblob  # weights of the mask at the indices above\n        \"\"\"\n\n    def make(self, key):\n\"\"\"Populate the Segmentation with the results parsed from analysis outputs.\"\"\"\n\n        method, imaging_dataset = get_loader_result(key, Curation)\n\n        if method == \"suite2p\":\n            suite2p_dataset = imaging_dataset\n\n            # ---- iterate through all s2p plane outputs ----\n            masks, cells = [], []\n            for plane, s2p in suite2p_dataset.planes.items():\n                mask_count = len(masks)  # increment mask id from all \"plane\"\n                for mask_idx, (is_cell, cell_prob, mask_stat) in enumerate(\n                    zip(s2p.iscell, s2p.cell_prob, s2p.stat)\n                ):\n                    masks.append(\n                        {\n                            **key,\n                            \"mask\": mask_idx + mask_count,\n                            \"segmentation_channel\": s2p.segmentation_channel,\n                            \"mask_npix\": mask_stat[\"npix\"],\n                            \"mask_center_x\": mask_stat[\"med\"][1],\n                            \"mask_center_y\": mask_stat[\"med\"][0],\n                            \"mask_center_z\": mask_stat.get(\"iplane\", plane),\n                            \"mask_xpix\": mask_stat[\"xpix\"],\n                            \"mask_ypix\": mask_stat[\"ypix\"],\n                            \"mask_zpix\": np.full(\n                                mask_stat[\"npix\"],\n                                mask_stat.get(\"iplane\", plane),\n                            ),\n                            \"mask_weights\": mask_stat[\"lam\"],\n                        }\n                    )\n                    if is_cell:\n                        cells.append(\n                            {\n                                **key,\n                                \"mask_classification_method\": \"suite2p_default_classifier\",\n                                \"mask\": mask_idx + mask_count,\n                                \"mask_type\": \"soma\",\n                                \"confidence\": cell_prob,\n                            }\n                        )\n\n            self.insert1(key)\n            self.Mask.insert(masks, ignore_extra_fields=True)\n\n            if cells:\n                MaskClassification.insert1(\n                    {\n                        **key,\n                        \"mask_classification_method\": \"suite2p_default_classifier\",\n                    },\n                    allow_direct_insert=True,\n                )\n                MaskClassification.MaskType.insert(\n                    cells, ignore_extra_fields=True, allow_direct_insert=True\n                )\n        elif method == \"caiman\":\n            caiman_dataset = imaging_dataset\n\n            # infer \"segmentation_channel\" - from params if available, else from caiman loader\n            params = (ProcessingParamSet * ProcessingTask &amp; key).fetch1(\"params\")\n            segmentation_channel = params.get(\n                \"segmentation_channel\", caiman_dataset.segmentation_channel\n            )\n\n            masks, cells = [], []\n            for mask in caiman_dataset.masks:\n                masks.append(\n                    {\n                        **key,\n                        \"segmentation_channel\": segmentation_channel,\n                        \"mask\": mask[\"mask_id\"],\n                        \"mask_npix\": mask[\"mask_npix\"],\n                        \"mask_center_x\": mask[\"mask_center_x\"],\n                        \"mask_center_y\": mask[\"mask_center_y\"],\n                        \"mask_center_z\": mask[\"mask_center_z\"],\n                        \"mask_xpix\": mask[\"mask_xpix\"],\n                        \"mask_ypix\": mask[\"mask_ypix\"],\n                        \"mask_zpix\": mask[\"mask_zpix\"],\n                        \"mask_weights\": mask[\"mask_weights\"],\n                    }\n                )\n                if caiman_dataset.cnmf.estimates.idx_components is not None:\n                    if mask[\"mask_id\"] in caiman_dataset.cnmf.estimates.idx_components:\n                        cells.append(\n                            {\n                                **key,\n                                \"mask_classification_method\": \"caiman_default_classifier\",\n                                \"mask\": mask[\"mask_id\"],\n                                \"mask_type\": \"soma\",\n                            }\n                        )\n\n            self.insert1(key)\n            self.Mask.insert(masks, ignore_extra_fields=True)\n\n            if cells:\n                MaskClassification.insert1(\n                    {\n                        **key,\n                        \"mask_classification_method\": \"caiman_default_classifier\",\n                    },\n                    allow_direct_insert=True,\n                )\n                MaskClassification.MaskType.insert(\n                    cells, ignore_extra_fields=True, allow_direct_insert=True\n                )\n        elif method == \"extract\":\n            extract_dataset = imaging_dataset\n            masks = [\n                dict(\n                    **key,\n                    segmentation_channel=0,\n                    mask=mask[\"mask_id\"],\n                    mask_npix=mask[\"mask_npix\"],\n                    mask_center_x=mask[\"mask_center_x\"],\n                    mask_center_y=mask[\"mask_center_y\"],\n                    mask_center_z=mask[\"mask_center_z\"],\n                    mask_xpix=mask[\"mask_xpix\"],\n                    mask_ypix=mask[\"mask_ypix\"],\n                    mask_zpix=mask[\"mask_zpix\"],\n                    mask_weights=mask[\"mask_weights\"],\n                )\n                for mask in extract_dataset.load_results()\n            ]\n\n            self.insert1(key)\n            self.Mask.insert(masks, ignore_extra_fields=True)\n        else:\n            raise NotImplementedError(f\"Unknown/unimplemented method: {method}\")\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_preprocess/#element_calcium_imaging.imaging_preprocess.Segmentation.Mask", "title": "<code>Mask</code>", "text": "<p>         Bases: <code>dj.Part</code></p> <p>Details of the masks identified from the Segmentation procedure.</p> <p>Attributes:</p> Name Type Description <code>Segmentation</code> <code>foreign key</code> <p>Primary key from Segmentation.</p> <code>mask</code> <code>int</code> <p>Unique mask ID.</p> <code>scan.Channel.proj(segmentation_channel='channel')</code> <code>foreign key</code> <p>Channel used for segmentation.</p> <code>mask_npix</code> <code>int</code> <p>Number of pixels in ROIs.</p> <code>mask_center_x</code> <code>int</code> <p>Center x coordinate in pixel.</p> <code>mask_center_y</code> <code>int</code> <p>Center y coordinate in pixel.</p> <code>mask_center_z</code> <code>int</code> <p>Center z coordinate in pixel.</p> <code>mask_xpix</code> <code>longblob</code> <p>X coordinates in pixels.</p> <code>mask_ypix</code> <code>longblob</code> <p>Y coordinates in pixels.</p> <code>mask_zpix</code> <code>longblob</code> <p>Z coordinates in pixels.</p> <code>mask_weights</code> <code>longblob</code> <p>Weights of the mask at the indices above.</p> Source code in <code>element_calcium_imaging/imaging_preprocess.py</code> <pre><code>class Mask(dj.Part):\n\"\"\"Details of the masks identified from the Segmentation procedure.\n\n    Attributes:\n        Segmentation (foreign key): Primary key from Segmentation.\n        mask (int): Unique mask ID.\n        scan.Channel.proj(segmentation_channel='channel') (foreign key): Channel\n            used for segmentation.\n        mask_npix (int): Number of pixels in ROIs.\n        mask_center_x (int): Center x coordinate in pixel.\n        mask_center_y (int): Center y coordinate in pixel.\n        mask_center_z (int): Center z coordinate in pixel.\n        mask_xpix (longblob): X coordinates in pixels.\n        mask_ypix (longblob): Y coordinates in pixels.\n        mask_zpix (longblob): Z coordinates in pixels.\n        mask_weights (longblob): Weights of the mask at the indices above.\n    \"\"\"\n\n    definition = \"\"\" # A mask produced by segmentation.\n    -&gt; master\n    mask               : smallint\n    ---\n    -&gt; scan.Channel.proj(segmentation_channel='channel')  # channel used for segmentation\n    mask_npix          : int       # number of pixels in ROIs\n    mask_center_x      : int       # center x coordinate in pixel\n    mask_center_y      : int       # center y coordinate in pixel\n    mask_center_z=null : int       # center z coordinate in pixel\n    mask_xpix          : longblob  # x coordinates in pixels\n    mask_ypix          : longblob  # y coordinates in pixels\n    mask_zpix=null     : longblob  # z coordinates in pixels\n    mask_weights       : longblob  # weights of the mask at the indices above\n    \"\"\"\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_preprocess/#element_calcium_imaging.imaging_preprocess.Segmentation.make", "title": "<code>make(key)</code>", "text": "<p>Populate the Segmentation with the results parsed from analysis outputs.</p> Source code in <code>element_calcium_imaging/imaging_preprocess.py</code> <pre><code>def make(self, key):\n\"\"\"Populate the Segmentation with the results parsed from analysis outputs.\"\"\"\n\n    method, imaging_dataset = get_loader_result(key, Curation)\n\n    if method == \"suite2p\":\n        suite2p_dataset = imaging_dataset\n\n        # ---- iterate through all s2p plane outputs ----\n        masks, cells = [], []\n        for plane, s2p in suite2p_dataset.planes.items():\n            mask_count = len(masks)  # increment mask id from all \"plane\"\n            for mask_idx, (is_cell, cell_prob, mask_stat) in enumerate(\n                zip(s2p.iscell, s2p.cell_prob, s2p.stat)\n            ):\n                masks.append(\n                    {\n                        **key,\n                        \"mask\": mask_idx + mask_count,\n                        \"segmentation_channel\": s2p.segmentation_channel,\n                        \"mask_npix\": mask_stat[\"npix\"],\n                        \"mask_center_x\": mask_stat[\"med\"][1],\n                        \"mask_center_y\": mask_stat[\"med\"][0],\n                        \"mask_center_z\": mask_stat.get(\"iplane\", plane),\n                        \"mask_xpix\": mask_stat[\"xpix\"],\n                        \"mask_ypix\": mask_stat[\"ypix\"],\n                        \"mask_zpix\": np.full(\n                            mask_stat[\"npix\"],\n                            mask_stat.get(\"iplane\", plane),\n                        ),\n                        \"mask_weights\": mask_stat[\"lam\"],\n                    }\n                )\n                if is_cell:\n                    cells.append(\n                        {\n                            **key,\n                            \"mask_classification_method\": \"suite2p_default_classifier\",\n                            \"mask\": mask_idx + mask_count,\n                            \"mask_type\": \"soma\",\n                            \"confidence\": cell_prob,\n                        }\n                    )\n\n        self.insert1(key)\n        self.Mask.insert(masks, ignore_extra_fields=True)\n\n        if cells:\n            MaskClassification.insert1(\n                {\n                    **key,\n                    \"mask_classification_method\": \"suite2p_default_classifier\",\n                },\n                allow_direct_insert=True,\n            )\n            MaskClassification.MaskType.insert(\n                cells, ignore_extra_fields=True, allow_direct_insert=True\n            )\n    elif method == \"caiman\":\n        caiman_dataset = imaging_dataset\n\n        # infer \"segmentation_channel\" - from params if available, else from caiman loader\n        params = (ProcessingParamSet * ProcessingTask &amp; key).fetch1(\"params\")\n        segmentation_channel = params.get(\n            \"segmentation_channel\", caiman_dataset.segmentation_channel\n        )\n\n        masks, cells = [], []\n        for mask in caiman_dataset.masks:\n            masks.append(\n                {\n                    **key,\n                    \"segmentation_channel\": segmentation_channel,\n                    \"mask\": mask[\"mask_id\"],\n                    \"mask_npix\": mask[\"mask_npix\"],\n                    \"mask_center_x\": mask[\"mask_center_x\"],\n                    \"mask_center_y\": mask[\"mask_center_y\"],\n                    \"mask_center_z\": mask[\"mask_center_z\"],\n                    \"mask_xpix\": mask[\"mask_xpix\"],\n                    \"mask_ypix\": mask[\"mask_ypix\"],\n                    \"mask_zpix\": mask[\"mask_zpix\"],\n                    \"mask_weights\": mask[\"mask_weights\"],\n                }\n            )\n            if caiman_dataset.cnmf.estimates.idx_components is not None:\n                if mask[\"mask_id\"] in caiman_dataset.cnmf.estimates.idx_components:\n                    cells.append(\n                        {\n                            **key,\n                            \"mask_classification_method\": \"caiman_default_classifier\",\n                            \"mask\": mask[\"mask_id\"],\n                            \"mask_type\": \"soma\",\n                        }\n                    )\n\n        self.insert1(key)\n        self.Mask.insert(masks, ignore_extra_fields=True)\n\n        if cells:\n            MaskClassification.insert1(\n                {\n                    **key,\n                    \"mask_classification_method\": \"caiman_default_classifier\",\n                },\n                allow_direct_insert=True,\n            )\n            MaskClassification.MaskType.insert(\n                cells, ignore_extra_fields=True, allow_direct_insert=True\n            )\n    elif method == \"extract\":\n        extract_dataset = imaging_dataset\n        masks = [\n            dict(\n                **key,\n                segmentation_channel=0,\n                mask=mask[\"mask_id\"],\n                mask_npix=mask[\"mask_npix\"],\n                mask_center_x=mask[\"mask_center_x\"],\n                mask_center_y=mask[\"mask_center_y\"],\n                mask_center_z=mask[\"mask_center_z\"],\n                mask_xpix=mask[\"mask_xpix\"],\n                mask_ypix=mask[\"mask_ypix\"],\n                mask_zpix=mask[\"mask_zpix\"],\n                mask_weights=mask[\"mask_weights\"],\n            )\n            for mask in extract_dataset.load_results()\n        ]\n\n        self.insert1(key)\n        self.Mask.insert(masks, ignore_extra_fields=True)\n    else:\n        raise NotImplementedError(f\"Unknown/unimplemented method: {method}\")\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_preprocess/#element_calcium_imaging.imaging_preprocess.MaskClassificationMethod", "title": "<code>MaskClassificationMethod</code>", "text": "<p>         Bases: <code>dj.Lookup</code></p> <p>Available mask classification methods.</p> <p>Attributes:</p> Name Type Description <code>mask_classification_method</code> <code>str</code> <p>Mask classification method.</p> Source code in <code>element_calcium_imaging/imaging_preprocess.py</code> <pre><code>@schema\nclass MaskClassificationMethod(dj.Lookup):\n\"\"\"Available mask classification methods.\n\n    Attributes:\n        mask_classification_method (str): Mask classification method.\n    \"\"\"\n\n    definition = \"\"\"\n    mask_classification_method: varchar(48)\n    \"\"\"\n\n    contents = zip([\"suite2p_default_classifier\", \"caiman_default_classifier\"])\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_preprocess/#element_calcium_imaging.imaging_preprocess.MaskClassification", "title": "<code>MaskClassification</code>", "text": "<p>         Bases: <code>dj.Computed</code></p> <p>Classes assigned to each mask.</p> <p>Attributes:</p> Name Type Description <code>Segmentation</code> <code>foreign key</code> <p>Primary key from Segmentation.</p> <code>MaskClassificationMethod</code> <code>foreign key</code> <p>Primary key from MaskClassificationMethod.</p> Source code in <code>element_calcium_imaging/imaging_preprocess.py</code> <pre><code>@schema\nclass MaskClassification(dj.Computed):\n\"\"\"Classes assigned to each mask.\n\n    Attributes:\n        Segmentation (foreign key): Primary key from Segmentation.\n        MaskClassificationMethod (foreign key): Primary key from\n            MaskClassificationMethod.\n    \"\"\"\n\n    definition = \"\"\"\n    -&gt; Segmentation\n    -&gt; MaskClassificationMethod\n    \"\"\"\n\n    class MaskType(dj.Part):\n\"\"\"Type assigned to each mask.\n\n        Attributes:\n            MaskClassification (foreign key): Primary key from MaskClassification.\n            Segmentation.Mask (foreign key): Primary key from Segmentation.Mask.\n            MaskType: Primary key from MaskType.\n            confidence (float, optional): Confidence level of the mask classification.\n        \"\"\"\n\n        definition = \"\"\"\n        -&gt; master\n        -&gt; Segmentation.Mask\n        ---\n        -&gt; MaskType\n        confidence=null: float\n        \"\"\"\n\n    def make(self, key):\n        pass\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_preprocess/#element_calcium_imaging.imaging_preprocess.MaskClassification.MaskType", "title": "<code>MaskType</code>", "text": "<p>         Bases: <code>dj.Part</code></p> <p>Type assigned to each mask.</p> <p>Attributes:</p> Name Type Description <code>MaskClassification</code> <code>foreign key</code> <p>Primary key from MaskClassification.</p> <code>Segmentation.Mask</code> <code>foreign key</code> <p>Primary key from Segmentation.Mask.</p> <code>MaskType</code> <code>foreign key</code> <p>Primary key from MaskType.</p> <code>confidence</code> <code>float</code> <p>Confidence level of the mask classification.</p> Source code in <code>element_calcium_imaging/imaging_preprocess.py</code> <pre><code>class MaskType(dj.Part):\n\"\"\"Type assigned to each mask.\n\n    Attributes:\n        MaskClassification (foreign key): Primary key from MaskClassification.\n        Segmentation.Mask (foreign key): Primary key from Segmentation.Mask.\n        MaskType: Primary key from MaskType.\n        confidence (float, optional): Confidence level of the mask classification.\n    \"\"\"\n\n    definition = \"\"\"\n    -&gt; master\n    -&gt; Segmentation.Mask\n    ---\n    -&gt; MaskType\n    confidence=null: float\n    \"\"\"\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_preprocess/#element_calcium_imaging.imaging_preprocess.Fluorescence", "title": "<code>Fluorescence</code>", "text": "<p>         Bases: <code>dj.Computed</code></p> <p>Fluorescence traces.</p> <p>Attributes:</p> Name Type Description <code>Segmentation</code> <code>foreign key</code> <p>Primary key from Segmentation.</p> Source code in <code>element_calcium_imaging/imaging_preprocess.py</code> <pre><code>@schema\nclass Fluorescence(dj.Computed):\n\"\"\"Fluorescence traces.\n\n    Attributes:\n        Segmentation (foreign key): Primary key from Segmentation.\n    \"\"\"\n\n    definition = \"\"\"# Fluorescence traces before spike extraction or filtering\n    -&gt; Segmentation\n    \"\"\"\n\n    class Trace(dj.Part):\n\"\"\"Traces obtained from segmented region of interests.\n\n        Attributes:\n            Fluorescence (foreign key): Primary key from Fluorescence.\n            Segmentation.Mask (foreign key): Primary key from Segmentation.Mask.\n            scan.Channel.proj(fluo_channel='channel') (int): The channel that this trace\n                comes from.\n            fluorescence (longblob): Fluorescence trace associated with this mask.\n            neuropil_fluorescence (longblob, optional): Neuropil fluorescence trace.\n        \"\"\"\n\n        definition = \"\"\"\n        -&gt; master\n        -&gt; Segmentation.Mask\n        -&gt; scan.Channel.proj(fluo_channel='channel')  # The channel that this trace comes from\n        ---\n        fluorescence                : longblob  # Fluorescence trace associated with this mask\n        neuropil_fluorescence=null  : longblob  # Neuropil fluorescence trace\n        \"\"\"\n\n    def make(self, key):\n\"\"\"Populate the Fluorescence with the results parsed from analysis outputs.\"\"\"\n\n        method, imaging_dataset = get_loader_result(key, Curation)\n\n        if method == \"suite2p\":\n            suite2p_dataset = imaging_dataset\n\n            # ---- iterate through all s2p plane outputs ----\n            fluo_traces, fluo_chn2_traces = [], []\n            for s2p in suite2p_dataset.planes.values():\n                mask_count = len(fluo_traces)  # increment mask id from all \"plane\"\n                for mask_idx, (f, fneu) in enumerate(zip(s2p.F, s2p.Fneu)):\n                    fluo_traces.append(\n                        {\n                            **key,\n                            \"mask\": mask_idx + mask_count,\n                            \"fluo_channel\": 0,\n                            \"fluorescence\": f,\n                            \"neuropil_fluorescence\": fneu,\n                        }\n                    )\n                if len(s2p.F_chan2):\n                    mask_chn2_count = len(\n                        fluo_chn2_traces\n                    )  # increment mask id from all planes\n                    for mask_idx, (f2, fneu2) in enumerate(\n                        zip(s2p.F_chan2, s2p.Fneu_chan2)\n                    ):\n                        fluo_chn2_traces.append(\n                            {\n                                **key,\n                                \"mask\": mask_idx + mask_chn2_count,\n                                \"fluo_channel\": 1,\n                                \"fluorescence\": f2,\n                                \"neuropil_fluorescence\": fneu2,\n                            }\n                        )\n\n            self.insert1(key)\n            self.Trace.insert(fluo_traces + fluo_chn2_traces)\n        elif method == \"caiman\":\n            caiman_dataset = imaging_dataset\n\n            # infer \"segmentation_channel\" - from params if available, else from caiman loader\n            params = (ProcessingParamSet * ProcessingTask &amp; key).fetch1(\"params\")\n            segmentation_channel = params.get(\n                \"segmentation_channel\", caiman_dataset.segmentation_channel\n            )\n\n            fluo_traces = []\n            for mask in caiman_dataset.masks:\n                fluo_traces.append(\n                    {\n                        **key,\n                        \"mask\": mask[\"mask_id\"],\n                        \"fluo_channel\": segmentation_channel,\n                        \"fluorescence\": mask[\"inferred_trace\"],\n                    }\n                )\n\n            self.insert1(key)\n            self.Trace.insert(fluo_traces)\n        elif method == \"extract\":\n            extract_dataset = imaging_dataset\n\n            fluo_traces = [\n                {\n                    **key,\n                    \"mask\": mask_id,\n                    \"fluo_channel\": 0,\n                    \"fluorescence\": fluorescence,\n                }\n                for mask_id, fluorescence in enumerate(extract_dataset.T)\n            ]\n\n            self.insert1(key)\n            self.Trace.insert(fluo_traces)\n\n        else:\n            raise NotImplementedError(\"Unknown/unimplemented method: {}\".format(method))\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_preprocess/#element_calcium_imaging.imaging_preprocess.Fluorescence.Trace", "title": "<code>Trace</code>", "text": "<p>         Bases: <code>dj.Part</code></p> <p>Traces obtained from segmented region of interests.</p> <p>Attributes:</p> Name Type Description <code>Fluorescence</code> <code>foreign key</code> <p>Primary key from Fluorescence.</p> <code>Segmentation.Mask</code> <code>foreign key</code> <p>Primary key from Segmentation.Mask.</p> <code>scan.Channel.proj(fluo_channel='channel')</code> <code>int</code> <p>The channel that this trace comes from.</p> <code>fluorescence</code> <code>longblob</code> <p>Fluorescence trace associated with this mask.</p> <code>neuropil_fluorescence</code> <code>longblob</code> <p>Neuropil fluorescence trace.</p> Source code in <code>element_calcium_imaging/imaging_preprocess.py</code> <pre><code>class Trace(dj.Part):\n\"\"\"Traces obtained from segmented region of interests.\n\n    Attributes:\n        Fluorescence (foreign key): Primary key from Fluorescence.\n        Segmentation.Mask (foreign key): Primary key from Segmentation.Mask.\n        scan.Channel.proj(fluo_channel='channel') (int): The channel that this trace\n            comes from.\n        fluorescence (longblob): Fluorescence trace associated with this mask.\n        neuropil_fluorescence (longblob, optional): Neuropil fluorescence trace.\n    \"\"\"\n\n    definition = \"\"\"\n    -&gt; master\n    -&gt; Segmentation.Mask\n    -&gt; scan.Channel.proj(fluo_channel='channel')  # The channel that this trace comes from\n    ---\n    fluorescence                : longblob  # Fluorescence trace associated with this mask\n    neuropil_fluorescence=null  : longblob  # Neuropil fluorescence trace\n    \"\"\"\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_preprocess/#element_calcium_imaging.imaging_preprocess.Fluorescence.make", "title": "<code>make(key)</code>", "text": "<p>Populate the Fluorescence with the results parsed from analysis outputs.</p> Source code in <code>element_calcium_imaging/imaging_preprocess.py</code> <pre><code>def make(self, key):\n\"\"\"Populate the Fluorescence with the results parsed from analysis outputs.\"\"\"\n\n    method, imaging_dataset = get_loader_result(key, Curation)\n\n    if method == \"suite2p\":\n        suite2p_dataset = imaging_dataset\n\n        # ---- iterate through all s2p plane outputs ----\n        fluo_traces, fluo_chn2_traces = [], []\n        for s2p in suite2p_dataset.planes.values():\n            mask_count = len(fluo_traces)  # increment mask id from all \"plane\"\n            for mask_idx, (f, fneu) in enumerate(zip(s2p.F, s2p.Fneu)):\n                fluo_traces.append(\n                    {\n                        **key,\n                        \"mask\": mask_idx + mask_count,\n                        \"fluo_channel\": 0,\n                        \"fluorescence\": f,\n                        \"neuropil_fluorescence\": fneu,\n                    }\n                )\n            if len(s2p.F_chan2):\n                mask_chn2_count = len(\n                    fluo_chn2_traces\n                )  # increment mask id from all planes\n                for mask_idx, (f2, fneu2) in enumerate(\n                    zip(s2p.F_chan2, s2p.Fneu_chan2)\n                ):\n                    fluo_chn2_traces.append(\n                        {\n                            **key,\n                            \"mask\": mask_idx + mask_chn2_count,\n                            \"fluo_channel\": 1,\n                            \"fluorescence\": f2,\n                            \"neuropil_fluorescence\": fneu2,\n                        }\n                    )\n\n        self.insert1(key)\n        self.Trace.insert(fluo_traces + fluo_chn2_traces)\n    elif method == \"caiman\":\n        caiman_dataset = imaging_dataset\n\n        # infer \"segmentation_channel\" - from params if available, else from caiman loader\n        params = (ProcessingParamSet * ProcessingTask &amp; key).fetch1(\"params\")\n        segmentation_channel = params.get(\n            \"segmentation_channel\", caiman_dataset.segmentation_channel\n        )\n\n        fluo_traces = []\n        for mask in caiman_dataset.masks:\n            fluo_traces.append(\n                {\n                    **key,\n                    \"mask\": mask[\"mask_id\"],\n                    \"fluo_channel\": segmentation_channel,\n                    \"fluorescence\": mask[\"inferred_trace\"],\n                }\n            )\n\n        self.insert1(key)\n        self.Trace.insert(fluo_traces)\n    elif method == \"extract\":\n        extract_dataset = imaging_dataset\n\n        fluo_traces = [\n            {\n                **key,\n                \"mask\": mask_id,\n                \"fluo_channel\": 0,\n                \"fluorescence\": fluorescence,\n            }\n            for mask_id, fluorescence in enumerate(extract_dataset.T)\n        ]\n\n        self.insert1(key)\n        self.Trace.insert(fluo_traces)\n\n    else:\n        raise NotImplementedError(\"Unknown/unimplemented method: {}\".format(method))\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_preprocess/#element_calcium_imaging.imaging_preprocess.ActivityExtractionMethod", "title": "<code>ActivityExtractionMethod</code>", "text": "<p>         Bases: <code>dj.Lookup</code></p> <p>Available activity extraction methods.</p> <p>Attributes:</p> Name Type Description <code>extraction_method</code> <code>str</code> <p>Extraction method.</p> Source code in <code>element_calcium_imaging/imaging_preprocess.py</code> <pre><code>@schema\nclass ActivityExtractionMethod(dj.Lookup):\n\"\"\"Available activity extraction methods.\n\n    Attributes:\n        extraction_method (str): Extraction method.\n    \"\"\"\n\n    definition = \"\"\"# Activity extraction method\n    extraction_method: varchar(32)\n    \"\"\"\n\n    contents = zip([\"suite2p_deconvolution\", \"caiman_deconvolution\", \"caiman_dff\"])\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_preprocess/#element_calcium_imaging.imaging_preprocess.Activity", "title": "<code>Activity</code>", "text": "<p>         Bases: <code>dj.Computed</code></p> <p>Inferred neural activity from fluorescence trace (e.g. dff, spikes, etc.).</p> <p>Attributes:</p> Name Type Description <code>Fluorescence</code> <code>foreign key</code> <p>Primary key from Fluorescence.</p> <code>ActivityExtractionMethod</code> <code>foreign key</code> <p>Primary key from ActivityExtractionMethod.</p> Source code in <code>element_calcium_imaging/imaging_preprocess.py</code> <pre><code>@schema\nclass Activity(dj.Computed):\n\"\"\"Inferred neural activity from fluorescence trace (e.g. dff, spikes, etc.).\n\n    Attributes:\n        Fluorescence (foreign key): Primary key from Fluorescence.\n        ActivityExtractionMethod (foreign key): Primary key from\n            ActivityExtractionMethod.\n    \"\"\"\n\n    definition = \"\"\"# Neural Activity\n    -&gt; Fluorescence\n    -&gt; ActivityExtractionMethod\n    \"\"\"\n\n    class Trace(dj.Part):\n\"\"\"Trace(s) for each mask.\n\n        Attributes:\n            Activity (foreign key): Primary key from Activity.\n            Fluorescence.Trace (foreign key): Fluorescence.Trace.\n            activity_trace (longblob): Neural activity from fluorescence trace.\n        \"\"\"\n\n        definition = \"\"\"\n        -&gt; master\n        -&gt; Fluorescence.Trace\n        ---\n        activity_trace: longblob\n        \"\"\"\n\n    @property\n    def key_source(self):\n        suite2p_key_source = (\n            Fluorescence\n            * ActivityExtractionMethod\n            * ProcessingParamSet.proj(\"processing_method\")\n            &amp; 'processing_method = \"suite2p\"'\n            &amp; 'extraction_method LIKE \"suite2p%\"'\n        )\n        caiman_key_source = (\n            Fluorescence\n            * ActivityExtractionMethod\n            * ProcessingParamSet.proj(\"processing_method\")\n            &amp; 'processing_method = \"caiman\"'\n            &amp; 'extraction_method LIKE \"caiman%\"'\n        )\n        return suite2p_key_source.proj() + caiman_key_source.proj()\n\n    def make(self, key):\n\"\"\"Populate the Activity with the results parsed from analysis outputs.\"\"\"\n\n        method, imaging_dataset = get_loader_result(key, Curation)\n\n        if method == \"suite2p\":\n            if key[\"extraction_method\"] == \"suite2p_deconvolution\":\n                suite2p_dataset = imaging_dataset\n                # ---- iterate through all s2p plane outputs ----\n                spikes = [\n                    dict(\n                        key,\n                        mask=mask_idx,\n                        fluo_channel=0,\n                        activity_trace=spks,\n                    )\n                    for mask_idx, spks in enumerate(\n                        s\n                        for plane in suite2p_dataset.planes.values()\n                        for s in plane.spks\n                    )\n                ]\n\n                self.insert1(key)\n                self.Trace.insert(spikes)\n        elif method == \"caiman\":\n            caiman_dataset = imaging_dataset\n\n            if key[\"extraction_method\"] in (\n                \"caiman_deconvolution\",\n                \"caiman_dff\",\n            ):\n                attr_mapper = {\n                    \"caiman_deconvolution\": \"spikes\",\n                    \"caiman_dff\": \"dff\",\n                }\n\n                # infer \"segmentation_channel\" - from params if available, else from caiman loader\n                params = (ProcessingParamSet * ProcessingTask &amp; key).fetch1(\"params\")\n                segmentation_channel = params.get(\n                    \"segmentation_channel\", caiman_dataset.segmentation_channel\n                )\n\n                self.insert1(key)\n                self.Trace.insert(\n                    dict(\n                        key,\n                        mask=mask[\"mask_id\"],\n                        fluo_channel=segmentation_channel,\n                        activity_trace=mask[attr_mapper[key[\"extraction_method\"]]],\n                    )\n                    for mask in caiman_dataset.masks\n                )\n        else:\n            raise NotImplementedError(\"Unknown/unimplemented method: {}\".format(method))\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_preprocess/#element_calcium_imaging.imaging_preprocess.Activity.Trace", "title": "<code>Trace</code>", "text": "<p>         Bases: <code>dj.Part</code></p> <p>Trace(s) for each mask.</p> <p>Attributes:</p> Name Type Description <code>Activity</code> <code>foreign key</code> <p>Primary key from Activity.</p> <code>Fluorescence.Trace</code> <code>foreign key</code> <p>Fluorescence.Trace.</p> <code>activity_trace</code> <code>longblob</code> <p>Neural activity from fluorescence trace.</p> Source code in <code>element_calcium_imaging/imaging_preprocess.py</code> <pre><code>class Trace(dj.Part):\n\"\"\"Trace(s) for each mask.\n\n    Attributes:\n        Activity (foreign key): Primary key from Activity.\n        Fluorescence.Trace (foreign key): Fluorescence.Trace.\n        activity_trace (longblob): Neural activity from fluorescence trace.\n    \"\"\"\n\n    definition = \"\"\"\n    -&gt; master\n    -&gt; Fluorescence.Trace\n    ---\n    activity_trace: longblob\n    \"\"\"\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_preprocess/#element_calcium_imaging.imaging_preprocess.Activity.make", "title": "<code>make(key)</code>", "text": "<p>Populate the Activity with the results parsed from analysis outputs.</p> Source code in <code>element_calcium_imaging/imaging_preprocess.py</code> <pre><code>def make(self, key):\n\"\"\"Populate the Activity with the results parsed from analysis outputs.\"\"\"\n\n    method, imaging_dataset = get_loader_result(key, Curation)\n\n    if method == \"suite2p\":\n        if key[\"extraction_method\"] == \"suite2p_deconvolution\":\n            suite2p_dataset = imaging_dataset\n            # ---- iterate through all s2p plane outputs ----\n            spikes = [\n                dict(\n                    key,\n                    mask=mask_idx,\n                    fluo_channel=0,\n                    activity_trace=spks,\n                )\n                for mask_idx, spks in enumerate(\n                    s\n                    for plane in suite2p_dataset.planes.values()\n                    for s in plane.spks\n                )\n            ]\n\n            self.insert1(key)\n            self.Trace.insert(spikes)\n    elif method == \"caiman\":\n        caiman_dataset = imaging_dataset\n\n        if key[\"extraction_method\"] in (\n            \"caiman_deconvolution\",\n            \"caiman_dff\",\n        ):\n            attr_mapper = {\n                \"caiman_deconvolution\": \"spikes\",\n                \"caiman_dff\": \"dff\",\n            }\n\n            # infer \"segmentation_channel\" - from params if available, else from caiman loader\n            params = (ProcessingParamSet * ProcessingTask &amp; key).fetch1(\"params\")\n            segmentation_channel = params.get(\n                \"segmentation_channel\", caiman_dataset.segmentation_channel\n            )\n\n            self.insert1(key)\n            self.Trace.insert(\n                dict(\n                    key,\n                    mask=mask[\"mask_id\"],\n                    fluo_channel=segmentation_channel,\n                    activity_trace=mask[attr_mapper[key[\"extraction_method\"]]],\n                )\n                for mask in caiman_dataset.masks\n            )\n    else:\n        raise NotImplementedError(\"Unknown/unimplemented method: {}\".format(method))\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_preprocess/#element_calcium_imaging.imaging_preprocess.ProcessingQualityMetrics", "title": "<code>ProcessingQualityMetrics</code>", "text": "<p>         Bases: <code>dj.Computed</code></p> <p>Quality metrics used to evaluate the results of the calcium imaging analysis pipeline.</p> <p>Attributes:</p> Name Type Description <code>Fluorescence</code> <code>foreign key</code> <p>Primary key from Fluorescence.</p> Source code in <code>element_calcium_imaging/imaging_preprocess.py</code> <pre><code>@schema\nclass ProcessingQualityMetrics(dj.Computed):\n\"\"\"Quality metrics used to evaluate the results of the calcium imaging analysis pipeline.\n\n    Attributes:\n        Fluorescence (foreign key): Primary key from Fluorescence.\n    \"\"\"\n\n    definition = \"\"\"\n    -&gt; Fluorescence\n    \"\"\"\n\n    class Mask(dj.Part):\n\"\"\"Quality metrics used to evaluate the masks.\n\n        Attributes:\n            Fluorescence (foreign key): Primary key from Fluorescence.\n            Segmentation.Mask (foreign key): Primary key from Segmentation.Mask.\n            mask_area (float): Mask area in square micrometer.\n            roundness (float): Roundness between 0 and 1. Values closer to 1 are rounder.\n        \"\"\"\n\n        definition = \"\"\"\n        -&gt; master\n        -&gt; Segmentation.Mask\n        ---\n        mask_area=null: float  # Mask area in square micrometer.\n        roundness: float       # Roundness between 0 and 1. Values closer to 1 are rounder.\n        \"\"\"\n\n    class Trace(dj.Part):\n\"\"\"Quality metrics used to evaluate the fluorescence traces.\n\n        Attributes:\n            Fluorescence (foreign key): Primary key from Fluorescence.\n            Fluorescence.Trace (foreign key): Primary key from Fluorescence.Trace.\n            skewness (float): Skewness of the fluorescence trace.\n            variance (float): Variance of the fluorescence trace.\n        \"\"\"\n\n        definition = \"\"\"\n        -&gt; master\n        -&gt; Fluorescence.Trace\n        ---\n        skewness: float   # Skewness of the fluorescence trace.\n        variance: float   # Variance of the fluorescence trace.\n        \"\"\"\n\n    def make(self, key):\n\"\"\"Populate the ProcessingQualityMetrics table and its part tables.\"\"\"\n        from scipy.stats import skew\n\n        (\n            mask_xpixs,\n            mask_ypixs,\n            mask_weights,\n            fluorescence,\n            fluo_channels,\n            mask_ids,\n            mask_npix,\n            px_height,\n            px_width,\n            um_height,\n            um_width,\n        ) = (Segmentation.Mask * scan.ScanInfo.Field * Fluorescence.Trace &amp; key).fetch(\n            \"mask_xpix\",\n            \"mask_ypix\",\n            \"mask_weights\",\n            \"fluorescence\",\n            \"fluo_channel\",\n            \"mask\",\n            \"mask_npix\",\n            \"px_height\",\n            \"px_width\",\n            \"um_height\",\n            \"um_width\",\n        )\n\n        norm_mean = lambda x: x.mean() / x.max()\n        roundnesses = [\n            norm_mean(np.linalg.eigvals(np.cov(x, y, aweights=w)))\n            for x, y, w in zip(mask_xpixs, mask_ypixs, mask_weights)\n        ]\n\n        fluorescence = np.stack(fluorescence)\n\n        self.insert1(key)\n\n        self.Mask.insert(\n            dict(key, mask=mask_id, mask_area=mask_area, roundness=roundness)\n            for mask_id, mask_area, roundness in zip(\n                mask_ids,\n                mask_npix * (um_height / px_height) * (um_width / px_width),\n                roundnesses,\n            )\n        )\n\n        self.Trace.insert(\n            dict(\n                key,\n                fluo_channel=fluo_channel,\n                mask=mask_id,\n                skewness=skewness,\n                variance=variance,\n            )\n            for fluo_channel, mask_id, skewness, variance in zip(\n                fluo_channels,\n                mask_ids,\n                skew(fluorescence, axis=1),\n                fluorescence.std(axis=1),\n            )\n        )\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_preprocess/#element_calcium_imaging.imaging_preprocess.ProcessingQualityMetrics.Mask", "title": "<code>Mask</code>", "text": "<p>         Bases: <code>dj.Part</code></p> <p>Quality metrics used to evaluate the masks.</p> <p>Attributes:</p> Name Type Description <code>Fluorescence</code> <code>foreign key</code> <p>Primary key from Fluorescence.</p> <code>Segmentation.Mask</code> <code>foreign key</code> <p>Primary key from Segmentation.Mask.</p> <code>mask_area</code> <code>float</code> <p>Mask area in square micrometer.</p> <code>roundness</code> <code>float</code> <p>Roundness between 0 and 1. Values closer to 1 are rounder.</p> Source code in <code>element_calcium_imaging/imaging_preprocess.py</code> <pre><code>class Mask(dj.Part):\n\"\"\"Quality metrics used to evaluate the masks.\n\n    Attributes:\n        Fluorescence (foreign key): Primary key from Fluorescence.\n        Segmentation.Mask (foreign key): Primary key from Segmentation.Mask.\n        mask_area (float): Mask area in square micrometer.\n        roundness (float): Roundness between 0 and 1. Values closer to 1 are rounder.\n    \"\"\"\n\n    definition = \"\"\"\n    -&gt; master\n    -&gt; Segmentation.Mask\n    ---\n    mask_area=null: float  # Mask area in square micrometer.\n    roundness: float       # Roundness between 0 and 1. Values closer to 1 are rounder.\n    \"\"\"\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_preprocess/#element_calcium_imaging.imaging_preprocess.ProcessingQualityMetrics.Trace", "title": "<code>Trace</code>", "text": "<p>         Bases: <code>dj.Part</code></p> <p>Quality metrics used to evaluate the fluorescence traces.</p> <p>Attributes:</p> Name Type Description <code>Fluorescence</code> <code>foreign key</code> <p>Primary key from Fluorescence.</p> <code>Fluorescence.Trace</code> <code>foreign key</code> <p>Primary key from Fluorescence.Trace.</p> <code>skewness</code> <code>float</code> <p>Skewness of the fluorescence trace.</p> <code>variance</code> <code>float</code> <p>Variance of the fluorescence trace.</p> Source code in <code>element_calcium_imaging/imaging_preprocess.py</code> <pre><code>class Trace(dj.Part):\n\"\"\"Quality metrics used to evaluate the fluorescence traces.\n\n    Attributes:\n        Fluorescence (foreign key): Primary key from Fluorescence.\n        Fluorescence.Trace (foreign key): Primary key from Fluorescence.Trace.\n        skewness (float): Skewness of the fluorescence trace.\n        variance (float): Variance of the fluorescence trace.\n    \"\"\"\n\n    definition = \"\"\"\n    -&gt; master\n    -&gt; Fluorescence.Trace\n    ---\n    skewness: float   # Skewness of the fluorescence trace.\n    variance: float   # Variance of the fluorescence trace.\n    \"\"\"\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_preprocess/#element_calcium_imaging.imaging_preprocess.ProcessingQualityMetrics.make", "title": "<code>make(key)</code>", "text": "<p>Populate the ProcessingQualityMetrics table and its part tables.</p> Source code in <code>element_calcium_imaging/imaging_preprocess.py</code> <pre><code>def make(self, key):\n\"\"\"Populate the ProcessingQualityMetrics table and its part tables.\"\"\"\n    from scipy.stats import skew\n\n    (\n        mask_xpixs,\n        mask_ypixs,\n        mask_weights,\n        fluorescence,\n        fluo_channels,\n        mask_ids,\n        mask_npix,\n        px_height,\n        px_width,\n        um_height,\n        um_width,\n    ) = (Segmentation.Mask * scan.ScanInfo.Field * Fluorescence.Trace &amp; key).fetch(\n        \"mask_xpix\",\n        \"mask_ypix\",\n        \"mask_weights\",\n        \"fluorescence\",\n        \"fluo_channel\",\n        \"mask\",\n        \"mask_npix\",\n        \"px_height\",\n        \"px_width\",\n        \"um_height\",\n        \"um_width\",\n    )\n\n    norm_mean = lambda x: x.mean() / x.max()\n    roundnesses = [\n        norm_mean(np.linalg.eigvals(np.cov(x, y, aweights=w)))\n        for x, y, w in zip(mask_xpixs, mask_ypixs, mask_weights)\n    ]\n\n    fluorescence = np.stack(fluorescence)\n\n    self.insert1(key)\n\n    self.Mask.insert(\n        dict(key, mask=mask_id, mask_area=mask_area, roundness=roundness)\n        for mask_id, mask_area, roundness in zip(\n            mask_ids,\n            mask_npix * (um_height / px_height) * (um_width / px_width),\n            roundnesses,\n        )\n    )\n\n    self.Trace.insert(\n        dict(\n            key,\n            fluo_channel=fluo_channel,\n            mask=mask_id,\n            skewness=skewness,\n            variance=variance,\n        )\n        for fluo_channel, mask_id, skewness, variance in zip(\n            fluo_channels,\n            mask_ids,\n            skew(fluorescence, axis=1),\n            fluorescence.std(axis=1),\n        )\n    )\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_preprocess/#element_calcium_imaging.imaging_preprocess.get_loader_result", "title": "<code>get_loader_result(key, table)</code>", "text": "<p>Retrieve the processed imaging results from a suite2p or caiman loader.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>dict</code> <p>The <code>key</code> to one entry of ProcessingTask or Curation</p> required <code>table</code> <code>dj.Table</code> <p>A datajoint table to retrieve the loaded results from (e.g. ProcessingTask, Curation)</p> required <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If the processing_method is different than 'suite2p' or 'caiman'.</p> <p>Returns:</p> Type Description <code>Callable</code> <p>A loader object of the loaded results (e.g. suite2p.Suite2p or caiman.CaImAn,</p> <code>Callable</code> <p>see element-interface for more information on the loaders.)</p> Source code in <code>element_calcium_imaging/imaging_preprocess.py</code> <pre><code>def get_loader_result(key: dict, table: dj.Table) -&gt; Callable:\n\"\"\"Retrieve the processed imaging results from a suite2p or caiman loader.\n\n    Args:\n        key (dict): The `key` to one entry of ProcessingTask or Curation\n        table (dj.Table): A datajoint table to retrieve the loaded results from (e.g.\n            ProcessingTask, Curation)\n\n    Raises:\n        NotImplementedError: If the processing_method is different than 'suite2p' or\n            'caiman'.\n\n    Returns:\n        A loader object of the loaded results (e.g. suite2p.Suite2p or caiman.CaImAn,\n        see element-interface for more information on the loaders.)\n    \"\"\"\n    method, output_dir = (ProcessingParamSet * table &amp; key).fetch1(\n        \"processing_method\", _table_attribute_mapper[table.__name__]\n    )\n\n    output_path = find_full_path(get_imaging_root_data_dir(), output_dir)\n\n    if method == \"suite2p\" or (\n        method == \"extract\" and table.__name__ == \"MotionCorrection\"\n    ):\n        from element_interface import suite2p_loader\n\n        loaded_dataset = suite2p_loader.Suite2p(output_path)\n    elif method == \"caiman\":\n        from element_interface import caiman_loader\n\n        loaded_dataset = caiman_loader.CaImAn(output_path)\n    elif method == \"extract\":\n        from element_interface import extract_loader\n\n        loaded_dataset = extract_loader.EXTRACT(output_path)\n    else:\n        raise NotImplementedError(\"Unknown/unimplemented method: {}\".format(method))\n\n    return method, loaded_dataset\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_report/", "title": "imaging_report.py", "text": ""}, {"location": "api/element_calcium_imaging/imaging_report/#element_calcium_imaging.imaging_report.activate", "title": "<code>activate(schema_name, imaging_schema_name, *, create_schema=True, create_tables=True)</code>", "text": "<p>Activate this schema.</p> <p>Parameters:</p> Name Type Description Default <code>schema_name</code> <code>str</code> <p>Schema name on the database server to activate the <code>imaging_report</code> schema</p> required <code>imaging_schema_name</code> <code>str</code> <p>Schema name of the activated imaging element for which this imaging_report schema will be downstream from</p> required <code>create_schema</code> <code>bool</code> <p>When True (default), create schema in the database if it does not yet exist.</p> <code>True</code> <code>create_tables</code> <code>bool</code> <p>When True (default), create tables in the database if they do not yet exist.</p> <code>True</code> Source code in <code>element_calcium_imaging/imaging_report.py</code> <pre><code>def activate(\n    schema_name: str,\n    imaging_schema_name: str,\n    *,\n    create_schema: bool = True,\n    create_tables: bool = True,\n):\n\"\"\"Activate this schema.\n\n    Args:\n        schema_name (str): Schema name on the database server to activate the\n            `imaging_report` schema\n        imaging_schema_name (str): Schema name of the activated imaging element for\n            which this imaging_report schema will be downstream from\n        create_schema (bool): When True (default), create schema in the database if it\n            does not yet exist.\n        create_tables (bool): When True (default), create tables in the database if they\n            do not yet exist.\n    \"\"\"\n    global imaging\n    imaging = dj.create_virtual_module(\"imaging\", imaging_schema_name)\n\n    schema.activate(\n        schema_name,\n        create_schema=create_schema,\n        create_tables=create_tables,\n        add_objects=imaging.__dict__,\n    )\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_report/#element_calcium_imaging.imaging_report.ScanLevelReport", "title": "<code>ScanLevelReport</code>", "text": "<p>         Bases: <code>dj.Computed</code></p> <p>Scan level report with figures.</p> <p>Attributes:</p> Name Type Description <code>imaging.Segmentation</code> <code>foreign key</code> <p>Primary key from imaging.Segmentation.</p> <code>cell_overlayed_image</code> <code>longblob</code> <p>Plotly figure object showing the segmented cells on the average image.</p> Source code in <code>element_calcium_imaging/imaging_report.py</code> <pre><code>@schema\nclass ScanLevelReport(dj.Computed):\n\"\"\"Scan level report with figures.\n\n    Attributes:\n        imaging.Segmentation (foreign key): Primary key from imaging.Segmentation.\n        cell_overlayed_image (longblob): Plotly figure object showing the segmented\n            cells on the average image.\n    \"\"\"\n\n    definition = \"\"\"\n    -&gt; imaging.Segmentation\n    ---\n    cell_overlayed_image: longblob\n    \"\"\"\n\n    def make(self, key):\n\"\"\"Compute and ingest the plotly figure objects.\"\"\"\n\n        image_fig = cell_plot.plot_cell_overlayed_image(imaging, key)\n        self.insert1({**key, \"cell_overlayed_image\": image_fig.to_json()})\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_report/#element_calcium_imaging.imaging_report.ScanLevelReport.make", "title": "<code>make(key)</code>", "text": "<p>Compute and ingest the plotly figure objects.</p> Source code in <code>element_calcium_imaging/imaging_report.py</code> <pre><code>def make(self, key):\n\"\"\"Compute and ingest the plotly figure objects.\"\"\"\n\n    image_fig = cell_plot.plot_cell_overlayed_image(imaging, key)\n    self.insert1({**key, \"cell_overlayed_image\": image_fig.to_json()})\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_report/#element_calcium_imaging.imaging_report.TraceReport", "title": "<code>TraceReport</code>", "text": "<p>         Bases: <code>dj.Computed</code></p> <p>Figures of traces.</p> <p>Attributes:</p> Name Type Description <code>imaging.Segmentation.Mask</code> <code>foreign key</code> <p>Primary key from imaging.Segmentation.Mask.</p> <code>cell_traces</code> <code>longblob</code> <p>Plotly figure object showing the cell traces.</p> Source code in <code>element_calcium_imaging/imaging_report.py</code> <pre><code>@schema\nclass TraceReport(dj.Computed):\n\"\"\"Figures of traces.\n\n    Attributes:\n        imaging.Segmentation.Mask (foreign key): Primary key from\n            imaging.Segmentation.Mask.\n        cell_traces (longblob): Plotly figure object showing the cell traces.\n    \"\"\"\n\n    definition = \"\"\"\n    -&gt; imaging.Segmentation.Mask\n    ---\n    cell_traces: longblob\n    \"\"\"\n\n    @property\n    def key_source(self):\n\"\"\"Limit the TraceReport to Masks that have Activity table populated.\n        database.\"\"\"\n\n        return imaging.Segmentation.Mask &amp; imaging.Activity\n\n    def make(self, key):\n\"\"\"Compute and ingest the plotly figure objects.\"\"\"\n\n        trace_fig = cell_plot.plot_cell_traces(imaging, key)\n        self.insert1({**key, \"cell_traces\": trace_fig.to_json()})\n</code></pre>"}, {"location": "api/element_calcium_imaging/imaging_report/#element_calcium_imaging.imaging_report.TraceReport.key_source", "title": "<code>key_source</code>  <code>property</code>", "text": "<p>Limit the TraceReport to Masks that have Activity table populated. database.</p>"}, {"location": "api/element_calcium_imaging/imaging_report/#element_calcium_imaging.imaging_report.TraceReport.make", "title": "<code>make(key)</code>", "text": "<p>Compute and ingest the plotly figure objects.</p> Source code in <code>element_calcium_imaging/imaging_report.py</code> <pre><code>def make(self, key):\n\"\"\"Compute and ingest the plotly figure objects.\"\"\"\n\n    trace_fig = cell_plot.plot_cell_traces(imaging, key)\n    self.insert1({**key, \"cell_traces\": trace_fig.to_json()})\n</code></pre>"}, {"location": "api/element_calcium_imaging/scan/", "title": "scan.py", "text": ""}, {"location": "api/element_calcium_imaging/scan/#element_calcium_imaging.scan.activate", "title": "<code>activate(scan_schema_name, *, create_schema=True, create_tables=True, linking_module=None)</code>", "text": "<p>Activate this schema.</p> <p>Parameters:</p> Name Type Description Default <code>scan_schema_name</code> <code>str</code> <p>Schema name on the database server to activate the <code>scan</code> module</p> required <code>create_schema</code> <code>bool</code> <p>When True (default), create schema in the database if it does not yet exist.</p> <code>True</code> <code>create_tables</code> <code>bool</code> <p>When True (default), create tables in the database if they do not yet exist.</p> <code>True</code> <code>linking_module</code> <code>str</code> <p>A module name or a module containing the required dependencies to activate the <code>scan</code> module.</p> <code>None</code> <p>Dependencies:</p> Upstream tables <ul> <li>Session: Parent table to Scan, typically identifying a recording session</li> <li>Equipment: Reference table for Scan, specifying the equipment used for the     acquisition of this scan.</li> <li>Location: Reference table for ScanLocation, specifying the scanned regions's     anatomical location in the brain.</li> </ul> Source code in <code>element_calcium_imaging/scan.py</code> <pre><code>def activate(\n    scan_schema_name: str,\n    *,\n    create_schema: bool = True,\n    create_tables: bool = True,\n    linking_module: str = None,\n):\n\"\"\"Activate this schema.\n\n    Args:\n        scan_schema_name (str): Schema name on the database server to activate the\n            `scan` module\n        create_schema (bool): When True (default), create schema in the database if it\n            does not yet exist.\n        create_tables (bool): When True (default), create tables in the database if they\n            do not yet exist.\n        linking_module (str): A module name or a module containing the required\n            dependencies to activate the `scan` module.\n\n    Dependencies:\n    Upstream tables:\n        + Session: Parent table to Scan, typically identifying a recording session\n        + Equipment: Reference table for Scan, specifying the equipment used for the\n            acquisition of this scan.\n        + Location: Reference table for ScanLocation, specifying the scanned regions's\n            anatomical location in the brain.\n    \"\"\"\n\n    if isinstance(linking_module, str):\n        linking_module = importlib.import_module(linking_module)\n    assert inspect.ismodule(\n        linking_module\n    ), \"The argument 'dependency' must be a module's name or a module\"\n\n    global _linking_module\n    _linking_module = linking_module\n\n    schema.activate(\n        scan_schema_name,\n        create_schema=create_schema,\n        create_tables=create_tables,\n        add_objects=_linking_module.__dict__,\n    )\n</code></pre>"}, {"location": "api/element_calcium_imaging/scan/#element_calcium_imaging.scan.get_imaging_root_data_dir", "title": "<code>get_imaging_root_data_dir()</code>", "text": "<p>Return imaging root data director(y/ies)</p> <p>Retrieve the root data director(y/ies) containing the imaging data for all subjects/sessions (e.g. acquired ScanImage raw files, output files from processing routines, etc.). All data paths and directories in DataJoint Elements are recommended to be stored as relative paths (posix format), with respect to some user-configured \"root\" directory, which varies from machine to machine (e.g. different mounted drive locations).</p> <p>Returns:</p> Name Type Description <code>dirs</code> <code>list</code> <p>A list of string(s) or Path(s) for the absolute paths of the imaging root data director(y/ies).</p> Source code in <code>element_calcium_imaging/scan.py</code> <pre><code>def get_imaging_root_data_dir() -&gt; list:\n\"\"\"Return imaging root data director(y/ies)\n\n    Retrieve the root data director(y/ies) containing the imaging data\n    for all subjects/sessions (e.g. acquired ScanImage raw files, output files from\n    processing routines, etc.). All data paths and directories in DataJoint Elements are\n    recommended to be stored as relative paths (posix format), with respect to some\n    user-configured \"root\" directory, which varies from machine to machine\n    (e.g. different mounted drive locations).\n\n    Returns:\n        dirs (list): A list of string(s) or Path(s) for the absolute paths of the imaging root data\n            director(y/ies).\n    \"\"\"\n\n    root_directories = _linking_module.get_imaging_root_data_dir()\n    if isinstance(root_directories, (str, pathlib.Path)):\n        root_directories = [root_directories]\n\n    if hasattr(_linking_module, \"get_processed_root_data_dir\"):\n        root_directories.append(_linking_module.get_processed_root_data_dir())\n\n    return root_directories\n</code></pre>"}, {"location": "api/element_calcium_imaging/scan/#element_calcium_imaging.scan.get_processed_root_data_dir", "title": "<code>get_processed_root_data_dir()</code>", "text": "<p>Retrieve the root directory for all processed data.</p> <p>All data paths and directories in DataJoint Elements are recommended to be stored as relative paths (posix format), with respect to some user-configured \"root\" directory, which varies from machine to machine (e.g. different mounted drive locations).</p> <p>Returns:</p> Name Type Description <code>dir</code> <code>str | pathlib.Path</code> <p>Absolute path of the processed imaging root data directory.</p> Source code in <code>element_calcium_imaging/scan.py</code> <pre><code>def get_processed_root_data_dir() -&gt; Union[str, pathlib.Path]:\n\"\"\"Retrieve the root directory for all processed data.\n\n    All data paths and directories in DataJoint Elements are recommended to be stored as\n    relative paths (posix format), with respect to some user-configured \"root\"\n    directory, which varies from machine to machine (e.g. different mounted drive\n    locations).\n\n    Returns:\n        dir (str| pathlib.Path): Absolute path of the processed imaging root data\n            directory.\n    \"\"\"\n\n    if hasattr(_linking_module, \"get_processed_root_data_dir\"):\n        return _linking_module.get_processed_root_data_dir()\n    else:\n        return get_imaging_root_data_dir()[0]\n</code></pre>"}, {"location": "api/element_calcium_imaging/scan/#element_calcium_imaging.scan.get_image_files", "title": "<code>get_image_files(scan_key, file_type)</code>", "text": "<p>Retrieve the list of image files associated with a given Scan.</p> <p>Parameters:</p> Name Type Description Default <code>scan_key</code> <code>dict</code> <p>Primary key of a Scan entry.</p> required <p>Returns:</p> Type Description <code>list</code> <p>A list of full file paths.</p> Source code in <code>element_calcium_imaging/scan.py</code> <pre><code>def get_image_files(scan_key: dict, file_type: str) -&gt; list:\n\"\"\"Retrieve the list of image files associated with a given Scan.\n\n    Args:\n        scan_key: Primary key of a Scan entry.\n\n    Returns:\n        A list of full file paths.\n    \"\"\"\n    return _linking_module.get_image_files(scan_key, file_type)\n</code></pre>"}, {"location": "api/element_calcium_imaging/scan/#element_calcium_imaging.scan.AcquisitionSoftware", "title": "<code>AcquisitionSoftware</code>", "text": "<p>         Bases: <code>dj.Lookup</code></p> <p>A list of acquisition softwares supported by the Element.</p> <p>Required to define a scan.</p> <p>Attributes:</p> Name Type Description <code>acq_software</code> <code>str</code> <p>Acquisition software</p> Source code in <code>element_calcium_imaging/scan.py</code> <pre><code>@schema\nclass AcquisitionSoftware(dj.Lookup):\n\"\"\"A list of acquisition softwares supported by the Element.\n\n    Required to define a scan.\n\n    Attributes:\n        acq_software (str): Acquisition software\n    \"\"\"\n\n    definition = \"\"\"  # Acquisition softwares\n    acq_software: varchar(24)\n    \"\"\"\n    contents = zip([\"ScanImage\", \"Scanbox\", \"NIS\", \"PrairieView\"])\n</code></pre>"}, {"location": "api/element_calcium_imaging/scan/#element_calcium_imaging.scan.Channel", "title": "<code>Channel</code>", "text": "<p>         Bases: <code>dj.Lookup</code></p> <p>Recording channels for the imaging wavelengths.</p> <p>Attributes:</p> Name Type Description <code>channel</code> <code>int</code> <p>Channel index</p> Source code in <code>element_calcium_imaging/scan.py</code> <pre><code>@schema\nclass Channel(dj.Lookup):\n\"\"\"Recording channels for the imaging wavelengths.\n\n    Attributes:\n        channel (int): Channel index\n    \"\"\"\n\n    definition = \"\"\"  # A recording channel\n    channel     : tinyint  # 0-based indexing\n    \"\"\"\n    contents = zip(range(5))\n</code></pre>"}, {"location": "api/element_calcium_imaging/scan/#element_calcium_imaging.scan.Scan", "title": "<code>Scan</code>", "text": "<p>         Bases: <code>dj.Manual</code></p> <p>Scan defined by a measurement done using a scanner and an acquisition software.</p> <p>The details of the scanning data is placed in other tables, including, ScanLocation, ScanInfo, and ScanInfo's part tables.</p> <p>Attributes:</p> Name Type Description <code>Session</code> <code>foreign key</code> <p>A primary key from Session.</p> <code>scan_id</code> <code>int</code> <p>Unique Scan ID.</p> <code>Equipment</code> <code>foreign key</code> <p>A primary key from Equipment.</p> <code>AcquisitionSoftware</code> <code>foreign key</code> <p>A primary key from AcquisitionSoftware.</p> <code>scan_notes</code> <code>str</code> <p>Notes of the experimenter regarding the scan.</p> Source code in <code>element_calcium_imaging/scan.py</code> <pre><code>@schema\nclass Scan(dj.Manual):\n\"\"\"Scan defined by a measurement done using a scanner and an acquisition software.\n\n    The details of the scanning data is placed in other tables, including,\n    ScanLocation, ScanInfo, and ScanInfo's part tables.\n\n    Attributes:\n        Session (foreign key): A primary key from Session.\n        scan_id (int): Unique Scan ID.\n        Equipment (foreign key, optional): A primary key from Equipment.\n        AcquisitionSoftware (foreign key): A primary key from AcquisitionSoftware.\n        scan_notes (str, optional): Notes of the experimenter regarding the scan.\n    \"\"\"\n\n    definition = \"\"\"\n    -&gt; Session\n    scan_id: int\n    ---\n    -&gt; [nullable] Equipment\n    -&gt; AcquisitionSoftware\n    scan_notes='' : varchar(4095)\n    \"\"\"\n</code></pre>"}, {"location": "api/element_calcium_imaging/scan/#element_calcium_imaging.scan.ScanLocation", "title": "<code>ScanLocation</code>", "text": "<p>         Bases: <code>dj.Manual</code></p> <p>Anatomical location of the scanned region in the brain</p> <p>Attributes:</p> Name Type Description <code>Scan</code> <code>foreign key</code> <p>A primary key from Scan.</p> <code>Locaton</code> <code>foreign key</code> <p>A primary key from Location.</p> Source code in <code>element_calcium_imaging/scan.py</code> <pre><code>@schema\nclass ScanLocation(dj.Manual):\n\"\"\"Anatomical location of the scanned region in the brain\n\n    Attributes:\n        Scan (foreign key): A primary key from Scan.\n        Locaton (foreign key): A primary key from Location.\n    \"\"\"\n\n    definition = \"\"\" # Anatomical location\n    -&gt; Scan\n    ---\n    -&gt; Location\n    \"\"\"\n</code></pre>"}, {"location": "api/element_calcium_imaging/scan/#element_calcium_imaging.scan.ScanInfo", "title": "<code>ScanInfo</code>", "text": "<p>         Bases: <code>dj.Imported</code></p> <p>Information about the scan extracted from the recorded files.</p> <p>Attributes:</p> Name Type Description <code>Scan</code> <code>foreign key</code> <p>A primary key from Scan.</p> <code>nfields</code> <code>int</code> <p>Number of fields.</p> <code>nchannels</code> <code>int</code> <p>Number of channels.</p> <code>ndepths</code> <code>int</code> <p>Number of scanning depths (planes).</p> <code>nframes</code> <code>int</code> <p>Number of recorded frames.</p> <code>nrois</code> <code>int</code> <p>Number of ROIs (see scanimage's multi ROI imaging).</p> <code>x</code> <code>float</code> <p>ScanImage's 0 point in the motor coordinate system (um).</p> <code>y</code> <code>float</code> <p>ScanImage's 0 point in the motor coordinate system (um).</p> <code>z</code> <code>float</code> <p>ScanImage's 0 point in the motor coordinate system (um).</p> <code>fps</code> <code>float) </code> <p>Frames per second (Hz) - Volumetric Scan Rate.</p> <code>bidirectional</code> <code>bool</code> <p>True = bidirectional scanning.</p> <code>usecs_per_line</code> <code>float</code> <p>Microseconds per scan line.</p> <code>fill_fraction</code> <code>float</code> <p>Raster scan temporal fill fraction (see scanimage)</p> <code>scan_datetime</code> <code>datetime</code> <p>Datetime of the scan.</p> <code>scan_duration</code> <code>float</code> <p>Duration of the scan (s).</p> <code>bidirectional_z</code> <code>bool</code> <p>True = bidirectional z-scan.</p> Source code in <code>element_calcium_imaging/scan.py</code> <pre><code>@schema\nclass ScanInfo(dj.Imported):\n\"\"\"\n    Information about the scan extracted from the recorded files.\n\n    Attributes:\n        Scan (foreign key): A primary key from Scan.\n        nfields (int): Number of fields.\n        nchannels (int): Number of channels.\n        ndepths (int): Number of scanning depths (planes).\n        nframes (int): Number of recorded frames.\n        nrois (int): Number of ROIs (see scanimage's multi ROI imaging).\n        x (float, optional): ScanImage's 0 point in the motor coordinate system (um).\n        y (float, optional): ScanImage's 0 point in the motor coordinate system (um).\n        z (float, optional): ScanImage's 0 point in the motor coordinate system (um).\n        fps (float) : Frames per second (Hz) - Volumetric Scan Rate.\n        bidirectional (bool): True = bidirectional scanning.\n        usecs_per_line (float, optional): Microseconds per scan line.\n        fill_fraction (float, optional): Raster scan temporal fill fraction (see\n            scanimage)\n        scan_datetime (datetime, optional): Datetime of the scan.\n        scan_duration (float, optional): Duration of the scan (s).\n        bidirectional_z (bool, optional): True = bidirectional z-scan.\n    \"\"\"\n\n    definition = \"\"\" # General data about the resoscans/mesoscans from header\n    -&gt; Scan\n    ---\n    nfields              : tinyint   # number of fields\n    nchannels            : tinyint   # number of channels\n    ndepths              : int       # Number of scanning depths (planes)\n    nframes              : int       # number of recorded frames\n    nrois                : tinyint   # number of ROIs (see scanimage's multi ROI imaging)\n    x=null               : float     # (um) ScanImage's 0 point in the motor coordinate system\n    y=null               : float     # (um) ScanImage's 0 point in the motor coordinate system\n    z=null               : float     # (um) ScanImage's 0 point in the motor coordinate system\n    fps                  : float     # (Hz) frames per second - Volumetric Scan Rate\n    bidirectional        : boolean   # true = bidirectional scanning\n    usecs_per_line=null  : float     # microseconds per scan line\n    fill_fraction=null   : float     # raster scan temporal fill fraction (see scanimage)\n    scan_datetime=null   : datetime  # datetime of the scan\n    scan_duration=null   : float     # (seconds) duration of the scan\n    bidirectional_z=null : boolean   # true = bidirectional z-scan\n    \"\"\"\n\n    class Field(dj.Part):\n\"\"\"Stores field information of scan, including its coordinates, size, pixel\n        pitch, etc.\n\n        Attributes:\n            ScanInfo (foreign key): A primary key from ScanInfo.\n            field_idx (int): Unique field index.\n            px_height (int): Image height in pixels.\n            px_width (int): Image width in pixels.\n            um_height (float, optional): Image height in microns.\n            um_width (float, optional): Image width in microns.\n            field_x (float, optional): X coordinate of the center of field in the motor\n                coordinate system (um).\n            field_y (float, optional): Y coordinate of the center of field in the motor\n                coordinate system (um).\n            field_z (float, optional): Relative depth of field (um).\n            delay_image (longblob, optional): Delay between the start of the scan and\n                pixels in this field (ms).\n            roi (int, optional): The scanning roi (as recorded in the acquisition\n                software) containing this field - only relevant to mesoscale scans.\n        \"\"\"\n\n        definition = \"\"\" # field-specific scan information\n        -&gt; master\n        field_idx         : int\n        ---\n        px_height         : smallint  # height in pixels\n        px_width          : smallint  # width in pixels\n        um_height=null    : float     # height in microns\n        um_width=null     : float     # width in microns\n        field_x=null      : float     # (um) center of field in the motor coordinate system\n        field_y=null      : float     # (um) center of field in the motor coordinate system\n        field_z=null      : float     # (um) relative depth of field\n        delay_image=null  : longblob  # (ms) delay between the start of the scan and pixels in this field\n        roi=null          : int       # the scanning roi (as recorded in the acquisition software) containing this field - only relevant to mesoscale scans\n        \"\"\"\n\n    class ScanFile(dj.Part):\n\"\"\"Filepath of the scan relative to root data directory.\n\n        Attributes:\n            ScanInfo (foreign key): A primary key from ScanInfo.\n            file_path (str): Path of the scan file relative to the root data directory.\n        \"\"\"\n\n        definition = \"\"\"\n        -&gt; master\n        file_path: varchar(255)  # Filepath relative to root data directory\n        \"\"\"\n\n    def make(self, key):\n\"\"\"Populate the ScanInfo with the information parsed from image files.\"\"\"\n\n        acq_software = (Scan &amp; key).fetch1(\"acq_software\")\n\n        if acq_software == \"ScanImage\":\n            import scanreader\n\n            # Read the scan\n            scan_filepaths = get_image_files(key, \"*.tif\")\n            scan = scanreader.read_scan(scan_filepaths)\n\n            # Insert in ScanInfo\n            x_zero, y_zero, z_zero = scan.motor_position_at_zero or (None, None, None)\n\n            self.insert1(\n                dict(\n                    key,\n                    nfields=scan.num_fields,\n                    nchannels=scan.num_channels,\n                    nframes=scan.num_frames,\n                    ndepths=scan.num_scanning_depths,\n                    x=x_zero,\n                    y=y_zero,\n                    z=z_zero,\n                    fps=scan.fps,\n                    bidirectional=scan.is_bidirectional,\n                    usecs_per_line=scan.seconds_per_line * 1e6,\n                    fill_fraction=scan.temporal_fill_fraction,\n                    nrois=scan.num_rois if scan.is_multiROI else 0,\n                    scan_duration=scan.num_frames / scan.fps,\n                )\n            )\n            # Insert Field(s)\n            if scan.is_multiROI:\n                self.Field.insert(\n                    [\n                        dict(\n                            key,\n                            field_idx=field_id,\n                            px_height=scan.field_heights[field_id],\n                            px_width=scan.field_widths[field_id],\n                            um_height=scan.field_heights_in_microns[field_id],\n                            um_width=scan.field_widths_in_microns[field_id],\n                            field_x=x_zero\n                            + scan._degrees_to_microns(scan.fields[field_id].x)\n                            if x_zero\n                            else None,\n                            field_y=y_zero\n                            + scan._degrees_to_microns(scan.fields[field_id].y)\n                            if y_zero\n                            else None,\n                            field_z=z_zero + scan.fields[field_id].depth\n                            if z_zero\n                            else None,\n                            delay_image=scan.field_offsets[field_id],\n                            roi=scan.field_rois[field_id][0],\n                        )\n                        for field_id in range(scan.num_fields)\n                    ]\n                )\n            else:\n                self.Field.insert(\n                    [\n                        dict(\n                            key,\n                            field_idx=plane_idx,\n                            px_height=scan.image_height,\n                            px_width=scan.image_width,\n                            um_height=getattr(scan, \"image_height_in_microns\", None),\n                            um_width=getattr(scan, \"image_width_in_microns\", None),\n                            field_x=x_zero if x_zero else None,\n                            field_y=y_zero if y_zero else None,\n                            field_z=z_zero + scan.scanning_depths[plane_idx]\n                            if z_zero\n                            else None,\n                            delay_image=scan.field_offsets[plane_idx],\n                        )\n                        for plane_idx in range(scan.num_scanning_depths)\n                    ]\n                )\n        elif acq_software == \"Scanbox\":\n            import sbxreader\n\n            # Read the scan\n            scan_filepaths = get_image_files(key, \"*.sbx\")\n            sbx_meta = sbxreader.sbx_get_metadata(scan_filepaths[0])\n            sbx_matinfo = sbxreader.sbx_get_info(scan_filepaths[0])\n            is_multiROI = bool(\n                sbx_matinfo.mesoscope.enabled\n            )  # currently not handling \"multiROI\" ingestion\n\n            if is_multiROI:\n                raise NotImplementedError(\n                    \"Loading routine not implemented for Scanbox multiROI scan mode\"\n                )\n\n            # Insert in ScanInfo\n            x_zero, y_zero, z_zero = sbx_meta[\"stage_pos\"]\n            self.insert1(\n                dict(\n                    key,\n                    nfields=sbx_meta[\"num_fields\"]\n                    if is_multiROI\n                    else sbx_meta[\"num_planes\"],\n                    nchannels=sbx_meta[\"num_channels\"],\n                    nframes=sbx_meta[\"num_frames\"],\n                    ndepths=sbx_meta[\"num_planes\"],\n                    x=x_zero,\n                    y=y_zero,\n                    z=z_zero,\n                    fps=sbx_meta[\"frame_rate\"],\n                    bidirectional=sbx_meta == \"bidirectional\",\n                    nrois=sbx_meta[\"num_rois\"] if is_multiROI else 0,\n                    scan_duration=(sbx_meta[\"num_frames\"] / sbx_meta[\"frame_rate\"]),\n                )\n            )\n            # Insert Field(s)\n            if not is_multiROI:\n                px_width, px_height = sbx_meta[\"frame_size\"]\n                self.Field.insert(\n                    [\n                        dict(\n                            key,\n                            field_idx=plane_idx,\n                            px_height=px_height,\n                            px_width=px_width,\n                            um_height=px_height * sbx_meta[\"um_per_pixel_y\"]\n                            if sbx_meta[\"um_per_pixel_y\"]\n                            else None,\n                            um_width=px_width * sbx_meta[\"um_per_pixel_x\"]\n                            if sbx_meta[\"um_per_pixel_x\"]\n                            else None,\n                            field_x=x_zero,\n                            field_y=y_zero,\n                            field_z=z_zero + sbx_meta[\"etl_pos\"][plane_idx],\n                        )\n                        for plane_idx in range(sbx_meta[\"num_planes\"])\n                    ]\n                )\n        elif acq_software == \"NIS\":\n            import nd2\n\n            # Read the scan\n            scan_filepaths = get_image_files(key, \"*.nd2\")\n            nd2_file = nd2.ND2File(scan_filepaths[0])\n            is_multiROI = False  # MultiROI to be implemented later\n\n            # Frame per second\n            try:\n                fps = 1000 / nd2_file.experiment[0].parameters.periods[0].periodDiff.avg\n            except:  # noqa: E722\n                fps = 1000 / nd2_file.experiment[0].parameters.periodDiff.avg\n\n            # Estimate ND2 file scan duration\n            def estimate_nd2_scan_duration(nd2_scan_obj):\n                # Calculates scan duration for Nikon images\n                ti = (\n                    nd2_scan_obj.frame_metadata(0)\n                    .channels[0]\n                    .time.absoluteJulianDayNumber\n                )  # Initial frame's JD.\n                tf = (\n                    nd2_scan_obj.frame_metadata(nd2_scan_obj.shape[0] - 1)\n                    .channels[0]\n                    .time.absoluteJulianDayNumber\n                )  # Final frame's JD.\n\n                return (tf - ti) * 86400 + 1 / fps\n\n            scan_duration = sum(\n                estimate_nd2_scan_duration(nd2.ND2File(f)) for f in scan_filepaths\n            )\n\n            try:\n                scan_datetime = nd2_file.text_info[\"date\"]\n                scan_datetime = datetime.strptime(\n                    scan_datetime,\n                    \"%m/%d/%Y %H:%M:%S %p\"\n                    if re.search((\"AM|PM\"), scan_datetime)\n                    else \"%m/%d/%Y %H:%M:%S\",\n                )\n                scan_datetime = datetime.strftime(scan_datetime, \"%Y-%m-%d %H:%M:%S\")\n            except:  # noqa: E722\n                scan_datetime = None\n\n            # Insert in ScanInfo\n            self.insert1(\n                dict(\n                    key,\n                    nfields=nd2_file.sizes.get(\"P\", 1),\n                    nchannels=nd2_file.attributes.channelCount,\n                    nframes=nd2_file.metadata.contents.frameCount,\n                    ndepths=nd2_file.sizes.get(\"Z\", 1),\n                    x=None,\n                    y=None,\n                    z=None,\n                    fps=fps,\n                    bidirectional=bool(\n                        nd2_file.custom_data[\"GrabberCameraSettingsV1_0\"][\n                            \"GrabberCameraSettings\"\n                        ][\"PropertiesQuality\"][\"ScanDirection\"]\n                    ),\n                    nrois=0,\n                    scan_datetime=scan_datetime,\n                    scan_duration=scan_duration,\n                )\n            )\n\n            # MultiROI to be implemented later\n\n            # Insert in Field\n            if not is_multiROI:\n                self.Field.insert(\n                    [\n                        dict(\n                            key,\n                            field_idx=plane_idx,\n                            px_height=nd2_file.attributes.heightPx,\n                            px_width=nd2_file.attributes.widthPx,\n                            um_height=nd2_file.attributes.heightPx\n                            * nd2_file.voxel_size().y,\n                            um_width=nd2_file.attributes.widthPx\n                            * nd2_file.voxel_size().x,\n                            field_x=None,\n                            field_y=None,\n                            field_z=None,\n                        )\n                        for plane_idx in range(nd2_file.sizes.get(\"Z\", 1))\n                    ]\n                )\n        elif acq_software == \"PrairieView\":\n            from element_interface import prairieviewreader\n\n            scan_filepaths = get_image_files(key, \"*.tif\")\n            PVScan_info = prairieviewreader.get_pv_metadata(scan_filepaths[0])\n            self.insert1(\n                dict(\n                    key,\n                    nfields=PVScan_info[\"num_fields\"],\n                    nchannels=PVScan_info[\"num_channels\"],\n                    ndepths=PVScan_info[\"num_planes\"],\n                    nframes=PVScan_info[\"num_frames\"],\n                    nrois=PVScan_info[\"num_rois\"],\n                    x=PVScan_info[\"x_pos\"],\n                    y=PVScan_info[\"y_pos\"],\n                    z=PVScan_info[\"z_pos\"],\n                    fps=PVScan_info[\"frame_rate\"],\n                    bidirectional=PVScan_info[\"bidirectional\"],\n                    bidirectional_z=PVScan_info[\"bidirectional_z\"],\n                    usecs_per_line=PVScan_info[\"usecs_per_line\"],\n                    scan_datetime=PVScan_info[\"scan_datetime\"],\n                    scan_duration=PVScan_info[\"scan_duration\"],\n                )\n            )\n\n            self.Field.insert(\n                dict(\n                    key,\n                    field_idx=plane_idx,\n                    px_height=PVScan_info[\"height_in_pixels\"],\n                    px_width=PVScan_info[\"width_in_pixels\"],\n                    um_height=PVScan_info[\"height_in_um\"],\n                    um_width=PVScan_info[\"width_in_um\"],\n                    field_x=PVScan_info[\"fieldX\"],\n                    field_y=PVScan_info[\"fieldY\"],\n                    field_z=PVScan_info[\"fieldZ\"]\n                    if PVScan_info[\"num_planes\"] == 1\n                    else PVScan_info[\"fieldZ\"][plane_idx],\n                )\n                for plane_idx in range(PVScan_info[\"num_planes\"])\n            )\n        else:\n            raise NotImplementedError(\n                f\"Loading routine not implemented for {acq_software} \"\n                \"acquisition software\"\n            )\n\n        # Insert file(s)\n        root_dir = find_root_directory(get_imaging_root_data_dir(), scan_filepaths[0])\n\n        scan_files = [\n            pathlib.Path(f).relative_to(root_dir).as_posix() for f in scan_filepaths\n        ]\n        self.ScanFile.insert([{**key, \"file_path\": f} for f in scan_files])\n</code></pre>"}, {"location": "api/element_calcium_imaging/scan/#element_calcium_imaging.scan.ScanInfo.Field", "title": "<code>Field</code>", "text": "<p>         Bases: <code>dj.Part</code></p> <p>Stores field information of scan, including its coordinates, size, pixel pitch, etc.</p> <p>Attributes:</p> Name Type Description <code>ScanInfo</code> <code>foreign key</code> <p>A primary key from ScanInfo.</p> <code>field_idx</code> <code>int</code> <p>Unique field index.</p> <code>px_height</code> <code>int</code> <p>Image height in pixels.</p> <code>px_width</code> <code>int</code> <p>Image width in pixels.</p> <code>um_height</code> <code>float</code> <p>Image height in microns.</p> <code>um_width</code> <code>float</code> <p>Image width in microns.</p> <code>field_x</code> <code>float</code> <p>X coordinate of the center of field in the motor coordinate system (um).</p> <code>field_y</code> <code>float</code> <p>Y coordinate of the center of field in the motor coordinate system (um).</p> <code>field_z</code> <code>float</code> <p>Relative depth of field (um).</p> <code>delay_image</code> <code>longblob</code> <p>Delay between the start of the scan and pixels in this field (ms).</p> <code>roi</code> <code>int</code> <p>The scanning roi (as recorded in the acquisition software) containing this field - only relevant to mesoscale scans.</p> Source code in <code>element_calcium_imaging/scan.py</code> <pre><code>class Field(dj.Part):\n\"\"\"Stores field information of scan, including its coordinates, size, pixel\n    pitch, etc.\n\n    Attributes:\n        ScanInfo (foreign key): A primary key from ScanInfo.\n        field_idx (int): Unique field index.\n        px_height (int): Image height in pixels.\n        px_width (int): Image width in pixels.\n        um_height (float, optional): Image height in microns.\n        um_width (float, optional): Image width in microns.\n        field_x (float, optional): X coordinate of the center of field in the motor\n            coordinate system (um).\n        field_y (float, optional): Y coordinate of the center of field in the motor\n            coordinate system (um).\n        field_z (float, optional): Relative depth of field (um).\n        delay_image (longblob, optional): Delay between the start of the scan and\n            pixels in this field (ms).\n        roi (int, optional): The scanning roi (as recorded in the acquisition\n            software) containing this field - only relevant to mesoscale scans.\n    \"\"\"\n\n    definition = \"\"\" # field-specific scan information\n    -&gt; master\n    field_idx         : int\n    ---\n    px_height         : smallint  # height in pixels\n    px_width          : smallint  # width in pixels\n    um_height=null    : float     # height in microns\n    um_width=null     : float     # width in microns\n    field_x=null      : float     # (um) center of field in the motor coordinate system\n    field_y=null      : float     # (um) center of field in the motor coordinate system\n    field_z=null      : float     # (um) relative depth of field\n    delay_image=null  : longblob  # (ms) delay between the start of the scan and pixels in this field\n    roi=null          : int       # the scanning roi (as recorded in the acquisition software) containing this field - only relevant to mesoscale scans\n    \"\"\"\n</code></pre>"}, {"location": "api/element_calcium_imaging/scan/#element_calcium_imaging.scan.ScanInfo.ScanFile", "title": "<code>ScanFile</code>", "text": "<p>         Bases: <code>dj.Part</code></p> <p>Filepath of the scan relative to root data directory.</p> <p>Attributes:</p> Name Type Description <code>ScanInfo</code> <code>foreign key</code> <p>A primary key from ScanInfo.</p> <code>file_path</code> <code>str</code> <p>Path of the scan file relative to the root data directory.</p> Source code in <code>element_calcium_imaging/scan.py</code> <pre><code>class ScanFile(dj.Part):\n\"\"\"Filepath of the scan relative to root data directory.\n\n    Attributes:\n        ScanInfo (foreign key): A primary key from ScanInfo.\n        file_path (str): Path of the scan file relative to the root data directory.\n    \"\"\"\n\n    definition = \"\"\"\n    -&gt; master\n    file_path: varchar(255)  # Filepath relative to root data directory\n    \"\"\"\n</code></pre>"}, {"location": "api/element_calcium_imaging/scan/#element_calcium_imaging.scan.ScanInfo.make", "title": "<code>make(key)</code>", "text": "<p>Populate the ScanInfo with the information parsed from image files.</p> Source code in <code>element_calcium_imaging/scan.py</code> <pre><code>def make(self, key):\n\"\"\"Populate the ScanInfo with the information parsed from image files.\"\"\"\n\n    acq_software = (Scan &amp; key).fetch1(\"acq_software\")\n\n    if acq_software == \"ScanImage\":\n        import scanreader\n\n        # Read the scan\n        scan_filepaths = get_image_files(key, \"*.tif\")\n        scan = scanreader.read_scan(scan_filepaths)\n\n        # Insert in ScanInfo\n        x_zero, y_zero, z_zero = scan.motor_position_at_zero or (None, None, None)\n\n        self.insert1(\n            dict(\n                key,\n                nfields=scan.num_fields,\n                nchannels=scan.num_channels,\n                nframes=scan.num_frames,\n                ndepths=scan.num_scanning_depths,\n                x=x_zero,\n                y=y_zero,\n                z=z_zero,\n                fps=scan.fps,\n                bidirectional=scan.is_bidirectional,\n                usecs_per_line=scan.seconds_per_line * 1e6,\n                fill_fraction=scan.temporal_fill_fraction,\n                nrois=scan.num_rois if scan.is_multiROI else 0,\n                scan_duration=scan.num_frames / scan.fps,\n            )\n        )\n        # Insert Field(s)\n        if scan.is_multiROI:\n            self.Field.insert(\n                [\n                    dict(\n                        key,\n                        field_idx=field_id,\n                        px_height=scan.field_heights[field_id],\n                        px_width=scan.field_widths[field_id],\n                        um_height=scan.field_heights_in_microns[field_id],\n                        um_width=scan.field_widths_in_microns[field_id],\n                        field_x=x_zero\n                        + scan._degrees_to_microns(scan.fields[field_id].x)\n                        if x_zero\n                        else None,\n                        field_y=y_zero\n                        + scan._degrees_to_microns(scan.fields[field_id].y)\n                        if y_zero\n                        else None,\n                        field_z=z_zero + scan.fields[field_id].depth\n                        if z_zero\n                        else None,\n                        delay_image=scan.field_offsets[field_id],\n                        roi=scan.field_rois[field_id][0],\n                    )\n                    for field_id in range(scan.num_fields)\n                ]\n            )\n        else:\n            self.Field.insert(\n                [\n                    dict(\n                        key,\n                        field_idx=plane_idx,\n                        px_height=scan.image_height,\n                        px_width=scan.image_width,\n                        um_height=getattr(scan, \"image_height_in_microns\", None),\n                        um_width=getattr(scan, \"image_width_in_microns\", None),\n                        field_x=x_zero if x_zero else None,\n                        field_y=y_zero if y_zero else None,\n                        field_z=z_zero + scan.scanning_depths[plane_idx]\n                        if z_zero\n                        else None,\n                        delay_image=scan.field_offsets[plane_idx],\n                    )\n                    for plane_idx in range(scan.num_scanning_depths)\n                ]\n            )\n    elif acq_software == \"Scanbox\":\n        import sbxreader\n\n        # Read the scan\n        scan_filepaths = get_image_files(key, \"*.sbx\")\n        sbx_meta = sbxreader.sbx_get_metadata(scan_filepaths[0])\n        sbx_matinfo = sbxreader.sbx_get_info(scan_filepaths[0])\n        is_multiROI = bool(\n            sbx_matinfo.mesoscope.enabled\n        )  # currently not handling \"multiROI\" ingestion\n\n        if is_multiROI:\n            raise NotImplementedError(\n                \"Loading routine not implemented for Scanbox multiROI scan mode\"\n            )\n\n        # Insert in ScanInfo\n        x_zero, y_zero, z_zero = sbx_meta[\"stage_pos\"]\n        self.insert1(\n            dict(\n                key,\n                nfields=sbx_meta[\"num_fields\"]\n                if is_multiROI\n                else sbx_meta[\"num_planes\"],\n                nchannels=sbx_meta[\"num_channels\"],\n                nframes=sbx_meta[\"num_frames\"],\n                ndepths=sbx_meta[\"num_planes\"],\n                x=x_zero,\n                y=y_zero,\n                z=z_zero,\n                fps=sbx_meta[\"frame_rate\"],\n                bidirectional=sbx_meta == \"bidirectional\",\n                nrois=sbx_meta[\"num_rois\"] if is_multiROI else 0,\n                scan_duration=(sbx_meta[\"num_frames\"] / sbx_meta[\"frame_rate\"]),\n            )\n        )\n        # Insert Field(s)\n        if not is_multiROI:\n            px_width, px_height = sbx_meta[\"frame_size\"]\n            self.Field.insert(\n                [\n                    dict(\n                        key,\n                        field_idx=plane_idx,\n                        px_height=px_height,\n                        px_width=px_width,\n                        um_height=px_height * sbx_meta[\"um_per_pixel_y\"]\n                        if sbx_meta[\"um_per_pixel_y\"]\n                        else None,\n                        um_width=px_width * sbx_meta[\"um_per_pixel_x\"]\n                        if sbx_meta[\"um_per_pixel_x\"]\n                        else None,\n                        field_x=x_zero,\n                        field_y=y_zero,\n                        field_z=z_zero + sbx_meta[\"etl_pos\"][plane_idx],\n                    )\n                    for plane_idx in range(sbx_meta[\"num_planes\"])\n                ]\n            )\n    elif acq_software == \"NIS\":\n        import nd2\n\n        # Read the scan\n        scan_filepaths = get_image_files(key, \"*.nd2\")\n        nd2_file = nd2.ND2File(scan_filepaths[0])\n        is_multiROI = False  # MultiROI to be implemented later\n\n        # Frame per second\n        try:\n            fps = 1000 / nd2_file.experiment[0].parameters.periods[0].periodDiff.avg\n        except:  # noqa: E722\n            fps = 1000 / nd2_file.experiment[0].parameters.periodDiff.avg\n\n        # Estimate ND2 file scan duration\n        def estimate_nd2_scan_duration(nd2_scan_obj):\n            # Calculates scan duration for Nikon images\n            ti = (\n                nd2_scan_obj.frame_metadata(0)\n                .channels[0]\n                .time.absoluteJulianDayNumber\n            )  # Initial frame's JD.\n            tf = (\n                nd2_scan_obj.frame_metadata(nd2_scan_obj.shape[0] - 1)\n                .channels[0]\n                .time.absoluteJulianDayNumber\n            )  # Final frame's JD.\n\n            return (tf - ti) * 86400 + 1 / fps\n\n        scan_duration = sum(\n            estimate_nd2_scan_duration(nd2.ND2File(f)) for f in scan_filepaths\n        )\n\n        try:\n            scan_datetime = nd2_file.text_info[\"date\"]\n            scan_datetime = datetime.strptime(\n                scan_datetime,\n                \"%m/%d/%Y %H:%M:%S %p\"\n                if re.search((\"AM|PM\"), scan_datetime)\n                else \"%m/%d/%Y %H:%M:%S\",\n            )\n            scan_datetime = datetime.strftime(scan_datetime, \"%Y-%m-%d %H:%M:%S\")\n        except:  # noqa: E722\n            scan_datetime = None\n\n        # Insert in ScanInfo\n        self.insert1(\n            dict(\n                key,\n                nfields=nd2_file.sizes.get(\"P\", 1),\n                nchannels=nd2_file.attributes.channelCount,\n                nframes=nd2_file.metadata.contents.frameCount,\n                ndepths=nd2_file.sizes.get(\"Z\", 1),\n                x=None,\n                y=None,\n                z=None,\n                fps=fps,\n                bidirectional=bool(\n                    nd2_file.custom_data[\"GrabberCameraSettingsV1_0\"][\n                        \"GrabberCameraSettings\"\n                    ][\"PropertiesQuality\"][\"ScanDirection\"]\n                ),\n                nrois=0,\n                scan_datetime=scan_datetime,\n                scan_duration=scan_duration,\n            )\n        )\n\n        # MultiROI to be implemented later\n\n        # Insert in Field\n        if not is_multiROI:\n            self.Field.insert(\n                [\n                    dict(\n                        key,\n                        field_idx=plane_idx,\n                        px_height=nd2_file.attributes.heightPx,\n                        px_width=nd2_file.attributes.widthPx,\n                        um_height=nd2_file.attributes.heightPx\n                        * nd2_file.voxel_size().y,\n                        um_width=nd2_file.attributes.widthPx\n                        * nd2_file.voxel_size().x,\n                        field_x=None,\n                        field_y=None,\n                        field_z=None,\n                    )\n                    for plane_idx in range(nd2_file.sizes.get(\"Z\", 1))\n                ]\n            )\n    elif acq_software == \"PrairieView\":\n        from element_interface import prairieviewreader\n\n        scan_filepaths = get_image_files(key, \"*.tif\")\n        PVScan_info = prairieviewreader.get_pv_metadata(scan_filepaths[0])\n        self.insert1(\n            dict(\n                key,\n                nfields=PVScan_info[\"num_fields\"],\n                nchannels=PVScan_info[\"num_channels\"],\n                ndepths=PVScan_info[\"num_planes\"],\n                nframes=PVScan_info[\"num_frames\"],\n                nrois=PVScan_info[\"num_rois\"],\n                x=PVScan_info[\"x_pos\"],\n                y=PVScan_info[\"y_pos\"],\n                z=PVScan_info[\"z_pos\"],\n                fps=PVScan_info[\"frame_rate\"],\n                bidirectional=PVScan_info[\"bidirectional\"],\n                bidirectional_z=PVScan_info[\"bidirectional_z\"],\n                usecs_per_line=PVScan_info[\"usecs_per_line\"],\n                scan_datetime=PVScan_info[\"scan_datetime\"],\n                scan_duration=PVScan_info[\"scan_duration\"],\n            )\n        )\n\n        self.Field.insert(\n            dict(\n                key,\n                field_idx=plane_idx,\n                px_height=PVScan_info[\"height_in_pixels\"],\n                px_width=PVScan_info[\"width_in_pixels\"],\n                um_height=PVScan_info[\"height_in_um\"],\n                um_width=PVScan_info[\"width_in_um\"],\n                field_x=PVScan_info[\"fieldX\"],\n                field_y=PVScan_info[\"fieldY\"],\n                field_z=PVScan_info[\"fieldZ\"]\n                if PVScan_info[\"num_planes\"] == 1\n                else PVScan_info[\"fieldZ\"][plane_idx],\n            )\n            for plane_idx in range(PVScan_info[\"num_planes\"])\n        )\n    else:\n        raise NotImplementedError(\n            f\"Loading routine not implemented for {acq_software} \"\n            \"acquisition software\"\n        )\n\n    # Insert file(s)\n    root_dir = find_root_directory(get_imaging_root_data_dir(), scan_filepaths[0])\n\n    scan_files = [\n        pathlib.Path(f).relative_to(root_dir).as_posix() for f in scan_filepaths\n    ]\n    self.ScanFile.insert([{**key, \"file_path\": f} for f in scan_files])\n</code></pre>"}, {"location": "api/element_calcium_imaging/scan/#element_calcium_imaging.scan.ScanQualityMetrics", "title": "<code>ScanQualityMetrics</code>", "text": "<p>         Bases: <code>dj.Computed</code></p> <p>Metrics to assess the quality of the scan.</p> <p>Attributes:</p> Name Type Description <code>ScanInfo.Field</code> <code>foreign key</code> <p>Primary key from ScanInfo.Field.</p> Source code in <code>element_calcium_imaging/scan.py</code> <pre><code>@schema\nclass ScanQualityMetrics(dj.Computed):\n\"\"\"Metrics to assess the quality of the scan.\n\n    Attributes:\n        ScanInfo.Field (foreign key): Primary key from ScanInfo.Field.\n    \"\"\"\n\n    definition = \"\"\"\n    -&gt; ScanInfo.Field\n    \"\"\"\n\n    class Frames(dj.Part):\n\"\"\"Metrics used to evaluate each frame.\n\n        Attributes:\n            ScanInfo.Field (foreign key): Primary key from ScanInfo.Field.\n            Channel (foreign key): Primary key from Channel.\n            min_intensity (longblob): Minimum value of each frame.\n            mean_intensity (longblob): Mean value of each frame.\n            max_intensity (longblob): Maximum value of each frame.\n            contrast (longblob): Contrast of each frame (i.e. difference between the 99 and 1 percentiles)\n        \"\"\"\n\n        definition = \"\"\"\n        -&gt; master\n        -&gt; Channel\n        ---\n        min_intensity: longblob   # Minimum value of each frame.\n        mean_intensity: longblob  # Mean value of each frame.\n        max_intensity: longblob   # Maximum value of each frame.\n        contrast: longblob        # Contrast of each frame (i.e. difference between the 99 and 1 percentiles)\n        \"\"\"\n\n    def make(self, key):\n        acq_software, nchannels = (Scan * ScanInfo &amp; key).fetch1(\n            \"acq_software\", \"nchannels\"\n        )\n\n        if acq_software == \"ScanImage\":\n            import scanreader\n\n            # Switch from FYXCT to TCYX\n            data = scanreader.read_scan(get_image_files(key, \"*.tif\"))[\n                key[\"field_idx\"]\n            ].transpose(3, 2, 0, 1)\n        elif acq_software == \"Scanbox\":\n            from sbxreader import sbx_memmap\n\n            # Switch from TFCYX to TCYX\n            data = sbx_memmap(get_image_files(key, \"*.sbx\"))[:, key[\"field_idx\"]]\n        elif acq_software == \"NIS\":\n            import nd2\n\n            nd2_file = nd2.ND2File(get_image_files(key, \"*.nd2\")[0])\n\n            nd2_dims = {k: i for i, k in enumerate(nd2_file.sizes)}\n\n            valid_dimensions = \"TZCYX\"\n            assert set(nd2_dims) &lt;= set(\n                valid_dimensions\n            ), f\"Unknown dimensions {set(nd2_dims)-set(valid_dimensions)} in file {get_image_files(key, '*.nd2')[0]}.\"\n\n            # Sort the dimensions in the order of TZCYX, skipping the missing ones.\n            data = nd2_file.asarray().transpose(\n                [nd2_dims[x] for x in valid_dimensions if x in nd2_dims]\n            )\n\n            # Expand array to include the missing dimensions.\n            for i, dim in enumerate(\"TZC\"):\n                if dim not in nd2_dims:\n                    data = np.expand_dims(data, i)\n\n            data = data[:, key[\"field_idx\"]]  # Switch from TFCYX to TCYX\n\n        self.insert1(key)\n\n        for channel in range(nchannels):\n            movie = data[:, channel, :, :]\n\n            self.Frames.insert1(\n                dict(\n                    key,\n                    channel=channel,\n                    min_intensity=movie.min(axis=(1, 2)),\n                    mean_intensity=movie.mean(axis=(1, 2)),\n                    max_intensity=movie.max(axis=(1, 2)),\n                    contrast=np.percentile(movie, 99, axis=(1, 2))\n                    - np.percentile(movie, 1, axis=(1, 2)),\n                )\n            )\n</code></pre>"}, {"location": "api/element_calcium_imaging/scan/#element_calcium_imaging.scan.ScanQualityMetrics.Frames", "title": "<code>Frames</code>", "text": "<p>         Bases: <code>dj.Part</code></p> <p>Metrics used to evaluate each frame.</p> <p>Attributes:</p> Name Type Description <code>ScanInfo.Field</code> <code>foreign key</code> <p>Primary key from ScanInfo.Field.</p> <code>Channel</code> <code>foreign key</code> <p>Primary key from Channel.</p> <code>min_intensity</code> <code>longblob</code> <p>Minimum value of each frame.</p> <code>mean_intensity</code> <code>longblob</code> <p>Mean value of each frame.</p> <code>max_intensity</code> <code>longblob</code> <p>Maximum value of each frame.</p> <code>contrast</code> <code>longblob</code> <p>Contrast of each frame (i.e. difference between the 99 and 1 percentiles)</p> Source code in <code>element_calcium_imaging/scan.py</code> <pre><code>class Frames(dj.Part):\n\"\"\"Metrics used to evaluate each frame.\n\n    Attributes:\n        ScanInfo.Field (foreign key): Primary key from ScanInfo.Field.\n        Channel (foreign key): Primary key from Channel.\n        min_intensity (longblob): Minimum value of each frame.\n        mean_intensity (longblob): Mean value of each frame.\n        max_intensity (longblob): Maximum value of each frame.\n        contrast (longblob): Contrast of each frame (i.e. difference between the 99 and 1 percentiles)\n    \"\"\"\n\n    definition = \"\"\"\n    -&gt; master\n    -&gt; Channel\n    ---\n    min_intensity: longblob   # Minimum value of each frame.\n    mean_intensity: longblob  # Mean value of each frame.\n    max_intensity: longblob   # Maximum value of each frame.\n    contrast: longblob        # Contrast of each frame (i.e. difference between the 99 and 1 percentiles)\n    \"\"\"\n</code></pre>"}, {"location": "api/element_calcium_imaging/plotting/cell_plot/", "title": "cell_plot.py", "text": ""}, {"location": "api/element_calcium_imaging/plotting/cell_plot/#element_calcium_imaging.plotting.cell_plot.mask_overlayed_image", "title": "<code>mask_overlayed_image(image, mask_xpix, mask_ypix, cell_mask_ids, low_q=0, high_q=0.99)</code>", "text": "<p>Overlay transparent cell masks on average image.</p> Source code in <code>element_calcium_imaging/plotting/cell_plot.py</code> <pre><code>def mask_overlayed_image(\n    image, mask_xpix, mask_ypix, cell_mask_ids, low_q=0, high_q=0.99\n):\n\"\"\"Overlay transparent cell masks on average image.\"\"\"\n\n    q_min, q_max = np.quantile(image, [low_q, high_q])\n    image = np.clip(image, q_min, q_max)\n    image = (image - q_min) / (q_max - q_min)\n\n    SATURATION = 0.7\n    image = image[:, :, None] * np.array([0, 0, 1])\n    maskid_image = np.full(image.shape[:2], -1)\n    for xpix, ypix, roi_id in zip(mask_xpix, mask_ypix, cell_mask_ids):\n        image[ypix, xpix, :2] = [np.random.rand(), SATURATION]\n        maskid_image[ypix, xpix] = roi_id\n    image = (colors.hsv_to_rgb(image) * 255).astype(int)\n    return image, maskid_image\n</code></pre>"}, {"location": "api/element_calcium_imaging/plotting/cell_plot/#element_calcium_imaging.plotting.cell_plot.get_tracelayout", "title": "<code>get_tracelayout(key, width=600, height=600)</code>", "text": "<p>Returns a dictionary of layout settings for the trace figures.</p> Source code in <code>element_calcium_imaging/plotting/cell_plot.py</code> <pre><code>def get_tracelayout(key, width=600, height=600) -&gt; dict:\n\"\"\"Returns a dictionary of layout settings for the trace figures.\"\"\"\n    text = f\"Trace for Cell {key['mask']}\" if isinstance(key, dict) else \"Trace\"\n\n    return dict(\n        margin=dict(l=0, r=0, b=0, t=65, pad=0),\n        width=width,\n        height=height,\n        transition={\"duration\": 0},\n        title={\n            \"text\": text,\n            \"xanchor\": \"center\",\n            \"yanchor\": \"top\",\n            \"y\": 0.97,\n            \"x\": 0.5,\n        },\n        xaxis={\n            \"title\": \"Time (sec)\",\n            \"visible\": True,\n            \"showticklabels\": True,\n            \"showgrid\": True,\n        },\n        yaxis={\n            \"title\": \"Fluorescence (a.u.)\",\n            \"visible\": True,\n            \"showticklabels\": True,\n            \"showgrid\": True,\n            \"anchor\": \"free\",\n            \"overlaying\": \"y\",\n            \"side\": \"left\",\n            \"position\": 0,\n        },\n        yaxis2={\n            \"title\": \"Calcium Event (a.u.)\",\n            \"visible\": True,\n            \"showticklabels\": True,\n            \"showgrid\": True,\n            \"anchor\": \"free\",\n            \"overlaying\": \"y\",\n            \"side\": \"right\",\n            \"position\": 1,\n        },\n        shapes=[\n            go.layout.Shape(\n                type=\"rect\",\n                xref=\"paper\",\n                yref=\"paper\",\n                x0=0,\n                y0=0,\n                x1=1.0,\n                y1=1.0,\n                line={\"width\": 1, \"color\": \"black\"},\n            )\n        ],\n        legend={\n            \"traceorder\": \"normal\",\n            \"yanchor\": \"top\",\n            \"y\": 0.99,\n            \"xanchor\": \"right\",\n            \"x\": 0.99,\n        },\n        plot_bgcolor=\"rgba(0,0,0,0.05)\",\n        modebar_remove=[\n            \"zoom\",\n            \"resetScale\",\n            \"pan\",\n            \"select\",\n            \"zoomIn\",\n            \"zoomOut\",\n            \"autoScale2d\",\n        ],\n    )\n</code></pre>"}, {"location": "api/element_calcium_imaging/plotting/cell_plot/#element_calcium_imaging.plotting.cell_plot.figure_data", "title": "<code>figure_data(imaging, segmentation_key)</code>", "text": "<p>Prepare the images for a given segmentation_key.</p> <p>Parameters:</p> Name Type Description Default <code>imaging</code> <code>dj.Table</code> <p>imaging table.</p> required <code>segmentation_key</code> <code>dict</code> <p>A primary key from Segmentation table.</p> required <p>Returns:</p> Name Type Description <code>background_with_cells</code> <code>np.array</code> <p>Average image with transparently overlayed cells.</p> <code>cells_maskid_image</code> <code>np.array</code> <p>Mask ID image.</p> Source code in <code>element_calcium_imaging/plotting/cell_plot.py</code> <pre><code>def figure_data(imaging, segmentation_key) -&gt; Tuple[np.array, np.array]:\n\"\"\"Prepare the images for a given segmentation_key.\n\n    Args:\n        imaging (dj.Table): imaging table.\n        segmentation_key (dict): A primary key from Segmentation table.\n\n    Returns:\n        background_with_cells (np.array): Average image with transparently overlayed\n            cells.\n        cells_maskid_image (np.array): Mask ID image.\n    \"\"\"\n\n    image = (imaging.MotionCorrection.Summary &amp; segmentation_key).fetch1(\n        \"average_image\"\n    )\n\n    cell_mask_ids, mask_xpix, mask_ypix = (\n        imaging.Segmentation.Mask * imaging.MaskClassification.MaskType\n        &amp; segmentation_key\n    ).fetch(\"mask\", \"mask_xpix\", \"mask_ypix\")\n\n    background_with_cells, cells_maskid_image = mask_overlayed_image(\n        image, mask_xpix, mask_ypix, cell_mask_ids, low_q=0, high_q=0.99\n    )\n\n    return background_with_cells, cells_maskid_image\n</code></pre>"}, {"location": "api/element_calcium_imaging/plotting/cell_plot/#element_calcium_imaging.plotting.cell_plot.plot_cell_overlayed_image", "title": "<code>plot_cell_overlayed_image(imaging, segmentation_key)</code>", "text": "<p>summary</p> <p>Parameters:</p> Name Type Description Default <code>imaging</code> <code>dj.Table</code> <p>imaging table.</p> required <code>segmentation_key</code> <code>dict</code> <p>A primary key from Segmentation table.</p> required <p>Returns:</p> Name Type Description <code>image_fig</code> <code>plotly.Fig</code> <p>Plotly figure object of the average image with transparently overlayed cells.</p> Source code in <code>element_calcium_imaging/plotting/cell_plot.py</code> <pre><code>def plot_cell_overlayed_image(imaging, segmentation_key) -&gt; go.Figure:\n\"\"\"_summary_\n\n    Args:\n        imaging (dj.Table): imaging table.\n        segmentation_key (dict): A primary key from Segmentation table.\n\n    Returns:\n        image_fig (plotly.Fig): Plotly figure object of the average image with\n            transparently overlayed cells.\n    \"\"\"\n\n    background_with_cells, cells_maskid_image = figure_data(imaging, segmentation_key)\n\n    image_fig = go.Figure(\n        go.Image(\n            z=background_with_cells,\n            hovertemplate=\"x: %{x} &lt;br&gt;y: %{y} &lt;br&gt;mask_id: %{customdata}\",\n            customdata=cells_maskid_image,\n        )\n    )\n    image_fig.update_layout(\n        title=\"Average Image with Cells\",\n        xaxis={\n            \"title\": \"X (px)\",\n            \"visible\": True,\n            \"showticklabels\": True,\n            \"showgrid\": False,\n        },\n        yaxis={\n            \"title\": \"Y (px)\",\n            \"visible\": True,\n            \"showticklabels\": True,\n            \"showgrid\": False,\n        },\n        paper_bgcolor=\"rgba(0,0,0,0)\",\n        plot_bgcolor=\"rgba(0,0,0,0)\",\n    )\n\n    return image_fig\n</code></pre>"}, {"location": "api/element_calcium_imaging/plotting/cell_plot/#element_calcium_imaging.plotting.cell_plot.plot_cell_traces", "title": "<code>plot_cell_traces(imaging, cell_key)</code>", "text": "<p>Prepare plotly trace figure.</p> <p>Parameters:</p> Name Type Description Default <code>imaging</code> <code>dj.Table</code> <p>imaging table.</p> required <code>cell_key</code> <code>dict</code> <p>A primary key from imaging.Activity.Trace table.</p> required <p>Returns:</p> Name Type Description <code>trace_fig</code> <code>go.Figure</code> <p>Plotly figure object of the traces.</p> Source code in <code>element_calcium_imaging/plotting/cell_plot.py</code> <pre><code>def plot_cell_traces(imaging, cell_key) -&gt; go.Figure:\n\"\"\"Prepare plotly trace figure.\n\n    Args:\n        imaging (dj.Table): imaging table.\n        cell_key (dict): A primary key from imaging.Activity.Trace table.\n\n    Returns:\n        trace_fig: Plotly figure object of the traces.\n    \"\"\"\n    activity_trace = (\n        imaging.Activity.Trace &amp; \"extraction_method LIKE '%deconvolution'\" &amp; cell_key\n    ).fetch1(\"activity_trace\")\n    fluorescence, fps = (scan.ScanInfo * imaging.Fluorescence.Trace &amp; cell_key).fetch1(\n        \"fluorescence\", \"fps\"\n    )\n\n    trace_fig = go.Figure(\n        [\n            go.Scatter(\n                x=np.arange(len(fluorescence)) / fps,\n                y=fluorescence,\n                name=\"Fluorescence\",\n                yaxis=\"y1\",\n            ),\n            go.Scatter(\n                x=np.arange(len(activity_trace)) / fps,\n                y=activity_trace,\n                name=\"Calcium Event\",\n                yaxis=\"y2\",\n            ),\n        ]\n    )\n\n    trace_fig.update_layout(get_tracelayout(cell_key))\n\n    return trace_fig\n</code></pre>"}, {"location": "api/element_calcium_imaging/plotting/widget/", "title": "widget.py", "text": ""}, {"location": "api/element_calcium_imaging/plotting/widget/#element_calcium_imaging.plotting.widget.main", "title": "<code>main(imaging, usedb=False)</code>", "text": "<p>Display the widget.</p> <p>Parameters:</p> Name Type Description Default <code>imaging</code> <code>dj.Table</code> <p>imaging table in the database.</p> required <code>usedb</code> <code>bool</code> <p>Whether to use the figures in the database or compute the figures on the fly.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>widget</code> <code>wg</code> <p>Widget to display the figures.</p> Source code in <code>element_calcium_imaging/plotting/widget.py</code> <pre><code>def main(imaging: ModuleType, usedb: bool = False) -&gt; wg:\n\"\"\"Display the widget.\n\n    Args:\n        imaging (dj.Table): imaging table in the database.\n        usedb (bool, optional): Whether to use the figures in the database or compute\n            the figures on the fly.\n\n    Returns:\n        widget: Widget to display the figures.\n    \"\"\"\n\n    motioncorrection_dropdown = wg.Dropdown(\n        options=imaging.Segmentation.fetch(\"KEY\"),\n        description=\"Result:\",\n        description_tooltip='Press \"Load\" to visualize the cells identified.',\n        disabled=False,\n        layout=wg.Layout(\n            width=\"95%\",\n            display=\"flex\",\n            flex_flow=\"row\",\n            justify_content=\"space-between\",\n            grid_area=\"motioncorrection_dropdown\",\n        ),\n        style={\"description_width\": \"80px\"},\n    )\n\n    load_button = wg.Button(\n        description=\"Load Image\",\n        tooltip=\"Load the average image.\",\n        layout=wg.Layout(width=\"120px\", grid_area=\"load_button\"),\n    )\n\n    FIG1_WIDTH = 600\n    FIG1_LAYOUT = go.Layout(\n        margin=dict(l=0, r=40, b=0, t=65, pad=0),\n        width=FIG1_WIDTH,\n        height=600,\n        transition={\"duration\": 0},\n        title={\n            \"text\": \"Average Image with Cells\",\n            \"xanchor\": \"center\",\n            \"yanchor\": \"top\",\n            \"y\": 0.97,\n            \"x\": 0.5,\n        },\n        xaxis={\n            \"title\": \"X (px)\",\n            \"visible\": True,\n            \"showticklabels\": True,\n            \"showgrid\": False,\n        },\n        yaxis={\n            \"title\": \"Y (px)\",\n            \"visible\": True,\n            \"showticklabels\": True,\n            \"showgrid\": False,\n        },\n        paper_bgcolor=\"rgba(0,0,0,0)\",\n        plot_bgcolor=\"rgba(0,0,0,0)\",\n        modebar_remove=[\n            \"zoom\",\n            \"resetScale\",\n            \"pan\",\n            \"select\",\n            \"zoomIn\",\n            \"zoomOut\",\n            \"autoScale2d\",\n        ],\n        shapes=[\n            go.layout.Shape(\n                type=\"rect\",\n                xref=\"paper\",\n                yref=\"paper\",\n                x0=0.035,\n                y0=0,\n                x1=0.965,\n                y1=1.0,\n                line={\"width\": 1, \"color\": \"black\"},\n            )\n        ],\n    )\n    fig1 = go.Figure(\n        go.Image(\n            z=None,\n            hovertemplate=\"x: %{x} &lt;br&gt;y: %{y} &lt;br&gt;mask_id: %{customdata} &lt;extra&gt;&lt;/extra&gt;\",\n            customdata=None,\n        ),\n        layout=FIG1_LAYOUT,\n    )\n\n    FIG2_WIDTH = 600\n    FIG2_HEIGHT = 600\n    fig2_layout = cell_plot.get_tracelayout(None, width=FIG2_WIDTH, height=FIG2_HEIGHT)\n\n    fig2 = go.Figure(\n        [\n            go.Scatter(\n                x=None,\n                y=None,\n                name=\"Fluorescence\",\n                yaxis=\"y1\",\n            ),\n            go.Scatter(x=None, y=None, name=\"Calcium Event\", yaxis=\"y2\"),\n        ],\n        layout=fig2_layout,\n    )\n\n    fig1_widget = go.FigureWidget(fig1)\n    fig2_widget = go.FigureWidget(fig2)\n\n    def tooltip_click(trace, points, selector):\n        mask_id = trace.customdata[points.ys[0]][points.xs[0]]\n\n        if mask_id &gt; -1:\n            cell_traces_figobj = from_json(\n                (\n                    TraceReport &amp; motioncorrection_dropdown.value &amp; f\"mask='{mask_id}'\"\n                ).fetch1(\"cell_traces\")\n            )\n\n            with fig2_widget.batch_update():\n                fig2_widget.data[0].x = cell_traces_figobj.data[0].x\n                fig2_widget.data[0].y = cell_traces_figobj.data[0].y\n                fig2_widget.data[0].name = cell_traces_figobj.data[0].name\n                fig2_widget.data[1].x = cell_traces_figobj.data[1].x\n                fig2_widget.data[1].y = cell_traces_figobj.data[1].y\n                fig2_widget.data[1].name = cell_traces_figobj.data[1].name\n                fig2_widget.layout[\"title\"] = {\n                    \"text\": f\"Trace for Cell {mask_id}\",\n                    \"xanchor\": \"center\",\n                    \"yanchor\": \"top\",\n                    \"y\": 0.97,\n                    \"x\": 0.5,\n                }\n\n    def response(change, usedb=False):\n        if usedb:\n            cell_overlayed_image = from_json(\n                (ScanLevelReport &amp; motioncorrection_dropdown.value).fetch1(\n                    \"cell_overlayed_image\"\n                )\n            )\n\n            with fig1_widget.batch_update():\n                fig1_widget.data[0].z = cell_overlayed_image.data[0].z\n                fig1_widget.data[0].customdata = cell_overlayed_image.data[0].customdata\n\n                fig2_widget.data[0].x = None\n                fig2_widget.data[0].y = None\n                fig2_widget.data[1].x = None\n                fig2_widget.data[1].y = None\n        else:\n            background_with_cells, cells_maskid_image = cell_plot.figure_data(\n                imaging, motioncorrection_dropdown.value\n            )\n\n            with fig1_widget.batch_update():\n                fig1_widget.data[0].z = background_with_cells\n                fig1_widget.data[0].customdata = cells_maskid_image\n\n                fig2_widget.layout.title = {\n                    \"text\": \"Trace\",\n                    \"xanchor\": \"center\",\n                    \"yanchor\": \"top\",\n                    \"y\": 0.97,\n                    \"x\": 0.5,\n                }\n                fig2_widget.data[0].x = None\n                fig2_widget.data[0].y = None\n                fig2_widget.data[1].x = None\n                fig2_widget.data[1].y = None\n\n    fig1_widget.data[0].on_click(tooltip_click)\n    load_button.on_click(partial(response, usedb=usedb))\n\n    return wg.VBox(\n        [\n            wg.HBox(\n                [motioncorrection_dropdown, load_button],\n                layout=wg.Layout(width=f\"{FIG1_WIDTH+FIG2_WIDTH}px\"),\n            ),\n            wg.HBox([fig1_widget, fig2_widget]),\n        ]\n    )\n</code></pre>"}, {"location": "api/element_calcium_imaging/plotting/widget/#element_calcium_imaging.plotting.widget.ScanLevelReport", "title": "<code>ScanLevelReport</code>", "text": "<p>         Bases: <code>dj.Computed</code></p> <p>Scan level report with figures.</p> <p>Attributes:</p> Name Type Description <code>imaging.Segmentation</code> <code>foreign key</code> <p>Primary key from imaging.Segmentation.</p> <code>cell_overlayed_image</code> <code>longblob</code> <p>Plotly figure object showing the segmented cells on the average image.</p> Source code in <code>element_calcium_imaging/imaging_report.py</code> <pre><code>@schema\nclass ScanLevelReport(dj.Computed):\n\"\"\"Scan level report with figures.\n\n    Attributes:\n        imaging.Segmentation (foreign key): Primary key from imaging.Segmentation.\n        cell_overlayed_image (longblob): Plotly figure object showing the segmented\n            cells on the average image.\n    \"\"\"\n\n    definition = \"\"\"\n    -&gt; imaging.Segmentation\n    ---\n    cell_overlayed_image: longblob\n    \"\"\"\n\n    def make(self, key):\n\"\"\"Compute and ingest the plotly figure objects.\"\"\"\n\n        image_fig = cell_plot.plot_cell_overlayed_image(imaging, key)\n        self.insert1({**key, \"cell_overlayed_image\": image_fig.to_json()})\n</code></pre>"}, {"location": "api/element_calcium_imaging/plotting/widget/#element_calcium_imaging.imaging_report.ScanLevelReport.make", "title": "<code>make(key)</code>", "text": "<p>Compute and ingest the plotly figure objects.</p> Source code in <code>element_calcium_imaging/imaging_report.py</code> <pre><code>def make(self, key):\n\"\"\"Compute and ingest the plotly figure objects.\"\"\"\n\n    image_fig = cell_plot.plot_cell_overlayed_image(imaging, key)\n    self.insert1({**key, \"cell_overlayed_image\": image_fig.to_json()})\n</code></pre>"}, {"location": "api/element_calcium_imaging/plotting/widget/#element_calcium_imaging.plotting.widget.TraceReport", "title": "<code>TraceReport</code>", "text": "<p>         Bases: <code>dj.Computed</code></p> <p>Figures of traces.</p> <p>Attributes:</p> Name Type Description <code>imaging.Segmentation.Mask</code> <code>foreign key</code> <p>Primary key from imaging.Segmentation.Mask.</p> <code>cell_traces</code> <code>longblob</code> <p>Plotly figure object showing the cell traces.</p> Source code in <code>element_calcium_imaging/imaging_report.py</code> <pre><code>@schema\nclass TraceReport(dj.Computed):\n\"\"\"Figures of traces.\n\n    Attributes:\n        imaging.Segmentation.Mask (foreign key): Primary key from\n            imaging.Segmentation.Mask.\n        cell_traces (longblob): Plotly figure object showing the cell traces.\n    \"\"\"\n\n    definition = \"\"\"\n    -&gt; imaging.Segmentation.Mask\n    ---\n    cell_traces: longblob\n    \"\"\"\n\n    @property\n    def key_source(self):\n\"\"\"Limit the TraceReport to Masks that have Activity table populated.\n        database.\"\"\"\n\n        return imaging.Segmentation.Mask &amp; imaging.Activity\n\n    def make(self, key):\n\"\"\"Compute and ingest the plotly figure objects.\"\"\"\n\n        trace_fig = cell_plot.plot_cell_traces(imaging, key)\n        self.insert1({**key, \"cell_traces\": trace_fig.to_json()})\n</code></pre>"}, {"location": "api/element_calcium_imaging/plotting/widget/#element_calcium_imaging.imaging_report.TraceReport.key_source", "title": "<code>key_source</code>  <code>property</code>", "text": "<p>Limit the TraceReport to Masks that have Activity table populated. database.</p>"}, {"location": "api/element_calcium_imaging/plotting/widget/#element_calcium_imaging.imaging_report.TraceReport.make", "title": "<code>make(key)</code>", "text": "<p>Compute and ingest the plotly figure objects.</p> Source code in <code>element_calcium_imaging/imaging_report.py</code> <pre><code>def make(self, key):\n\"\"\"Compute and ingest the plotly figure objects.\"\"\"\n\n    trace_fig = cell_plot.plot_cell_traces(imaging, key)\n    self.insert1({**key, \"cell_traces\": trace_fig.to_json()})\n</code></pre>"}, {"location": "tutorials/", "title": "Tutorials", "text": "<ul> <li>Element Calcium Imaging includes an interactive tutorial on GitHub Codespaces, which is configured for users to run the pipeline.</li> </ul> <ul> <li>DataJoint Elements are modular and can be connected into a complete pipeline.  In the interactive tutorial are example Jupyter notebooks that combine five DataJoint Elements - Lab, Animal, Session, Event, and Calcium Imaging.  The notebooks describe the pipeline and provide instructions for running the pipeline.  For convenience, these notebooks are also rendered on this website:<ul> <li>Tutorial notebook</li> <li>Quality metrics notebook</li> </ul> </li> </ul>"}, {"location": "tutorials/#installation-instructions-for-active-projects", "title": "Installation Instructions for Active Projects", "text": "<ul> <li>The Element Calcium Imaging described above can be modified for a user's specific experimental requirements and thereby used in active projects.  </li> </ul> <ul> <li>The GitHub Codespace and Dev Container is configured for tutorials and prototyping. We recommend users to configure a database specifically for production pipelines.  Instructions for a local installation of the integrated development environment with a database can be found on the User Guide page.</li> </ul>"}, {"location": "tutorials/#videos", "title": "Videos", "text": "<ul> <li>The YouTube tutorial gives an overview  of the workflow files and notebooks, as well as core concepts related to calcium imaging analysis.</li> </ul>"}, {"location": "tutorials/#extract", "title": "EXTRACT", "text": "<ul> <li>Analysis with the EXTRACT package is currently supported for single channel, single plane scans using Suite2p for motion correction. For processing with EXTRACT, please set <code>processing_method=\"extract\"</code> in the ProcessingParamSet table, and provide the <code>params</code> attribute of the ProcessingParamSet table in the <code>{'suite2p': {...}, 'extract': {...}}</code> dictionary format. Please also install the MATLAB engine API for Python.</li> </ul>"}, {"location": "tutorials/quality_metrics/", "title": "Quality Metrics Notebook", "text": "In\u00a0[1]: Copied! <pre>import datetime\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tutorial_pipeline import scan, imaging\n</pre> import datetime import numpy as np import matplotlib.pyplot as plt from tutorial_pipeline import scan, imaging <pre>[2023-06-05 21:19:02,761][WARNING]: lab.Project and related tables will be removed in a future version of Element Lab. Please use the project schema.\n[2023-06-05 21:19:02,765][INFO]: Connecting root@fakeservices.datajoint.io:3306\n[2023-06-05 21:19:02,773][INFO]: Connected root@fakeservices.datajoint.io:3306\n</pre> In\u00a0[2]: Copied! <pre>scan.ScanQualityMetrics.populate(display_progress=True)\nimaging.ProcessingQualityMetrics.populate(display_progress=True)\n</pre> scan.ScanQualityMetrics.populate(display_progress=True) imaging.ProcessingQualityMetrics.populate(display_progress=True) In\u00a0[3]: Copied! <pre>key = dict(\n    subject=\"subject1\",\n    session_datetime=datetime.datetime(2023, 5, 11, 12, 00, 00),\n    scan_id=0,\n    field_idx=0,\n    channel=0,\n)\n\nquery = scan.ScanQualityMetrics.Frames &amp; key\nquery\n</pre> key = dict(     subject=\"subject1\",     session_datetime=datetime.datetime(2023, 5, 11, 12, 00, 00),     scan_id=0,     field_idx=0,     channel=0, )  query = scan.ScanQualityMetrics.Frames &amp; key query Out[3]: <p>subject</p> <p>session_datetime</p> <p>scan_id</p> <p>field_idx</p> <p>channel</p> 0-based indexing <p>min_intensity</p> Minimum value of each frame. <p>mean_intensity</p> Mean value of each frame. <p>max_intensity</p> Maximum value of each frame. <p>contrast</p> Contrast of each frame (i.e. difference between the 99 and 1 percentiles) subject1 2023-05-11 12:00:00 0 0 0 =BLOB= =BLOB= =BLOB= =BLOB= <p>Total: 1</p> In\u00a0[4]: Copied! <pre>scan_metrics = query.fetch1()\n</pre> scan_metrics = query.fetch1() In\u00a0[5]: Copied! <pre>plt.plot(\n    range(len(scan_metrics[\"min_intensity\"])),\n    scan_metrics[\"min_intensity\"],\n    label=\"Minimum intensity\",\n    color=\"red\",\n)\n\nplt.plot(\n    range(len(scan_metrics[\"mean_intensity\"])),\n    scan_metrics[\"mean_intensity\"],\n    label=\"Mean intensity\",\n    color=\"green\",\n)\n\nplt.plot(\n    range(len(scan_metrics[\"max_intensity\"])),\n    scan_metrics[\"max_intensity\"],\n    label=\"Max intensity\",\n    color=\"black\",\n)\n\nplt.plot(\n    range(len(scan_metrics[\"contrast\"])),\n    scan_metrics[\"contrast\"],\n    label=\"Contrast\",\n    color=\"blue\",\n)\n\nplt.title(\"Scan quality metrics\")\nplt.xlabel(\"Frame (#)\")\nplt.ylabel(\"Intensity\")\nplt.legend(loc=\"center\", bbox_to_anchor=(0.5, -0.2), ncol=4)\nplt.show()\n</pre> plt.plot(     range(len(scan_metrics[\"min_intensity\"])),     scan_metrics[\"min_intensity\"],     label=\"Minimum intensity\",     color=\"red\", )  plt.plot(     range(len(scan_metrics[\"mean_intensity\"])),     scan_metrics[\"mean_intensity\"],     label=\"Mean intensity\",     color=\"green\", )  plt.plot(     range(len(scan_metrics[\"max_intensity\"])),     scan_metrics[\"max_intensity\"],     label=\"Max intensity\",     color=\"black\", )  plt.plot(     range(len(scan_metrics[\"contrast\"])),     scan_metrics[\"contrast\"],     label=\"Contrast\",     color=\"blue\", )  plt.title(\"Scan quality metrics\") plt.xlabel(\"Frame (#)\") plt.ylabel(\"Intensity\") plt.legend(loc=\"center\", bbox_to_anchor=(0.5, -0.2), ncol=4) plt.show() In\u00a0[6]: Copied! <pre>key = dict(\n    subject=\"subject1\",\n    session_datetime=datetime.datetime(2023, 5, 11, 12, 00, 00),\n    scan_id=0,\n    paramset_idx=0,\n    curation_id=0,\n    field_idx=0,\n)\nquery = imaging.MotionCorrection.Summary &amp; key\nquery\n</pre> key = dict(     subject=\"subject1\",     session_datetime=datetime.datetime(2023, 5, 11, 12, 00, 00),     scan_id=0,     paramset_idx=0,     curation_id=0,     field_idx=0, ) query = imaging.MotionCorrection.Summary &amp; key query Out[6]: Summary images for each field and channel after corrections <p>subject</p> <p>session_datetime</p> <p>scan_id</p> <p>paramset_idx</p> Unique parameter set ID. <p>curation_id</p> <p>field_idx</p> <p>ref_image</p> image used as alignment template <p>average_image</p> mean of registered frames <p>correlation_image</p> correlation map (computed during cell detection) <p>max_proj_image</p> max of registered frames subject1 2023-05-11 12:00:00 0 0 0 0 =BLOB= =BLOB= =BLOB= =BLOB= <p>Total: 1</p> In\u00a0[7]: Copied! <pre>summary_images = query.fetch1()\n</pre> summary_images = query.fetch1() In\u00a0[8]: Copied! <pre>fig, axes = plt.subplots(1, 3, figsize=(12, 9))\n\naxes[0].imshow(summary_images[\"average_image\"])\naxes[0].set_title(\"Average Image\")\naxes[0].set_xlabel(\"x (pixels)\")\naxes[0].set_ylabel(\"y (pixels)\")\n\naxes[1].imshow(summary_images[\"correlation_image\"])\naxes[1].set_title(\"Correlation Image\")\naxes[1].set_xlabel(\"x (pixels)\")\naxes[1].set_yticks([])\naxes[1].set_yticklabels([])\n\naxes[2].imshow(summary_images[\"max_proj_image\"])\naxes[2].set_title(\"Max projection Image\")\naxes[2].set_xlabel(\"x (pixels)\")\naxes[2].set_yticks([])\naxes[2].set_yticklabels([])\n\nplt.show()\n</pre> fig, axes = plt.subplots(1, 3, figsize=(12, 9))  axes[0].imshow(summary_images[\"average_image\"]) axes[0].set_title(\"Average Image\") axes[0].set_xlabel(\"x (pixels)\") axes[0].set_ylabel(\"y (pixels)\")  axes[1].imshow(summary_images[\"correlation_image\"]) axes[1].set_title(\"Correlation Image\") axes[1].set_xlabel(\"x (pixels)\") axes[1].set_yticks([]) axes[1].set_yticklabels([])  axes[2].imshow(summary_images[\"max_proj_image\"]) axes[2].set_title(\"Max projection Image\") axes[2].set_xlabel(\"x (pixels)\") axes[2].set_yticks([]) axes[2].set_yticklabels([])  plt.show() In\u00a0[9]: Copied! <pre>mask_xpix, mask_ypix = (\n    imaging.Segmentation.Mask * imaging.MaskClassification.MaskType\n    &amp; key\n    &amp; \"mask_center_z=0\"\n    &amp; \"mask_npix &gt; 100\"\n    &amp; \"confidence &gt; 0.90\"\n).fetch(\"mask_xpix\", \"mask_ypix\")\n\nmask_image = np.zeros(np.shape(summary_images[\"correlation_image\"]), dtype=bool)\nfor xpix, ypix in zip(mask_xpix, mask_ypix):\n    try:\n        mask_image[ypix, xpix] = True\n    except Exception as e:\n        print(e)\n\nplt.xlabel(\"x (pixels)\")\nplt.ylabel(\"y (pixels)\")\nplt.imshow(summary_images[\"correlation_image\"])\nplt.contour(mask_image, colors=\"white\", linewidths=0.5)\nplt.show()\n</pre> mask_xpix, mask_ypix = (     imaging.Segmentation.Mask * imaging.MaskClassification.MaskType     &amp; key     &amp; \"mask_center_z=0\"     &amp; \"mask_npix &gt; 100\"     &amp; \"confidence &gt; 0.90\" ).fetch(\"mask_xpix\", \"mask_ypix\")  mask_image = np.zeros(np.shape(summary_images[\"correlation_image\"]), dtype=bool) for xpix, ypix in zip(mask_xpix, mask_ypix):     try:         mask_image[ypix, xpix] = True     except Exception as e:         print(e)  plt.xlabel(\"x (pixels)\") plt.ylabel(\"y (pixels)\") plt.imshow(summary_images[\"correlation_image\"]) plt.contour(mask_image, colors=\"white\", linewidths=0.5) plt.show() <pre>index 504 is out of bounds for axis 0 with size 504\nindex 504 is out of bounds for axis 0 with size 504\nindex 504 is out of bounds for axis 0 with size 504\nindex 504 is out of bounds for axis 0 with size 504\nindex 504 is out of bounds for axis 0 with size 504\nindex 506 is out of bounds for axis 1 with size 506\nindex 506 is out of bounds for axis 1 with size 506\nindex 504 is out of bounds for axis 0 with size 504\n</pre> In\u00a0[10]: Copied! <pre>key = dict(\n    subject=\"subject1\",\n    session_datetime=datetime.datetime(2023, 5, 11, 12, 00, 00),\n    scan_id=0,\n    paramset_idx=0,\n    curation_id=0,\n)\n\nquery = imaging.ProcessingQualityMetrics.Mask &amp; key\nquery\n</pre> key = dict(     subject=\"subject1\",     session_datetime=datetime.datetime(2023, 5, 11, 12, 00, 00),     scan_id=0,     paramset_idx=0,     curation_id=0, )  query = imaging.ProcessingQualityMetrics.Mask &amp; key query Out[10]: <p>subject</p> <p>session_datetime</p> <p>scan_id</p> <p>paramset_idx</p> Unique parameter set ID. <p>curation_id</p> <p>mask</p> <p>mask_area</p> Mask area in square micrometer. <p>roundness</p> Roundness between 0 and 1. Values closer to 1 are rounder. subject1 2023-05-11 12:00:00 0 0 0 0 nan 0.753574subject1 2023-05-11 12:00:00 0 0 0 1 nan 0.749964subject1 2023-05-11 12:00:00 0 0 0 2 nan 0.843484subject1 2023-05-11 12:00:00 0 0 0 3 nan 0.646408subject1 2023-05-11 12:00:00 0 0 0 4 nan 0.721577subject1 2023-05-11 12:00:00 0 0 0 5 nan 0.712069subject1 2023-05-11 12:00:00 0 0 0 6 nan 0.734321subject1 2023-05-11 12:00:00 0 0 0 7 nan 0.684134subject1 2023-05-11 12:00:00 0 0 0 8 nan 0.600041subject1 2023-05-11 12:00:00 0 0 0 9 nan 0.903313subject1 2023-05-11 12:00:00 0 0 0 10 nan 0.808169subject1 2023-05-11 12:00:00 0 0 0 11 nan 0.877421 <p>...</p> <p>Total: 1276</p> In\u00a0[11]: Copied! <pre>roundness = query.fetch(\"roundness\")\n</pre> roundness = query.fetch(\"roundness\") In\u00a0[12]: Copied! <pre>plt.hist(roundness, bins=20, color=\"white\", edgecolor=\"black\")\n\nplt.title(\"Mask roundness\")\nplt.xlabel(\"Roundness\")\nplt.ylabel(\"Count (#)\")\nplt.show()\n</pre> plt.hist(roundness, bins=20, color=\"white\", edgecolor=\"black\")  plt.title(\"Mask roundness\") plt.xlabel(\"Roundness\") plt.ylabel(\"Count (#)\") plt.show() In\u00a0[13]: Copied! <pre>key = dict(\n    subject=\"subject1\",\n    session_datetime=datetime.datetime(2023, 5, 11, 12, 00, 00),\n    scan_id=0,\n    paramset_idx=0,\n    curation_id=0,\n    fluo_channel=0,\n)\n\nquery = imaging.ProcessingQualityMetrics.Trace &amp; key\nquery\n</pre> key = dict(     subject=\"subject1\",     session_datetime=datetime.datetime(2023, 5, 11, 12, 00, 00),     scan_id=0,     paramset_idx=0,     curation_id=0,     fluo_channel=0, )  query = imaging.ProcessingQualityMetrics.Trace &amp; key query Out[13]: <p>subject</p> <p>session_datetime</p> <p>scan_id</p> <p>paramset_idx</p> Unique parameter set ID. <p>curation_id</p> <p>mask</p> <p>fluo_channel</p> 0-based indexing <p>skewness</p> Skewness of the fluorescence trace. <p>variance</p> Variance of the fluorescence trace. subject1 2023-05-11 12:00:00 0 0 0 0 0 2.28541 865.221subject1 2023-05-11 12:00:00 0 0 0 1 0 2.18231 342.718subject1 2023-05-11 12:00:00 0 0 0 2 0 2.49255 784.625subject1 2023-05-11 12:00:00 0 0 0 3 0 3.98893 153.951subject1 2023-05-11 12:00:00 0 0 0 4 0 2.83063 315.717subject1 2023-05-11 12:00:00 0 0 0 5 0 2.74945 194.228subject1 2023-05-11 12:00:00 0 0 0 6 0 6.43236 183.582subject1 2023-05-11 12:00:00 0 0 0 7 0 4.58705 184.103subject1 2023-05-11 12:00:00 0 0 0 8 0 3.45196 204.443subject1 2023-05-11 12:00:00 0 0 0 9 0 3.10743 237.697subject1 2023-05-11 12:00:00 0 0 0 10 0 5.04266 121.186subject1 2023-05-11 12:00:00 0 0 0 11 0 2.18527 335.129 <p>...</p> <p>Total: 1276</p> In\u00a0[14]: Copied! <pre>skewness, variance = query.fetch(\"skewness\", \"variance\")\n</pre> skewness, variance = query.fetch(\"skewness\", \"variance\") In\u00a0[15]: Copied! <pre>fig, axes = plt.subplots(1, 2, figsize=(9, 4))\n\naxes[0].scatter(range(len(skewness)), np.sort(skewness), color=\"black\", s=0.5)\naxes[0].set_title(\"Temporal skewness\")\naxes[0].set_xlabel(\"Cell\")\naxes[0].set_ylabel(\"Sorted skewness\")\n\naxes[1].scatter(range(len(variance)), np.sort(variance), color=\"black\", s=0.5)\naxes[1].set_title(\"Temporal variance\")\naxes[1].set_xlabel(\"Cell\")\naxes[1].set_ylabel(\"Sorted variance\")\n\nplt.show()\n</pre> fig, axes = plt.subplots(1, 2, figsize=(9, 4))  axes[0].scatter(range(len(skewness)), np.sort(skewness), color=\"black\", s=0.5) axes[0].set_title(\"Temporal skewness\") axes[0].set_xlabel(\"Cell\") axes[0].set_ylabel(\"Sorted skewness\")  axes[1].scatter(range(len(variance)), np.sort(variance), color=\"black\", s=0.5) axes[1].set_title(\"Temporal variance\") axes[1].set_xlabel(\"Cell\") axes[1].set_ylabel(\"Sorted variance\")  plt.show() In\u00a0[\u00a0]: Copied! <pre>\n</pre>"}, {"location": "tutorials/quality_metrics/#calcium-imaging-quality-metrics", "title": "Calcium Imaging Quality Metrics\u00b6", "text": "<p>Visualize the calcium imaging quality metrics for the raw and processed scans that are stored in the DataJoint pipeline (i.e. <code>element-calcium-imaging</code>).</p> <p>If you are new to using this DataJoint pipeline for analyzing calcium imaging data, please see the tutorial notebook for an in-depth explanation to set up and run the workflow.</p> <p>This quality metrics notebook can run in a GitHub Codespace, and requires the example data to be populated into the database using the tutorial notebook.</p>"}, {"location": "tutorials/quality_metrics/#populate-quality-metrics-tables", "title": "Populate quality metrics tables\u00b6", "text": ""}, {"location": "tutorials/quality_metrics/#scan-quality-metrics", "title": "Scan quality metrics\u00b6", "text": "<p>Intensity values (minimum, mean, max, contrast) can be used to evaluate the consistency of imaging for each frame, and changing values could indicate changes in imaging conditions or technical issues with the equipment or software (e.g. photobleaching, saturation, etc.). In which case, it may be necessary to adjust the imaging protocol, or troubleshoot the equipment or software.</p>"}, {"location": "tutorials/quality_metrics/#motion-corrected-summary-images", "title": "Motion corrected summary images\u00b6", "text": ""}, {"location": "tutorials/quality_metrics/#segmentation-masks", "title": "Segmentation masks\u00b6", "text": ""}, {"location": "tutorials/quality_metrics/#mask-quality-metrics", "title": "Mask quality metrics\u00b6", "text": "Metric Description Source Mask area Area can be used to evaluate the accuracy and consistency of the segmentation process. The mask area can be compared to the expected area of a single cell to determine if segmentation lead to false positives or false negatives. Stringer &amp; Pachitariu, Current Opinion in Neurobiology 2019 Mask roundness Roundness is to evaluate how closely a segmented mask's shape resembles a perfect circle. A perfectly round mask will have a value of 1, while a more elongated or irregular mask will have a lower roundness value. Roundness can help identify cells that have been improperly segmented. For example, cells that are elongated or irregular in shape may have been segmented incorrectly due to noise, overlapping cells, or other factors. By comparing the roundness of segmented masks to a threshold value, cells that are improperly segmented can be identified and corrected. Tegtmeier et al., Frontiers in Neuroscience 2018"}, {"location": "tutorials/quality_metrics/#trace-quality-metrics", "title": "Trace quality metrics\u00b6", "text": "<p>Temporal skewness and variance of the fluorescence activity can indicate the stability of the signal over time. Changes in this metric between imaging sessions could indicate technical issues in the experimental conditions or data processing. Additionally, changes in the animal's behavior or physiological state could also affect this metric, so it is important to interpret any changes within the context of the experimental conditions and the animal's behavior and physiology. (Stringer &amp; Pachitariu, Current Opinion in Neurobiology 2019)</p> <p>For illustrative purposes, below we will fetch and plot these metrics for a single session.</p>"}, {"location": "tutorials/tutorial/", "title": "Tutorial Notebook", "text": "In\u00a0[1]: Copied! <pre>import datajoint as dj\nimport datetime\nimport matplotlib.pyplot as plt\nimport numpy as np\n</pre> import datajoint as dj import datetime import matplotlib.pyplot as plt import numpy as np In\u00a0[2]: Copied! <pre>from tutorial_pipeline import (\n    lab,\n    subject,\n    session,\n    scan,\n    imaging,\n    imaging_report,\n    Equipment,\n)\n</pre> from tutorial_pipeline import (     lab,     subject,     session,     scan,     imaging,     imaging_report,     Equipment, ) <pre>[2023-06-30 17:56:21,374][WARNING]: lab.Project and related tables will be removed in a future version of Element Lab. Please use the project schema.\n[2023-06-30 17:56:21,377][INFO]: Connecting root@fakeservices.datajoint.io:3306\n[2023-06-30 17:56:21,401][INFO]: Connected root@fakeservices.datajoint.io:3306\n</pre> <p>Each Python module (e.g. <code>subject</code>) contains a schema object that enables interaction with the schema in the database.</p> In\u00a0[3]: Copied! <pre>subject.schema\n</pre> subject.schema Out[3]: <pre>Schema `neuro_subject`</pre> <p>The Python classes in the module correspond to a table in the database server.</p> In\u00a0[4]: Copied! <pre>subject.Subject()\n</pre> subject.Subject() Out[4]: <p>subject</p> <p>subject_nickname</p> <p>sex</p> <p>subject_birth_date</p> <p>subject_description</p> <p>Total: 0</p> In\u00a0[5]: Copied! <pre>(\n    dj.Diagram(subject.Subject)\n    + dj.Diagram(session.Session)\n    + dj.Diagram(scan)\n    + dj.Diagram(imaging)\n)\n</pre> (     dj.Diagram(subject.Subject)     + dj.Diagram(session.Session)     + dj.Diagram(scan)     + dj.Diagram(imaging) ) Out[5]: %3 0 0 imaging.MotionCorrection imaging.MotionCorrection 0-&gt;imaging.MotionCorrection 1 1 imaging.Segmentation.Mask imaging.Segmentation.Mask 1-&gt;imaging.Segmentation.Mask 2 2 imaging.Fluorescence.Trace imaging.Fluorescence.Trace 2-&gt;imaging.Fluorescence.Trace subject.Subject subject.Subject session.Session session.Session subject.Subject-&gt;session.Session scan.Scan scan.Scan session.Session-&gt;scan.Scan scan.ScanLocation scan.ScanLocation scan.Scan-&gt;scan.ScanLocation scan.ScanInfo scan.ScanInfo scan.Scan-&gt;scan.ScanInfo imaging.ProcessingTask imaging.ProcessingTask scan.Scan-&gt;imaging.ProcessingTask scan.ScanInfo.ScanFile scan.ScanInfo.ScanFile scan.ScanInfo.Field scan.ScanInfo.Field scan.ScanQualityMetrics scan.ScanQualityMetrics scan.ScanInfo.Field-&gt;scan.ScanQualityMetrics imaging.MotionCorrection.Summary imaging.MotionCorrection.Summary scan.ScanInfo.Field-&gt;imaging.MotionCorrection.Summary scan.ScanInfo-&gt;scan.ScanInfo.ScanFile scan.ScanInfo-&gt;scan.ScanInfo.Field scan.ScanQualityMetrics.Frames scan.ScanQualityMetrics.Frames scan.ScanQualityMetrics-&gt;scan.ScanQualityMetrics.Frames scan.Channel scan.Channel scan.Channel-&gt;0 scan.Channel-&gt;1 scan.Channel-&gt;2 scan.Channel-&gt;scan.ScanQualityMetrics.Frames scan.AcquisitionSoftware scan.AcquisitionSoftware scan.AcquisitionSoftware-&gt;scan.Scan imaging.Processing imaging.Processing imaging.ProcessingTask-&gt;imaging.Processing imaging.Curation imaging.Curation imaging.Curation-&gt;imaging.MotionCorrection imaging.Segmentation imaging.Segmentation imaging.Curation-&gt;imaging.Segmentation imaging.MotionCorrection.RigidMotionCorrection imaging.MotionCorrection.RigidMotionCorrection imaging.MotionCorrection.NonRigidMotionCorrection imaging.MotionCorrection.NonRigidMotionCorrection imaging.MotionCorrection.Block imaging.MotionCorrection.Block imaging.MotionCorrection.NonRigidMotionCorrection-&gt;imaging.MotionCorrection.Block imaging.MotionCorrection-&gt;imaging.MotionCorrection.Summary imaging.MotionCorrection-&gt;imaging.MotionCorrection.RigidMotionCorrection imaging.MotionCorrection-&gt;imaging.MotionCorrection.NonRigidMotionCorrection imaging.ProcessingQualityMetrics.Mask imaging.ProcessingQualityMetrics.Mask imaging.Segmentation.Mask-&gt;imaging.ProcessingQualityMetrics.Mask imaging.MaskClassification.MaskType imaging.MaskClassification.MaskType imaging.Segmentation.Mask-&gt;imaging.MaskClassification.MaskType imaging.Segmentation.Mask-&gt;imaging.Fluorescence.Trace imaging.Segmentation-&gt;imaging.Segmentation.Mask imaging.MaskClassification imaging.MaskClassification imaging.Segmentation-&gt;imaging.MaskClassification imaging.Fluorescence imaging.Fluorescence imaging.Segmentation-&gt;imaging.Fluorescence imaging.ProcessingQualityMetrics.Trace imaging.ProcessingQualityMetrics.Trace imaging.ProcessingQualityMetrics imaging.ProcessingQualityMetrics imaging.ProcessingQualityMetrics-&gt;imaging.ProcessingQualityMetrics.Trace imaging.ProcessingQualityMetrics-&gt;imaging.ProcessingQualityMetrics.Mask imaging.Processing-&gt;imaging.Curation imaging.MaskClassification-&gt;imaging.MaskClassification.MaskType imaging.Fluorescence.Trace-&gt;imaging.ProcessingQualityMetrics.Trace imaging.Activity.Trace imaging.Activity.Trace imaging.Fluorescence.Trace-&gt;imaging.Activity.Trace imaging.Fluorescence-&gt;imaging.ProcessingQualityMetrics imaging.Fluorescence-&gt;imaging.Fluorescence.Trace imaging.Activity imaging.Activity imaging.Fluorescence-&gt;imaging.Activity imaging.Activity-&gt;imaging.Activity.Trace imaging.ProcessingParamSet imaging.ProcessingParamSet imaging.ProcessingParamSet-&gt;imaging.ProcessingTask imaging.ProcessingMethod imaging.ProcessingMethod imaging.ProcessingMethod-&gt;imaging.ProcessingParamSet imaging.MaskType imaging.MaskType imaging.MaskType-&gt;imaging.MaskClassification.MaskType imaging.MaskClassificationMethod imaging.MaskClassificationMethod imaging.MaskClassificationMethod-&gt;imaging.MaskClassification imaging.CellCompartment imaging.CellCompartment imaging.ActivityExtractionMethod imaging.ActivityExtractionMethod imaging.ActivityExtractionMethod-&gt;imaging.Activity In\u00a0[6]: Copied! <pre>print(subject.Subject.describe())\n</pre> print(subject.Subject.describe()) <pre>subject              : varchar(8)                   \n---\nsubject_nickname     : varchar(64)                  \nsex                  : enum('M','F','U')            \nsubject_birth_date   : date                         \nsubject_description  : varchar(1024)                \n\n</pre> In\u00a0[7]: Copied! <pre>subject.Subject.heading\n</pre> subject.Subject.heading Out[7]: <pre># \nsubject              : varchar(8)                   # \n---\nsubject_nickname     : varchar(64)                  # \nsex                  : enum('M','F','U')            # \nsubject_birth_date   : date                         # \nsubject_description  : varchar(1024)                # </pre> <p>The cells above show all attributes of the subject table. We will insert data into the <code>subject.Subject</code> table.</p> In\u00a0[8]: Copied! <pre>subject.Subject.insert1(\n    dict(\n        subject=\"subject1\",\n        subject_nickname=\"subject1_nickname\",\n        sex=\"F\",\n        subject_birth_date=\"2020-01-01\",\n        subject_description=\"ScanImage acquisition. Suite2p processing.\",\n    )\n)\nsubject.Subject()\n</pre> subject.Subject.insert1(     dict(         subject=\"subject1\",         subject_nickname=\"subject1_nickname\",         sex=\"F\",         subject_birth_date=\"2020-01-01\",         subject_description=\"ScanImage acquisition. Suite2p processing.\",     ) ) subject.Subject() Out[8]: <p>subject</p> <p>subject_nickname</p> <p>sex</p> <p>subject_birth_date</p> <p>subject_description</p> subject1 subject1_nickname F 2020-01-01 ScanImage acquisition. Suite2p processing. <p>Total: 1</p> <p>Let's repeat the steps above for the <code>Session</code> table.</p> In\u00a0[9]: Copied! <pre>print(session.Session.describe())\n</pre> print(session.Session.describe()) <pre>-&gt; subject.Subject\nsession_datetime     : datetime                     \n\n</pre> In\u00a0[10]: Copied! <pre>session.Session.heading\n</pre> session.Session.heading Out[10]: <pre># \nsubject              : varchar(8)                   # \nsession_datetime     : datetime                     # </pre> <p>Notice that <code>describe</code> displays the table definition with the dependencies (i.e. foreign key references). The <code>Session</code> table depends on the upstream <code>Subject</code> table.</p> <p>Whereas <code>heading</code> displays all the attributes of the table definition, regardless of whether they are declared in an upstream table.</p> <p>Next we can insert in the <code>session.Session</code> table by passing a dictionary to the <code>insert1</code> method.</p> In\u00a0[11]: Copied! <pre>session_key = dict(subject=\"subject1\", session_datetime=\"2021-04-30 12:22:15\")\n</pre> session_key = dict(subject=\"subject1\", session_datetime=\"2021-04-30 12:22:15\") In\u00a0[12]: Copied! <pre>session.Session.insert1(session_key)\nsession.Session()\n</pre> session.Session.insert1(session_key) session.Session() Out[12]: <p>subject</p> <p>session_datetime</p> subject1 2021-04-30 12:22:15 <p>Total: 1</p> <p>The <code>SessionDirectory</code> table locates the relevant data files in a directory path relative to the root directory defined in your <code>dj.config[\"custom\"]</code>. More information about <code>dj.config</code> is provided in the User Guide.</p> In\u00a0[13]: Copied! <pre>session.SessionDirectory.insert1(dict(**session_key, session_dir=\"subject1/session1\"))\nsession.SessionDirectory()\n</pre> session.SessionDirectory.insert1(dict(**session_key, session_dir=\"subject1/session1\")) session.SessionDirectory() Out[13]: <p>subject</p> <p>session_datetime</p> <p>session_dir</p> Path to the data directory for a session subject1 2021-04-30 12:22:15 subject1/session1 <p>Total: 1</p> <p>Next, we'll use <code>describe</code> and <code>heading</code> for the Scan table. Do you notice anything we might have missed here?</p> In\u00a0[14]: Copied! <pre>print(scan.Scan.describe())\n</pre> print(scan.Scan.describe()) <pre>-&gt; session.Session\nscan_id              : int                          \n---\n-&gt; [nullable] Equipment\n-&gt; scan.AcquisitionSoftware\nscan_notes           : varchar(4095)                \n\n</pre> <p>The <code>Scan</code> table's attributes include the <code>Session</code> table and the <code>Equipment</code> table. Let's insert into the <code>Equipment</code> table and then <code>Scan</code>.</p> In\u00a0[16]: Copied! <pre>Equipment.insert1(\n    dict(\n        device=\"Mesoscope1\",\n        modality=\"Calcium imaging\",\n        description=\"Example microscope\",\n    )\n)\n</pre> Equipment.insert1(     dict(         device=\"Mesoscope1\",         modality=\"Calcium imaging\",         description=\"Example microscope\",     ) ) In\u00a0[17]: Copied! <pre>scan.Scan.insert1(\n    dict(\n        **session_key,\n        scan_id=0,\n        device=\"Mesoscope1\",\n        acq_software=\"ScanImage\",\n        scan_notes=\"\",\n    )\n)\nscan.Scan()\n</pre> scan.Scan.insert1(     dict(         **session_key,         scan_id=0,         device=\"Mesoscope1\",         acq_software=\"ScanImage\",         scan_notes=\"\",     ) ) scan.Scan() Out[17]: <p>subject</p> <p>session_datetime</p> <p>scan_id</p> <p>device</p> <p>acq_software</p> <p>scan_notes</p> subject1 2021-04-30 12:22:15 0 Mesoscope1 ScanImage <p>Total: 1</p> In\u00a0[18]: Copied! <pre>scan.ScanInfo.heading\n</pre> scan.ScanInfo.heading Out[18]: <pre># General data about the resoscans/mesoscans from header\nsubject              : varchar(8)                   # \nsession_datetime     : datetime                     # \nscan_id              : int                          # \n---\nnfields              : tinyint                      # number of fields\nnchannels            : tinyint                      # number of channels\nndepths              : int                          # Number of scanning depths (planes)\nnframes              : int                          # number of recorded frames\nnrois                : tinyint                      # number of ROIs (see scanimage's multi ROI imaging)\nx=null               : float                        # (um) ScanImage's 0 point in the motor coordinate system\ny=null               : float                        # (um) ScanImage's 0 point in the motor coordinate system\nz=null               : float                        # (um) ScanImage's 0 point in the motor coordinate system\nfps                  : float                        # (Hz) frames per second - Volumetric Scan Rate\nbidirectional        : tinyint                      # true = bidirectional scanning\nusecs_per_line=null  : float                        # microseconds per scan line\nfill_fraction=null   : float                        # raster scan temporal fill fraction (see scanimage)\nscan_datetime=null   : datetime                     # datetime of the scan\nscan_duration=null   : float                        # (seconds) duration of the scan\nbidirectional_z=null : tinyint                      # true = bidirectional z-scan</pre> In\u00a0[19]: Copied! <pre>scan.ScanInfo.Field.heading\n</pre> scan.ScanInfo.Field.heading Out[19]: <pre># field-specific scan information\nsubject              : varchar(8)                   # \nsession_datetime     : datetime                     # \nscan_id              : int                          # \nfield_idx            : int                          # \n---\npx_height            : smallint                     # height in pixels\npx_width             : smallint                     # width in pixels\num_height=null       : float                        # height in microns\num_width=null        : float                        # width in microns\nfield_x=null         : float                        # (um) center of field in the motor coordinate system\nfield_y=null         : float                        # (um) center of field in the motor coordinate system\nfield_z=null         : float                        # (um) relative depth of field\ndelay_image=null     : longblob                     # (ms) delay between the start of the scan and pixels in this field\nroi=null             : int                          # the scanning roi (as recorded in the acquisition software) containing this field - only relevant to mesoscale scans</pre> In\u00a0[20]: Copied! <pre>scan.ScanInfo()\n</pre> scan.ScanInfo() Out[20]: General data about the resoscans/mesoscans from header <p>subject</p> <p>session_datetime</p> <p>scan_id</p> <p>nfields</p> number of fields <p>nchannels</p> number of channels <p>ndepths</p> Number of scanning depths (planes) <p>nframes</p> number of recorded frames <p>nrois</p> number of ROIs (see scanimage's multi ROI imaging) <p>x</p> (um) ScanImage's 0 point in the motor coordinate system <p>y</p> (um) ScanImage's 0 point in the motor coordinate system <p>z</p> (um) ScanImage's 0 point in the motor coordinate system <p>fps</p> (Hz) frames per second - Volumetric Scan Rate <p>bidirectional</p> true = bidirectional scanning <p>usecs_per_line</p> microseconds per scan line <p>fill_fraction</p> raster scan temporal fill fraction (see scanimage) <p>scan_datetime</p> datetime of the scan <p>scan_duration</p> (seconds) duration of the scan <p>bidirectional_z</p> true = bidirectional z-scan <p>Total: 0</p> In\u00a0[21]: Copied! <pre>scan.ScanInfo.Field()\n</pre> scan.ScanInfo.Field() Out[21]: field-specific scan information <p>subject</p> <p>session_datetime</p> <p>scan_id</p> <p>field_idx</p> <p>px_height</p> height in pixels <p>px_width</p> width in pixels <p>um_height</p> height in microns <p>um_width</p> width in microns <p>field_x</p> (um) center of field in the motor coordinate system <p>field_y</p> (um) center of field in the motor coordinate system <p>field_z</p> (um) relative depth of field <p>delay_image</p> (ms) delay between the start of the scan and pixels in this field <p>roi</p> the scanning roi (as recorded in the acquisition software) containing this field - only relevant to mesoscale scans <p>Total: 0</p> In\u00a0[22]: Copied! <pre># duration depends on your network bandwidth to s3\nscan.ScanInfo.populate(display_progress=True)\n</pre> # duration depends on your network bandwidth to s3 scan.ScanInfo.populate(display_progress=True) <pre>ScanInfo:   0%|          | 0/1 [00:00&lt;?, ?it/s]ScanInfo: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [05:41&lt;00:00, 341.51s/it]\n</pre> <p>Let's view the information was entered into these tables.</p> In\u00a0[23]: Copied! <pre>scan.ScanInfo()\n</pre> scan.ScanInfo() Out[23]: General data about the resoscans/mesoscans from header <p>subject</p> <p>session_datetime</p> <p>scan_id</p> <p>nfields</p> number of fields <p>nchannels</p> number of channels <p>ndepths</p> Number of scanning depths (planes) <p>nframes</p> number of recorded frames <p>nrois</p> number of ROIs (see scanimage's multi ROI imaging) <p>x</p> (um) ScanImage's 0 point in the motor coordinate system <p>y</p> (um) ScanImage's 0 point in the motor coordinate system <p>z</p> (um) ScanImage's 0 point in the motor coordinate system <p>fps</p> (Hz) frames per second - Volumetric Scan Rate <p>bidirectional</p> true = bidirectional scanning <p>usecs_per_line</p> microseconds per scan line <p>fill_fraction</p> raster scan temporal fill fraction (see scanimage) <p>scan_datetime</p> datetime of the scan <p>scan_duration</p> (seconds) duration of the scan <p>bidirectional_z</p> true = bidirectional z-scan subject1 2021-04-30 12:22:15 0 1 1 1 3000 0 13441.9 15745.0 -205821.0 29.2398 1 63.0981 0.712867 None 102.6 None <p>Total: 1</p> In\u00a0[24]: Copied! <pre>scan.ScanInfo.Field()\n</pre> scan.ScanInfo.Field() Out[24]: field-specific scan information <p>subject</p> <p>session_datetime</p> <p>scan_id</p> <p>field_idx</p> <p>px_height</p> height in pixels <p>px_width</p> width in pixels <p>um_height</p> height in microns <p>um_width</p> width in microns <p>field_x</p> (um) center of field in the motor coordinate system <p>field_y</p> (um) center of field in the motor coordinate system <p>field_z</p> (um) relative depth of field <p>delay_image</p> (ms) delay between the start of the scan and pixels in this field <p>roi</p> the scanning roi (as recorded in the acquisition software) containing this field - only relevant to mesoscale scans subject1 2021-04-30 12:22:15 0 0 512 512 nan nan 13441.9 15745.0 -205821.0 =BLOB= None <p>Total: 1</p> <p>Let's define the Suite2p parameters by making an entry in the <code>ProcessingParamSet</code> table.</p> In\u00a0[25]: Copied! <pre>import suite2p\n\nparams_suite2p = suite2p.default_ops()\nparams_suite2p[\"nonrigid\"] = False\n\nimaging.ProcessingParamSet.insert_new_params(\n    processing_method=\"suite2p\",\n    paramset_idx=0,\n    params=params_suite2p,\n    paramset_desc=\"Calcium imaging analysis with Suite2p using default parameters\",\n)\n</pre> import suite2p  params_suite2p = suite2p.default_ops() params_suite2p[\"nonrigid\"] = False  imaging.ProcessingParamSet.insert_new_params(     processing_method=\"suite2p\",     paramset_idx=0,     params=params_suite2p,     paramset_desc=\"Calcium imaging analysis with Suite2p using default parameters\", ) <p>The <code>ProcessingTask</code> table is used to select the <code>ProcessingParamSet</code> entry that is used to process a selected <code>Scan</code> entry in the downstream tables.</p> In\u00a0[26]: Copied! <pre>print(imaging.ProcessingTask.describe())\n</pre> print(imaging.ProcessingTask.describe()) <pre># Manual table for defining a processing task ready to be run\n-&gt; scan.Scan\n-&gt; imaging.ProcessingParamSet\n---\nprocessing_output_dir : varchar(255)                 # Output directory of the processed scan relative to root data directory\ntask_mode            : enum('load','trigger')       # 'load': load computed analysis results, 'trigger': trigger computation\n\n</pre> In\u00a0[27]: Copied! <pre>imaging.ProcessingTask.heading\n</pre> imaging.ProcessingTask.heading Out[27]: <pre># Manual table for defining a processing task ready to be run\nsubject              : varchar(8)                   # \nsession_datetime     : datetime                     # \nscan_id              : int                          # \nparamset_idx         : smallint                     # Unique parameter set ID.\n---\nprocessing_output_dir : varchar(255)                 # Output directory of the processed scan relative to root data directory\ntask_mode            : enum('load','trigger')       # 'load': load computed analysis results, 'trigger': trigger computation</pre> <p>The <code>ProcessingTask</code> table contains two important attributes: processing algorithm defined in <code>ProcessingParamSet</code>. When set to <code>trigger</code>, the</p> <ul> <li><code>paramset_idx</code> - Allows the user to choose the parameter set with which you want to run image processing.</li> <li><code>task_mode</code> - Can be set to <code>load</code> or <code>trigger</code>. When set to <code>load</code>, running the processing step initiates a search for existing output files of the image</li> </ul> <p>processing step will run image processing on the raw data.</p> In\u00a0[28]: Copied! <pre>imaging.ProcessingTask.insert1(\n    dict(\n        **session_key,\n        scan_id=0,\n        paramset_idx=0,\n        task_mode=\"load\",  # load or trigger\n        processing_output_dir=\"subject1/session1/suite2p\",\n    )\n)\n</pre> imaging.ProcessingTask.insert1(     dict(         **session_key,         scan_id=0,         paramset_idx=0,         task_mode=\"load\",  # load or trigger         processing_output_dir=\"subject1/session1/suite2p\",     ) ) <p>Let's call populate on the <code>Processing</code> table, which checks the Suite2p results since <code>task_mode=load</code>.</p> In\u00a0[29]: Copied! <pre>imaging.Processing.populate(session_key, display_progress=True)\n</pre> imaging.Processing.populate(session_key, display_progress=True) <pre>Processing:   0%|          | 0/1 [00:00&lt;?, ?it/s]Processing: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00&lt;00:00,  1.05it/s]\n</pre> <p>Once processing is complete, you can optionally curate the output of Suite2p using the <code>Curation</code> table.</p> In\u00a0[30]: Copied! <pre>imaging.Curation.heading\n</pre> imaging.Curation.heading Out[30]: <pre># Curation(s) results\nsubject              : varchar(8)                   # \nsession_datetime     : datetime                     # \nscan_id              : int                          # \nparamset_idx         : smallint                     # Unique parameter set ID.\ncuration_id          : int                          # \n---\ncuration_time        : datetime                     # Time of generation of this set of curated results\ncuration_output_dir  : varchar(255)                 # Output directory of the curated results, relative to root data directory\nmanual_curation      : tinyint                      # Has manual curation been performed on this result?\ncuration_note        : varchar(2000)                # </pre> In\u00a0[31]: Copied! <pre>imaging.Curation.insert1(\n    dict(\n        **session_key,\n        scan_id=0,\n        paramset_idx=0,\n        curation_id=0,\n        curation_time=\"2021-04-30 12:22:15.032\",\n        curation_output_dir=\"subject1/session1/suite2p\",\n        manual_curation=False,\n        curation_note=\"\",\n    )\n)\n</pre> imaging.Curation.insert1(     dict(         **session_key,         scan_id=0,         paramset_idx=0,         curation_id=0,         curation_time=\"2021-04-30 12:22:15.032\",         curation_output_dir=\"subject1/session1/suite2p\",         manual_curation=False,         curation_note=\"\",     ) ) <p>Now, we will populate several tables that store the output of image processing and plots.</p> In\u00a0[32]: Copied! <pre>imaging.MotionCorrection.populate(display_progress=True)\nimaging.Segmentation.populate(display_progress=True)\nimaging.Fluorescence.populate(display_progress=True)\nimaging.Activity.populate(display_progress=True)\nimaging_report.ScanLevelReport.populate(display_progress=True)\nimaging_report.TraceReport.populate(display_progress=True)\n</pre> imaging.MotionCorrection.populate(display_progress=True) imaging.Segmentation.populate(display_progress=True) imaging.Fluorescence.populate(display_progress=True) imaging.Activity.populate(display_progress=True) imaging_report.ScanLevelReport.populate(display_progress=True) imaging_report.TraceReport.populate(display_progress=True) <pre>MotionCorrection:   0%|          | 0/1 [00:00&lt;?, ?it/s]MotionCorrection: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:09&lt;00:00,  9.92s/it]\nSegmentation: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:08&lt;00:00,  8.57s/it]\nFluorescence: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:07&lt;00:00,  7.97s/it]\nActivity: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:02&lt;00:00,  2.74s/it]\nScanLevelReport: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01&lt;00:00,  1.20s/it]\nTraceReport: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1276/1276 [01:21&lt;00:00, 15.71it/s]\n</pre> In\u00a0[33]: Copied! <pre>subject.Subject()\n</pre> subject.Subject() Out[33]: <p>subject</p> <p>subject_nickname</p> <p>sex</p> <p>subject_birth_date</p> <p>subject_description</p> subject1 subject1_nickname F 2020-01-01 ScanImage acquisition. Suite2p processing. <p>Total: 1</p> <p>Let's query the contents of the <code>Mask</code> part table.</p> In\u00a0[34]: Copied! <pre>imaging.Segmentation.Mask()\n</pre> imaging.Segmentation.Mask() Out[34]: A mask produced by segmentation. <p>subject</p> <p>session_datetime</p> <p>scan_id</p> <p>paramset_idx</p> Unique parameter set ID. <p>curation_id</p> <p>mask</p> <p>segmentation_channel</p> 0-based indexing <p>mask_npix</p> number of pixels in ROIs <p>mask_center_x</p> center x coordinate in pixel <p>mask_center_y</p> center y coordinate in pixel <p>mask_center_z</p> center z coordinate in pixel <p>mask_xpix</p> x coordinates in pixels <p>mask_ypix</p> y coordinates in pixels <p>mask_zpix</p> z coordinates in pixels <p>mask_weights</p> weights of the mask at the indices above subject1 2021-04-30 12:22:15 0 0 0 0 0 305 176 149 0 =BLOB= =BLOB= =BLOB= =BLOB=subject1 2021-04-30 12:22:15 0 0 0 1 0 177 156 377 0 =BLOB= =BLOB= =BLOB= =BLOB=subject1 2021-04-30 12:22:15 0 0 0 2 0 187 160 165 0 =BLOB= =BLOB= =BLOB= =BLOB=subject1 2021-04-30 12:22:15 0 0 0 3 0 208 48 285 0 =BLOB= =BLOB= =BLOB= =BLOB=subject1 2021-04-30 12:22:15 0 0 0 4 0 153 148 305 0 =BLOB= =BLOB= =BLOB= =BLOB=subject1 2021-04-30 12:22:15 0 0 0 5 0 247 256 277 0 =BLOB= =BLOB= =BLOB= =BLOB=subject1 2021-04-30 12:22:15 0 0 0 6 0 146 104 261 0 =BLOB= =BLOB= =BLOB= =BLOB=subject1 2021-04-30 12:22:15 0 0 0 7 0 413 276 189 0 =BLOB= =BLOB= =BLOB= =BLOB=subject1 2021-04-30 12:22:15 0 0 0 8 0 223 92 277 0 =BLOB= =BLOB= =BLOB= =BLOB=subject1 2021-04-30 12:22:15 0 0 0 9 0 150 340 9 0 =BLOB= =BLOB= =BLOB= =BLOB=subject1 2021-04-30 12:22:15 0 0 0 10 0 140 336 69 0 =BLOB= =BLOB= =BLOB= =BLOB=subject1 2021-04-30 12:22:15 0 0 0 11 0 184 136 349 0 =BLOB= =BLOB= =BLOB= =BLOB= <p>...</p> <p>Total: 1276</p> <p>With the <code>&amp;</code> operator, we will restrict the contents of the <code>imaging.Segmentation.Mask</code> table to the entry where the <code>mask</code> attribute is 10.</p> In\u00a0[35]: Copied! <pre>imaging.Segmentation.Mask &amp; \"mask = '10'\"\n</pre> imaging.Segmentation.Mask &amp; \"mask = '10'\" Out[35]: A mask produced by segmentation. <p>subject</p> <p>session_datetime</p> <p>scan_id</p> <p>paramset_idx</p> Unique parameter set ID. <p>curation_id</p> <p>mask</p> <p>segmentation_channel</p> 0-based indexing <p>mask_npix</p> number of pixels in ROIs <p>mask_center_x</p> center x coordinate in pixel <p>mask_center_y</p> center y coordinate in pixel <p>mask_center_z</p> center z coordinate in pixel <p>mask_xpix</p> x coordinates in pixels <p>mask_ypix</p> y coordinates in pixels <p>mask_zpix</p> z coordinates in pixels <p>mask_weights</p> weights of the mask at the indices above subject1 2021-04-30 12:22:15 0 0 0 10 0 140 336 69 0 =BLOB= =BLOB= =BLOB= =BLOB= <p>Total: 1</p> <p>DataJoint queries can be a highly flexible tool with several operators.  The next operator we will explore is <code>join</code> which combines matching information from tables.</p> <p>First let's view the contents of each table.</p> In\u00a0[36]: Copied! <pre>imaging.Segmentation.Mask()\n</pre> imaging.Segmentation.Mask() Out[36]: A mask produced by segmentation. <p>subject</p> <p>session_datetime</p> <p>scan_id</p> <p>paramset_idx</p> Unique parameter set ID. <p>curation_id</p> <p>mask</p> <p>segmentation_channel</p> 0-based indexing <p>mask_npix</p> number of pixels in ROIs <p>mask_center_x</p> center x coordinate in pixel <p>mask_center_y</p> center y coordinate in pixel <p>mask_center_z</p> center z coordinate in pixel <p>mask_xpix</p> x coordinates in pixels <p>mask_ypix</p> y coordinates in pixels <p>mask_zpix</p> z coordinates in pixels <p>mask_weights</p> weights of the mask at the indices above subject1 2021-04-30 12:22:15 0 0 0 0 0 305 176 149 0 =BLOB= =BLOB= =BLOB= =BLOB=subject1 2021-04-30 12:22:15 0 0 0 1 0 177 156 377 0 =BLOB= =BLOB= =BLOB= =BLOB=subject1 2021-04-30 12:22:15 0 0 0 2 0 187 160 165 0 =BLOB= =BLOB= =BLOB= =BLOB=subject1 2021-04-30 12:22:15 0 0 0 3 0 208 48 285 0 =BLOB= =BLOB= =BLOB= =BLOB=subject1 2021-04-30 12:22:15 0 0 0 4 0 153 148 305 0 =BLOB= =BLOB= =BLOB= =BLOB=subject1 2021-04-30 12:22:15 0 0 0 5 0 247 256 277 0 =BLOB= =BLOB= =BLOB= =BLOB=subject1 2021-04-30 12:22:15 0 0 0 6 0 146 104 261 0 =BLOB= =BLOB= =BLOB= =BLOB=subject1 2021-04-30 12:22:15 0 0 0 7 0 413 276 189 0 =BLOB= =BLOB= =BLOB= =BLOB=subject1 2021-04-30 12:22:15 0 0 0 8 0 223 92 277 0 =BLOB= =BLOB= =BLOB= =BLOB=subject1 2021-04-30 12:22:15 0 0 0 9 0 150 340 9 0 =BLOB= =BLOB= =BLOB= =BLOB=subject1 2021-04-30 12:22:15 0 0 0 10 0 140 336 69 0 =BLOB= =BLOB= =BLOB= =BLOB=subject1 2021-04-30 12:22:15 0 0 0 11 0 184 136 349 0 =BLOB= =BLOB= =BLOB= =BLOB= <p>...</p> <p>Total: 1276</p> In\u00a0[37]: Copied! <pre>imaging.MaskClassification.MaskType()\n</pre> imaging.MaskClassification.MaskType() Out[37]: <p>subject</p> <p>session_datetime</p> <p>scan_id</p> <p>paramset_idx</p> Unique parameter set ID. <p>curation_id</p> <p>mask_classification_method</p> <p>mask</p> <p>mask_type</p> <p>confidence</p> subject1 2021-04-30 12:22:15 0 0 0 suite2p_default_classifier 0 soma 0.81364subject1 2021-04-30 12:22:15 0 0 0 suite2p_default_classifier 1 soma 0.850127subject1 2021-04-30 12:22:15 0 0 0 suite2p_default_classifier 2 soma 0.747744subject1 2021-04-30 12:22:15 0 0 0 suite2p_default_classifier 3 soma 0.856031subject1 2021-04-30 12:22:15 0 0 0 suite2p_default_classifier 4 soma 0.985041subject1 2021-04-30 12:22:15 0 0 0 suite2p_default_classifier 5 soma 0.825305subject1 2021-04-30 12:22:15 0 0 0 suite2p_default_classifier 6 soma 0.99609subject1 2021-04-30 12:22:15 0 0 0 suite2p_default_classifier 7 soma 0.947971subject1 2021-04-30 12:22:15 0 0 0 suite2p_default_classifier 8 soma 0.963464subject1 2021-04-30 12:22:15 0 0 0 suite2p_default_classifier 9 soma 0.913962subject1 2021-04-30 12:22:15 0 0 0 suite2p_default_classifier 10 soma 0.951404subject1 2021-04-30 12:22:15 0 0 0 suite2p_default_classifier 11 soma 0.922488 <p>...</p> <p>Total: 481</p> <p>Let's use the <code>join</code> operator to combine matching information in <code>imaging.Segmentation.Mask</code> and <code>imaging.MaskClassification.MaskType</code>.   The result contains all matching combinations of entities from both arguments.</p> In\u00a0[38]: Copied! <pre>imaging.Segmentation.Mask * imaging.MaskClassification.MaskType\n</pre> imaging.Segmentation.Mask * imaging.MaskClassification.MaskType Out[38]: <p>subject</p> <p>session_datetime</p> <p>scan_id</p> <p>paramset_idx</p> Unique parameter set ID. <p>curation_id</p> <p>mask</p> <p>mask_classification_method</p> <p>segmentation_channel</p> 0-based indexing <p>mask_npix</p> number of pixels in ROIs <p>mask_center_x</p> center x coordinate in pixel <p>mask_center_y</p> center y coordinate in pixel <p>mask_center_z</p> center z coordinate in pixel <p>mask_xpix</p> x coordinates in pixels <p>mask_ypix</p> y coordinates in pixels <p>mask_zpix</p> z coordinates in pixels <p>mask_weights</p> weights of the mask at the indices above <p>mask_type</p> <p>confidence</p> subject1 2021-04-30 12:22:15 0 0 0 0 suite2p_default_classifier 0 305 176 149 0 =BLOB= =BLOB= =BLOB= =BLOB= soma 0.81364subject1 2021-04-30 12:22:15 0 0 0 1 suite2p_default_classifier 0 177 156 377 0 =BLOB= =BLOB= =BLOB= =BLOB= soma 0.850127subject1 2021-04-30 12:22:15 0 0 0 2 suite2p_default_classifier 0 187 160 165 0 =BLOB= =BLOB= =BLOB= =BLOB= soma 0.747744subject1 2021-04-30 12:22:15 0 0 0 3 suite2p_default_classifier 0 208 48 285 0 =BLOB= =BLOB= =BLOB= =BLOB= soma 0.856031subject1 2021-04-30 12:22:15 0 0 0 4 suite2p_default_classifier 0 153 148 305 0 =BLOB= =BLOB= =BLOB= =BLOB= soma 0.985041subject1 2021-04-30 12:22:15 0 0 0 5 suite2p_default_classifier 0 247 256 277 0 =BLOB= =BLOB= =BLOB= =BLOB= soma 0.825305subject1 2021-04-30 12:22:15 0 0 0 6 suite2p_default_classifier 0 146 104 261 0 =BLOB= =BLOB= =BLOB= =BLOB= soma 0.99609subject1 2021-04-30 12:22:15 0 0 0 7 suite2p_default_classifier 0 413 276 189 0 =BLOB= =BLOB= =BLOB= =BLOB= soma 0.947971subject1 2021-04-30 12:22:15 0 0 0 8 suite2p_default_classifier 0 223 92 277 0 =BLOB= =BLOB= =BLOB= =BLOB= soma 0.963464subject1 2021-04-30 12:22:15 0 0 0 9 suite2p_default_classifier 0 150 340 9 0 =BLOB= =BLOB= =BLOB= =BLOB= soma 0.913962subject1 2021-04-30 12:22:15 0 0 0 10 suite2p_default_classifier 0 140 336 69 0 =BLOB= =BLOB= =BLOB= =BLOB= soma 0.951404subject1 2021-04-30 12:22:15 0 0 0 11 suite2p_default_classifier 0 184 136 349 0 =BLOB= =BLOB= =BLOB= =BLOB= soma 0.922488 <p>...</p> <p>Total: 481</p> <p>We can chain these operators together.</p> In\u00a0[39]: Copied! <pre>imaging.Segmentation.Mask * imaging.MaskClassification.MaskType &amp; \"mask = '10'\"\n</pre> imaging.Segmentation.Mask * imaging.MaskClassification.MaskType &amp; \"mask = '10'\" Out[39]: <p>subject</p> <p>session_datetime</p> <p>scan_id</p> <p>paramset_idx</p> Unique parameter set ID. <p>curation_id</p> <p>mask</p> <p>mask_classification_method</p> <p>segmentation_channel</p> 0-based indexing <p>mask_npix</p> number of pixels in ROIs <p>mask_center_x</p> center x coordinate in pixel <p>mask_center_y</p> center y coordinate in pixel <p>mask_center_z</p> center z coordinate in pixel <p>mask_xpix</p> x coordinates in pixels <p>mask_ypix</p> y coordinates in pixels <p>mask_zpix</p> z coordinates in pixels <p>mask_weights</p> weights of the mask at the indices above <p>mask_type</p> <p>confidence</p> subject1 2021-04-30 12:22:15 0 0 0 10 suite2p_default_classifier 0 140 336 69 0 =BLOB= =BLOB= =BLOB= =BLOB= soma 0.951404 <p>Total: 1</p> In\u00a0[40]: Copied! <pre>imaging.Fluorescence.Trace.fetch(as_dict=True)\n</pre> imaging.Fluorescence.Trace.fetch(as_dict=True) Out[40]: <pre>[{'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 0,\n  'fluo_channel': 0,\n  'fluorescence': array([ 21.180176,  12.217835,  16.598837, ...,  28.693102, -15.97107 ,\n          33.69037 ], dtype=float32),\n  'neuropil_fluorescence': array([-128.18867 , -124.745834, -124.03663 , ..., -110.560486,\n         -106.99001 , -102.409546], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 1,\n  'fluo_channel': 0,\n  'fluorescence': array([-169.26733, -171.18303, -174.36722, ..., -148.03305, -163.48308,\n         -139.91939], dtype=float32),\n  'neuropil_fluorescence': array([-211.88542, -209.3125 , -204.45   , ..., -208.53125, -206.28958,\n         -203.3375 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 2,\n  'fluo_channel': 0,\n  'fluorescence': array([  42.980694,   53.32483 ,   50.93809 , ..., 1173.2704  ,\n          967.8007  ,  986.73175 ], dtype=float32),\n  'neuropil_fluorescence': array([-127.07417, -126.82417, -108.76649, ..., -121.62637, -123.91209,\n         -118.9533 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 3,\n  'fluo_channel': 0,\n  'fluorescence': array([-179.4019 , -190.85756, -185.28091, ..., -212.5552 , -193.70125,\n         -196.2373 ], dtype=float32),\n  'neuropil_fluorescence': array([-220.7252 , -219.09038, -217.09479, ..., -219.64658, -220.76561,\n         -222.50551], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 4,\n  'fluo_channel': 0,\n  'fluorescence': array([-165.05598, -158.67276, -130.26764, ..., -161.41843, -137.48427,\n         -151.21622], dtype=float32),\n  'neuropil_fluorescence': array([-162.56061, -161.41667, -162.34343, ..., -161.51515, -157.96213,\n         -168.30302], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 5,\n  'fluo_channel': 0,\n  'fluorescence': array([-200.36859, -195.71559, -187.77449, ..., -199.39868, -183.31949,\n         -189.72943], dtype=float32),\n  'neuropil_fluorescence': array([-213.79892, -213.58435, -212.7112 , ..., -209.9892 , -212.92578,\n         -207.61134], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 6,\n  'fluo_channel': 0,\n  'fluorescence': array([-119.270386, -116.48309 , -119.13046 , ...,  -70.56637 ,\n          -42.967213,  -27.967813], dtype=float32),\n  'neuropil_fluorescence': array([-128.63747 , -132.30656 , -135.24817 , ..., -111.41606 ,\n         -126.03893 , -111.564476], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 7,\n  'fluo_channel': 0,\n  'fluorescence': array([-115.72348 , -111.01902 ,  -87.00039 , ..., -123.4907  ,\n         -116.423546, -125.27107 ], dtype=float32),\n  'neuropil_fluorescence': array([-138.09044 , -126.00801 , -129.26942 , ..., -126.608574,\n         -125.75648 , -127.36599 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 8,\n  'fluo_channel': 0,\n  'fluorescence': array([-168.81947, -185.1664 , -170.31334, ..., -183.83258, -179.78181,\n         -183.30875], dtype=float32),\n  'neuropil_fluorescence': array([-189.91794, -193.2407 , -202.04924, ..., -188.16739, -197.77023,\n         -195.53282], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 9,\n  'fluo_channel': 0,\n  'fluorescence': array([-148.96033, -159.8661 , -154.13075, ..., -179.89749, -178.08688,\n         -167.14963], dtype=float32),\n  'neuropil_fluorescence': array([-212.6325, -203.34  , -196.7425, ..., -207.7425, -202.865 ,\n         -211.52  ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 10,\n  'fluo_channel': 0,\n  'fluorescence': array([-174.71472, -152.99025, -149.77199, ..., -192.70879, -170.37114,\n         -184.093  ], dtype=float32),\n  'neuropil_fluorescence': array([-192.75792, -192.3733 , -178.7104 , ..., -192.35294, -186.75113,\n         -193.67421], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 11,\n  'fluo_channel': 0,\n  'fluorescence': array([-144.20465, -142.8325 , -137.25075, ..., -150.28966, -144.27316,\n         -147.74568], dtype=float32),\n  'neuropil_fluorescence': array([-182.44847, -171.57184, -169.84906, ..., -172.0929 , -167.88824,\n         -167.69376], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 12,\n  'fluo_channel': 0,\n  'fluorescence': array([ -55.680813,  -56.00467 , -105.3325  , ...,  -95.87572 ,\n          -37.77468 ,  -42.26278 ], dtype=float32),\n  'neuropil_fluorescence': array([-124.347626, -122.53752 , -108.33231 , ..., -100.20214 ,\n         -104.01072 ,  -95.37826 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 13,\n  'fluo_channel': 0,\n  'fluorescence': array([-148.22667 , -130.41156 , -112.11902 , ..., -116.844345,\n         -129.4522  , -145.55185 ], dtype=float32),\n  'neuropil_fluorescence': array([-138.21075, -130.17732, -125.7311 , ..., -144.23692, -122.0189 ,\n         -132.7747 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 14,\n  'fluo_channel': 0,\n  'fluorescence': array([-182.56346, -173.99026, -176.82208, ..., -189.21301, -171.55942,\n         -186.37318], dtype=float32),\n  'neuropil_fluorescence': array([-213.25   , -211.56989, -190.25537, ..., -215.19624, -214.21506,\n         -212.23387], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 15,\n  'fluo_channel': 0,\n  'fluorescence': array([-44.803455, -46.08815 , -20.42361 , ..., -25.381914,  23.924887,\n         -10.638894], dtype=float32),\n  'neuropil_fluorescence': array([-107.67819 ,  -96.16223 ,  -83.31117 , ...,  -84.57979 ,\n          -87.276596, -104.555855], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 16,\n  'fluo_channel': 0,\n  'fluorescence': array([-227.35135, -219.47246, -236.32515, ..., -229.45338, -231.68489,\n         -217.97104], dtype=float32),\n  'neuropil_fluorescence': array([-217.34782, -222.75182, -221.00815, ..., -225.7971 , -219.76358,\n         -223.20018], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 17,\n  'fluo_channel': 0,\n  'fluorescence': array([-80.82915 , -45.725048, -50.01754 , ..., -48.05431 , -31.906225,\n         -53.109745], dtype=float32),\n  'neuropil_fluorescence': array([-181.03358, -153.14212, -154.65892, ..., -157.67442, -157.79329,\n         -158.14987], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 18,\n  'fluo_channel': 0,\n  'fluorescence': array([-137.74371, -131.6773 , -140.47942, ..., -146.0634 , -125.64323,\n         -141.63643], dtype=float32),\n  'neuropil_fluorescence': array([-150.38434, -144.81673, -139.71352, ..., -150.86655, -151.0943 ,\n         -152.32028], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 19,\n  'fluo_channel': 0,\n  'fluorescence': array([-146.22267 , -172.82167 , -132.61713 , ..., -111.797424,\n         -135.33577 , -129.97862 ], dtype=float32),\n  'neuropil_fluorescence': array([-204.81523, -194.92665, -198.24965, ..., -199.94077, -198.30043,\n         -201.81665], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 20,\n  'fluo_channel': 0,\n  'fluorescence': array([-198.0494 , -168.85464, -177.22144, ..., -167.30692, -187.22612,\n         -172.26001], dtype=float32),\n  'neuropil_fluorescence': array([-198.81909, -203.70854, -195.48492, ..., -199.0402 , -200.37437,\n         -198.93718], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 21,\n  'fluo_channel': 0,\n  'fluorescence': array([-189.93504, -157.01518, -196.69229, ..., -201.59229, -194.89941,\n         -194.97226], dtype=float32),\n  'neuropil_fluorescence': array([-213.77412, -207.70078, -206.51738, ..., -210.67375, -212.00966,\n         -213.70078], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 22,\n  'fluo_channel': 0,\n  'fluorescence': array([-117.18565 , -123.23563 , -129.36525 , ...,  -87.20656 ,\n         -118.554985, -128.8101  ], dtype=float32),\n  'neuropil_fluorescence': array([-186.43047, -182.1192 , -177.39073, ..., -185.86313, -194.63576,\n         -184.95143], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 23,\n  'fluo_channel': 0,\n  'fluorescence': array([-236.93431, -241.32161, -248.19783, ..., -227.16083, -241.49934,\n         -233.13733], dtype=float32),\n  'neuropil_fluorescence': array([-254.79608, -255.41599, -253.5938 , ..., -256.4943 , -251.7341 ,\n         -251.34421], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 24,\n  'fluo_channel': 0,\n  'fluorescence': array([-189.76682, -196.41595, -189.82816, ..., -197.86797, -181.73044,\n         -196.63617], dtype=float32),\n  'neuropil_fluorescence': array([-203.08543, -199.91263, -200.0369 , ..., -197.62718, -202.21165,\n         -200.69708], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 25,\n  'fluo_channel': 0,\n  'fluorescence': array([-32.49185 , -57.698635, -65.283394, ...,  60.178425,  40.30542 ,\n          54.226433], dtype=float32),\n  'neuropil_fluorescence': array([-192.2381 , -191.1873 , -190.98254, ..., -196.76508, -191.26825,\n         -191.17143], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 26,\n  'fluo_channel': 0,\n  'fluorescence': array([-10.044948,   9.297727, -32.355476, ..., -19.622604,   7.718963,\n         -22.337574], dtype=float32),\n  'neuropil_fluorescence': array([-119.098175, -109.29452 , -113.80365 , ..., -108.23744 ,\n         -122.54794 , -111.45434 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 27,\n  'fluo_channel': 0,\n  'fluorescence': array([ 81.81241  ,  53.698086 ,  66.46232  , ..., -31.26251  ,\n         -24.14934  ,  -2.7564688], dtype=float32),\n  'neuropil_fluorescence': array([-178.81744, -175.08992, -168.23706, ..., -177.9891 , -182.64032,\n         -188.66486], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 28,\n  'fluo_channel': 0,\n  'fluorescence': array([-157.57341, -172.9847 , -153.97134, ..., -191.01764, -184.29982,\n         -171.56174], dtype=float32),\n  'neuropil_fluorescence': array([-171.32346, -171.6492 , -169.46925, ..., -183.85764, -180.84055,\n         -186.25967], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 29,\n  'fluo_channel': 0,\n  'fluorescence': array([-183.76567, -192.30402, -178.48776, ..., -135.41222, -160.74315,\n         -145.30162], dtype=float32),\n  'neuropil_fluorescence': array([-192.96448, -202.91803, -183.77869, ..., -192.45901, -201.11476,\n         -195.19398], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 30,\n  'fluo_channel': 0,\n  'fluorescence': array([ -44.96631 ,  -44.145626,  -72.411415, ..., -106.09647 ,\n         -117.322495, -106.67276 ], dtype=float32),\n  'neuropil_fluorescence': array([-150.55905, -147.55118, -147.90945, ..., -154.81299, -166.05708,\n         -166.51968], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 31,\n  'fluo_channel': 0,\n  'fluorescence': array([-123.950264,  -87.38169 , -124.92187 , ..., -143.27017 ,\n         -122.1478  , -140.90213 ], dtype=float32),\n  'neuropil_fluorescence': array([-166.06451, -151.95053, -165.94409, ..., -169.31613, -157.01721,\n         -163.11829], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 32,\n  'fluo_channel': 0,\n  'fluorescence': array([-111.8359  ,  -95.142044,  -66.72059 , ...,  100.805374,\n           69.71697 ,   65.93716 ], dtype=float32),\n  'neuropil_fluorescence': array([-162.76892, -144.20717, -142.71846, ..., -159.85126, -162.62816,\n         -154.98141], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 33,\n  'fluo_channel': 0,\n  'fluorescence': array([-134.54971, -120.0702 , -140.33571, ..., -151.89763, -154.81204,\n         -169.95396], dtype=float32),\n  'neuropil_fluorescence': array([-132.17412, -103.95529, -114.68235, ..., -113.32235, -128.74823,\n         -121.10588], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 34,\n  'fluo_channel': 0,\n  'fluorescence': array([-161.32217, -142.7205 , -141.39578, ..., -133.50186, -137.03217,\n         -154.48393], dtype=float32),\n  'neuropil_fluorescence': array([-214.275  , -211.57307, -195.30577, ..., -199.95961, -211.87308,\n         -204.46538], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 35,\n  'fluo_channel': 0,\n  'fluorescence': array([-72.920395, -47.08513 , -80.330864, ..., -85.0679  , -67.21991 ,\n         -43.40879 ], dtype=float32),\n  'neuropil_fluorescence': array([-144.87593 , -139.10173 , -142.      , ..., -124.67742 ,\n         -132.92308 , -122.062035], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 36,\n  'fluo_channel': 0,\n  'fluorescence': array([-218.7249 , -212.84991, -202.60808, ..., -228.76935, -221.93938,\n         -219.45273], dtype=float32),\n  'neuropil_fluorescence': array([-216.8363 , -219.16693, -215.28363, ..., -214.72772, -214.41653,\n         -218.45543], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 37,\n  'fluo_channel': 0,\n  'fluorescence': array([ -97.21355,  -81.09855, -110.10665, ...,  -85.97683,  -68.95902,\n          -86.43661], dtype=float32),\n  'neuropil_fluorescence': array([-185.42018, -178.44131, -176.56807, ..., -189.02113, -175.69952,\n         -183.0446 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 38,\n  'fluo_channel': 0,\n  'fluorescence': array([-183.98743, -162.73775, -163.34062, ..., -179.17598, -169.86264,\n         -172.42749], dtype=float32),\n  'neuropil_fluorescence': array([-224.45886, -216.61366, -214.27615, ..., -213.16318, -220.41005,\n         -219.98885], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 39,\n  'fluo_channel': 0,\n  'fluorescence': array([-132.33386, -121.83051, -148.97571, ..., -225.28317, -230.68758,\n         -203.89415], dtype=float32),\n  'neuropil_fluorescence': array([-261.20276, -255.20967, -253.14285, ..., -260.92627, -259.7189 ,\n         -263.21198], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 40,\n  'fluo_channel': 0,\n  'fluorescence': array([  3.8497005, -10.305673 ,  -8.944222 , ...,  -5.645932 ,\n           4.0239162,  13.512929 ], dtype=float32),\n  'neuropil_fluorescence': array([-140.53032, -146.06421, -143.0547 , ..., -140.91557, -139.54697,\n         -136.75862], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 41,\n  'fluo_channel': 0,\n  'fluorescence': array([-203.49088, -167.81462, -165.47557, ...,  -93.5207 , -123.119  ,\n         -134.76906], dtype=float32),\n  'neuropil_fluorescence': array([-217.13809, -215.04762, -211.53094, ..., -215.82619, -220.46906,\n         -211.35477], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 42,\n  'fluo_channel': 0,\n  'fluorescence': array([-116.51622 ,  -71.72302 , -109.67615 , ...,  -68.82018 ,\n         -105.61579 , -101.650345], dtype=float32),\n  'neuropil_fluorescence': array([-189.26277, -166.90997, -173.96107, ..., -181.0219 , -180.5742 ,\n         -175.50365], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 43,\n  'fluo_channel': 0,\n  'fluorescence': array([-120.17752, -124.83072, -130.42741, ...,  -99.45144,  -96.21577,\n         -124.21901], dtype=float32),\n  'neuropil_fluorescence': array([-197.4011 , -196.60715, -198.56319, ..., -206.25275, -192.42033,\n         -202.1044 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 44,\n  'fluo_channel': 0,\n  'fluorescence': array([-159.46765, -143.22917, -151.7831 , ..., -171.2457 , -140.81514,\n         -163.40747], dtype=float32),\n  'neuropil_fluorescence': array([-198.27591, -199.59758, -192.393  , ..., -192.47375, -189.8035 ,\n         -194.22746], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 45,\n  'fluo_channel': 0,\n  'fluorescence': array([-104.26333 ,  -92.42863 ,  -72.13909 , ...,  -59.57685 ,\n          -51.64952 ,  -55.951885], dtype=float32),\n  'neuropil_fluorescence': array([-178.10722, -167.78119, -162.56454, ..., -165.75711, -178.43326,\n         -173.79431], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 46,\n  'fluo_channel': 0,\n  'fluorescence': array([ -88.48904 ,  -88.09516 , -100.23228 , ..., -109.146255,\n         -116.42792 , -124.98354 ], dtype=float32),\n  'neuropil_fluorescence': array([-192.96184, -185.71565, -186.77863, ..., -190.1126 , -189.06107,\n         -199.44084], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 47,\n  'fluo_channel': 0,\n  'fluorescence': array([-211.29042, -197.68388, -216.40205, ..., -190.55795, -206.7829 ,\n         -205.24072], dtype=float32),\n  'neuropil_fluorescence': array([-234.66534, -230.35449, -228.3082 , ..., -226.11375, -229.88757,\n         -223.70238], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 48,\n  'fluo_channel': 0,\n  'fluorescence': array([-31.01376 , -56.480076, -26.710825, ..., -19.891321, -18.626543,\n         -20.198261], dtype=float32),\n  'neuropil_fluorescence': array([-97.77562 , -86.40997 , -76.9903  , ..., -89.249306, -83.48615 ,\n         -86.16482 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 49,\n  'fluo_channel': 0,\n  'fluorescence': array([-115.94613 , -111.476944,  -78.46872 , ..., -115.22328 ,\n         -101.618355, -127.590004], dtype=float32),\n  'neuropil_fluorescence': array([-187.0366 , -174.64725, -177.16139, ..., -178.9351 , -183.71048,\n         -178.88353], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 50,\n  'fluo_channel': 0,\n  'fluorescence': array([-25.410503 , -15.383116 ,   3.9452572, ...,  -2.80086  ,\n         -21.482502 , -21.228481 ], dtype=float32),\n  'neuropil_fluorescence': array([-144.25824, -141.4066 , -130.6401 , ..., -133.03572, -108.99725,\n         -110.48077], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 51,\n  'fluo_channel': 0,\n  'fluorescence': array([-156.49742, -133.4118 , -145.41364, ..., -136.27827,  -65.56344,\n         -143.23871], dtype=float32),\n  'neuropil_fluorescence': array([-124.382225, -134.02821 , -131.88576 , ..., -126.86742 ,\n         -133.22003 , -132.04231 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 52,\n  'fluo_channel': 0,\n  'fluorescence': array([-149.65054, -169.78934, -174.4805 , ..., -167.23853, -171.25117,\n         -166.70184], dtype=float32),\n  'neuropil_fluorescence': array([-217.08482, -214.19643, -212.3259 , ..., -212.85268, -212.68527,\n         -209.95312], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 53,\n  'fluo_channel': 0,\n  'fluorescence': array([-180.10703, -189.8349 , -190.46756, ..., -203.71825, -202.61803,\n         -192.27464], dtype=float32),\n  'neuropil_fluorescence': array([-220.00278, -215.85042, -216.53186, ..., -222.78394, -220.3047 ,\n         -224.62881], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 54,\n  'fluo_channel': 0,\n  'fluorescence': array([-142.75081, -130.88437, -161.52837, ..., -170.29324, -179.5519 ,\n         -154.88734], dtype=float32),\n  'neuropil_fluorescence': array([-215.59831, -201.82866, -217.64607, ..., -219.07303, -207.54494,\n         -210.82303], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 55,\n  'fluo_channel': 0,\n  'fluorescence': array([ -79.28337,  -68.82533,  -46.95379, ...,  -70.81418, -137.78636,\n         -113.84658], dtype=float32),\n  'neuropil_fluorescence': array([-196.5057 , -172.82129, -163.20152, ..., -207.8327 , -203.01775,\n         -206.59062], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 56,\n  'fluo_channel': 0,\n  'fluorescence': array([-127.84417, -129.28546, -162.41869, ..., -124.46698, -143.5701 ,\n         -127.61962], dtype=float32),\n  'neuropil_fluorescence': array([-157.7371 , -143.95361, -152.86082, ..., -159.62114, -166.0567 ,\n         -151.48969], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 57,\n  'fluo_channel': 0,\n  'fluorescence': array([ -78.15949  ,  -48.437294 ,    3.2452543, ...,  926.4789   ,\n          987.55963  , 1049.8948   ], dtype=float32),\n  'neuropil_fluorescence': array([-120.820366, -120.1471  , -130.50636 , ..., -119.02405 ,\n         -104.68883 , -112.319664], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 58,\n  'fluo_channel': 0,\n  'fluorescence': array([-19.513802, -27.309216, -26.185965, ..., -49.896046, -57.802025,\n         -41.172157], dtype=float32),\n  'neuropil_fluorescence': array([-128.64873, -111.30344, -111.00897, ..., -126.44694, -122.07773,\n         -129.67116], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 59,\n  'fluo_channel': 0,\n  'fluorescence': array([ -96.251  ,  -80.78947,  -28.76978, ..., -170.7195 , -164.17151,\n         -147.65729], dtype=float32),\n  'neuropil_fluorescence': array([-203.20857, -209.50652, -201.00558, ..., -215.31099, -201.90317,\n         -213.68529], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 60,\n  'fluo_channel': 0,\n  'fluorescence': array([-253.31233, -240.81865, -245.41473, ..., -260.6626 , -249.97903,\n         -256.77237], dtype=float32),\n  'neuropil_fluorescence': array([-267.8969 , -267.06805, -263.64743, ..., -262.68042, -265.24744,\n         -265.5402 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 61,\n  'fluo_channel': 0,\n  'fluorescence': array([-80.15509 , -80.26711 , -59.255363, ..., -76.562164, -74.924576,\n         -88.32225 ], dtype=float32),\n  'neuropil_fluorescence': array([-164.72528, -165.98242, -174.29561, ..., -176.36264, -167.92638,\n         -163.15384], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 62,\n  'fluo_channel': 0,\n  'fluorescence': array([-2.6570432, 23.383663 , 65.80783  , ..., 30.069935 , 23.43609  ,\n         31.786516 ], dtype=float32),\n  'neuropil_fluorescence': array([-169.51369, -132.38316, -146.01263, ..., -153.4379 , -134.99579,\n         -139.26105], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 63,\n  'fluo_channel': 0,\n  'fluorescence': array([-104.89259, -105.71122, -111.99289, ..., -110.86931, -105.29077,\n         -124.25081], dtype=float32),\n  'neuropil_fluorescence': array([-191.19743, -195.6    , -195.28975, ..., -188.73077, -191.56667,\n         -194.98206], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 64,\n  'fluo_channel': 0,\n  'fluorescence': array([-187.87512, -192.47554, -195.66144, ..., -209.78212, -208.54173,\n         -179.6352 ], dtype=float32),\n  'neuropil_fluorescence': array([-170.99503, -187.50249, -181.46767, ..., -185.36568, -195.91791,\n         -181.10199], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 65,\n  'fluo_channel': 0,\n  'fluorescence': array([-232.28706, -234.31207, -244.25638, ..., -216.6127 , -237.22914,\n         -213.74222], dtype=float32),\n  'neuropil_fluorescence': array([-238.4477 , -238.56448, -232.73479, ..., -238.50365, -239.61801,\n         -243.83455], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 66,\n  'fluo_channel': 0,\n  'fluorescence': array([-160.5222 , -182.16386, -165.95264, ..., -183.7369 , -166.50003,\n         -167.52533], dtype=float32),\n  'neuropil_fluorescence': array([-223.44  , -218.475 , -217.845 , ..., -222.44  , -220.7325,\n         -222.275 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 67,\n  'fluo_channel': 0,\n  'fluorescence': array([-193.12344, -147.74648, -179.79485, ..., -210.75078, -200.53079,\n         -150.23392], dtype=float32),\n  'neuropil_fluorescence': array([-205.71602, -193.66768, -189.25226, ..., -195.1133 , -198.929  ,\n         -191.62085], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 68,\n  'fluo_channel': 0,\n  'fluorescence': array([-189.06721, -181.84566, -153.76515, ..., -194.2845 , -186.71823,\n         -157.14737], dtype=float32),\n  'neuropil_fluorescence': array([-234.12434, -242.32805, -235.57936, ..., -228.7381 , -233.46825,\n         -240.53175], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 69,\n  'fluo_channel': 0,\n  'fluorescence': array([-37.19257 , -19.477743, -16.169935, ..., -48.63792 , -69.84096 ,\n         -79.27687 ], dtype=float32),\n  'neuropil_fluorescence': array([-195.60114, -194.42735, -190.8661 , ..., -187.29488, -191.25926,\n         -191.2037 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 70,\n  'fluo_channel': 0,\n  'fluorescence': array([ -87.57433 , -109.51834 ,  -68.745834, ...,  -64.53773 ,\n          -90.60816 , -101.13413 ], dtype=float32),\n  'neuropil_fluorescence': array([-149.04836, -161.71503, -148.48532, ..., -165.5665 , -163.67012,\n         -144.5803 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 71,\n  'fluo_channel': 0,\n  'fluorescence': array([-207.26048, -212.69878, -198.50882, ..., -197.50537, -214.71971,\n         -204.50706], dtype=float32),\n  'neuropil_fluorescence': array([-172.86597, -156.91608, -164.28438, ..., -163.73193, -156.29138,\n         -165.45804], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 72,\n  'fluo_channel': 0,\n  'fluorescence': array([-79.30463 , -48.111565, -69.43321 , ..., -36.195923, -62.4542  ,\n         -56.907627], dtype=float32),\n  'neuropil_fluorescence': array([-111.49375 , -115.140625, -110.13125 , ..., -119.52812 ,\n         -114.41563 , -111.7375  ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 73,\n  'fluo_channel': 0,\n  'fluorescence': array([-175.54935, -171.80084, -150.28253, ..., -170.2641 , -182.81158,\n         -159.9778 ], dtype=float32),\n  'neuropil_fluorescence': array([-205.33803, -209.26526, -199.43896, ..., -201.73709, -208.85681,\n         -208.11032], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 74,\n  'fluo_channel': 0,\n  'fluorescence': array([-119.58519 , -129.98434 , -107.63842 , ..., -118.504745,\n          -89.790726, -102.57008 ], dtype=float32),\n  'neuropil_fluorescence': array([-123.3743 , -117.63687, -104.88268, ..., -120.57821, -123.01676,\n         -107.13687], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 75,\n  'fluo_channel': 0,\n  'fluorescence': array([-149.83946, -158.82758, -169.21736, ..., -153.3896 , -153.36389,\n         -127.17283], dtype=float32),\n  'neuropil_fluorescence': array([-224.08252, -225.0118 , -216.53635, ..., -216.9273 , -218.58153,\n         -217.19057], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 76,\n  'fluo_channel': 0,\n  'fluorescence': array([-137.25134, -182.13875, -169.1678 , ..., -186.99098, -174.35782,\n         -139.89749], dtype=float32),\n  'neuropil_fluorescence': array([-203.52032, -193.31165, -195.25475, ..., -197.65312, -192.81844,\n         -214.60434], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 77,\n  'fluo_channel': 0,\n  'fluorescence': array([  12.099093,  -37.338585,  -52.149006, ..., -233.11887 ,\n         -232.41475 , -219.80016 ], dtype=float32),\n  'neuropil_fluorescence': array([-245.19164, -250.38766, -249.63216, ..., -243.53525, -251.13435,\n         -245.45815], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 78,\n  'fluo_channel': 0,\n  'fluorescence': array([-179.14943, -182.1253 , -158.23843, ..., -150.9413 , -190.28033,\n         -161.05429], dtype=float32),\n  'neuropil_fluorescence': array([-202.65807, -191.52043, -194.4172 , ..., -198.56345, -205.78064,\n         -204.47742], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 79,\n  'fluo_channel': 0,\n  'fluorescence': array([ -83.87475 ,  -96.38467 ,  -99.83239 , ..., -116.714424,\n          -75.12845 ,  -52.10111 ], dtype=float32),\n  'neuropil_fluorescence': array([-163.19513, -148.03104, -146.05544, ..., -158.57872, -153.86919,\n         -158.45233], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 80,\n  'fluo_channel': 0,\n  'fluorescence': array([-155.42107, -139.25734, -115.31146, ..., -128.31516,  -94.6203 ,\n         -124.00369], dtype=float32),\n  'neuropil_fluorescence': array([-165.2619 , -163.40874, -161.7004 , ..., -140.27182, -167.25595,\n         -161.69643], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 81,\n  'fluo_channel': 0,\n  'fluorescence': array([-84.68362 , -83.298325, -71.360825, ..., -68.87202 , -85.643936,\n         -86.482216], dtype=float32),\n  'neuropil_fluorescence': array([-174.3082 , -177.24168, -175.18182, ..., -159.56541, -168.14412,\n         -164.65633], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 82,\n  'fluo_channel': 0,\n  'fluorescence': array([ -73.66212 ,  -66.81203 ,  -40.195133, ..., -103.89937 ,\n          -91.13391 , -104.78274 ], dtype=float32),\n  'neuropil_fluorescence': array([-199.30052, -194.48155, -201.3058 , ..., -193.70123, -198.58699,\n         -195.67311], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 83,\n  'fluo_channel': 0,\n  'fluorescence': array([ -63.834057, -128.1902  ,  -48.60602 , ...,  -91.59826 ,\n         -114.673355, -109.09897 ], dtype=float32),\n  'neuropil_fluorescence': array([-206.73177, -207.48   , -201.04941, ..., -201.48706, -203.62589,\n         -202.33412], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 84,\n  'fluo_channel': 0,\n  'fluorescence': array([-147.09308, -144.28717, -138.68787, ..., -164.54092, -141.67982,\n         -142.62083], dtype=float32),\n  'neuropil_fluorescence': array([-168.4013 , -162.31888, -153.64859, ..., -174.1063 , -172.8872 ,\n         -178.47722], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 85,\n  'fluo_channel': 0,\n  'fluorescence': array([-144.83737 , -124.667336, -140.29233 , ..., -154.78389 ,\n         -142.1583  , -125.01922 ], dtype=float32),\n  'neuropil_fluorescence': array([-164.32   , -167.96   , -156.3242 , ..., -162.77052, -155.81895,\n         -160.10316], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 86,\n  'fluo_channel': 0,\n  'fluorescence': array([  8.156587 , -34.92955  ,  74.20246  , ...,  11.057793 ,\n           0.8369042, -67.158356 ], dtype=float32),\n  'neuropil_fluorescence': array([-123.6944, -127.5648, -130.8432, ..., -135.0352, -139.9984,\n         -136.4192], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 87,\n  'fluo_channel': 0,\n  'fluorescence': array([-200.17387, -190.77603, -178.46869, ..., -178.88812, -184.6617 ,\n         -186.86366], dtype=float32),\n  'neuropil_fluorescence': array([-219.64963, -213.0365 , -214.72263, ..., -219.84671, -216.63991,\n         -213.86131], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 88,\n  'fluo_channel': 0,\n  'fluorescence': array([-53.575222, -23.916147, -34.700916, ..., -52.311466, -39.237682,\n         -59.98731 ], dtype=float32),\n  'neuropil_fluorescence': array([-141.94527, -141.32587, -138.1393 , ..., -140.60199, -135.07463,\n         -144.13184], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 89,\n  'fluo_channel': 0,\n  'fluorescence': array([-142.36305 , -100.09268 , -119.120895, ..., -127.959175,\n         -133.13132 , -129.67805 ], dtype=float32),\n  'neuropil_fluorescence': array([-212.7106 , -201.56667, -195.95605, ..., -206.32576, -213.59697,\n         -206.74849], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 90,\n  'fluo_channel': 0,\n  'fluorescence': array([-172.3582   , -185.07195  , -166.00595  , ...,   -3.6923888,\n          -15.741239 ,  -16.036732 ], dtype=float32),\n  'neuropil_fluorescence': array([-205.06483, -209.77472, -198.76985, ..., -198.97893, -198.80064,\n         -194.66289], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 91,\n  'fluo_channel': 0,\n  'fluorescence': array([-108.82113, -117.30753, -126.75079, ...,  -73.45062, -106.66771,\n         -125.15012], dtype=float32),\n  'neuropil_fluorescence': array([-180.89548, -168.03673, -182.13841, ..., -177.18361, -171.18079,\n         -182.64972], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 92,\n  'fluo_channel': 0,\n  'fluorescence': array([-103.02391 ,  -92.461655, -111.19847 , ...,  -74.86911 ,\n          -80.46975 ,  -96.76834 ], dtype=float32),\n  'neuropil_fluorescence': array([-133.92857 , -136.3375  , -129.22322 , ..., -140.26071 ,\n         -131.00893 , -116.394646], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 93,\n  'fluo_channel': 0,\n  'fluorescence': array([-167.16748, -176.70049, -153.78839, ..., -167.26541, -168.62607,\n         -179.21596], dtype=float32),\n  'neuropil_fluorescence': array([-187.68149, -194.67654, -192.00494, ..., -187.85925, -191.79259,\n         -176.4    ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 94,\n  'fluo_channel': 0,\n  'fluorescence': array([ -0.7410181,   6.156826 ,  21.473583 , ..., -44.433662 ,\n          11.88832  ,  18.532822 ], dtype=float32),\n  'neuropil_fluorescence': array([ -99.94865,  -88.91351,  -92.24865, ..., -103.73784,  -95.57027,\n          -91.27838], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 95,\n  'fluo_channel': 0,\n  'fluorescence': array([-204.4856 , -205.05562, -214.52815, ..., -222.93054, -204.43556,\n         -215.1078 ], dtype=float32),\n  'neuropil_fluorescence': array([-224.32372, -214.52724, -209.8109 , ..., -226.10257, -220.95352,\n         -222.16827], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 96,\n  'fluo_channel': 0,\n  'fluorescence': array([-56.6036  , -50.415962, -14.734417, ...,   2.505546, -69.423035,\n         -30.500896], dtype=float32),\n  'neuropil_fluorescence': array([-164.43498, -170.54846, -160.92908, ..., -156.49646, -157.30733,\n         -145.06383], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 97,\n  'fluo_channel': 0,\n  'fluorescence': array([ -87.69948 ,  -96.591675, -114.23877 , ...,  -89.059006,\n         -105.856125, -121.70957 ], dtype=float32),\n  'neuropil_fluorescence': array([-136.33855, -141.10371, -129.09198, ..., -133.13895, -136.10176,\n         -124.05088], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 98,\n  'fluo_channel': 0,\n  'fluorescence': array([-220.53242, -227.0129 , -207.64803, ..., -235.09517, -225.62146,\n         -236.81583], dtype=float32),\n  'neuropil_fluorescence': array([-259.80942, -250.15842, -249.52475, ..., -256.70544, -256.16336,\n         -253.43813], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 99,\n  'fluo_channel': 0,\n  'fluorescence': array([-187.05798, -163.28365, -173.41005, ..., -189.10541, -176.9316 ,\n         -207.97589], dtype=float32),\n  'neuropil_fluorescence': array([-203.62785, -216.53165, -205.43037, ..., -216.37215, -197.77469,\n         -219.94177], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 100,\n  'fluo_channel': 0,\n  'fluorescence': array([-124.519226, -110.037445, -117.179375, ..., -101.35285 ,\n          -68.83583 , -117.807   ], dtype=float32),\n  'neuropil_fluorescence': array([-154.97218, -149.56027, -139.73245, ..., -156.21854, -145.3298 ,\n         -151.87814], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 101,\n  'fluo_channel': 0,\n  'fluorescence': array([-201.06053, -197.65329, -181.10208, ..., -223.35054, -217.02242,\n         -179.99927], dtype=float32),\n  'neuropil_fluorescence': array([-240.25415, -247.06078, -238.30386, ..., -245.45027, -249.75967,\n         -242.06906], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 102,\n  'fluo_channel': 0,\n  'fluorescence': array([-140.58438, -140.67073, -149.40228, ..., -153.36407, -138.36093,\n         -110.32296], dtype=float32),\n  'neuropil_fluorescence': array([-192.87212, -194.28133, -192.14322, ..., -196.08185, -192.09718,\n         -186.9821 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 103,\n  'fluo_channel': 0,\n  'fluorescence': array([-89.414986, -78.56687 , -64.27232 , ...,   2.704593, -10.57992 ,\n          21.718693], dtype=float32),\n  'neuropil_fluorescence': array([-110.043816, -112.21263 , -119.05541 , ...,  -94.72036 ,\n          -99.21778 ,  -98.765465], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 104,\n  'fluo_channel': 0,\n  'fluorescence': array([-160.89476, -158.54507, -158.96404, ..., -200.56325, -177.61807,\n         -166.90497], dtype=float32),\n  'neuropil_fluorescence': array([-194.71922, -182.78618, -191.96112, ..., -201.41252, -188.81857,\n         -193.01295], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 105,\n  'fluo_channel': 0,\n  'fluorescence': array([-168.64186, -139.09178, -166.89865, ..., -149.21902, -136.75757,\n         -170.0938 ], dtype=float32),\n  'neuropil_fluorescence': array([-225.59528, -220.72821, -227.07681, ..., -221.16396, -219.99704,\n         -225.38109], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 106,\n  'fluo_channel': 0,\n  'fluorescence': array([-224.18776, -218.78734, -218.67053, ..., -219.11427, -228.27031,\n         -211.29228], dtype=float32),\n  'neuropil_fluorescence': array([-259.37973, -262.2644 , -264.69186, ..., -258.73956, -262.499  ,\n         -261.22067], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 107,\n  'fluo_channel': 0,\n  'fluorescence': array([-179.63347, -179.88728, -149.50117, ..., -173.12692, -173.43385,\n         -174.16649], dtype=float32),\n  'neuropil_fluorescence': array([-214.73248, -211.2293 , -207.15286, ..., -210.47134, -208.81316,\n         -210.16136], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 108,\n  'fluo_channel': 0,\n  'fluorescence': array([-71.9564  , -41.188316, -44.24605 , ...,  19.904888,  17.034027,\n         -37.36014 ], dtype=float32),\n  'neuropil_fluorescence': array([-142.36655, -138.17905, -128.9527 , ..., -116.01013, -115.46622,\n         -104.28716], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 109,\n  'fluo_channel': 0,\n  'fluorescence': array([-205.08516, -206.42017, -197.79372, ..., -196.24605, -189.70184,\n         -187.61082], dtype=float32),\n  'neuropil_fluorescence': array([-210.03482, -205.53482, -190.14676, ..., -199.99254, -197.75623,\n         -202.06966], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 110,\n  'fluo_channel': 0,\n  'fluorescence': array([-138.61209, -143.26384, -145.97386, ..., -148.36801, -164.36383,\n         -174.05717], dtype=float32),\n  'neuropil_fluorescence': array([-192.13388, -177.04645, -181.37704, ..., -199.03279, -194.5601 ,\n         -198.36066], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 111,\n  'fluo_channel': 0,\n  'fluorescence': array([-186.06143, -169.33922, -165.7404 , ..., -189.35684, -195.52197,\n         -201.27563], dtype=float32),\n  'neuropil_fluorescence': array([-228.71207, -230.7432 , -222.15823, ..., -228.95201, -233.33852,\n         -231.84047], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 112,\n  'fluo_channel': 0,\n  'fluorescence': array([-152.3073 , -180.0179 , -115.50044, ..., -161.39044, -144.14941,\n         -149.07047], dtype=float32),\n  'neuropil_fluorescence': array([ -99.10553 ,  -93.201004,  -94.08543 , ..., -109.27387 ,\n          -81.81909 ,  -80.5201  ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 113,\n  'fluo_channel': 0,\n  'fluorescence': array([-158.27364, -172.06609, -145.3336 , ..., -177.26451, -174.01265,\n         -179.51689], dtype=float32),\n  'neuropil_fluorescence': array([-187.45575, -180.68031, -175.92867, ..., -179.20343, -182.42668,\n         -182.99736], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 114,\n  'fluo_channel': 0,\n  'fluorescence': array([-214.26521, -215.28542, -202.49402, ..., -234.30347, -215.237  ,\n         -207.45863], dtype=float32),\n  'neuropil_fluorescence': array([-185.57222, -174.33333, -180.15695, ..., -184.42917, -176.24167,\n         -189.72362], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 115,\n  'fluo_channel': 0,\n  'fluorescence': array([ -66.063446, -104.92439 ,  -79.15133 , ...,  -98.4035  ,\n          -89.951324,  -63.58437 ], dtype=float32),\n  'neuropil_fluorescence': array([-127.31858 , -111.79056 , -117.99262 , ..., -108.13422 ,\n         -113.100296, -112.54277 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 116,\n  'fluo_channel': 0,\n  'fluorescence': array([-206.06006, -191.21252, -203.88832, ..., -197.86063, -222.70604,\n         -189.30528], dtype=float32),\n  'neuropil_fluorescence': array([-197.65987, -212.9796 , -208.53061, ..., -208.05443, -208.9932 ,\n         -205.06349], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 117,\n  'fluo_channel': 0,\n  'fluorescence': array([-150.94627, -136.39774, -145.50247, ..., -134.01038, -145.90924,\n         -166.58473], dtype=float32),\n  'neuropil_fluorescence': array([-210.7456 , -211.22508, -205.83118, ..., -212.25674, -201.82767,\n         -211.4408 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 118,\n  'fluo_channel': 0,\n  'fluorescence': array([-144.51923, -171.33508, -133.83253, ..., -195.09375, -180.44989,\n         -140.26825], dtype=float32),\n  'neuropil_fluorescence': array([-207.92319, -202.40329, -208.9561 , ..., -201.87929, -202.87242,\n         -205.11522], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 119,\n  'fluo_channel': 0,\n  'fluorescence': array([-176.85703, -167.37595, -167.5867 , ..., -194.78348, -207.14148,\n         -211.24548], dtype=float32),\n  'neuropil_fluorescence': array([-226.93988, -221.495  , -219.77155, ..., -227.7956 , -231.58917,\n         -233.11623], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 120,\n  'fluo_channel': 0,\n  'fluorescence': array([-240.56277, -240.89299, -240.05872, ..., -246.79105, -251.49762,\n         -244.95686], dtype=float32),\n  'neuropil_fluorescence': array([-254.98692, -257.85046, -251.2785 , ..., -254.06915, -256.03177,\n         -256.48224], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 121,\n  'fluo_channel': 0,\n  'fluorescence': array([-61.339085, -87.6321  , -57.645927, ..., -47.33764 , -62.077236,\n         -93.98277 ], dtype=float32),\n  'neuropil_fluorescence': array([-126.855034, -119.70762 , -114.14251 , ..., -110.18673 ,\n         -116.309586, -131.08109 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 122,\n  'fluo_channel': 0,\n  'fluorescence': array([-164.32613, -161.87427, -144.47266, ..., -145.91522, -178.1104 ,\n         -133.71912], dtype=float32),\n  'neuropil_fluorescence': array([-212.18579, -200.20493, -201.63661, ..., -195.05737, -190.84427,\n         -191.2295 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 123,\n  'fluo_channel': 0,\n  'fluorescence': array([-177.79967, -211.83505, -185.76357, ..., -184.2884 , -170.63535,\n         -207.8085 ], dtype=float32),\n  'neuropil_fluorescence': array([-231.94916, -229.95883, -230.17433, ..., -224.33656, -217.63438,\n         -229.02179], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 124,\n  'fluo_channel': 0,\n  'fluorescence': array([-47.758797 ,  -3.8811758, -25.302082 , ..., -48.98487  ,\n         -45.706    , -21.145952 ], dtype=float32),\n  'neuropil_fluorescence': array([-132.82143 , -110.733086, -116.32143 , ..., -116.4624  ,\n         -120.919174, -109.016914], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 125,\n  'fluo_channel': 0,\n  'fluorescence': array([-74.29707 , -36.747787, -49.540226, ..., -23.537605, -38.90672 ,\n         -43.92095 ], dtype=float32),\n  'neuropil_fluorescence': array([-146.08476, -152.9005 , -141.23833, ..., -137.86487, -137.03317,\n         -135.20393], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 126,\n  'fluo_channel': 0,\n  'fluorescence': array([-232.70654, -244.81396, -234.86488, ..., -232.1155 , -244.03134,\n         -232.88577], dtype=float32),\n  'neuropil_fluorescence': array([-248.03949, -214.22533, -215.88037, ..., -235.96283, -241.16725,\n         -236.4971 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 127,\n  'fluo_channel': 0,\n  'fluorescence': array([ -76.28732 ,  -83.93752 ,  -59.253735, ...,  -60.334423,\n         -130.49615 ,  -46.450565], dtype=float32),\n  'neuropil_fluorescence': array([-186.86774, -159.75291, -164.25291, ..., -173.94041, -163.6497 ,\n         -169.34012], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 128,\n  'fluo_channel': 0,\n  'fluorescence': array([-184.35158, -152.68245, -137.47028, ..., -145.755  , -188.31993,\n         -196.11763], dtype=float32),\n  'neuropil_fluorescence': array([-229.84395, -217.72073, -219.83162, ..., -226.2156 , -225.07187,\n         -217.95482], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 129,\n  'fluo_channel': 0,\n  'fluorescence': array([ -75.16701 ,  -83.4684  , -114.413704, ..., -126.544716,\n         -152.60191 , -146.45909 ], dtype=float32),\n  'neuropil_fluorescence': array([-183.80426, -177.27519, -179.5562 , ..., -187.27132, -187.42636,\n         -178.3527 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 130,\n  'fluo_channel': 0,\n  'fluorescence': array([-136.96147 , -116.812126, -107.01017 , ..., -118.002205,\n         -148.6857  , -132.8099  ], dtype=float32),\n  'neuropil_fluorescence': array([-197.34872, -187.64615, -173.0641 , ..., -180.50256, -181.30513,\n         -182.33333], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 131,\n  'fluo_channel': 0,\n  'fluorescence': array([-196.09694, -209.68117, -205.82085, ..., -203.38919, -209.9486 ,\n         -221.50471], dtype=float32),\n  'neuropil_fluorescence': array([-186.39378, -183.94118, -190.6013 , ..., -189.43628, -187.56372,\n         -185.5049 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 132,\n  'fluo_channel': 0,\n  'fluorescence': array([ -95.55966,  -95.87457,  -72.86125, ...,  -80.09114, -105.10182,\n         -106.72774], dtype=float32),\n  'neuropil_fluorescence': array([-128.03703 , -124.162964, -117.269135, ..., -134.47902 ,\n         -125.748146, -134.2395  ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 133,\n  'fluo_channel': 0,\n  'fluorescence': array([-125.54966 ,  -89.584145,  -95.425606, ..., -114.55713 ,\n          -96.89712 ,  -93.23986 ], dtype=float32),\n  'neuropil_fluorescence': array([-147.0967 , -138.69211, -150.29007, ..., -155.78117, -146.75317,\n         -162.75572], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 134,\n  'fluo_channel': 0,\n  'fluorescence': array([-118.05009 , -110.47744 ,  -84.259155, ..., -120.18726 ,\n         -145.30817 , -131.04538 ], dtype=float32),\n  'neuropil_fluorescence': array([-141.42606, -134.94923, -134.40176, ..., -147.54305, -144.02428,\n         -138.54083], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 135,\n  'fluo_channel': 0,\n  'fluorescence': array([-187.66452, -191.0933 , -161.34456, ..., -160.11227, -175.09605,\n         -157.67545], dtype=float32),\n  'neuropil_fluorescence': array([-215.3    , -220.42267, -216.004  , ..., -223.516  , -220.92134,\n         -215.89734], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 136,\n  'fluo_channel': 0,\n  'fluorescence': array([ -62.352837,  -45.931046, -112.926125, ...,  -90.42055 ,\n          -14.089426,  -64.61415 ], dtype=float32),\n  'neuropil_fluorescence': array([-171.4864 , -168.30759, -171.62231, ..., -163.7897 , -165.55222,\n         -173.00143], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 137,\n  'fluo_channel': 0,\n  'fluorescence': array([-154.90645, -170.04236, -168.79399, ..., -167.7559 , -140.61552,\n         -158.14948], dtype=float32),\n  'neuropil_fluorescence': array([-149.42584, -147.82838, -143.0911 , ..., -142.28178, -141.06145,\n         -135.82838], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 138,\n  'fluo_channel': 0,\n  'fluorescence': array([-157.07695, -172.71864, -117.00496, ..., -141.88597, -130.30957,\n         -150.72156], dtype=float32),\n  'neuropil_fluorescence': array([-158.47838, -164.56216, -156.94865, ..., -162.77838, -152.7    ,\n         -155.03242], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 139,\n  'fluo_channel': 0,\n  'fluorescence': array([-128.64076, -132.84328, -157.25883, ..., -132.9441 , -167.10126,\n         -152.72372], dtype=float32),\n  'neuropil_fluorescence': array([-158.43437, -164.9117 , -150.19809, ..., -154.9475 , -167.76134,\n         -160.18616], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 140,\n  'fluo_channel': 0,\n  'fluorescence': array([-230.58206, -238.18007, -232.4876 , ..., -230.00896, -247.06374,\n         -241.43552], dtype=float32),\n  'neuropil_fluorescence': array([-251.66191, -253.45364, -257.786  , ..., -249.56918, -252.0642 ,\n         -251.04422], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 141,\n  'fluo_channel': 0,\n  'fluorescence': array([-188.0009 , -173.1458 , -177.89305, ..., -179.16588, -195.61734,\n         -181.23589], dtype=float32),\n  'neuropil_fluorescence': array([-183.3512 , -189.41072, -179.75   , ..., -185.5119 , -182.90356,\n         -183.53094], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 142,\n  'fluo_channel': 0,\n  'fluorescence': array([-181.35834, -180.73378, -178.67563, ..., -222.7309 , -164.89494,\n         -180.08664], dtype=float32),\n  'neuropil_fluorescence': array([-205.18895, -205.20613, -196.0135 , ..., -208.60368, -210.43803,\n         -209.04663], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 143,\n  'fluo_channel': 0,\n  'fluorescence': array([-20.352133  ,  15.604859  , -37.618877  , ...,  -0.25218952,\n           8.278918  ,  -2.7722564 ], dtype=float32),\n  'neuropil_fluorescence': array([-143.85916, -148.46735, -146.33675, ..., -142.95647, -138.2151 ,\n         -134.49808], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 144,\n  'fluo_channel': 0,\n  'fluorescence': array([ 36.758495, -11.304668,  36.70065 , ...,  90.24238 ,  60.580723,\n          41.38939 ], dtype=float32),\n  'neuropil_fluorescence': array([-116.46303 , -103.12324 ,  -90.080986, ...,  -86.628525,\n          -91.43838 ,  -99.110916], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 145,\n  'fluo_channel': 0,\n  'fluorescence': array([-160.32033, -154.40952, -159.71173, ..., -175.38123, -191.86977,\n         -167.94922], dtype=float32),\n  'neuropil_fluorescence': array([-205.05643, -195.67268, -200.8736 , ..., -201.5395 , -204.36118,\n         -201.10835], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 146,\n  'fluo_channel': 0,\n  'fluorescence': array([-251.63045, -250.38203, -242.42337, ..., -261.36124, -240.21039,\n         -243.34923], dtype=float32),\n  'neuropil_fluorescence': array([-253.35071, -257.83368, -254.29459, ..., -253.06212, -252.04008,\n         -255.78557], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 147,\n  'fluo_channel': 0,\n  'fluorescence': array([-111.204605,  -91.475624,  -73.899475, ...,  -97.54759 ,\n          -82.942635,  -97.95058 ], dtype=float32),\n  'neuropil_fluorescence': array([-161.165  , -146.7145 , -153.15352, ..., -148.78192, -155.9914 ,\n         -151.7145 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 148,\n  'fluo_channel': 0,\n  'fluorescence': array([-110.0556  ,  -54.130974, -127.99221 , ..., -139.84178 ,\n         -118.10097 , -139.08562 ], dtype=float32),\n  'neuropil_fluorescence': array([-148.86554, -135.84874, -144.04202, ..., -127.13725, -132.89915,\n         -147.24089], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 149,\n  'fluo_channel': 0,\n  'fluorescence': array([-198.50221, -197.77217, -183.04701, ..., -203.23785, -203.42413,\n         -197.11604], dtype=float32),\n  'neuropil_fluorescence': array([-202.44194, -209.68164, -210.4663 , ..., -200.91948, -207.07303,\n         -204.0131 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 150,\n  'fluo_channel': 0,\n  'fluorescence': array([ -97.40018, -156.55551, -108.67062, ..., -145.95848, -116.38305,\n         -136.25995], dtype=float32),\n  'neuropil_fluorescence': array([-132.67255 , -127.947105, -120.49874 , ..., -130.61713 ,\n         -132.23425 , -122.37783 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 151,\n  'fluo_channel': 0,\n  'fluorescence': array([-199.35655, -173.79211, -184.74202, ..., -191.3281 , -169.89085,\n         -199.50504], dtype=float32),\n  'neuropil_fluorescence': array([-208.90741, -207.10957, -214.53703, ..., -211.95679, -211.5679 ,\n         -216.21759], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 152,\n  'fluo_channel': 0,\n  'fluorescence': array([-156.7461 , -160.24445, -145.13512, ..., -155.1974 , -154.11618,\n         -158.84221], dtype=float32),\n  'neuropil_fluorescence': array([-170.02505, -168.95216, -179.10706, ..., -176.47609, -167.74033,\n         -173.90205], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 153,\n  'fluo_channel': 0,\n  'fluorescence': array([-58.47592 , -55.68474 ,   6.827513, ...,  45.813095,  -2.525781,\n         -13.861055], dtype=float32),\n  'neuropil_fluorescence': array([-131.72655, -126.64075, -128.0697 , ..., -131.9705 , -121.21984,\n         -127.44504], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 154,\n  'fluo_channel': 0,\n  'fluorescence': array([-187.8405 , -200.49216, -182.59431, ..., -184.13838, -178.0435 ,\n         -209.74442], dtype=float32),\n  'neuropil_fluorescence': array([-212.17769, -209.3533 , -217.02066, ..., -214.35124, -211.96695,\n         -216.83884], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 155,\n  'fluo_channel': 0,\n  'fluorescence': array([ -99.542984, -114.59888 ,  -73.879524, ...,  -26.31544 ,\n          -55.442577,  -63.239468], dtype=float32),\n  'neuropil_fluorescence': array([-149.07541, -146.90045, -145.97285, ..., -146.07089, -131.81749,\n         -139.00905], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 156,\n  'fluo_channel': 0,\n  'fluorescence': array([-143.4333 , -113.72616, -105.09994, ..., -118.48181, -116.41409,\n         -121.07403], dtype=float32),\n  'neuropil_fluorescence': array([-195.99574, -202.50851, -190.38936, ..., -192.71915, -202.9234 ,\n         -206.75533], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 157,\n  'fluo_channel': 0,\n  'fluorescence': array([-122.695885, -122.658325, -152.1637  , ..., -166.23889 ,\n         -125.31067 , -158.06883 ], dtype=float32),\n  'neuropil_fluorescence': array([-196.16542, -203.70398, -195.81094, ..., -195.22762, -200.20274,\n         -204.97139], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 158,\n  'fluo_channel': 0,\n  'fluorescence': array([-129.379  , -142.88438, -125.12311, ...,  -41.75693,  -92.20019,\n          -80.87533], dtype=float32),\n  'neuropil_fluorescence': array([-137.18315 , -128.62637 , -135.13919 , ..., -107.849815,\n         -102.809525,  -97.35897 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 159,\n  'fluo_channel': 0,\n  'fluorescence': array([-230.45247, -216.58617, -228.32635, ..., -222.11937, -203.63797,\n         -225.25314], dtype=float32),\n  'neuropil_fluorescence': array([-217.01276, -207.44626, -217.27504, ..., -206.55374, -206.08562,\n         -197.29507], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 160,\n  'fluo_channel': 0,\n  'fluorescence': array([-50.491047, -55.878113, -56.9357  , ..., -63.648952, -19.740208,\n         -17.236385], dtype=float32),\n  'neuropil_fluorescence': array([ -99.41284,  -99.73624, -105.54587, ...,  -94.96789,  -82.15367,\n          -98.36009], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 161,\n  'fluo_channel': 0,\n  'fluorescence': array([-186.68051, -231.43742, -215.14487, ..., -210.22408, -199.26576,\n         -197.19357], dtype=float32),\n  'neuropil_fluorescence': array([-212.62122, -200.18687, -208.28535, ..., -217.04546, -202.87878,\n         -211.25252], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 162,\n  'fluo_channel': 0,\n  'fluorescence': array([-144.78984, -161.63008, -153.45178, ..., -175.66957, -178.27605,\n         -180.31717], dtype=float32),\n  'neuropil_fluorescence': array([-176.65868, -178.76248, -172.33333, ..., -170.93213, -182.18762,\n         -168.22754], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 163,\n  'fluo_channel': 0,\n  'fluorescence': array([-162.77704, -116.27791, -155.88783, ..., -140.88495, -135.02783,\n         -131.31084], dtype=float32),\n  'neuropil_fluorescence': array([-203.1579 , -189.9251 , -186.0324 , ..., -196.67612, -198.43523,\n         -192.08907], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 164,\n  'fluo_channel': 0,\n  'fluorescence': array([-213.14224, -225.71503, -206.31001, ..., -217.51161, -219.43764,\n         -229.82164], dtype=float32),\n  'neuropil_fluorescence': array([-221.5235 , -220.06837, -213.15384, ..., -224.50854, -224.22223,\n         -219.9701 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 165,\n  'fluo_channel': 0,\n  'fluorescence': array([ -89.90663, -116.09033,  -77.44239, ..., -132.47581,  -93.76163,\n          -85.04505], dtype=float32),\n  'neuropil_fluorescence': array([-134.2959  , -128.55879 , -130.22061 , ..., -124.702774,\n         -119.220604, -128.42537 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 166,\n  'fluo_channel': 0,\n  'fluorescence': array([  5.1270995, -11.124026 ,  15.760505 , ...,  38.372288 ,\n         -12.798685 ,  27.190418 ], dtype=float32),\n  'neuropil_fluorescence': array([-112.54366, -122.11831,  -93.61408, ..., -114.10704, -115.69014,\n          -87.81409], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 167,\n  'fluo_channel': 0,\n  'fluorescence': array([-147.85857 ,  -94.066124,  -91.591354, ...,  -79.99924 ,\n         -105.89876 ,  -90.32072 ], dtype=float32),\n  'neuropil_fluorescence': array([-161.90996, -154.59715, -153.65877, ..., -168.12323, -151.0782 ,\n         -152.70853], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 168,\n  'fluo_channel': 0,\n  'fluorescence': array([-111.04745 , -103.66082 , -147.42902 , ...,  -68.05047 ,\n          -92.132545,  -77.2149  ], dtype=float32),\n  'neuropil_fluorescence': array([-179.80792, -181.63196, -179.9868 , ..., -171.55278, -183.31232,\n         -182.45601], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 169,\n  'fluo_channel': 0,\n  'fluorescence': array([-166.71938, -128.14409, -109.08976, ..., -146.30319, -141.72667,\n         -115.22645], dtype=float32),\n  'neuropil_fluorescence': array([-179.59253, -171.36502, -173.78438, ..., -182.3056 , -184.74702,\n         -175.40916], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 170,\n  'fluo_channel': 0,\n  'fluorescence': array([-175.00734 , -125.659325, -103.121086, ..., -126.332146,\n         -137.07805 , -122.338875], dtype=float32),\n  'neuropil_fluorescence': array([-162.66615, -164.50995, -169.84686, ..., -170.56967, -165.83308,\n         -151.7519 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 171,\n  'fluo_channel': 0,\n  'fluorescence': array([-181.5017 , -186.68037, -169.30293, ..., -158.18814, -161.85316,\n         -173.81487], dtype=float32),\n  'neuropil_fluorescence': array([-195.69348, -207.37392, -193.75   , ..., -199.29782, -195.17174,\n         -203.3    ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 172,\n  'fluo_channel': 0,\n  'fluorescence': array([-153.29022, -174.31523,  -78.78775, ..., -202.56186, -159.46208,\n         -127.08274], dtype=float32),\n  'neuropil_fluorescence': array([-196.66016, -194.9375 , -192.48438, ..., -198.10547, -194.94792,\n         -198.39323], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 173,\n  'fluo_channel': 0,\n  'fluorescence': array([-192.80957, -173.45863, -184.77582, ...,  -77.02822, -122.17667,\n         -118.76542], dtype=float32),\n  'neuropil_fluorescence': array([-211.89943, -196.88046, -198.3852 , ..., -213.40038, -215.52371,\n         -206.03415], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 174,\n  'fluo_channel': 0,\n  'fluorescence': array([ 46.41379  , -24.572021 ,  36.334515 , ...,   6.7754993,\n           9.816924 ,  -5.993405 ], dtype=float32),\n  'neuropil_fluorescence': array([-170.37093, -166.34335, -166.14537, ..., -164.88972, -146.31328,\n         -151.93735], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 175,\n  'fluo_channel': 0,\n  'fluorescence': array([-212.94627, -223.2141 , -229.10912, ..., -210.93277, -227.37991,\n         -219.80911], dtype=float32),\n  'neuropil_fluorescence': array([-241.81187, -238.14038, -237.84949, ..., -232.91316, -238.29523,\n         -241.     ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 176,\n  'fluo_channel': 0,\n  'fluorescence': array([-126.75511,  -91.24039,  -96.79038, ..., -138.92056,  -97.31159,\n         -105.8885 ], dtype=float32),\n  'neuropil_fluorescence': array([-157.68161, -159.41704, -159.71524, ..., -155.3565 , -159.8834 ,\n         -160.30493], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 177,\n  'fluo_channel': 0,\n  'fluorescence': array([ -68.275444,   20.033659,  130.85017 , ..., -128.05875 ,\n          -91.52495 , -157.58287 ], dtype=float32),\n  'neuropil_fluorescence': array([-153.44519, -150.53691, -165.915  , ..., -168.75615, -178.33557,\n         -167.85905], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 178,\n  'fluo_channel': 0,\n  'fluorescence': array([-131.1266 , -142.30873, -129.53299, ..., -157.99765, -167.98561,\n         -139.85913], dtype=float32),\n  'neuropil_fluorescence': array([-168.92206, -177.61597, -170.08176, ..., -174.73764, -187.91064,\n         -182.173  ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 179,\n  'fluo_channel': 0,\n  'fluorescence': array([-211.51648, -187.55786, -210.45316, ..., -195.55997, -205.17506,\n         -192.81628], dtype=float32),\n  'neuropil_fluorescence': array([-156.83565, -152.60446, -145.8273 , ..., -181.60724, -187.75209,\n         -195.23955], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 180,\n  'fluo_channel': 0,\n  'fluorescence': array([-235.145  , -217.96872, -250.78284, ..., -239.8292 , -226.9696 ,\n         -228.13762], dtype=float32),\n  'neuropil_fluorescence': array([-249.61894, -232.89894, -229.45264, ..., -232.03369, -242.68631,\n         -233.90736], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 181,\n  'fluo_channel': 0,\n  'fluorescence': array([-197.44202, -206.36464, -197.98685, ..., -179.36792, -200.15347,\n         -212.08119], dtype=float32),\n  'neuropil_fluorescence': array([-230.75623, -235.00746, -229.35324, ..., -238.50497, -234.9005 ,\n         -234.94527], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 182,\n  'fluo_channel': 0,\n  'fluorescence': array([-142.36266, -144.0477 , -162.89458, ..., -155.34976, -156.91232,\n         -158.99068], dtype=float32),\n  'neuropil_fluorescence': array([-133.00218 , -116.27233 , -111.66013 , ..., -126.976036,\n         -132.4488  , -128.35512 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 183,\n  'fluo_channel': 0,\n  'fluorescence': array([-126.206665,  -91.25695 ,  -80.22665 , ..., -104.1674  ,\n          -92.298454,  -99.0037  ], dtype=float32),\n  'neuropil_fluorescence': array([-190.2495 , -190.30339, -184.44711, ..., -183.77246, -190.76048,\n         -177.68663], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 184,\n  'fluo_channel': 0,\n  'fluorescence': array([-167.29568, -151.43546, -165.14471, ..., -185.10019, -184.30501,\n         -181.4936 ], dtype=float32),\n  'neuropil_fluorescence': array([-183.51498, -186.101  , -179.78468, ..., -192.2364 , -187.97891,\n         -186.71254], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 185,\n  'fluo_channel': 0,\n  'fluorescence': array([-182.4837 , -154.34737, -155.70724, ..., -202.47154, -199.79036,\n         -177.68533], dtype=float32),\n  'neuropil_fluorescence': array([-179.94833, -161.02338, -165.94588, ..., -170.63838, -167.44649,\n         -173.28413], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 186,\n  'fluo_channel': 0,\n  'fluorescence': array([-269.8102 , -262.56857, -253.8727 , ..., -247.81252, -253.50674,\n         -257.43033], dtype=float32),\n  'neuropil_fluorescence': array([-270.71634, -271.01077, -267.40216, ..., -269.2334 , -269.1149 ,\n         -268.36444], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 187,\n  'fluo_channel': 0,\n  'fluorescence': array([-126.23888 ,  -97.7024  , -123.875046, ...,  -80.918915,\n         -113.15131 , -130.46234 ], dtype=float32),\n  'neuropil_fluorescence': array([-154.01334, -154.37143, -160.07239, ..., -148.05524, -153.42667,\n         -151.59238], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 188,\n  'fluo_channel': 0,\n  'fluorescence': array([-228.56306, -227.79346, -204.19441, ..., -221.05568, -216.41954,\n         -218.5088 ], dtype=float32),\n  'neuropil_fluorescence': array([-214.76009, -206.07399, -210.1435 , ..., -219.01346, -203.84529,\n         -209.26233], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 189,\n  'fluo_channel': 0,\n  'fluorescence': array([-217.69379, -207.14056, -185.95564, ..., -210.25508, -204.68027,\n         -188.28958], dtype=float32),\n  'neuropil_fluorescence': array([-234.44836, -234.02519, -234.09572, ..., -238.83627, -231.4005 ,\n         -237.42065], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 190,\n  'fluo_channel': 0,\n  'fluorescence': array([-232.78442, -237.94958, -223.33034, ..., -225.98174, -215.71867,\n         -242.85545], dtype=float32),\n  'neuropil_fluorescence': array([-218.55682, -218.1108 , -204.33238, ..., -198.61647, -214.3125 ,\n         -219.85796], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 191,\n  'fluo_channel': 0,\n  'fluorescence': array([-170.27539 , -164.43149 , -124.069885, ..., -147.22166 ,\n         -163.4071  , -154.1535  ], dtype=float32),\n  'neuropil_fluorescence': array([-160.41129, -159.46217, -153.44154, ..., -173.79918, -168.99725,\n         -171.57497], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 192,\n  'fluo_channel': 0,\n  'fluorescence': array([-164.08623, -173.20026, -158.90968, ..., -178.43977, -181.19351,\n         -176.12508], dtype=float32),\n  'neuropil_fluorescence': array([-217.40218, -207.86685, -202.59511, ..., -203.94293, -208.94836,\n         -211.04892], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 193,\n  'fluo_channel': 0,\n  'fluorescence': array([-140.38634 ,  -89.64688 , -131.96727 , ..., -101.59224 ,\n         -113.968346, -144.07167 ], dtype=float32),\n  'neuropil_fluorescence': array([-210.50732, -197.72195, -206.78049, ..., -204.69756, -196.59512,\n         -206.02196], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 194,\n  'fluo_channel': 0,\n  'fluorescence': array([-202.0918 , -193.12163, -180.76077, ..., -151.71092, -196.3668 ,\n         -183.94708], dtype=float32),\n  'neuropil_fluorescence': array([-185.22438, -183.6842 , -190.59557, ..., -194.53186, -188.58171,\n         -189.38504], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 195,\n  'fluo_channel': 0,\n  'fluorescence': array([ 90.15757   ,   5.0633416 , 106.238075  , ...,  97.74868   ,\n          91.12212   ,  -0.67480844], dtype=float32),\n  'neuropil_fluorescence': array([-155.14369, -156.28006, -155.25513, ..., -141.68475, -158.7654 ,\n         -141.02052], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 196,\n  'fluo_channel': 0,\n  'fluorescence': array([-172.01262, -188.56454, -118.80179, ..., -128.71388, -219.73038,\n         -175.89117], dtype=float32),\n  'neuropil_fluorescence': array([-171.28415, -163.90437, -164.35109, ..., -175.53415, -184.69263,\n         -186.16667], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 197,\n  'fluo_channel': 0,\n  'fluorescence': array([-150.90164 ,  -84.6797  , -118.0388  , ...,   84.82163 ,\n           74.380325,   14.617824], dtype=float32),\n  'neuropil_fluorescence': array([-199.61424, -197.16765, -195.24481, ..., -188.01187, -190.7819 ,\n         -181.95401], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 198,\n  'fluo_channel': 0,\n  'fluorescence': array([-177.25331, -168.151  , -139.39198, ..., -143.61171, -141.40958,\n         -152.53745], dtype=float32),\n  'neuropil_fluorescence': array([-155.3048 , -140.38014, -149.26883, ..., -142.30309, -147.27568,\n         -139.9452 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 199,\n  'fluo_channel': 0,\n  'fluorescence': array([-188.60266, -192.57425, -207.8326 , ..., -179.5426 , -188.94034,\n         -171.79962], dtype=float32),\n  'neuropil_fluorescence': array([-174.07202, -161.37119, -164.93074, ..., -189.16066, -182.37119,\n         -180.58864], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 200,\n  'fluo_channel': 0,\n  'fluorescence': array([-181.71782, -188.14275, -167.54884, ..., -188.1124 , -179.8599 ,\n         -189.13135], dtype=float32),\n  'neuropil_fluorescence': array([-195.35411, -185.76309, -192.05237, ..., -196.37656, -176.29926,\n         -187.37906], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 201,\n  'fluo_channel': 0,\n  'fluorescence': array([-163.23955, -163.24171, -144.16072, ..., -160.74178, -149.11694,\n         -148.73436], dtype=float32),\n  'neuropil_fluorescence': array([-177.86118, -185.92941, -177.62823, ..., -171.05176, -179.17647,\n         -174.95294], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 202,\n  'fluo_channel': 0,\n  'fluorescence': array([-156.26947, -189.6037 , -146.4149 , ..., -143.85933, -168.18907,\n         -170.03557], dtype=float32),\n  'neuropil_fluorescence': array([-204.38568, -211.78513, -200.88155, ..., -209.93114, -208.69147,\n         -201.33058], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 203,\n  'fluo_channel': 0,\n  'fluorescence': array([-232.53583, -224.17938, -239.722  , ..., -228.10773, -248.21402,\n         -239.11772], dtype=float32),\n  'neuropil_fluorescence': array([-239.01456, -244.01456, -244.36383, ..., -237.89189, -244.51143,\n         -239.91476], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 204,\n  'fluo_channel': 0,\n  'fluorescence': array([-157.93874, -173.0744 , -171.27246, ..., -150.48602, -176.18762,\n         -153.22499], dtype=float32),\n  'neuropil_fluorescence': array([-180.50255, -180.1199 , -159.60715, ..., -172.44643, -169.52296,\n         -176.37755], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 205,\n  'fluo_channel': 0,\n  'fluorescence': array([-96.30738, -67.74579, -84.58445, ..., -57.02671, -96.7911 ,\n         -86.51087], dtype=float32),\n  'neuropil_fluorescence': array([-187.45949, -182.76456, -191.39746, ..., -190.77974, -180.69746,\n         -185.91899], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 206,\n  'fluo_channel': 0,\n  'fluorescence': array([-182.74342, -179.16399, -153.46544, ..., -144.67941, -156.04428,\n         -162.6986 ], dtype=float32),\n  'neuropil_fluorescence': array([-180.18182, -176.06017, -172.49733, ..., -179.69652, -174.94786,\n         -172.64305], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 207,\n  'fluo_channel': 0,\n  'fluorescence': array([-187.54767, -190.68527, -193.44652, ..., -203.05301, -189.25601,\n         -212.45941], dtype=float32),\n  'neuropil_fluorescence': array([-208.6514 , -212.62596, -203.07634, ..., -210.67938, -206.20865,\n         -217.15521], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 208,\n  'fluo_channel': 0,\n  'fluorescence': array([-224.41504, -235.54411, -210.37543, ..., -220.99924, -243.9578 ,\n         -220.71567], dtype=float32),\n  'neuropil_fluorescence': array([-232.78354, -229.18427, -235.30232, ..., -244.54562, -244.1467 ,\n         -235.28444], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 209,\n  'fluo_channel': 0,\n  'fluorescence': array([-92.85849 , -63.395008, -11.359428, ..., -83.19367 , -80.61714 ,\n         -66.92577 ], dtype=float32),\n  'neuropil_fluorescence': array([-153.12263, -143.45839, -146.89928, ..., -141.61606, -143.80583,\n         -147.67737], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 210,\n  'fluo_channel': 0,\n  'fluorescence': array([-155.88768, -162.76334, -151.2059 , ..., -133.7542 , -133.30563,\n         -129.1247 ], dtype=float32),\n  'neuropil_fluorescence': array([-213.69713, -221.20366, -215.84856, ..., -204.12271, -209.58485,\n         -214.42558], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 211,\n  'fluo_channel': 0,\n  'fluorescence': array([-228.55574, -212.3518 , -205.00127, ..., -217.58255, -214.54552,\n         -211.47968], dtype=float32),\n  'neuropil_fluorescence': array([-232.61186, -235.98112, -231.75201, ..., -239.25067, -235.4097 ,\n         -230.75742], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 212,\n  'fluo_channel': 0,\n  'fluorescence': array([-167.32256, -167.23198, -165.5179 , ..., -158.26968, -183.12929,\n         -154.94113], dtype=float32),\n  'neuropil_fluorescence': array([-208.12163, -203.03378, -202.19144, ..., -209.44595, -208.93694,\n         -195.56982], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 213,\n  'fluo_channel': 0,\n  'fluorescence': array([-206.07492, -198.33087, -196.17448, ..., -217.34213, -198.40562,\n         -209.06451], dtype=float32),\n  'neuropil_fluorescence': array([-202.26389, -201.5754 , -196.79167, ..., -208.58531, -192.80159,\n         -189.21031], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 214,\n  'fluo_channel': 0,\n  'fluorescence': array([-176.25676, -162.17342, -198.75293, ..., -175.56227, -170.99178,\n         -176.33405], dtype=float32),\n  'neuropil_fluorescence': array([-221.28517, -221.03015, -221.49623, ..., -233.67714, -227.72362,\n         -221.40326], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 215,\n  'fluo_channel': 0,\n  'fluorescence': array([-27.46497   , -12.539558  , -53.584084  , ..., -17.656313  ,\n          11.742172  ,  -0.25947392], dtype=float32),\n  'neuropil_fluorescence': array([-164.48257, -115.76944, -148.11528, ..., -155.28687, -134.07239,\n         -133.95442], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 216,\n  'fluo_channel': 0,\n  'fluorescence': array([-160.75923, -166.06686, -174.8524 , ..., -145.69255, -181.49081,\n         -169.11026], dtype=float32),\n  'neuropil_fluorescence': array([-221.37746, -218.875  , -214.80147, ..., -220.04657, -220.85785,\n         -221.88481], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 217,\n  'fluo_channel': 0,\n  'fluorescence': array([-84.474495, -61.176857, -49.6484  , ..., -59.550358, -61.71932 ,\n         -29.2957  ], dtype=float32),\n  'neuropil_fluorescence': array([-120.41213, -113.93933, -116.34519, ..., -125.48745, -141.07532,\n         -125.67155], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 218,\n  'fluo_channel': 0,\n  'fluorescence': array([-174.5396 , -176.48022, -153.75015, ..., -143.65358, -151.08186,\n         -156.85292], dtype=float32),\n  'neuropil_fluorescence': array([-158.50636, -161.26718, -157.257  , ..., -151.29007, -165.14503,\n         -158.78372], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 219,\n  'fluo_channel': 0,\n  'fluorescence': array([  45.051025,   30.373833,  -10.111523, ..., -210.8693  ,\n         -206.20576 , -220.1261  ], dtype=float32),\n  'neuropil_fluorescence': array([-230.0864 , -225.53348, -227.7797 , ..., -238.67603, -235.57019,\n         -228.90497], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 220,\n  'fluo_channel': 0,\n  'fluorescence': array([-174.98196, -171.81036, -132.5238 , ..., -135.76459, -133.3711 ,\n         -142.66316], dtype=float32),\n  'neuropil_fluorescence': array([-210.50711, -217.23933, -219.7109 , ..., -214.87677, -204.15402,\n         -214.97867], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 221,\n  'fluo_channel': 0,\n  'fluorescence': array([-119.69347 , -148.09422 , -123.949265, ..., -121.379196,\n         -135.4693  , -135.88963 ], dtype=float32),\n  'neuropil_fluorescence': array([-181.62169, -172.78307, -167.35185, ..., -178.291  , -179.2963 ,\n         -186.4947 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 222,\n  'fluo_channel': 0,\n  'fluorescence': array([ -93.33971 ,  -67.754684, -107.239456, ...,  -75.41802 ,\n          -76.60447 ,  -71.441025], dtype=float32),\n  'neuropil_fluorescence': array([-108.56911 , -120.09214 , -106.00813 , ...,  -85.39024 ,\n          -92.677505, -101.308945], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 223,\n  'fluo_channel': 0,\n  'fluorescence': array([-239.88663, -252.1986 , -237.82533, ..., -248.38393, -257.2178 ,\n         -251.82297], dtype=float32),\n  'neuropil_fluorescence': array([-235.58783, -237.23236, -234.92531, ..., -236.42186, -235.27802,\n         -235.62102], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 224,\n  'fluo_channel': 0,\n  'fluorescence': array([-62.65876 , -37.089527, -23.979204, ..., -84.17141 , -67.14794 ,\n         -53.60642 ], dtype=float32),\n  'neuropil_fluorescence': array([-152.2899 , -158.09358, -149.5945 , ..., -162.34128, -152.7468 ,\n         -152.30092], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 225,\n  'fluo_channel': 0,\n  'fluorescence': array([  -8.214664,  -79.04554 , -107.0137  , ...,  -77.84574 ,\n          -74.302124,  -96.059875], dtype=float32),\n  'neuropil_fluorescence': array([-177.21547, -171.21547, -175.80386, ..., -167.58287, -175.75415,\n         -179.08563], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 226,\n  'fluo_channel': 0,\n  'fluorescence': array([-232.15553, -214.89426, -222.74512, ..., -195.64845, -214.79965,\n         -217.62881], dtype=float32),\n  'neuropil_fluorescence': array([-231.21506, -221.37634, -222.30914, ..., -223.75269, -222.7715 ,\n         -221.30376], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 227,\n  'fluo_channel': 0,\n  'fluorescence': array([-213.31367, -199.68236, -237.74942, ..., -241.7261 , -196.41837,\n         -222.38297], dtype=float32),\n  'neuropil_fluorescence': array([-234.15942, -230.31262, -228.21532, ..., -242.0973 , -235.85094,\n         -234.09317], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 228,\n  'fluo_channel': 0,\n  'fluorescence': array([ -50.368534,  -78.16213 ,  -32.542168, ..., -116.43427 ,\n         -105.508865,  -43.123035], dtype=float32),\n  'neuropil_fluorescence': array([-104.65838,  -92.35489,  -84.01327, ...,  -87.37811,  -87.32836,\n          -96.36982], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 229,\n  'fluo_channel': 0,\n  'fluorescence': array([-193.40712, -138.32895, -149.49503, ..., -169.15991, -217.88014,\n         -162.95969], dtype=float32),\n  'neuropil_fluorescence': array([-184.6034 , -172.81328, -181.87962, ..., -173.43518, -177.12808,\n         -187.34413], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 230,\n  'fluo_channel': 0,\n  'fluorescence': array([-149.12872 , -119.525375, -112.65033 , ..., -158.25175 ,\n         -121.523605, -144.46315 ], dtype=float32),\n  'neuropil_fluorescence': array([-156.7931 , -165.5411 , -142.87799, ..., -170.5809 , -154.75597,\n         -153.31564], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 231,\n  'fluo_channel': 0,\n  'fluorescence': array([-23.992867,  46.6281  , -99.709915, ..., -66.749535,  13.167266,\n         -74.868805], dtype=float32),\n  'neuropil_fluorescence': array([-175.25508, -180.49619, -174.97081, ..., -173.91371, -165.86041,\n         -166.13326], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 232,\n  'fluo_channel': 0,\n  'fluorescence': array([-237.48404, -228.1507 , -235.50621, ..., -228.86282, -218.641  ,\n         -216.3395 ], dtype=float32),\n  'neuropil_fluorescence': array([-215.45833, -216.13889, -215.5787 , ..., -226.25462, -228.53087,\n         -222.11111], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 233,\n  'fluo_channel': 0,\n  'fluorescence': array([-225.98062, -204.2693 , -220.26265, ..., -230.45816, -223.00732,\n         -205.23375], dtype=float32),\n  'neuropil_fluorescence': array([-237.70105, -235.6923 , -237.99825, ..., -244.31993, -243.15034,\n         -238.80244], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 234,\n  'fluo_channel': 0,\n  'fluorescence': array([-101.23783 ,  -33.26413 ,  -34.630013, ...,  -78.656715,\n          -93.585335,  -56.10988 ], dtype=float32),\n  'neuropil_fluorescence': array([-150.3092 , -142.37405, -151.64253, ..., -157.44646, -140.80544,\n         -146.07692], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 235,\n  'fluo_channel': 0,\n  'fluorescence': array([-62.293423, -72.755775, -83.38407 , ..., -71.100586, -83.7798  ,\n         -82.68601 ], dtype=float32),\n  'neuropil_fluorescence': array([-130.20798 , -124.7849  , -119.497154, ..., -118.48006 ,\n         -110.71652 , -121.43874 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 236,\n  'fluo_channel': 0,\n  'fluorescence': array([-165.60759, -189.07121, -168.66629, ..., -179.12178, -178.82388,\n         -181.207  ], dtype=float32),\n  'neuropil_fluorescence': array([-202.42699, -206.62108, -204.19963, ..., -202.15897, -203.2865 ,\n         -208.73013], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 237,\n  'fluo_channel': 0,\n  'fluorescence': array([-120.5262  ,  -77.41957 , -100.552246, ...,  -95.45435 ,\n         -106.398254,  -92.693535], dtype=float32),\n  'neuropil_fluorescence': array([-156.72679, -164.20955, -165.52785, ..., -154.99734, -144.1512 ,\n         -158.81963], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 238,\n  'fluo_channel': 0,\n  'fluorescence': array([-217.13367, -223.47336, -186.84433, ..., -218.41988, -211.30708,\n         -216.89867], dtype=float32),\n  'neuropil_fluorescence': array([-217.21951, -215.17683, -217.3374 , ..., -211.9817 , -223.47357,\n         -216.94308], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 239,\n  'fluo_channel': 0,\n  'fluorescence': array([-253.00664, -265.15637, -225.79018, ..., -225.1316 , -225.92784,\n         -237.4574 ], dtype=float32),\n  'neuropil_fluorescence': array([-237.51936, -232.47609, -241.02051, ..., -232.14807, -230.2688 ,\n         -232.     ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 240,\n  'fluo_channel': 0,\n  'fluorescence': array([-194.03183, -216.70064, -230.5149 , ..., -219.35994, -197.99246,\n         -227.4164 ], dtype=float32),\n  'neuropil_fluorescence': array([-222.31818, -219.68687, -220.04797, ..., -226.07323, -221.49243,\n         -215.70454], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 241,\n  'fluo_channel': 0,\n  'fluorescence': array([-229.26622, -241.55353, -246.58138, ..., -232.76147, -242.04944,\n         -253.93758], dtype=float32),\n  'neuropil_fluorescence': array([-258.18265, -264.15753, -258.3379 , ..., -256.879  , -260.3927 ,\n         -260.242  ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 242,\n  'fluo_channel': 0,\n  'fluorescence': array([ -53.845448,  -99.229485, -138.11087 , ..., -120.821434,\n          -95.547615, -101.547714], dtype=float32),\n  'neuropil_fluorescence': array([-133.50206, -132.2971 , -126.90784, ..., -135.37415, -138.1458 ,\n         -134.18982], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 243,\n  'fluo_channel': 0,\n  'fluorescence': array([   1.1027898,  -75.23985  ,  -83.245735 , ..., -154.8358   ,\n          -50.864525 ,   63.498657 ], dtype=float32),\n  'neuropil_fluorescence': array([-105.53259,  -96.73132, -107.99364, ...,  -77.60413,  -84.10652,\n          -90.76153], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 244,\n  'fluo_channel': 0,\n  'fluorescence': array([-44.455887, -55.239594, -49.807602, ..., -22.783699, -52.075844,\n         -27.405466], dtype=float32),\n  'neuropil_fluorescence': array([ -98.54233 , -101.119026,  -95.228   , ..., -102.20788 ,\n          -97.379715,  -98.713326], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 245,\n  'fluo_channel': 0,\n  'fluorescence': array([-165.36974, -167.20023, -182.05629, ..., -186.8991 , -158.05746,\n         -170.48781], dtype=float32),\n  'neuropil_fluorescence': array([-188.16776, -193.00436, -201.18083, ..., -206.95425, -206.33333,\n         -198.05011], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 246,\n  'fluo_channel': 0,\n  'fluorescence': array([-220.26785, -216.59605, -217.44206, ..., -228.76482, -225.19862,\n         -224.34056], dtype=float32),\n  'neuropil_fluorescence': array([-222.10376, -222.24503, -218.14128, ..., -225.95364, -222.12804,\n         -222.00221], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 247,\n  'fluo_channel': 0,\n  'fluorescence': array([-214.17374, -199.00644, -215.06018, ..., -201.725  , -219.07494,\n         -196.06696], dtype=float32),\n  'neuropil_fluorescence': array([-211.34666, -211.36533, -207.37866, ..., -191.04533, -203.49066,\n         -205.624  ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 248,\n  'fluo_channel': 0,\n  'fluorescence': array([-167.95181, -189.44377, -181.70822, ..., -205.93567, -197.65028,\n         -194.3089 ], dtype=float32),\n  'neuropil_fluorescence': array([-197.44347, -199.30984, -202.31718, ..., -203.52129, -192.92511,\n         -197.71365], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 249,\n  'fluo_channel': 0,\n  'fluorescence': array([-185.92624, -181.43806, -169.22293, ..., -180.77693, -161.72842,\n         -182.50652], dtype=float32),\n  'neuropil_fluorescence': array([-198.15384, -196.7074 , -185.50981, ..., -199.26999, -189.29713,\n         -193.55052], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 250,\n  'fluo_channel': 0,\n  'fluorescence': array([-166.2422 , -182.04083, -144.25949, ..., -179.10193, -169.26166,\n         -165.94273], dtype=float32),\n  'neuropil_fluorescence': array([-193.79666, -199.74658, -194.6601 , ..., -205.1305 , -195.5129 ,\n         -197.47496], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 251,\n  'fluo_channel': 0,\n  'fluorescence': array([-193.46555, -214.17601, -171.86847, ..., -197.17519, -196.81107,\n         -183.95111], dtype=float32),\n  'neuropil_fluorescence': array([-181.3379 , -180.66667, -176.3242 , ..., -182.38812, -188.59132,\n         -189.37444], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 252,\n  'fluo_channel': 0,\n  'fluorescence': array([-164.75403, -172.9277 , -167.95497, ..., -147.45665, -166.62659,\n         -172.43431], dtype=float32),\n  'neuropil_fluorescence': array([-185.1287 , -178.88203, -176.31636, ..., -171.67293, -175.06166,\n         -187.69705], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 253,\n  'fluo_channel': 0,\n  'fluorescence': array([-236.94228, -227.56886, -234.78346, ..., -234.00829, -242.70154,\n         -240.09915], dtype=float32),\n  'neuropil_fluorescence': array([-242.179  , -243.8537 , -241.06712, ..., -252.4957 , -245.95525,\n         -245.91739], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 254,\n  'fluo_channel': 0,\n  'fluorescence': array([-227.80695, -175.33984, -202.15277, ..., -212.11102, -158.7177 ,\n         -169.11914], dtype=float32),\n  'neuropil_fluorescence': array([-205.9819 , -203.05731, -206.12369, ..., -211.55957, -205.61388,\n         -207.90045], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 255,\n  'fluo_channel': 0,\n  'fluorescence': array([-195.40167, -188.47961, -183.36644, ..., -174.07285, -193.89081,\n         -180.71672], dtype=float32),\n  'neuropil_fluorescence': array([-220.78078, -211.1855 , -218.20067, ..., -220.41989, -219.99493,\n         -216.93086], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 256,\n  'fluo_channel': 0,\n  'fluorescence': array([-223.0314 , -234.67976, -218.68916, ..., -225.65373, -235.50406,\n         -238.45352], dtype=float32),\n  'neuropil_fluorescence': array([-229.93277, -234.54903, -229.97198, ..., -234.18767, -231.15126,\n         -235.21568], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 257,\n  'fluo_channel': 0,\n  'fluorescence': array([-116.82504 , -123.16622 , -102.285645, ..., -123.70638 ,\n         -128.03938 , -102.76177 ], dtype=float32),\n  'neuropil_fluorescence': array([-163.64644, -162.0343 , -153.9868 , ..., -156.67018, -160.83377,\n         -167.95778], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 258,\n  'fluo_channel': 0,\n  'fluorescence': array([-115.387405, -115.218155, -131.4189  , ..., -159.06775 ,\n         -152.81165 , -103.13224 ], dtype=float32),\n  'neuropil_fluorescence': array([-168.54059, -165.93358, -160.22325, ..., -143.93173, -152.44096,\n         -155.89299], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 259,\n  'fluo_channel': 0,\n  'fluorescence': array([-169.64554 , -116.53559 , -107.546715, ..., -165.41844 ,\n         -155.32584 , -154.62212 ], dtype=float32),\n  'neuropil_fluorescence': array([-204.34949, -199.38393, -200.19771, ..., -197.97449, -201.22322,\n         -196.9579 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 260,\n  'fluo_channel': 0,\n  'fluorescence': array([-207.76517, -184.73154, -173.95656, ..., -207.83649, -199.59296,\n         -202.46553], dtype=float32),\n  'neuropil_fluorescence': array([-215.75983, -216.74236, -205.83188, ..., -219.63756, -222.07205,\n         -215.79694], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 261,\n  'fluo_channel': 0,\n  'fluorescence': array([38.194057 ,  2.5905855,  4.589311 , ..., -9.770676 , 91.70099  ,\n         65.809746 ], dtype=float32),\n  'neuropil_fluorescence': array([-152.66768, -133.50531, -139.40971, ..., -136.39453, -126.30349,\n         -139.96358], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 262,\n  'fluo_channel': 0,\n  'fluorescence': array([-187.67729, -213.48447, -174.8277 , ..., -189.8939 , -187.03296,\n         -197.36299], dtype=float32),\n  'neuropil_fluorescence': array([-203.44827, -199.82361, -206.45757, ..., -201.83289, -203.71619,\n         -191.29178], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 263,\n  'fluo_channel': 0,\n  'fluorescence': array([ -82.397385,  -94.846535, -154.2727  , ..., -188.20929 ,\n         -116.70529 ,  -85.38685 ], dtype=float32),\n  'neuropil_fluorescence': array([-115.83393, -125.05179, -121.61429, ..., -129.03929, -132.325  ,\n         -126.82143], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 264,\n  'fluo_channel': 0,\n  'fluorescence': array([ 31.080956, 106.656044,  -3.954814, ..., -42.08829 ,  49.13903 ,\n         141.27472 ], dtype=float32),\n  'neuropil_fluorescence': array([-141.4072  , -135.45833 , -124.844696, ..., -123.14962 ,\n         -130.24243 , -114.38636 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 265,\n  'fluo_channel': 0,\n  'fluorescence': array([-177.4321 , -174.09406, -139.84099, ..., -142.89124, -144.79758,\n         -158.67241], dtype=float32),\n  'neuropil_fluorescence': array([-199.3831 , -196.6169 , -200.61539, ..., -194.82051, -193.96532,\n         -196.6727 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 266,\n  'fluo_channel': 0,\n  'fluorescence': array([-253.06381, -250.25935, -246.77646, ..., -216.84761, -229.56728,\n         -237.0863 ], dtype=float32),\n  'neuropil_fluorescence': array([-234.14949, -220.3299 , -209.59021, ..., -218.81958, -227.32732,\n         -220.9201 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 267,\n  'fluo_channel': 0,\n  'fluorescence': array([-256.22546, -254.94362, -250.89098, ..., -260.8616 , -254.41867,\n         -263.6503 ], dtype=float32),\n  'neuropil_fluorescence': array([-259.66928, -254.23875, -259.99216, ..., -260.5636 , -258.37964,\n         -260.14874], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 268,\n  'fluo_channel': 0,\n  'fluorescence': array([-188.84633, -219.62819, -179.74216, ..., -211.12889, -206.83537,\n         -193.9849 ], dtype=float32),\n  'neuropil_fluorescence': array([-230.2    , -227.38919, -228.7946 , ..., -231.88379, -230.63243,\n         -226.77298], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 269,\n  'fluo_channel': 0,\n  'fluorescence': array([ -73.70321 , -118.66799 , -161.27003 , ..., -122.296326,\n         -118.90094 , -119.350235], dtype=float32),\n  'neuropil_fluorescence': array([-167.16985, -173.16603, -162.23665, ..., -164.48665, -164.81679,\n         -156.06107], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 270,\n  'fluo_channel': 0,\n  'fluorescence': array([-100.13255 ,  -38.122635,  -59.402374, ...,  -28.636698,\n          -37.20854 ,  -67.38762 ], dtype=float32),\n  'neuropil_fluorescence': array([-143.43053, -139.25038, -129.9542 , ..., -123.85343, -122.57252,\n         -124.01679], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 271,\n  'fluo_channel': 0,\n  'fluorescence': array([-265.40598, -245.03558, -257.64804, ..., -244.37144, -233.4238 ,\n         -242.31696], dtype=float32),\n  'neuropil_fluorescence': array([-251.11548, -249.80344, -251.90417, ..., -247.89926, -242.74448,\n         -253.78378], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 272,\n  'fluo_channel': 0,\n  'fluorescence': array([12.9020405, 23.91642  , 70.70604  , ..., 25.378271 , 33.719585 ,\n         66.04217  ], dtype=float32),\n  'neuropil_fluorescence': array([-169.63701, -158.23843, -160.72064, ..., -169.01068, -162.65836,\n         -158.85587], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 273,\n  'fluo_channel': 0,\n  'fluorescence': array([-117.75733 ,  -62.379295,  -65.0929  , ..., -118.54483 ,\n          -70.50063 , -132.17253 ], dtype=float32),\n  'neuropil_fluorescence': array([-146.42328, -131.3201 , -122.6455 , ..., -136.0291 , -131.16138,\n         -135.26984], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 274,\n  'fluo_channel': 0,\n  'fluorescence': array([-250.12315, -241.49037, -258.75528, ..., -241.25989, -227.1836 ,\n         -234.24931], dtype=float32),\n  'neuropil_fluorescence': array([-238.35593, -242.0226 , -240.36346, ..., -240.97928, -243.93408,\n         -237.43503], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 275,\n  'fluo_channel': 0,\n  'fluorescence': array([-152.34833 , -128.61893 , -119.137085, ..., -143.61577 ,\n         -116.80879 , -124.17599 ], dtype=float32),\n  'neuropil_fluorescence': array([-177.68677, -182.92343, -175.41068, ..., -180.43852, -171.8399 ,\n         -174.99304], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 276,\n  'fluo_channel': 0,\n  'fluorescence': array([ -0.8461133,  13.634043 ,   5.2904463, ..., -45.702038 ,\n         -19.542374 , -52.307873 ], dtype=float32),\n  'neuropil_fluorescence': array([-147.09563, -147.70355, -143.84427, ..., -149.70901, -139.21858,\n         -153.01639], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 277,\n  'fluo_channel': 0,\n  'fluorescence': array([-196.34712, -190.44711, -198.94824, ..., -189.84203, -188.57498,\n         -197.78413], dtype=float32),\n  'neuropil_fluorescence': array([-208.28784, -210.26091, -207.91829, ..., -209.76973, -209.79016,\n         -207.27855], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 278,\n  'fluo_channel': 0,\n  'fluorescence': array([-154.03952, -159.33188, -162.74146, ..., -208.91814, -194.5029 ,\n         -165.85721], dtype=float32),\n  'neuropil_fluorescence': array([-214.43071, -197.50436, -206.92384, ..., -205.50063, -209.37453,\n         -209.5131 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 279,\n  'fluo_channel': 0,\n  'fluorescence': array([-264.15652, -265.44928, -270.2597 , ..., -259.21783, -267.02457,\n         -262.92493], dtype=float32),\n  'neuropil_fluorescence': array([-273.80637, -269.5467 , -267.33258, ..., -271.01138, -266.49658,\n         -267.68564], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 280,\n  'fluo_channel': 0,\n  'fluorescence': array([-222.51872, -241.36044, -244.11195, ..., -236.55704, -238.55244,\n         -247.4744 ], dtype=float32),\n  'neuropil_fluorescence': array([-264.12903, -260.4668 , -261.11575, ..., -255.89374, -260.47818,\n         -259.27515], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 281,\n  'fluo_channel': 0,\n  'fluorescence': array([-157.70976, -166.1489 , -119.6704 , ..., -172.6497 , -198.48106,\n         -163.10626], dtype=float32),\n  'neuropil_fluorescence': array([-193.78598, -196.11609, -188.92987, ..., -188.6445 , -196.2358 ,\n         -182.33131], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 282,\n  'fluo_channel': 0,\n  'fluorescence': array([-167.04906 , -107.485596, -103.55098 , ..., -120.64316 ,\n         -160.31046 , -174.78104 ], dtype=float32),\n  'neuropil_fluorescence': array([-170.94444, -165.17442, -169.95607, ..., -168.63954, -175.27002,\n         -182.27907], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 283,\n  'fluo_channel': 0,\n  'fluorescence': array([-172.30423, -175.24588, -151.55415, ..., -197.23218, -196.2225 ,\n         -176.06432], dtype=float32),\n  'neuropil_fluorescence': array([-189.52899, -176.83333, -174.80193, ..., -178.62077, -181.17874,\n         -186.7343 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 284,\n  'fluo_channel': 0,\n  'fluorescence': array([-137.63934, -167.95052, -164.7706 , ..., -141.7821 , -122.82317,\n         -158.87384], dtype=float32),\n  'neuropil_fluorescence': array([-132.20334 , -117.97493 , -136.08078 , ..., -123.194984,\n         -133.62953 , -125.73259 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 285,\n  'fluo_channel': 0,\n  'fluorescence': array([-225.2364 , -218.47153, -212.3804 , ..., -236.9442 , -205.18486,\n         -212.64046], dtype=float32),\n  'neuropil_fluorescence': array([-233.53616, -239.51122, -234.02245, ..., -247.80548, -238.95012,\n         -244.80798], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 286,\n  'fluo_channel': 0,\n  'fluorescence': array([-150.89545, -161.79932, -134.21503, ..., -149.80489, -167.91809,\n         -141.58322], dtype=float32),\n  'neuropil_fluorescence': array([-191.51036, -180.61658, -175.76425, ..., -185.44818, -175.37306,\n         -179.09067], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 287,\n  'fluo_channel': 0,\n  'fluorescence': array([-135.1435 , -168.17397, -132.84685, ..., -117.96031, -140.82135,\n         -146.1151 ], dtype=float32),\n  'neuropil_fluorescence': array([-176.2563 , -180.74815, -170.56296, ..., -175.26814, -167.71704,\n         -167.45482], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 288,\n  'fluo_channel': 0,\n  'fluorescence': array([-218.96864, -229.02383, -203.65068, ..., -213.64377, -229.09175,\n         -195.04584], dtype=float32),\n  'neuropil_fluorescence': array([-232.65553, -233.89352, -223.8121 , ..., -239.19624, -242.3904 ,\n         -239.03758], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 289,\n  'fluo_channel': 0,\n  'fluorescence': array([-130.77087 ,  -95.780495,  -68.02432 , ..., -161.79784 ,\n         -144.08206 , -139.997   ], dtype=float32),\n  'neuropil_fluorescence': array([-162.2938 , -160.35876, -155.5791 , ..., -164.14407, -155.33615,\n         -168.08192], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 290,\n  'fluo_channel': 0,\n  'fluorescence': array([ -32.934254,  -95.04554 ,  -23.849436, ...,  -78.15392 ,\n         -147.88907 , -102.45713 ], dtype=float32),\n  'neuropil_fluorescence': array([-113.62281,  -95.34649, -102.91886, ...,  -98.17325,  -97.76535,\n          -84.5329 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 291,\n  'fluo_channel': 0,\n  'fluorescence': array([ -6.180505, -34.710953,  53.325157, ..., -11.234239,  96.28478 ,\n          34.72668 ], dtype=float32),\n  'neuropil_fluorescence': array([-116.907074, -112.70909 , -110.29293 , ..., -132.03636 ,\n          -94.45859 , -115.92929 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 292,\n  'fluo_channel': 0,\n  'fluorescence': array([-189.17688, -199.29707, -183.68976, ..., -200.40039, -190.19221,\n         -183.63002], dtype=float32),\n  'neuropil_fluorescence': array([-217.07013, -221.66753, -212.77142, ..., -224.85194, -217.17143,\n         -225.36623], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 293,\n  'fluo_channel': 0,\n  'fluorescence': array([-164.94435, -148.04376, -192.93373, ..., -154.27647, -161.0604 ,\n         -166.02335], dtype=float32),\n  'neuropil_fluorescence': array([-174.83498, -189.27786, -170.64738, ..., -165.99013, -166.96756,\n         -170.7024 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 294,\n  'fluo_channel': 0,\n  'fluorescence': array([-147.71329, -146.90726,  -99.36065, ..., -157.69257, -136.30568,\n         -133.80675], dtype=float32),\n  'neuropil_fluorescence': array([-193.07748, -190.97786, -179.04428, ..., -194.92435, -194.45757,\n         -198.82288], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 295,\n  'fluo_channel': 0,\n  'fluorescence': array([-217.71167, -223.17746, -231.72672, ..., -240.35664, -238.69795,\n         -243.25513], dtype=float32),\n  'neuropil_fluorescence': array([-253.36363, -249.86603, -244.19139, ..., -260.20575, -252.96411,\n         -261.4952 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 296,\n  'fluo_channel': 0,\n  'fluorescence': array([-97.38572 , -89.374596, -70.70435 , ..., -88.95789 , -49.76713 ,\n         -93.26832 ], dtype=float32),\n  'neuropil_fluorescence': array([-201.10905, -194.33179, -198.25754, ..., -196.64037, -198.5986 ,\n         -198.92575], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 297,\n  'fluo_channel': 0,\n  'fluorescence': array([ -85.176636, -105.52271 , -149.04335 , ...,  -87.76927 ,\n         -122.96296 , -161.53517 ], dtype=float32),\n  'neuropil_fluorescence': array([-194.53398, -205.53398, -199.46117, ..., -205.12378, -195.28156,\n         -197.95389], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 298,\n  'fluo_channel': 0,\n  'fluorescence': array([-202.54485, -170.61465, -199.9271 , ..., -197.21936, -172.77098,\n         -202.51596], dtype=float32),\n  'neuropil_fluorescence': array([-203.67418, -208.18024, -208.42981, ..., -209.67764, -210.63084,\n         -213.7851 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 299,\n  'fluo_channel': 0,\n  'fluorescence': array([  -3.0734248, -100.81439  ,  -94.12331  , ...,   28.520044 ,\n         -138.16742  ,  -95.017525 ], dtype=float32),\n  'neuropil_fluorescence': array([-184.36842, -183.34296, -180.01189, ..., -176.34126, -181.16978,\n         -181.6214 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 300,\n  'fluo_channel': 0,\n  'fluorescence': array([-146.68808, -174.86653, -162.76451, ..., -158.49939, -128.18272,\n         -154.73737], dtype=float32),\n  'neuropil_fluorescence': array([-162.83487, -171.82753, -163.68074, ..., -174.65321, -182.65138,\n         -171.0477 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 301,\n  'fluo_channel': 0,\n  'fluorescence': array([-216.43326, -203.55322, -215.2879 , ..., -206.75223, -202.3153 ,\n         -203.80902], dtype=float32),\n  'neuropil_fluorescence': array([-234.57104, -230.38606, -233.20107, ..., -229.31903, -221.437  ,\n         -227.14745], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 302,\n  'fluo_channel': 0,\n  'fluorescence': array([-232.18674, -229.50552, -230.20232, ..., -211.9034 , -239.95772,\n         -239.2506 ], dtype=float32),\n  'neuropil_fluorescence': array([-215.32042, -203.3433 , -205.63556, ..., -217.14964, -201.33978,\n         -206.73592], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 303,\n  'fluo_channel': 0,\n  'fluorescence': array([-246.54256, -255.30687, -237.44714, ..., -253.44778, -235.82407,\n         -244.66988], dtype=float32),\n  'neuropil_fluorescence': array([-241.93272, -240.24545, -239.35454, ..., -242.29272, -246.09454,\n         -241.99272], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 304,\n  'fluo_channel': 0,\n  'fluorescence': array([-192.66943, -210.28087, -190.74768, ..., -196.7232 , -187.27815,\n         -211.40672], dtype=float32),\n  'neuropil_fluorescence': array([-206.66449, -198.76253, -190.6318 , ..., -201.71678, -205.77342,\n         -205.73639], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 305,\n  'fluo_channel': 0,\n  'fluorescence': array([-154.27863, -140.52562, -173.43913, ..., -151.4958 , -173.5066 ,\n         -167.43948], dtype=float32),\n  'neuropil_fluorescence': array([-176.53192, -175.82446, -179.95213, ..., -190.14627, -185.86967,\n         -178.67819], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 306,\n  'fluo_channel': 0,\n  'fluorescence': array([-194.41394, -168.09785, -189.48137, ..., -203.2181 , -194.97672,\n         -191.56396], dtype=float32),\n  'neuropil_fluorescence': array([-215.60335, -212.62198, -216.99069, ..., -216.5568 , -212.46368,\n         -212.52328], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 307,\n  'fluo_channel': 0,\n  'fluorescence': array([-169.68573,  -91.08567, -128.56525, ..., -161.44913, -135.81918,\n         -101.56802], dtype=float32),\n  'neuropil_fluorescence': array([-140.37166 , -137.41888 , -141.80904 , ..., -122.49281 ,\n         -115.80493 , -100.712524], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 308,\n  'fluo_channel': 0,\n  'fluorescence': array([-122.70072 , -133.92465 , -137.22388 , ...,  -90.80795 ,\n         -130.1948  , -125.074005], dtype=float32),\n  'neuropil_fluorescence': array([-154.28458, -155.11835, -152.22208, ..., -152.87367, -158.18085,\n         -149.15027], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 309,\n  'fluo_channel': 0,\n  'fluorescence': array([18.179255, 52.593475, 59.830513, ..., 45.109367, 19.138096,\n         30.317965], dtype=float32),\n  'neuropil_fluorescence': array([-142.23656, -143.18549, -146.41129, ..., -139.88979, -133.27957,\n         -132.1707 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 310,\n  'fluo_channel': 0,\n  'fluorescence': array([-133.51385, -137.43954, -116.55736, ..., -127.97335, -116.91924,\n         -156.83586], dtype=float32),\n  'neuropil_fluorescence': array([-175.88571, -176.73674, -180.85715, ..., -177.91837, -181.11224,\n         -167.38776], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 311,\n  'fluo_channel': 0,\n  'fluorescence': array([-155.54556, -162.06229, -158.28708, ..., -185.23701, -200.17519,\n         -217.87903], dtype=float32),\n  'neuropil_fluorescence': array([-186.56873, -176.23181, -190.97305, ..., -196.90836, -187.4717 ,\n         -189.8841 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 312,\n  'fluo_channel': 0,\n  'fluorescence': array([-21.789957, -21.66012 , -48.71478 , ..., -82.63959 , -96.92237 ,\n         -12.943764], dtype=float32),\n  'neuropil_fluorescence': array([-119.12546 , -107.54909 , -115.12909 , ..., -115.178185,\n         -111.20909 , -127.12909 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 313,\n  'fluo_channel': 0,\n  'fluorescence': array([-275.50623, -270.07767, -270.16852, ..., -265.58   , -260.6899 ,\n         -272.38214], dtype=float32),\n  'neuropil_fluorescence': array([-269.03607, -267.8574 , -269.33115, ..., -272.6246 , -265.49835,\n         -269.6459 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 314,\n  'fluo_channel': 0,\n  'fluorescence': array([-151.58955, -128.62225, -180.39467, ..., -151.27286, -184.18959,\n         -169.88763], dtype=float32),\n  'neuropil_fluorescence': array([-201.41837, -196.44897, -197.99184, ..., -205.14899, -195.81429,\n         -204.35101], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 315,\n  'fluo_channel': 0,\n  'fluorescence': array([-155.20497, -147.93834, -147.51666, ..., -160.46472, -154.6156 ,\n         -143.26935], dtype=float32),\n  'neuropil_fluorescence': array([-181.64093, -173.03232, -178.21005, ..., -165.53322, -168.19211,\n         -165.48654], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 316,\n  'fluo_channel': 0,\n  'fluorescence': array([-158.07317 , -127.50977 , -171.49858 , ..., -115.30527 ,\n         -163.03526 , -121.194466], dtype=float32),\n  'neuropil_fluorescence': array([-191.65434, -178.17827, -176.96521, ..., -189.68695, -200.49348,\n         -200.99783], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 317,\n  'fluo_channel': 0,\n  'fluorescence': array([-225.852  , -226.69325, -217.31934, ..., -211.69601, -200.3084 ,\n         -213.89528], dtype=float32),\n  'neuropil_fluorescence': array([-223.06914, -216.85666, -221.65599, ..., -208.7268 , -216.00844,\n         -206.71332], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 318,\n  'fluo_channel': 0,\n  'fluorescence': array([-249.77509, -237.15573, -236.97847, ..., -253.44077, -254.53868,\n         -247.0392 ], dtype=float32),\n  'neuropil_fluorescence': array([-243.04489, -225.803  , -224.20699, ..., -227.42644, -229.45137,\n         -230.0399 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 319,\n  'fluo_channel': 0,\n  'fluorescence': array([-141.8558  ,  -41.574856, -169.84294 , ..., -113.858   ,\n          -37.65505 , -147.28935 ], dtype=float32),\n  'neuropil_fluorescence': array([-198.4361 , -192.48872, -190.07268, ..., -189.90225, -183.401  ,\n         -198.12532], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 320,\n  'fluo_channel': 0,\n  'fluorescence': array([ 158.20387,  153.26395,  167.91736, ..., -232.17404, -188.31587,\n         -211.44012], dtype=float32),\n  'neuropil_fluorescence': array([-206.06311, -178.54044, -179.58383, ..., -206.12228, -208.1992 ,\n         -214.78896], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 321,\n  'fluo_channel': 0,\n  'fluorescence': array([-184.49583, -168.30705, -176.4077 , ..., -173.4246 , -177.78926,\n         -162.14336], dtype=float32),\n  'neuropil_fluorescence': array([-186.98035, -183.16383, -172.89384, ..., -186.13893, -174.21887,\n         -179.4941 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 322,\n  'fluo_channel': 0,\n  'fluorescence': array([-132.33778 ,  -94.51463 ,  -78.158134, ...,  -74.831245,\n         -115.809   , -180.53967 ], dtype=float32),\n  'neuropil_fluorescence': array([-153.25375, -152.34962, -144.00375, ..., -139.98685, -149.37782,\n         -147.25188], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 323,\n  'fluo_channel': 0,\n  'fluorescence': array([-151.6827 , -186.91298, -154.80379, ..., -119.6143 , -157.83966,\n         -119.71764], dtype=float32),\n  'neuropil_fluorescence': array([-189.38564, -196.64516, -184.45454, ..., -180.70235, -183.739  ,\n         -187.03519], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 324,\n  'fluo_channel': 0,\n  'fluorescence': array([-116.238754, -108.97474 ,  -81.86005 , ..., -115.88458 ,\n         -102.08983 , -105.85033 ], dtype=float32),\n  'neuropil_fluorescence': array([-194.70134, -191.64   , -187.776  , ..., -188.10133, -190.41333,\n         -193.112  ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 325,\n  'fluo_channel': 0,\n  'fluorescence': array([-130.88054 , -106.082664, -116.63274 , ..., -101.23593 ,\n          -94.473694, -125.162285], dtype=float32),\n  'neuropil_fluorescence': array([-138.      , -143.01709 , -148.0342  , ..., -126.03704 ,\n         -131.97151 , -116.350426], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 326,\n  'fluo_channel': 0,\n  'fluorescence': array([-178.04749, -136.64081, -178.37842, ..., -150.1413 , -139.65694,\n         -178.93562], dtype=float32),\n  'neuropil_fluorescence': array([-123.21896, -121.00862, -137.56207, ..., -125.92414, -131.07414,\n         -129.98103], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 327,\n  'fluo_channel': 0,\n  'fluorescence': array([-194.60043, -204.56691, -188.92662, ..., -202.11047, -228.43515,\n         -213.30669], dtype=float32),\n  'neuropil_fluorescence': array([-226.08356, -236.9765 , -228.84334, ..., -235.77806, -237.75719,\n         -239.93472], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 328,\n  'fluo_channel': 0,\n  'fluorescence': array([-205.74895, -171.84355, -185.44974, ..., -196.9889 , -215.52687,\n         -215.84506], dtype=float32),\n  'neuropil_fluorescence': array([-197.65025, -190.60837, -195.70197, ..., -186.14532, -188.39902,\n         -195.60591], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 329,\n  'fluo_channel': 0,\n  'fluorescence': array([-163.0586 , -138.32355, -154.06052, ..., -147.12558, -150.6106 ,\n         -121.09697], dtype=float32),\n  'neuropil_fluorescence': array([-184.77284, -183.53847, -197.92429, ..., -195.57332, -186.11539,\n         -187.71875], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 330,\n  'fluo_channel': 0,\n  'fluorescence': array([-156.25298 , -123.1493  , -115.65706 , ..., -140.84557 ,\n         -113.77969 , -117.022224], dtype=float32),\n  'neuropil_fluorescence': array([-181.16534, -169.46216, -172.96016, ..., -178.20518, -169.58168,\n         -190.7251 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 331,\n  'fluo_channel': 0,\n  'fluorescence': array([ -54.84945 ,  -92.333954,  -71.96401 , ..., -129.61562 ,\n          -54.044216,   73.12117 ], dtype=float32),\n  'neuropil_fluorescence': array([-158.77386, -146.6285 , -169.9354 , ..., -158.31424, -157.02937,\n         -158.64171], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 332,\n  'fluo_channel': 0,\n  'fluorescence': array([-257.52805, -212.19185, -225.19096, ..., -171.84044, -154.4582 ,\n         -219.78224], dtype=float32),\n  'neuropil_fluorescence': array([-190.40182, -197.87215, -196.3592 , ..., -186.32877, -199.59056,\n         -199.18265], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 333,\n  'fluo_channel': 0,\n  'fluorescence': array([-183.91783, -164.71095, -156.69153, ..., -206.2262 , -206.99123,\n         -150.22923], dtype=float32),\n  'neuropil_fluorescence': array([-159.8108 , -145.81892, -136.77298, ..., -147.10811, -155.36757,\n         -159.6973 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 334,\n  'fluo_channel': 0,\n  'fluorescence': array([-239.23294, -228.70897, -229.06836, ..., -220.1215 , -229.58417,\n         -209.10948], dtype=float32),\n  'neuropil_fluorescence': array([-217.35443, -211.27342, -205.96962, ..., -204.88101, -204.93924,\n         -207.86076], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 335,\n  'fluo_channel': 0,\n  'fluorescence': array([-143.96301 , -185.90462 , -165.13394 , ...,  -85.12636 ,\n         -122.967125, -143.75165 ], dtype=float32),\n  'neuropil_fluorescence': array([-144.43079, -160.78531, -153.73447, ..., -142.92656, -145.04802,\n         -151.01836], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 336,\n  'fluo_channel': 0,\n  'fluorescence': array([ -66.10146 ,  -46.717762,   28.048794, ..., -131.42284 ,\n           32.771046,  -48.187046], dtype=float32),\n  'neuropil_fluorescence': array([-122.64641 , -114.67587 , -108.32965 , ..., -116.639046,\n         -105.26335 , -123.392265], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 337,\n  'fluo_channel': 0,\n  'fluorescence': array([-136.0118 , -146.1628 , -127.32085, ..., -178.14514, -180.50032,\n         -181.2428 ], dtype=float32),\n  'neuropil_fluorescence': array([-169.58333, -191.30807, -175.25505, ..., -190.90657, -197.09091,\n         -182.71718], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 338,\n  'fluo_channel': 0,\n  'fluorescence': array([-105.521095, -120.46471 , -106.14476 , ..., -118.95552 ,\n         -119.07193 , -130.6589  ], dtype=float32),\n  'neuropil_fluorescence': array([-198.96907, -188.41649, -190.32166, ..., -189.99174, -191.62474,\n         -186.97113], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 339,\n  'fluo_channel': 0,\n  'fluorescence': array([ -69.88221 ,  -15.126948,  -94.12589 , ...,  -93.284256,\n          -10.781388, -108.19577 ], dtype=float32),\n  'neuropil_fluorescence': array([-110.28673 , -107.82227 ,  -94.40285 , ..., -107.65166 ,\n         -112.753555,  -97.945496], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 340,\n  'fluo_channel': 0,\n  'fluorescence': array([-218.08334, -231.48335, -249.25635, ..., -227.72108, -225.84975,\n         -219.95583], dtype=float32),\n  'neuropil_fluorescence': array([-191.6156 , -177.17827, -177.73538, ..., -183.33148, -193.51811,\n         -181.90529], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 341,\n  'fluo_channel': 0,\n  'fluorescence': array([-137.6569  , -100.923065, -204.24947 , ..., -189.25252 ,\n         -186.01576 , -245.7186  ], dtype=float32),\n  'neuropil_fluorescence': array([-197.31236, -201.18872, -199.71367, ..., -214.1757 , -200.7744 ,\n         -199.0282 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 342,\n  'fluo_channel': 0,\n  'fluorescence': array([-154.43188, -150.53038, -172.81963, ..., -171.44803, -162.6475 ,\n         -123.0331 ], dtype=float32),\n  'neuropil_fluorescence': array([-204.01529, -201.33406, -208.23145, ..., -216.29913, -226.34497,\n         -220.45851], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 343,\n  'fluo_channel': 0,\n  'fluorescence': array([-180.04475 ,  -80.82848 , -133.84958 , ..., -185.74315 ,\n          -25.529572, -202.08742 ], dtype=float32),\n  'neuropil_fluorescence': array([-142.01352, -135.62973, -154.2027 , ..., -170.61621, -164.98108,\n         -150.94324], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 344,\n  'fluo_channel': 0,\n  'fluorescence': array([-214.82391, -200.70105, -203.60324, ..., -219.41068, -207.86201,\n         -187.44128], dtype=float32),\n  'neuropil_fluorescence': array([-178.80763, -179.70149, -185.41957, ..., -194.34163, -186.3068 ,\n         -175.89055], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 345,\n  'fluo_channel': 0,\n  'fluorescence': array([-168.75562, -185.27518, -188.39499, ..., -182.72862, -161.9214 ,\n         -173.12662], dtype=float32),\n  'neuropil_fluorescence': array([-201.71272, -202.60965, -189.55702, ..., -200.92545, -194.23245,\n         -206.95833], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 346,\n  'fluo_channel': 0,\n  'fluorescence': array([-101.470375,  -19.159084, -110.41585 , ...,  -77.44052 ,\n          -86.39106 , -144.66916 ], dtype=float32),\n  'neuropil_fluorescence': array([-150.7516 , -145.8651 , -139.87152, ..., -134.51178, -120.803  ,\n         -136.87366], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 347,\n  'fluo_channel': 0,\n  'fluorescence': array([ -93.76278, -125.90302, -172.40698, ..., -105.60322, -176.00517,\n         -153.32983], dtype=float32),\n  'neuropil_fluorescence': array([-165.76471, -164.70279, -158.55882, ..., -165.43654, -163.83282,\n         -157.57121], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 348,\n  'fluo_channel': 0,\n  'fluorescence': array([ -93.71865 ,  -83.73524 ,  -84.015144, ..., -100.53863 ,\n          -82.18538 ,  -98.349594], dtype=float32),\n  'neuropil_fluorescence': array([-139.86852, -149.82007, -146.06747, ..., -140.39447, -121.8045 ,\n         -130.53633], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 349,\n  'fluo_channel': 0,\n  'fluorescence': array([-247.7868 , -252.35243, -235.64832, ..., -235.20966, -238.7584 ,\n         -243.66537], dtype=float32),\n  'neuropil_fluorescence': array([-235.6599 , -237.18443, -236.89679, ..., -237.7225 , -238.03046,\n         -235.8291 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 350,\n  'fluo_channel': 0,\n  'fluorescence': array([-202.14203, -202.74005, -174.69333, ..., -160.47665, -199.83885,\n         -192.22853], dtype=float32),\n  'neuropil_fluorescence': array([-214.01619, -211.46559, -208.86505, ..., -209.91364, -211.96222,\n         -212.39542], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 351,\n  'fluo_channel': 0,\n  'fluorescence': array([-248.81584, -234.27191, -235.63611, ..., -239.41753, -226.02368,\n         -231.16753], dtype=float32),\n  'neuropil_fluorescence': array([-238.50311, -237.85715, -231.38303, ..., -247.33333, -242.97308,\n         -237.56729], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 352,\n  'fluo_channel': 0,\n  'fluorescence': array([ -82.01185,  -77.33861, -133.5144 , ..., -169.72006, -127.59219,\n         -140.57738], dtype=float32),\n  'neuropil_fluorescence': array([-185.56403, -184.43022, -177.74533, ..., -188.89784, -184.7482 ,\n         -184.1669 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 353,\n  'fluo_channel': 0,\n  'fluorescence': array([-100.178505, -117.661995, -125.976585, ..., -111.522964,\n          -88.13503 ,  -83.71707 ], dtype=float32),\n  'neuropil_fluorescence': array([-176.65778, -172.56828, -177.76923, ..., -188.00784, -176.81161,\n         -183.45998], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 354,\n  'fluo_channel': 0,\n  'fluorescence': array([-209.87074, -225.31946, -203.19585, ..., -188.15031, -210.95471,\n         -205.89417], dtype=float32),\n  'neuropil_fluorescence': array([-217.56468, -220.81108, -217.79466, ..., -219.95688, -229.82545,\n         -227.10883], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 355,\n  'fluo_channel': 0,\n  'fluorescence': array([ -95.679344,  -13.438223,  -65.524994, ...,  -65.0225  ,\n         -128.25215 , -122.2217  ], dtype=float32),\n  'neuropil_fluorescence': array([-139.15965, -124.73684, -136.64386, ..., -139.96666, -145.4649 ,\n         -136.32106], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 356,\n  'fluo_channel': 0,\n  'fluorescence': array([-232.83366, -256.85446, -217.38293, ..., -237.24167, -230.56262,\n         -250.8676 ], dtype=float32),\n  'neuropil_fluorescence': array([-246.52809, -250.27809, -246.70506, ..., -248.98596, -245.69382,\n         -244.45506], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 357,\n  'fluo_channel': 0,\n  'fluorescence': array([-141.86688, -135.14029, -141.71239, ..., -131.80083, -149.72137,\n         -119.73206], dtype=float32),\n  'neuropil_fluorescence': array([-193.30214, -191.20856, -189.08289, ..., -193.58289, -184.98396,\n         -192.37166], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 358,\n  'fluo_channel': 0,\n  'fluorescence': array([-201.70015, -202.37181, -199.61975, ..., -237.8937 , -225.79842,\n         -206.88042], dtype=float32),\n  'neuropil_fluorescence': array([-224.89114, -227.75443, -215.43797, ..., -237.49367, -220.1519 ,\n         -225.24304], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 359,\n  'fluo_channel': 0,\n  'fluorescence': array([-152.79636, -138.08974, -122.52896, ..., -145.43373, -129.17403,\n         -119.16097], dtype=float32),\n  'neuropil_fluorescence': array([-168.99533, -163.51247, -151.01091, ..., -164.51558, -162.71962,\n         -158.28972], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 360,\n  'fluo_channel': 0,\n  'fluorescence': array([-164.50848, -167.84975, -185.844  , ..., -150.23874, -170.49165,\n         -178.33916], dtype=float32),\n  'neuropil_fluorescence': array([-226.9598 , -213.7923 , -220.87102, ..., -213.20602, -216.72864,\n         -213.80402], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 361,\n  'fluo_channel': 0,\n  'fluorescence': array([-118.39356 , -127.07425 , -114.98613 , ..., -118.644135,\n         -109.909134, -115.06394 ], dtype=float32),\n  'neuropil_fluorescence': array([-176.48602, -166.66237, -163.87743, ..., -182.04086, -166.04732,\n         -164.56775], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 362,\n  'fluo_channel': 0,\n  'fluorescence': array([ -25.684889,  -30.3205  , -164.97855 , ..., -100.995186,\n          -69.68914 , -101.31832 ], dtype=float32),\n  'neuropil_fluorescence': array([-169.72743, -158.35243, -166.23785, ..., -159.67188, -170.72223,\n         -173.0677 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 363,\n  'fluo_channel': 0,\n  'fluorescence': array([-204.36919, -204.35417, -193.54913, ..., -198.73373, -217.66579,\n         -224.51488], dtype=float32),\n  'neuropil_fluorescence': array([-200.304, -188.394, -183.096, ..., -198.252, -193.38 , -201.188],\n        dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 364,\n  'fluo_channel': 0,\n  'fluorescence': array([-194.80832, -181.43094, -183.93855, ..., -183.37375, -195.96526,\n         -186.12383], dtype=float32),\n  'neuropil_fluorescence': array([-212.1953 , -216.40941, -211.22118, ..., -214.22118, -217.38118,\n         -210.61647], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 365,\n  'fluo_channel': 0,\n  'fluorescence': array([-58.12733 , -43.919575, -58.46304 , ...,  47.843784, -74.73002 ,\n          35.976986], dtype=float32),\n  'neuropil_fluorescence': array([-125.026085, -122.26087 , -117.655075, ..., -108.19421 ,\n         -116.666664, -116.16956 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 366,\n  'fluo_channel': 0,\n  'fluorescence': array([ -66.2288 ,  -94.63303, -163.49083, ...,  -55.89437,  -72.73523,\n         -118.39697], dtype=float32),\n  'neuropil_fluorescence': array([-186.23398, -177.79968, -173.53847, ..., -176.09616, -176.19711,\n         -183.73878], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 367,\n  'fluo_channel': 0,\n  'fluorescence': array([-126.79211 , -124.347534,  -17.346409, ...,  -97.14969 ,\n         -129.23047 , -123.89053 ], dtype=float32),\n  'neuropil_fluorescence': array([-185.66324, -179.575  , -178.2853 , ..., -177.90442, -178.40147,\n         -172.86177], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 368,\n  'fluo_channel': 0,\n  'fluorescence': array([-206.54243, -194.954  , -218.60353, ..., -200.9006 , -202.92387,\n         -212.33739], dtype=float32),\n  'neuropil_fluorescence': array([-220.9647 , -223.94353, -222.33647, ..., -223.48   , -220.50117,\n         -210.49883], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 369,\n  'fluo_channel': 0,\n  'fluorescence': array([-147.67561 , -164.65085 ,  -97.94191 , ..., -103.38052 ,\n          -91.78729 , -116.046234], dtype=float32),\n  'neuropil_fluorescence': array([-166.14854, -157.95624, -155.46286, ..., -148.5199 , -161.81564,\n         -149.28514], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 370,\n  'fluo_channel': 0,\n  'fluorescence': array([-129.33986 , -104.773735,  -98.646355, ..., -134.7812  ,\n          -87.873886,  -83.69562 ], dtype=float32),\n  'neuropil_fluorescence': array([-167.03235, -147.782  , -150.24614, ..., -162.29395, -157.68073,\n         -155.60197], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 371,\n  'fluo_channel': 0,\n  'fluorescence': array([-164.0872 , -195.12427, -163.26666, ..., -138.40329, -191.27539,\n         -165.26549], dtype=float32),\n  'neuropil_fluorescence': array([-155.59622, -164.90378, -156.05836, ..., -154.2571 , -163.19716,\n         -157.11198], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 372,\n  'fluo_channel': 0,\n  'fluorescence': array([-181.08838 ,  -38.00926 ,  -13.028366, ...,  894.2969  ,\n          692.06915 , 1133.3065  ], dtype=float32),\n  'neuropil_fluorescence': array([-121.24599 , -130.21658 , -120.778076, ..., -119.99733 ,\n         -111.2246  , -127.681816], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 373,\n  'fluo_channel': 0,\n  'fluorescence': array([-106.30461 ,  -88.12437 ,  -78.04682 , ...,  -95.9469  ,\n         -112.66734 ,  -99.542984], dtype=float32),\n  'neuropil_fluorescence': array([-143.2677 , -129.51991, -122.97124, ..., -141.56859, -139.97345,\n         -135.12831], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 374,\n  'fluo_channel': 0,\n  'fluorescence': array([ 42.806656,  11.769793,  11.174741, ..., -19.061886, -54.880543,\n         -21.56603 ], dtype=float32),\n  'neuropil_fluorescence': array([-109.39086 , -108.75635 , -104.51523 , ..., -111.77919 ,\n         -124.378174, -113.880714], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 375,\n  'fluo_channel': 0,\n  'fluorescence': array([-247.53629, -222.18716, -243.6162 , ..., -254.34467, -237.7171 ,\n         -222.17697], dtype=float32),\n  'neuropil_fluorescence': array([-220.0337 , -225.3104 , -223.80618, ..., -226.1545 , -229.89326,\n         -223.9368 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 376,\n  'fluo_channel': 0,\n  'fluorescence': array([-142.27603 , -122.525475, -102.072464, ...,  -78.73239 ,\n          -24.431665, -105.44881 ], dtype=float32),\n  'neuropil_fluorescence': array([-193.04317, -198.58034, -185.73141, ..., -198.34532, -202.23262,\n         -199.88249], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 377,\n  'fluo_channel': 0,\n  'fluorescence': array([-151.62001 , -149.8949  , -125.4026  , ...,  -43.584805,\n          -21.435446,  -45.900806], dtype=float32),\n  'neuropil_fluorescence': array([-167.11052, -149.06053, -161.2    , ..., -154.19211, -155.83421,\n         -165.76315], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 378,\n  'fluo_channel': 0,\n  'fluorescence': array([-145.39505, -111.12437, -114.16081, ..., -116.83078, -131.58752,\n         -130.3494 ], dtype=float32),\n  'neuropil_fluorescence': array([-128.86533, -118.19814, -142.72446, ..., -148.07431, -136.02477,\n         -143.93344], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 379,\n  'fluo_channel': 0,\n  'fluorescence': array([-237.80705, -180.27814, -168.26378, ..., -226.94267, -167.76575,\n         -160.88914], dtype=float32),\n  'neuropil_fluorescence': array([-197.88483, -207.49158, -204.5618 , ..., -198.60393, -199.70787,\n         -202.39044], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 380,\n  'fluo_channel': 0,\n  'fluorescence': array([-180.79405, -178.2911 , -164.87004, ..., -220.13715, -160.07756,\n         -172.90895], dtype=float32),\n  'neuropil_fluorescence': array([-200.90262, -199.42572, -197.12485, ..., -190.46692, -193.14357,\n         -196.15605], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 381,\n  'fluo_channel': 0,\n  'fluorescence': array([ -71.97302 , -193.35406 , -194.50343 , ..., -109.6261  ,\n          -82.535866,  -59.592865], dtype=float32),\n  'neuropil_fluorescence': array([-206.30655, -206.5625 , -196.10715, ..., -200.39435, -200.89435,\n         -205.04613], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 382,\n  'fluo_channel': 0,\n  'fluorescence': array([ -87.00276 ,  -92.036385,  -95.40887 , ..., -109.3466  ,\n          -89.166916, -101.751045], dtype=float32),\n  'neuropil_fluorescence': array([-153.33522, -140.1188 , -142.94766, ..., -152.34229, -144.72278,\n         -152.38472], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 383,\n  'fluo_channel': 0,\n  'fluorescence': array([-257.56036, -235.52887, -225.1378 , ..., -236.27058, -251.74715,\n         -221.82831], dtype=float32),\n  'neuropil_fluorescence': array([-172.91914, -174.5617 , -170.2383 , ..., -207.46666, -201.8227 ,\n         -206.00568], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 384,\n  'fluo_channel': 0,\n  'fluorescence': array([-218.1777 , -242.52979, -235.65811, ..., -245.74016, -221.42934,\n         -241.48402], dtype=float32),\n  'neuropil_fluorescence': array([-244.54884, -242.84651, -241.85582, ..., -247.02094, -245.0186 ,\n         -241.74419], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 385,\n  'fluo_channel': 0,\n  'fluorescence': array([-210.74721, -233.38965, -195.93611, ..., -208.98515, -192.44203,\n         -208.87648], dtype=float32),\n  'neuropil_fluorescence': array([-213.46297, -213.00618, -202.74445, ..., -214.50124, -219.80988,\n         -216.58025], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 386,\n  'fluo_channel': 0,\n  'fluorescence': array([-203.67429, -197.5664 , -199.1441 , ..., -201.23758, -205.20035,\n         -210.38568], dtype=float32),\n  'neuropil_fluorescence': array([-188.5308 , -195.91943, -199.13507, ..., -175.56873, -182.61137,\n         -192.59004], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 387,\n  'fluo_channel': 0,\n  'fluorescence': array([-122.081924,  -49.739708, -118.896126, ..., -170.97722 ,\n         -172.3888  , -163.94809 ], dtype=float32),\n  'neuropil_fluorescence': array([-214.41063, -207.99557, -208.11668, ..., -215.4638 , -217.29395,\n         -205.04875], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 388,\n  'fluo_channel': 0,\n  'fluorescence': array([-153.82079, -190.25586, -148.09804, ..., -178.45164, -155.32542,\n         -180.01988], dtype=float32),\n  'neuropil_fluorescence': array([-164.78003, -161.39594, -158.91202, ..., -163.57361, -148.45685,\n         -154.71405], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 389,\n  'fluo_channel': 0,\n  'fluorescence': array([-135.22511 , -202.38689 ,  -78.037735, ..., -212.52841 ,\n          -87.430244, -146.18863 ], dtype=float32),\n  'neuropil_fluorescence': array([-148.81583, -154.41841, -144.39903, ..., -145.25525, -134.06624,\n         -132.98062], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 390,\n  'fluo_channel': 0,\n  'fluorescence': array([ -97.66518 ,  -83.625336,  -68.81155 , ..., -125.18303 ,\n           13.765315, -145.96996 ], dtype=float32),\n  'neuropil_fluorescence': array([-106.36435 ,  -87.11272 ,  -90.29358 , ...,  -90.49148 ,\n          -90.28047 ,  -94.187416], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 391,\n  'fluo_channel': 0,\n  'fluorescence': array([-125.27141, -107.85386, -160.10446, ...,  -24.93105,  -84.02889,\n          -84.42586], dtype=float32),\n  'neuropil_fluorescence': array([-156.553  , -143.20967, -139.70967, ..., -139.76729, -133.02304,\n         -114.57373], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 392,\n  'fluo_channel': 0,\n  'fluorescence': array([ -69.44262 ,   40.545425, -143.02289 , ..., -176.80193 ,\n          -98.57363 ,  -68.284004], dtype=float32),\n  'neuropil_fluorescence': array([-143.2426 , -143.87721, -155.0429 , ..., -145.61095, -141.36243,\n         -150.17604], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 393,\n  'fluo_channel': 0,\n  'fluorescence': array([-176.27727, -181.03848, -198.76865, ..., -173.27592, -166.4994 ,\n         -173.86469], dtype=float32),\n  'neuropil_fluorescence': array([-215.69168, -212.43205, -206.90263, ..., -209.52536, -216.86815,\n         -214.04463], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 394,\n  'fluo_channel': 0,\n  'fluorescence': array([-160.83112, -166.8239 , -173.74612, ..., -138.95602, -155.21094,\n         -158.08287], dtype=float32),\n  'neuropil_fluorescence': array([-156.02702, -157.27026, -157.63243, ..., -152.85947, -147.4    ,\n         -151.02702], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 395,\n  'fluo_channel': 0,\n  'fluorescence': array([ -89.537796,  -40.133873,  -75.50926 , ...,  -79.35155 ,\n         -123.535805, -111.360054], dtype=float32),\n  'neuropil_fluorescence': array([-152.61697, -149.32076, -147.95284, ..., -151.35849, -149.28679,\n         -143.6566 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 396,\n  'fluo_channel': 0,\n  'fluorescence': array([-172.57036, -180.64426, -215.93013, ..., -206.88228, -189.24364,\n         -200.25711], dtype=float32),\n  'neuropil_fluorescence': array([-187.90141, -189.00403, -190.52113, ..., -189.76257, -191.26157,\n         -182.44467], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 397,\n  'fluo_channel': 0,\n  'fluorescence': array([-229.7684 , -220.71378, -237.60435, ..., -214.11748, -239.38635,\n         -204.34125], dtype=float32),\n  'neuropil_fluorescence': array([-252.63127, -253.27403, -245.77905, ..., -247.79913, -249.57819,\n         -249.38307], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 398,\n  'fluo_channel': 0,\n  'fluorescence': array([-224.32408, -216.9391 , -235.49875, ..., -219.83432, -232.44394,\n         -247.0091 ], dtype=float32),\n  'neuropil_fluorescence': array([-240.52702, -242.83784, -241.97748, ..., -244.58784, -241.82658,\n         -234.68468], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 399,\n  'fluo_channel': 0,\n  'fluorescence': array([-166.12242, -154.0495 , -116.00497, ..., -162.93672, -119.93661,\n         -144.70984], dtype=float32),\n  'neuropil_fluorescence': array([-194.46927, -196.60269, -197.91154, ..., -205.62369, -196.92503,\n         -209.31334], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 400,\n  'fluo_channel': 0,\n  'fluorescence': array([-192.00299, -171.99243, -197.55771, ..., -183.50507, -187.62247,\n         -189.13867], dtype=float32),\n  'neuropil_fluorescence': array([-176.66884, -179.97168, -168.60785, ..., -184.64706, -171.3682 ,\n         -178.8976 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 401,\n  'fluo_channel': 0,\n  'fluorescence': array([-117.8685  , -179.97598 , -108.03952 , ..., -123.106804,\n         -123.63209 , -130.98557 ], dtype=float32),\n  'neuropil_fluorescence': array([-189.65384, -194.03671, -193.80594, ..., -190.62762, -187.25175,\n         -192.59091], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 402,\n  'fluo_channel': 0,\n  'fluorescence': array([-107.67238  ,  -48.948753 ,  -41.945568 , ...,   -3.3616345,\n         -106.65874  ,  -80.553764 ], dtype=float32),\n  'neuropil_fluorescence': array([-135.30064, -125.51173, -134.13432, ..., -123.29424, -130.73134,\n         -121.20469], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 403,\n  'fluo_channel': 0,\n  'fluorescence': array([-260.97052, -261.98828, -261.50943, ..., -245.0352 , -256.6017 ,\n         -273.36295], dtype=float32),\n  'neuropil_fluorescence': array([-263.81805, -262.77292, -263.31342, ..., -262.22974, -265.23904,\n         -264.08102], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 404,\n  'fluo_channel': 0,\n  'fluorescence': array([-233.69914, -222.90994, -194.3933 , ..., -232.56227, -197.02048,\n         -218.63002], dtype=float32),\n  'neuropil_fluorescence': array([-231.28854, -222.10793, -224.54846, ..., -227.79295, -227.56168,\n         -219.59251], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 405,\n  'fluo_channel': 0,\n  'fluorescence': array([-161.49936 ,  -88.46949 , -189.0524  , ...,  -55.242317,\n         -114.25569 , -168.25261 ], dtype=float32),\n  'neuropil_fluorescence': array([-198.84041, -194.15573, -194.8108 , ..., -194.10167, -186.46848,\n         -187.18147], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 406,\n  'fluo_channel': 0,\n  'fluorescence': array([-153.23083, -145.27759, -146.2551 , ..., -128.13791, -146.5184 ,\n         -153.07802], dtype=float32),\n  'neuropil_fluorescence': array([-187.17128, -183.65239, -189.15617, ..., -175.05794, -185.43324,\n         -190.34761], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 407,\n  'fluo_channel': 0,\n  'fluorescence': array([-132.0943 , -176.01521, -142.10088, ..., -144.89636, -138.0569 ,\n         -134.52817], dtype=float32),\n  'neuropil_fluorescence': array([-196.13148, -199.08478, -189.16609, ..., -201.27336, -197.42734,\n         -199.36505], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 408,\n  'fluo_channel': 0,\n  'fluorescence': array([-139.17299, -182.82729,  -96.59239, ..., -188.63982, -170.01785,\n         -131.7601 ], dtype=float32),\n  'neuropil_fluorescence': array([-182.62979, -179.93759, -175.63121, ..., -172.87943, -163.94043,\n         -168.54326], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 409,\n  'fluo_channel': 0,\n  'fluorescence': array([-206.93983, -205.62337, -220.78499, ..., -207.44925, -185.35208,\n         -223.59258], dtype=float32),\n  'neuropil_fluorescence': array([-205.83469, -205.26016, -200.83469, ..., -207.42276, -218.36043,\n         -202.01355], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 410,\n  'fluo_channel': 0,\n  'fluorescence': array([-188.49025, -205.72038, -201.73367, ..., -196.69025, -195.69362,\n         -191.14871], dtype=float32),\n  'neuropil_fluorescence': array([-215.74318, -220.45105, -215.21669, ..., -215.40129, -212.46068,\n         -212.45908], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 411,\n  'fluo_channel': 0,\n  'fluorescence': array([-49.910362 ,  37.558495 , -35.914448 , ...,  47.109566 ,\n          -1.1677623, -24.433456 ], dtype=float32),\n  'neuropil_fluorescence': array([-168.45084, -147.46349, -150.11938, ..., -157.93259, -159.39888,\n         -155.85674], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 412,\n  'fluo_channel': 0,\n  'fluorescence': array([ -72.381256 , -129.5931   ,  -89.39122  , ...,    5.2627773,\n          -60.658348 ,  -71.47047  ], dtype=float32),\n  'neuropil_fluorescence': array([-167.92218, -170.46498, -175.24902, ..., -168.51167, -165.43774,\n         -171.34825], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 413,\n  'fluo_channel': 0,\n  'fluorescence': array([-101.66659 , -123.874855, -105.469345, ..., -151.97197 ,\n         -146.83966 ,  -97.95508 ], dtype=float32),\n  'neuropil_fluorescence': array([-209.9135 , -197.85294, -207.15572, ..., -205.87889, -208.46367,\n         -199.58478], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 414,\n  'fluo_channel': 0,\n  'fluorescence': array([ -14.323145, -115.24807 ,  -90.95798 , ...,  -78.06308 ,\n          -40.786125,  -92.353516], dtype=float32),\n  'neuropil_fluorescence': array([-117.051155, -116.86633 , -119.63367 , ..., -127.85478 ,\n         -127.924095, -118.0462  ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 415,\n  'fluo_channel': 0,\n  'fluorescence': array([-181.55144, -172.25752, -188.27908, ..., -186.11595, -190.40475,\n         -193.66391], dtype=float32),\n  'neuropil_fluorescence': array([-204.82321, -199.49643, -198.20892, ..., -212.70535, -201.70178,\n         -205.2625 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 416,\n  'fluo_channel': 0,\n  'fluorescence': array([-145.78061 , -210.87561 ,  -61.167225, ..., -172.33334 ,\n          -83.03108 , -182.84651 ], dtype=float32),\n  'neuropil_fluorescence': array([-194.9956 , -194.98973, -193.61143, ..., -196.80792, -186.9956 ,\n         -195.01613], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 417,\n  'fluo_channel': 0,\n  'fluorescence': array([-189.40945, -216.96918, -121.6564 , ..., -209.47438, -229.91426,\n         -153.85913], dtype=float32),\n  'neuropil_fluorescence': array([-200.91423, -197.39452, -202.86621, ..., -207.63293, -204.8868 ,\n         -203.8542 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 418,\n  'fluo_channel': 0,\n  'fluorescence': array([  18.055809,  -65.87482 ,  -95.86596 , ..., -104.77951 ,\n         -113.629135, -115.83126 ], dtype=float32),\n  'neuropil_fluorescence': array([-127.49888 , -130.02922 , -111.64494 , ..., -117.469666,\n         -121.1236  , -127.01348 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 419,\n  'fluo_channel': 0,\n  'fluorescence': array([-168.79002, -199.60092, -156.39113, ..., -172.77522, -127.20971,\n         -160.3346 ], dtype=float32),\n  'neuropil_fluorescence': array([-217.25754, -217.76102, -207.2065 , ..., -210.72621, -216.19954,\n         -206.5986 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 420,\n  'fluo_channel': 0,\n  'fluorescence': array([  3.5869899, -67.464134 , -75.889206 , ..., -16.363117 ,\n          50.558376 ,  16.521278 ], dtype=float32),\n  'neuropil_fluorescence': array([-195.39607, -189.38135, -190.4288 , ..., -198.07529, -191.25204,\n         -202.51064], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 421,\n  'fluo_channel': 0,\n  'fluorescence': array([-109.42673, -116.87709, -132.01291, ..., -136.40276, -129.16428,\n         -143.15544], dtype=float32),\n  'neuropil_fluorescence': array([-131.28464, -141.82771, -124.53558, ..., -123.57678, -110.40824,\n         -112.18352], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 422,\n  'fluo_channel': 0,\n  'fluorescence': array([-173.6733 , -199.92047, -193.25792, ..., -146.9409 , -158.85461,\n         -143.79916], dtype=float32),\n  'neuropil_fluorescence': array([-192.78592, -179.06754, -179.38219, ..., -192.29167, -190.23132,\n         -190.3477 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 423,\n  'fluo_channel': 0,\n  'fluorescence': array([-226.99223, -226.8239 , -223.4847 , ..., -227.83658, -243.43768,\n         -209.38123], dtype=float32),\n  'neuropil_fluorescence': array([-181.57704, -185.73428, -188.11949, ..., -181.9717 , -187.96541,\n         -181.68239], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 424,\n  'fluo_channel': 0,\n  'fluorescence': array([ -91.454865,   17.225964,  -78.30267 , ...,  -31.72153 ,\n           21.306122, -107.551216], dtype=float32),\n  'neuropil_fluorescence': array([-167.10843, -180.9191 , -183.12909, ..., -170.284  , -161.00345,\n         -160.34767], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 425,\n  'fluo_channel': 0,\n  'fluorescence': array([-209.56122, -216.58366, -237.17828, ..., -184.78351, -217.34607,\n         -210.42766], dtype=float32),\n  'neuropil_fluorescence': array([-218.85382, -201.32378, -199.46858, ..., -203.35655, -209.81148,\n         -209.53006], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 426,\n  'fluo_channel': 0,\n  'fluorescence': array([-120.33477 , -110.54728 , -110.33841 , ..., -111.03028 ,\n         -124.810646, -141.1202  ], dtype=float32),\n  'neuropil_fluorescence': array([-176.72728, -157.44545, -172.64772, ..., -195.29318, -190.98181,\n         -184.33409], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 427,\n  'fluo_channel': 0,\n  'fluorescence': array([-169.02177, -151.53221, -106.49245, ..., -167.66539, -149.22792,\n         -194.13368], dtype=float32),\n  'neuropil_fluorescence': array([-211.92778, -205.82222, -204.88889, ..., -213.08333, -209.18056,\n         -207.29306], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 428,\n  'fluo_channel': 0,\n  'fluorescence': array([-201.54318, -200.81151, -181.1888 , ..., -189.09583, -171.25842,\n         -192.73721], dtype=float32),\n  'neuropil_fluorescence': array([-230.2155 , -225.27846, -225.89589, ..., -235.95883, -226.60533,\n         -237.13318], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 429,\n  'fluo_channel': 0,\n  'fluorescence': array([ -66.38341 ,   18.603012, -104.167946, ...,  -56.38547 ,\n          -94.21545 ,  -21.715105], dtype=float32),\n  'neuropil_fluorescence': array([-147.36723, -143.36534, -138.40302, ..., -135.21657, -132.27872,\n         -131.61394], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 430,\n  'fluo_channel': 0,\n  'fluorescence': array([ -25.49545 ,  -30.037006,  -56.587273, ...,   23.022058,\n         -112.275635,  -75.31529 ], dtype=float32),\n  'neuropil_fluorescence': array([-155.8327 , -138.07034, -159.72243, ..., -150.61217, -138.47148,\n         -148.1768 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 431,\n  'fluo_channel': 0,\n  'fluorescence': array([-196.80519,  -91.04134, -133.50304, ..., -192.69626, -108.0641 ,\n         -115.81706], dtype=float32),\n  'neuropil_fluorescence': array([-200.9504 , -208.25595, -195.9246 , ..., -206.64087, -200.66866,\n         -198.96031], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 432,\n  'fluo_channel': 0,\n  'fluorescence': array([-256.14346, -222.39311, -241.84488, ..., -241.88205, -241.61223,\n         -224.99767], dtype=float32),\n  'neuropil_fluorescence': array([-229.01245, -232.79715, -219.71886, ..., -231.86833, -226.1993 ,\n         -234.69572], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 433,\n  'fluo_channel': 0,\n  'fluorescence': array([-159.50482 , -113.850006, -120.48362 , ..., -158.79013 ,\n         -178.38243 , -176.11572 ], dtype=float32),\n  'neuropil_fluorescence': array([-203.22536, -201.68169, -204.90422, ..., -206.57465, -211.89577,\n         -200.27324], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 434,\n  'fluo_channel': 0,\n  'fluorescence': array([-188.80739, -200.26163, -176.98712, ..., -192.99435, -186.65111,\n         -176.22247], dtype=float32),\n  'neuropil_fluorescence': array([-131.40486, -132.83548, -116.32475, ..., -127.54793, -129.77254,\n         -135.85837], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 435,\n  'fluo_channel': 0,\n  'fluorescence': array([ -75.80993 ,  -66.02649 , -111.053856, ...,  -77.94535 ,\n         -134.01309 , -108.169846], dtype=float32),\n  'neuropil_fluorescence': array([-212.80397, -199.97728, -206.6875 , ..., -200.90909, -200.3267 ,\n         -204.88353], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 436,\n  'fluo_channel': 0,\n  'fluorescence': array([-192.93236, -212.59502, -220.95683, ..., -206.02696, -203.90111,\n         -222.71936], dtype=float32),\n  'neuropil_fluorescence': array([-224.82812, -223.84895, -217.54688, ..., -221.81511, -214.17448,\n         -222.49219], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 437,\n  'fluo_channel': 0,\n  'fluorescence': array([-209.73438, -174.397  , -130.36421, ..., -173.41869, -168.23904,\n         -154.566  ], dtype=float32),\n  'neuropil_fluorescence': array([-185.56947, -187.05344, -185.61832, ..., -195.42595, -186.97404,\n         -184.2    ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 438,\n  'fluo_channel': 0,\n  'fluorescence': array([-168.76343, -144.07294,  -55.9982 , ..., -183.95322, -201.14365,\n         -155.68347], dtype=float32),\n  'neuropil_fluorescence': array([-192.78836, -188.05026, -191.0873 , ..., -187.78836, -190.78307,\n         -173.69048], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 439,\n  'fluo_channel': 0,\n  'fluorescence': array([-151.95831 , -122.454254,  -89.82235 , ..., -152.68565 ,\n         -145.29019 , -146.11844 ], dtype=float32),\n  'neuropil_fluorescence': array([-186.00479, -172.17746, -176.95444, ..., -174.60431, -173.94724,\n         -179.3813 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 440,\n  'fluo_channel': 0,\n  'fluorescence': array([-219.72719, -229.18758, -178.32248, ..., -238.00412, -217.20352,\n         -193.7051 ], dtype=float32),\n  'neuropil_fluorescence': array([-224.60068, -223.55838, -212.41794, ..., -231.14383, -223.84602,\n         -224.74619], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 441,\n  'fluo_channel': 0,\n  'fluorescence': array([-150.05663, -129.0988 , -101.73109, ..., -141.21692, -109.81515,\n         -165.97775], dtype=float32),\n  'neuropil_fluorescence': array([-158.84561, -166.07126, -157.07126, ..., -163.81235, -147.62946,\n         -162.78622], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 442,\n  'fluo_channel': 0,\n  'fluorescence': array([-214.40704, -217.1223 , -178.31827, ..., -211.07423, -118.41746,\n         -215.16788], dtype=float32),\n  'neuropil_fluorescence': array([-225.3009 , -222.13188, -215.97568, ..., -220.6466 , -216.62996,\n         -219.97183], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 443,\n  'fluo_channel': 0,\n  'fluorescence': array([-183.95627, -180.2993 , -172.07977, ..., -194.41673, -156.30022,\n         -164.86603], dtype=float32),\n  'neuropil_fluorescence': array([-202.86208, -211.19029, -200.58238, ..., -205.0498 , -206.31673,\n         -210.9272 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 444,\n  'fluo_channel': 0,\n  'fluorescence': array([-148.40372 ,  -82.95733 , -125.364235, ..., -103.145004,\n         -120.437325, -164.61122 ], dtype=float32),\n  'neuropil_fluorescence': array([-166.60706, -172.27415, -163.2598 , ..., -179.67624, -180.0731 ,\n         -175.2363 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 445,\n  'fluo_channel': 0,\n  'fluorescence': array([ -93.02644, -143.10074, -152.4402 , ...,  -80.11215,  123.40801,\n          -79.53259], dtype=float32),\n  'neuropil_fluorescence': array([-168.09508, -168.48239, -162.66373, ..., -171.76056, -162.97008,\n         -161.25175], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 446,\n  'fluo_channel': 0,\n  'fluorescence': array([-229.15134, -202.26715, -259.90744, ..., -236.7041 , -238.44933,\n         -242.0573 ], dtype=float32),\n  'neuropil_fluorescence': array([-177.9744 , -172.81476, -179.00752, ..., -183.86748, -176.37952,\n         -176.15512], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 447,\n  'fluo_channel': 0,\n  'fluorescence': array([-232.68686, -251.066  , -241.25217, ..., -262.11432, -246.89618,\n         -248.71188], dtype=float32),\n  'neuropil_fluorescence': array([-260.56067, -259.08197, -259.69672, ..., -266.84592, -261.26065,\n         -267.0295 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 448,\n  'fluo_channel': 0,\n  'fluorescence': array([-125.55219 , -130.17992 ,  -82.579506, ...,  -79.409676,\n         -190.53412 ,  -94.3687  ], dtype=float32),\n  'neuropil_fluorescence': array([-166.57965, -166.82341, -161.8426 , ..., -152.04031, -163.14012,\n         -155.98273], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 449,\n  'fluo_channel': 0,\n  'fluorescence': array([-209.298  , -197.74638, -188.18529, ..., -192.81071, -183.5533 ,\n         -211.58696], dtype=float32),\n  'neuropil_fluorescence': array([-220.44276, -220.25452, -218.36446, ..., -214.87651, -214.98795,\n         -214.66264], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 450,\n  'fluo_channel': 0,\n  'fluorescence': array([-145.09348 , -127.12783 ,  -56.005318, ...,  551.5911  ,\n          457.7246  ,  532.69183 ], dtype=float32),\n  'neuropil_fluorescence': array([-174.81871, -159.23685, -163.89328, ..., -153.06287, -153.32018,\n         -152.06725], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 451,\n  'fluo_channel': 0,\n  'fluorescence': array([-125.688065, -118.9065  , -107.98073 , ...,  -59.874943,\n          -64.70262 ,  -67.17591 ], dtype=float32),\n  'neuropil_fluorescence': array([-145.24121, -143.76717, -134.33836, ..., -130.0067 , -131.76717,\n         -127.19263], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 452,\n  'fluo_channel': 0,\n  'fluorescence': array([-148.0047 , -154.65585, -128.72948, ..., -164.02629, -149.81915,\n         -114.88062], dtype=float32),\n  'neuropil_fluorescence': array([-136.90208 , -116.852325, -132.80257 , ..., -114.73997 ,\n         -120.02408 , -120.914925], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 453,\n  'fluo_channel': 0,\n  'fluorescence': array([-214.61407, -144.536  , -186.42038, ..., -206.23033, -198.09537,\n         -154.07365], dtype=float32),\n  'neuropil_fluorescence': array([-206.49931, -210.30621, -206.2607 , ..., -207.3669 , -207.67725,\n         -210.04414], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 454,\n  'fluo_channel': 0,\n  'fluorescence': array([-194.0385 , -190.1019 , -178.47229, ..., -181.91052, -178.95844,\n         -193.59135], dtype=float32),\n  'neuropil_fluorescence': array([-213.21812, -205.89255, -201.81155, ..., -208.27586, -207.73938,\n         -209.4611 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 455,\n  'fluo_channel': 0,\n  'fluorescence': array([-115.84086 ,  -93.09862 , -154.5645  , ...,  -74.219215,\n         -136.75029 ,  -96.8613  ], dtype=float32),\n  'neuropil_fluorescence': array([-190.81693, -186.2982 , -183.72954, ..., -184.28294, -182.90985,\n         -177.59361], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 456,\n  'fluo_channel': 0,\n  'fluorescence': array([-202.90271, -155.05731, -207.77885, ..., -182.78027, -180.03313,\n         -138.66042], dtype=float32),\n  'neuropil_fluorescence': array([-146.96112, -150.2635 , -137.43196, ..., -142.6501 , -134.35854,\n         -134.92441], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 457,\n  'fluo_channel': 0,\n  'fluorescence': array([-175.6561  ,  -70.03457 ,  -75.27955 , ..., -171.56941 ,\n          -51.819435,  -66.36375 ], dtype=float32),\n  'neuropil_fluorescence': array([-184.28654, -158.67885, -161.3923 , ..., -174.33461, -165.2827 ,\n         -168.77884], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 458,\n  'fluo_channel': 0,\n  'fluorescence': array([-167.77596, -148.03513, -140.5758 , ..., -160.35153, -178.26512,\n         -167.02365], dtype=float32),\n  'neuropil_fluorescence': array([-180.03323, -160.25485, -161.47646, ..., -166.44044, -162.99446,\n         -171.01385], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 459,\n  'fluo_channel': 0,\n  'fluorescence': array([-183.32996, -169.81856, -180.29742, ..., -193.90848, -180.20514,\n         -168.39165], dtype=float32),\n  'neuropil_fluorescence': array([-206.03801, -198.07364, -198.89073, ..., -191.99287, -192.00238,\n         -192.15677], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 460,\n  'fluo_channel': 0,\n  'fluorescence': array([-133.70529, -154.76599, -153.23303, ..., -161.36261, -187.76561,\n         -156.71559], dtype=float32),\n  'neuropil_fluorescence': array([-175.8    , -181.35814, -169.96744, ..., -180.97209, -175.17209,\n         -181.14651], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 461,\n  'fluo_channel': 0,\n  'fluorescence': array([-185.82579, -175.06451, -178.33887, ..., -200.66164, -119.20908,\n         -174.14989], dtype=float32),\n  'neuropil_fluorescence': array([-198.45198, -184.48022, -197.65536, ..., -195.0678 , -199.32768,\n         -183.2938 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 462,\n  'fluo_channel': 0,\n  'fluorescence': array([-232.81847 , -161.05159 , -204.35268 , ..., -132.03662 ,\n         -121.840546, -164.94818 ], dtype=float32),\n  'neuropil_fluorescence': array([-202.40602, -205.32832, -206.98495, ..., -205.198  , -203.22807,\n         -204.4436 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 463,\n  'fluo_channel': 0,\n  'fluorescence': array([-191.29787, -199.49539, -204.92593, ..., -196.20348, -200.09341,\n         -181.31789], dtype=float32),\n  'neuropil_fluorescence': array([-196.36165, -193.70389, -190.02428, ..., -203.08981, -204.29854,\n         -190.7597 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 464,\n  'fluo_channel': 0,\n  'fluorescence': array([-204.88857, -211.84738, -211.3768 , ..., -200.33734, -227.56462,\n         -202.52824], dtype=float32),\n  'neuropil_fluorescence': array([-149.00938, -151.63145, -128.74413, ..., -162.15727, -144.18779,\n         -159.92958], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 465,\n  'fluo_channel': 0,\n  'fluorescence': array([308.96442  , 348.108    , 386.12448  , ...,  -1.3826265,\n          41.05864  , -18.658693 ], dtype=float32),\n  'neuropil_fluorescence': array([-148.44276, -166.84233, -148.12743, ..., -154.7365 , -146.17279,\n         -155.10152], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 466,\n  'fluo_channel': 0,\n  'fluorescence': array([-207.8099 , -177.92863, -189.82988, ..., -196.70172, -197.4327 ,\n         -202.43379], dtype=float32),\n  'neuropil_fluorescence': array([-205.47713, -186.39543, -184.5719 , ..., -194.38889, -190.7451 ,\n         -192.6013 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 467,\n  'fluo_channel': 0,\n  'fluorescence': array([-152.9646 , -198.50726, -161.03018, ..., -200.00171, -166.82115,\n         -164.35995], dtype=float32),\n  'neuropil_fluorescence': array([-195.0991 , -201.71745, -189.20415, ..., -202.58876, -203.4793 ,\n         -203.56361], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 468,\n  'fluo_channel': 0,\n  'fluorescence': array([-155.09845  ,   -9.127135 ,  -69.161476 , ...,  -89.529854 ,\n            6.9793344,   62.48194  ], dtype=float32),\n  'neuropil_fluorescence': array([-142.20815, -137.6629 , -137.42534, ..., -130.16516, -112.99095,\n         -103.76244], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 469,\n  'fluo_channel': 0,\n  'fluorescence': array([-186.90402, -181.87283, -187.2419 , ..., -202.0942 , -199.72882,\n         -175.23477], dtype=float32),\n  'neuropil_fluorescence': array([-168.42598, -168.2829 , -163.67105, ..., -169.35197, -166.8898 ,\n         -162.82402], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 470,\n  'fluo_channel': 0,\n  'fluorescence': array([-168.17119, -162.92151, -157.80447, ..., -176.5266 , -165.67159,\n         -154.25832], dtype=float32),\n  'neuropil_fluorescence': array([-169.72089, -167.23737, -169.41759, ..., -179.64835, -188.91429,\n         -181.2022 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 471,\n  'fluo_channel': 0,\n  'fluorescence': array([-187.59596, -231.49281, -182.90146, ..., -225.07019, -208.99445,\n         -190.77945], dtype=float32),\n  'neuropil_fluorescence': array([-200.04596, -200.80087, -199.07002, ..., -211.41576, -214.92122,\n         -202.98688], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 472,\n  'fluo_channel': 0,\n  'fluorescence': array([-210.41534, -220.61507, -185.81657, ..., -149.36191, -165.37082,\n         -193.17664], dtype=float32),\n  'neuropil_fluorescence': array([-211.69565, -227.78044, -215.39783, ..., -207.75217, -219.08696,\n         -209.28912], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 473,\n  'fluo_channel': 0,\n  'fluorescence': array([-210.02333, -198.87546, -203.07684, ..., -189.9469 , -217.51974,\n         -216.65666], dtype=float32),\n  'neuropil_fluorescence': array([-234.97595, -231.26854, -229.24449, ..., -232.75752, -231.38878,\n         -236.8477 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 474,\n  'fluo_channel': 0,\n  'fluorescence': array([-167.20648, -249.21448, -184.51918, ...,  -74.54742,  -59.37063,\n         -112.37874], dtype=float32),\n  'neuropil_fluorescence': array([-126.666664, -135.53107 , -127.05367 , ...,  -90.75141 ,\n          -98.42655 ,  -94.38418 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 475,\n  'fluo_channel': 0,\n  'fluorescence': array([-228.49295, -196.39926, -203.22469, ..., -219.00792, -215.61978,\n         -200.74014], dtype=float32),\n  'neuropil_fluorescence': array([-191.05939, -204.54156, -206.06888, ..., -212.18289, -205.6437 ,\n         -204.5772 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 476,\n  'fluo_channel': 0,\n  'fluorescence': array([ 28.984934 ,  -1.0991791, -13.616669 , ...,  76.723366 ,\n         -27.438026 ,  22.416391 ], dtype=float32),\n  'neuropil_fluorescence': array([-146.73279, -142.3719 , -137.78513, ..., -142.7989 , -144.21487,\n         -157.74931], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 477,\n  'fluo_channel': 0,\n  'fluorescence': array([-29.971384 , -15.742142 ,   9.90296  , ..., -11.795236 ,\n           4.8119125,  38.314114 ], dtype=float32),\n  'neuropil_fluorescence': array([-117.77358 , -102.646225, -106.40094 , ...,  -95.4434  ,\n         -100.73113 , -102.09906 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 478,\n  'fluo_channel': 0,\n  'fluorescence': array([-101.6576  , -124.58423 , -134.10764 , ..., -141.01654 ,\n          -99.60715 ,  -86.116776], dtype=float32),\n  'neuropil_fluorescence': array([-159.82033, -149.95271, -138.1773 , ..., -143.81796, -158.38062,\n         -166.61229], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 479,\n  'fluo_channel': 0,\n  'fluorescence': array([-186.44289, -128.49847, -164.54091, ..., -177.00424, -169.7008 ,\n         -141.18816], dtype=float32),\n  'neuropil_fluorescence': array([-160.52   , -159.16444, -163.05112, ..., -159.72888, -163.48889,\n         -160.44444], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 480,\n  'fluo_channel': 0,\n  'fluorescence': array([ -54.786404, -127.62058 ,   48.94745 , ..., -184.53503 ,\n          -70.86528 , -108.55941 ], dtype=float32),\n  'neuropil_fluorescence': array([-165.20605, -160.95555, -148.15959, ..., -163.65454, -157.89899,\n         -164.7293 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 481,\n  'fluo_channel': 0,\n  'fluorescence': array([-232.60165, -228.12955, -221.7841 , ..., -235.15373, -240.69138,\n         -228.6301 ], dtype=float32),\n  'neuropil_fluorescence': array([-247.99492, -246.02034, -243.73051, ..., -251.85933, -248.79152,\n         -246.71864], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 482,\n  'fluo_channel': 0,\n  'fluorescence': array([-120.53899, -104.11732,  -92.16791, ..., -102.74199,  -70.28321,\n          -78.40008], dtype=float32),\n  'neuropil_fluorescence': array([-124.63008, -117.64838, -116.24797, ..., -111.14838, -124.54269,\n         -130.50203], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 483,\n  'fluo_channel': 0,\n  'fluorescence': array([ -73.7276 , -132.09334, -112.99952, ..., -144.86702, -128.92572,\n          -75.41748], dtype=float32),\n  'neuropil_fluorescence': array([-192.45677, -186.47694, -190.97983, ..., -202.8588 , -194.72478,\n         -203.66138], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 484,\n  'fluo_channel': 0,\n  'fluorescence': array([-226.99257, -191.2677 , -190.78563, ..., -204.19762, -226.65987,\n         -202.30463], dtype=float32),\n  'neuropil_fluorescence': array([-184.77374, -180.85754, -199.59218, ..., -194.72067, -198.69273,\n         -197.72626], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 485,\n  'fluo_channel': 0,\n  'fluorescence': array([-116.46921 ,  -93.0442  ,  -49.416065, ..., -119.940956,\n         -114.16649 , -115.034775], dtype=float32),\n  'neuropil_fluorescence': array([-116.44855, -125.06213, -115.06602, ..., -143.45049, -134.40582,\n         -129.45242], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 486,\n  'fluo_channel': 0,\n  'fluorescence': array([-159.20778, -167.05565, -161.59927, ..., -169.2371 , -160.58638,\n         -166.7194 ], dtype=float32),\n  'neuropil_fluorescence': array([-174.73177, -194.15886, -200.125  , ..., -186.61458, -196.00781,\n         -192.21875], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 487,\n  'fluo_channel': 0,\n  'fluorescence': array([-209.5971  , -174.47896 , -226.22699 , ..., -114.023674,\n         -154.21219 , -150.53429 ], dtype=float32),\n  'neuropil_fluorescence': array([-228.18303, -219.62396, -224.26622, ..., -217.93011, -223.9817 ,\n         -225.33112], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 488,\n  'fluo_channel': 0,\n  'fluorescence': array([ -75.64674 , -122.46632 , -132.23198 , ..., -190.21263 ,\n         -111.737854, -111.658226], dtype=float32),\n  'neuropil_fluorescence': array([-208.0669 , -207.24014, -208.11664, ..., -212.15437, -210.36363,\n         -213.3825 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 489,\n  'fluo_channel': 0,\n  'fluorescence': array([-170.61931, -169.01355, -132.11082, ..., -168.83665, -182.55354,\n         -197.23273], dtype=float32),\n  'neuropil_fluorescence': array([-219.28651, -206.84691, -208.55478, ..., -210.4972 , -212.9073 ,\n         -208.3764 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 490,\n  'fluo_channel': 0,\n  'fluorescence': array([-132.35394 ,  -73.69647 ,  -87.108116, ..., -196.63466 ,\n         -140.55165 , -124.21653 ], dtype=float32),\n  'neuropil_fluorescence': array([-135.27556, -149.99777, -132.5    , ..., -140.17334, -134.14444,\n         -150.88667], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 491,\n  'fluo_channel': 0,\n  'fluorescence': array([-138.44745, -166.78287, -141.41502, ..., -162.1189 , -161.81769,\n         -201.26924], dtype=float32),\n  'neuropil_fluorescence': array([-116.55617, -135.09863, -130.4959 , ..., -144.8548 , -119.61918,\n         -126.7863 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 492,\n  'fluo_channel': 0,\n  'fluorescence': array([ -55.597683, -162.44423 ,  -60.949318, ...,  -67.30129 ,\n          -19.008497, -109.67676 ], dtype=float32),\n  'neuropil_fluorescence': array([-124.08784, -117.61712, -104.06982, ..., -115.54054, -130.32433,\n         -127.28153], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 493,\n  'fluo_channel': 0,\n  'fluorescence': array([-175.14125, -152.25186, -199.20296, ..., -190.69583, -184.51013,\n         -174.16953], dtype=float32),\n  'neuropil_fluorescence': array([-174.67078, -163.9856 , -178.34773, ..., -176.58847, -177.54938,\n         -164.72427], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 494,\n  'fluo_channel': 0,\n  'fluorescence': array([-165.96935, -233.53612, -222.25731, ..., -224.84271, -218.7546 ,\n         -229.23827], dtype=float32),\n  'neuropil_fluorescence': array([-240.31436, -248.11664, -240.93315, ..., -243.18208, -239.17496,\n         -251.30014], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 495,\n  'fluo_channel': 0,\n  'fluorescence': array([-110.53951 , -141.78786 ,  -92.575554, ..., -122.37147 ,\n         -105.04809 ,  -97.8188  ], dtype=float32),\n  'neuropil_fluorescence': array([-141.75041, -136.04187, -134.70854, ..., -138.98325, -144.82915,\n         -142.03015], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 496,\n  'fluo_channel': 0,\n  'fluorescence': array([-127.642166, -128.70795 , -138.22554 , ..., -150.12933 ,\n         -172.36292 , -145.95795 ], dtype=float32),\n  'neuropil_fluorescence': array([-169.644  , -166.50568, -169.79819, ..., -189.90475, -186.21996,\n         -187.33107], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 497,\n  'fluo_channel': 0,\n  'fluorescence': array([ -89.14438 ,  -85.34381 ,  -55.271065, ...,  -96.12219 ,\n         -105.79715 , -160.30495 ], dtype=float32),\n  'neuropil_fluorescence': array([-132.48305, -140.58757, -132.89265, ..., -129.35876, -127.41525,\n         -129.5226 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 498,\n  'fluo_channel': 0,\n  'fluorescence': array([-208.79677, -249.0262 , -233.36385, ..., -225.41702, -246.48756,\n         -215.86842], dtype=float32),\n  'neuropil_fluorescence': array([-227.41364, -233.62424, -227.40909, ..., -236.34848, -236.67122,\n         -230.34697], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 499,\n  'fluo_channel': 0,\n  'fluorescence': array([-231.62776, -242.03178, -225.46184, ..., -227.85226, -221.12411,\n         -239.65993], dtype=float32),\n  'neuropil_fluorescence': array([-205.06618, -198.86275, -200.41667, ..., -195.15932, -208.26715,\n         -199.7451 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 500,\n  'fluo_channel': 0,\n  'fluorescence': array([-156.29178, -145.02997, -193.72772, ..., -194.06938, -146.16693,\n          -85.16331], dtype=float32),\n  'neuropil_fluorescence': array([-184.1757 , -185.67323, -184.26108, ..., -182.66338, -180.7422 ,\n         -174.72578], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 501,\n  'fluo_channel': 0,\n  'fluorescence': array([-143.15448, -110.65832,  -97.88545, ..., -131.20332, -148.26883,\n         -108.52516], dtype=float32),\n  'neuropil_fluorescence': array([-167.21854, -170.22552, -171.53146, ..., -157.73427, -161.03847,\n         -150.98251], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 502,\n  'fluo_channel': 0,\n  'fluorescence': array([ -18.690893,   12.603642,   11.411709, ...,  -86.408615,\n          -46.8074  , -105.64448 ], dtype=float32),\n  'neuropil_fluorescence': array([-153.94217, -152.60448, -159.9944 , ..., -180.23694, -171.82649,\n         -164.28731], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 503,\n  'fluo_channel': 0,\n  'fluorescence': array([ -98.77332 ,  -86.12344 ,  -80.662796, ..., -113.62176 ,\n          -74.086876,  -83.49683 ], dtype=float32),\n  'neuropil_fluorescence': array([-121.752335, -121.294395,  -93.100464, ..., -101.03271 ,\n         -104.29673 ,  -90.90888 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 504,\n  'fluo_channel': 0,\n  'fluorescence': array([-142.83578 , -131.44498 ,  -67.59724 , ...,  108.263336,\n          253.60089 ,   77.613266], dtype=float32),\n  'neuropil_fluorescence': array([-168.74132, -171.42744, -173.50946, ..., -156.55836, -168.17351,\n         -158.95111], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 505,\n  'fluo_channel': 0,\n  'fluorescence': array([-181.7328 , -203.64917, -132.5457 , ..., -220.72333, -175.32893,\n         -179.72035], dtype=float32),\n  'neuropil_fluorescence': array([-195.81096, -193.44931, -198.63014, ..., -197.30411, -196.27672,\n         -194.1589 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 506,\n  'fluo_channel': 0,\n  'fluorescence': array([-145.2696 ,  -86.25509, -109.26438, ..., -145.08075, -161.74548,\n         -147.10611], dtype=float32),\n  'neuropil_fluorescence': array([-206.86028, -182.2036 , -196.5509 , ..., -208.91217, -205.1996 ,\n         -198.59082], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 507,\n  'fluo_channel': 0,\n  'fluorescence': array([-220.05048 , -175.41925 ,  -99.316505, ..., -198.74452 ,\n         -163.14516 , -102.3129  ], dtype=float32),\n  'neuropil_fluorescence': array([-208.42352, -198.12   , -198.02118, ..., -199.30353, -200.05647,\n         -196.14824], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 508,\n  'fluo_channel': 0,\n  'fluorescence': array([-135.6576  , -235.59743 , -206.60449 , ..., -137.46104 ,\n         -100.007225, -151.17299 ], dtype=float32),\n  'neuropil_fluorescence': array([-188.68651, -186.54167, -185.8512 , ..., -179.28374, -190.2381 ,\n         -188.94246], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 509,\n  'fluo_channel': 0,\n  'fluorescence': array([-108.84623, -140.22105, -159.40723, ..., -113.21242,  -93.98938,\n         -161.95027], dtype=float32),\n  'neuropil_fluorescence': array([-214.9311 , -200.63777, -208.6311 , ..., -208.41333, -209.13777,\n         -208.95111], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 510,\n  'fluo_channel': 0,\n  'fluorescence': array([-211.5119 , -197.08817, -196.32005, ..., -199.54265, -182.50406,\n         -203.34297], dtype=float32),\n  'neuropil_fluorescence': array([-212.42747, -210.57253, -207.03087, ..., -211.375  , -213.8534 ,\n         -215.66975], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 511,\n  'fluo_channel': 0,\n  'fluorescence': array([ -61.98478,   44.87227,  -95.36757, ...,  -59.06252, -173.94984,\n         -128.75465], dtype=float32),\n  'neuropil_fluorescence': array([-160.23836, -167.47672, -160.80273, ..., -168.79726, -172.70137,\n         -185.61917], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 512,\n  'fluo_channel': 0,\n  'fluorescence': array([-172.50813, -160.82056,  -57.12699, ..., -190.18481, -127.56835,\n         -109.4108 ], dtype=float32),\n  'neuropil_fluorescence': array([-186.78226, -187.36896, -181.31451, ..., -160.33467, -188.32259,\n         -178.7379 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 513,\n  'fluo_channel': 0,\n  'fluorescence': array([-155.66602, -148.20859, -152.89204, ..., -184.54861, -153.31349,\n         -162.78317], dtype=float32),\n  'neuropil_fluorescence': array([-191.38182, -179.2078 , -180.85585, ..., -185.25455, -181.24156,\n         -187.57793], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 514,\n  'fluo_channel': 0,\n  'fluorescence': array([-115.37093, -140.6325 , -121.7812 , ..., -152.5386 , -148.99995,\n         -145.0382 ], dtype=float32),\n  'neuropil_fluorescence': array([-177.14609, -169.96297, -167.61934, ..., -170.0679 , -165.47325,\n         -182.30658], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 515,\n  'fluo_channel': 0,\n  'fluorescence': array([ -47.320652, -114.80528 ,  -99.884735, ...,  -86.22997 ,\n           90.93272 , -142.86899 ], dtype=float32),\n  'neuropil_fluorescence': array([-150.14114 , -135.11961 , -153.51196 , ..., -143.22488 ,\n         -142.59808 , -114.452156], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 516,\n  'fluo_channel': 0,\n  'fluorescence': array([-165.94592  ,  -79.93453  , -117.75155  , ...,   -1.3437271,\n          -62.617283 ,  107.83372  ], dtype=float32),\n  'neuropil_fluorescence': array([-160.97096, -163.3539 , -147.3902 , ..., -162.32123, -152.94556,\n         -152.98729], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 517,\n  'fluo_channel': 0,\n  'fluorescence': array([-153.36664 , -127.871666, -146.59627 , ..., -117.35949 ,\n         -144.02045 , -134.07059 ], dtype=float32),\n  'neuropil_fluorescence': array([-137.7874 , -139.91602, -144.2336 , ..., -150.17323, -152.98163,\n         -157.51181], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 518,\n  'fluo_channel': 0,\n  'fluorescence': array([-220.60332, -189.44614, -137.39494, ..., -206.14967, -137.9595 ,\n         -167.73245], dtype=float32),\n  'neuropil_fluorescence': array([-212.6845 , -206.03476, -206.55481, ..., -205.1377 , -210.4492 ,\n         -207.90776], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 519,\n  'fluo_channel': 0,\n  'fluorescence': array([-180.09671, -141.62106, -163.02763, ..., -174.50914, -192.33499,\n         -183.50043], dtype=float32),\n  'neuropil_fluorescence': array([-184.17268, -182.21391, -177.34793, ..., -184.34793, -186.5129 ,\n         -182.81444], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 520,\n  'fluo_channel': 0,\n  'fluorescence': array([ -43.94974 , -122.910675, -151.89229 , ...,  -46.30739 ,\n         -132.63757 , -182.69283 ], dtype=float32),\n  'neuropil_fluorescence': array([-181.68971, -189.87206, -180.7397 , ..., -176.05147, -173.00589,\n         -172.94118], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 521,\n  'fluo_channel': 0,\n  'fluorescence': array([-170.9871 , -143.22832, -170.28523, ..., -178.7204 , -162.54895,\n         -104.8789 ], dtype=float32),\n  'neuropil_fluorescence': array([-139.95528, -148.034  , -136.44008, ..., -150.7585 , -141.07513,\n         -140.99106], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 522,\n  'fluo_channel': 0,\n  'fluorescence': array([-138.68098, -125.21901, -158.54729, ..., -142.58626, -163.87659,\n         -128.5566 ], dtype=float32),\n  'neuropil_fluorescence': array([-155.62831, -157.19974, -154.31746, ..., -159.72223, -148.28969,\n         -149.14285], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 523,\n  'fluo_channel': 0,\n  'fluorescence': array([  47.755825,  166.30376 ,  171.66351 , ...,  -41.946747,\n         -175.5734  ,  -94.51141 ], dtype=float32),\n  'neuropil_fluorescence': array([-145.20734, -151.27522, -147.16147, ..., -155.36147, -135.25505,\n         -133.66422], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 524,\n  'fluo_channel': 0,\n  'fluorescence': array([-225.09055, -212.11588, -220.13098, ..., -202.13922, -233.62633,\n         -234.10329], dtype=float32),\n  'neuropil_fluorescence': array([-239.51991, -230.92506, -229.5246 , ..., -230.94614, -224.48009,\n         -232.32085], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 525,\n  'fluo_channel': 0,\n  'fluorescence': array([-158.89307, -143.81859, -188.9979 , ..., -145.65117, -201.2701 ,\n         -160.41261], dtype=float32),\n  'neuropil_fluorescence': array([-218.54915, -223.77628, -222.31526, ..., -221.46101, -220.35423,\n         -220.47627], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 526,\n  'fluo_channel': 0,\n  'fluorescence': array([-143.45827, -123.77823, -173.83246, ..., -190.4291 , -156.04434,\n         -151.72496], dtype=float32),\n  'neuropil_fluorescence': array([-178.71394, -178.74573, -184.57701, ..., -183.58557, -181.08313,\n         -183.50978], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 527,\n  'fluo_channel': 0,\n  'fluorescence': array([ -62.255676, -105.90172 , -117.62154 , ..., -130.20885 ,\n         -107.06215 , -103.136604], dtype=float32),\n  'neuropil_fluorescence': array([-91.9075, -93.5025, -75.3975, ..., -98.2725, -86.9525, -87.225 ],\n        dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 528,\n  'fluo_channel': 0,\n  'fluorescence': array([-287.31393, -275.40878, -283.41125, ..., -280.2745 , -285.59454,\n         -285.6796 ], dtype=float32),\n  'neuropil_fluorescence': array([-279.62924, -279.8289 , -278.91623, ..., -284.05704, -283.2549 ,\n         -282.33334], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 529,\n  'fluo_channel': 0,\n  'fluorescence': array([-49.525997, -58.59554 , -34.52679 , ..., -50.424423, -45.26061 ,\n         -46.434113], dtype=float32),\n  'neuropil_fluorescence': array([-144.11084, -135.29082, -136.24196, ..., -140.38022, -140.73183,\n         -148.77235], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 530,\n  'fluo_channel': 0,\n  'fluorescence': array([  12.542957,  -36.963398,  -76.89895 , ...,  -29.857594,\n         -114.60725 ,  -22.17474 ], dtype=float32),\n  'neuropil_fluorescence': array([-140.83368 , -131.17047 , -119.68399 , ..., -121.970894,\n         -134.35966 , -121.30769 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 531,\n  'fluo_channel': 0,\n  'fluorescence': array([ -56.433537,  -47.811287,  -86.26508 , ...,   35.078697,\n         -161.76619 ,  -93.98586 ], dtype=float32),\n  'neuropil_fluorescence': array([-151.4921 , -155.91699, -144.50395, ..., -162.1581 , -160.22134,\n         -153.68182], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 532,\n  'fluo_channel': 0,\n  'fluorescence': array([-143.39577, -100.33398, -141.6457 , ..., -126.64821, -121.11372,\n         -161.70067], dtype=float32),\n  'neuropil_fluorescence': array([-174.23643, -162.846  , -165.72668, ..., -166.53362, -159.44252,\n         -169.07158], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 533,\n  'fluo_channel': 0,\n  'fluorescence': array([-242.87793, -267.17117, -214.03821, ..., -228.11256, -229.23729,\n         -201.67006], dtype=float32),\n  'neuropil_fluorescence': array([-222.89743, -234.92877, -221.4131 , ..., -217.7151 , -226.55841,\n         -215.05698], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 534,\n  'fluo_channel': 0,\n  'fluorescence': array([-161.4461  , -170.72621 , -119.67396 , ...,  -26.755663,\n          -74.60212 , -150.73999 ], dtype=float32),\n  'neuropil_fluorescence': array([-167.56711, -164.3327 , -164.76749, ..., -149.80151, -143.4121 ,\n         -146.82608], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 535,\n  'fluo_channel': 0,\n  'fluorescence': array([-114.2842 , -151.16191, -219.0966 , ..., -217.22469, -122.65121,\n          -88.81509], dtype=float32),\n  'neuropil_fluorescence': array([-165.97533, -159.70065, -172.4671 , ..., -160.86513, -157.84868,\n         -165.96382], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 536,\n  'fluo_channel': 0,\n  'fluorescence': array([-153.56506, -183.31206, -279.19153, ..., -269.00027, -287.27115,\n         -121.66086], dtype=float32),\n  'neuropil_fluorescence': array([-215.37314, -207.99864, -209.99728, ..., -213.39078, -217.34328,\n         -220.05156], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 537,\n  'fluo_channel': 0,\n  'fluorescence': array([-253.71167, -255.70235, -250.18416, ..., -247.47234, -237.81801,\n         -252.95547], dtype=float32),\n  'neuropil_fluorescence': array([-256.0431 , -252.61678, -258.75735, ..., -252.26758, -252.70975,\n         -253.39229], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 538,\n  'fluo_channel': 0,\n  'fluorescence': array([ -86.95097, -105.85797, -187.73451, ..., -187.94287, -181.48749,\n         -177.94325], dtype=float32),\n  'neuropil_fluorescence': array([-196.12688, -196.75793, -188.06177, ..., -189.07011, -191.37897,\n         -193.74124], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 539,\n  'fluo_channel': 0,\n  'fluorescence': array([-126.873436,  -86.43134 ,  -72.007095, ...,  -84.74353 ,\n         -111.2763  , -133.24501 ], dtype=float32),\n  'neuropil_fluorescence': array([-164.82526, -167.46402, -160.91043, ..., -171.90161, -166.45227,\n         -166.8047 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 540,\n  'fluo_channel': 0,\n  'fluorescence': array([-228.62799 , -196.12459 , -184.99396 , ...,  -37.014675,\n          -98.91914 ,  -81.64121 ], dtype=float32),\n  'neuropil_fluorescence': array([-194.97649, -188.8065 , -188.77577, ..., -187.35262, -189.73056,\n         -194.34177], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 541,\n  'fluo_channel': 0,\n  'fluorescence': array([-177.9623 , -160.6928 , -127.05546, ..., -130.63223, -165.89067,\n         -175.84692], dtype=float32),\n  'neuropil_fluorescence': array([-164.41052, -164.61894, -160.37685, ..., -206.25262, -207.98526,\n         -205.16211], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 542,\n  'fluo_channel': 0,\n  'fluorescence': array([-221.71143, -209.39975, -199.1583 , ..., -189.51752, -204.43837,\n         -200.08612], dtype=float32),\n  'neuropil_fluorescence': array([-221.23755, -217.48671, -226.28737, ..., -216.16113, -213.88206,\n         -209.51163], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 543,\n  'fluo_channel': 0,\n  'fluorescence': array([-171.85432, -145.19553,  -82.00642, ..., -175.79854, -169.03569,\n         -169.11906], dtype=float32),\n  'neuropil_fluorescence': array([-150.0791 , -151.59322, -150.02637, ..., -168.47081, -161.44444,\n         -149.6629 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 544,\n  'fluo_channel': 0,\n  'fluorescence': array([-118.653694, -117.31345 ,  -18.84646 , ..., -143.72478 ,\n           17.264858,  -83.22436 ], dtype=float32),\n  'neuropil_fluorescence': array([-188.54958, -172.00284, -164.02266, ..., -188.78754, -167.78754,\n         -188.31445], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 545,\n  'fluo_channel': 0,\n  'fluorescence': array([-184.13339, -211.69044, -152.38359, ..., -216.3457 , -263.74875,\n         -188.29155], dtype=float32),\n  'neuropil_fluorescence': array([-211.81897, -208.25517, -210.75   , ..., -206.23103, -204.81207,\n         -202.3    ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 546,\n  'fluo_channel': 0,\n  'fluorescence': array([-110.70571, -123.13528, -132.87994, ..., -176.70882,  -98.03729,\n         -110.37075], dtype=float32),\n  'neuropil_fluorescence': array([-155.30412, -136.94846, -149.54639, ..., -154.1366 , -157.51804,\n         -152.58247], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 547,\n  'fluo_channel': 0,\n  'fluorescence': array([-190.96922, -209.99136, -132.22467, ..., -153.05588, -162.86874,\n         -177.58585], dtype=float32),\n  'neuropil_fluorescence': array([-190.6368 , -184.09277, -194.13365, ..., -203.31761, -195.86478,\n         -193.3522 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 548,\n  'fluo_channel': 0,\n  'fluorescence': array([-249.93874, -245.34007, -264.79205, ..., -239.2925 , -234.01068,\n         -257.39658], dtype=float32),\n  'neuropil_fluorescence': array([-243.39432, -236.98224, -238.82771, ..., -242.03908, -238.00888,\n         -241.01599], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 549,\n  'fluo_channel': 0,\n  'fluorescence': array([ -37.910408,  -84.894264, -107.61679 , ..., -123.54814 ,\n         -160.9798  ,  -84.482445], dtype=float32),\n  'neuropil_fluorescence': array([-114.24585, -120.37209, -116.36711, ..., -111.04485, -118.53821,\n         -117.55482], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 550,\n  'fluo_channel': 0,\n  'fluorescence': array([-202.38832, -227.87099, -207.01523, ..., -207.27673, -218.4409 ,\n         -210.34465], dtype=float32),\n  'neuropil_fluorescence': array([-231.90332, -236.61327, -240.44199, ..., -237.91989, -240.3978 ,\n         -243.85359], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 551,\n  'fluo_channel': 0,\n  'fluorescence': array([  -3.0399888,  -14.041535 , -155.91393  , ...,  -79.93719  ,\n          -76.23764  ,    4.9871   ], dtype=float32),\n  'neuropil_fluorescence': array([-127.186  , -122.78556, -128.79869, ..., -122.70022, -129.37637,\n         -115.01313], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 552,\n  'fluo_channel': 0,\n  'fluorescence': array([-163.37823, -224.30922, -219.13   , ..., -156.45615, -107.95183,\n         -169.0791 ], dtype=float32),\n  'neuropil_fluorescence': array([-206.58209, -198.07675, -196.03625, ..., -205.16205, -202.39873,\n         -202.17697], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 553,\n  'fluo_channel': 0,\n  'fluorescence': array([-249.66472, -245.5032 , -234.01146, ..., -241.71051, -253.45229,\n         -243.4325 ], dtype=float32),\n  'neuropil_fluorescence': array([-237.55113, -234.37782, -230.06065, ..., -241.53726, -238.06065,\n         -241.86308], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 554,\n  'fluo_channel': 0,\n  'fluorescence': array([-137.4914 , -202.3104 , -245.14485, ..., -210.05687, -219.46986,\n         -199.86444], dtype=float32),\n  'neuropil_fluorescence': array([-207.47858, -210.42143, -206.14821, ..., -206.3    , -203.20357,\n         -200.04465], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 555,\n  'fluo_channel': 0,\n  'fluorescence': array([ -95.476524, -110.00233 ,  -41.91704 , ..., -149.5515  ,\n          -77.99357 , -135.2595  ], dtype=float32),\n  'neuropil_fluorescence': array([-176.99643, -180.56964, -172.00893, ..., -171.18214, -179.26071,\n         -178.34465], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 556,\n  'fluo_channel': 0,\n  'fluorescence': array([-227.99744, -228.82188, -210.09142, ..., -223.43521, -231.93602,\n         -249.53941], dtype=float32),\n  'neuropil_fluorescence': array([-203.8361 , -206.03563, -214.44418, ..., -227.09264, -222.73634,\n         -221.84323], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 557,\n  'fluo_channel': 0,\n  'fluorescence': array([-232.66548, -235.95822, -227.62662, ..., -241.88002, -226.00444,\n         -248.00627], dtype=float32),\n  'neuropil_fluorescence': array([-248.79944, -239.50847, -238.6243 , ..., -238.77684, -240.58475,\n         -240.13841], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 558,\n  'fluo_channel': 0,\n  'fluorescence': array([-209.53543, -217.87866, -229.45412, ..., -207.16847, -213.16402,\n         -205.9169 ], dtype=float32),\n  'neuropil_fluorescence': array([-195.18524, -199.26628, -201.33574, ..., -197.19392, -197.53111,\n         -191.79016], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 559,\n  'fluo_channel': 0,\n  'fluorescence': array([-151.50632 ,  -63.789116,  -16.159037, ..., -173.18304 ,\n         -179.38364 ,  -69.46528 ], dtype=float32),\n  'neuropil_fluorescence': array([-132.96385, -133.28313, -136.99599, ..., -136.48193, -132.46385,\n         -144.69077], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 560,\n  'fluo_channel': 0,\n  'fluorescence': array([-128.53151   , -179.24788   , -112.41535   , ..., -133.68535   ,\n          -93.753975  ,   -0.95390075], dtype=float32),\n  'neuropil_fluorescence': array([-155.47165, -160.11111, -153.10658, ..., -141.72336, -147.10884,\n         -139.48073], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 561,\n  'fluo_channel': 0,\n  'fluorescence': array([-153.28755 , -139.40656 ,  -11.076379, ..., -143.16704 ,\n         -104.04838 , -133.08228 ], dtype=float32),\n  'neuropil_fluorescence': array([-217.83115, -212.8195 , -217.86609, ..., -216.8952 , -208.34644,\n         -216.54585], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 562,\n  'fluo_channel': 0,\n  'fluorescence': array([-246.22426, -260.3966 , -268.77795, ..., -268.6744 , -270.59332,\n         -243.79015], dtype=float32),\n  'neuropil_fluorescence': array([-263.29224, -250.40533, -249.2732 , ..., -259.10037, -256.7268 ,\n         -263.5235 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 563,\n  'fluo_channel': 0,\n  'fluorescence': array([-179.15918 , -203.81586 , -179.19844 , ..., -108.440926,\n         -179.39555 , -111.330536], dtype=float32),\n  'neuropil_fluorescence': array([-196.69853, -196.84727, -192.58832, ..., -205.90306, -201.27225,\n         -200.75565], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 564,\n  'fluo_channel': 0,\n  'fluorescence': array([-104.46077, -120.6835 , -144.33879, ..., -134.7998 , -131.45305,\n         -138.14069], dtype=float32),\n  'neuropil_fluorescence': array([-185.51846, -185.22017, -186.92613, ..., -176.38779, -186.25284,\n         -181.07812], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 565,\n  'fluo_channel': 0,\n  'fluorescence': array([-170.94618, -196.31499, -180.0141 , ..., -163.24794, -152.26192,\n         -172.80025], dtype=float32),\n  'neuropil_fluorescence': array([-216.461  , -210.68652, -212.74751, ..., -213.08511, -209.96738,\n         -206.19148], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 566,\n  'fluo_channel': 0,\n  'fluorescence': array([-124.73835 ,  -89.329094, -225.9121  , ..., -163.93227 ,\n         -165.53444 , -174.448   ], dtype=float32),\n  'neuropil_fluorescence': array([-173.06621, -165.16469, -173.28862, ..., -182.51103, -166.58405,\n         -172.02547], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 567,\n  'fluo_channel': 0,\n  'fluorescence': array([-249.35011, -227.50513, -257.81094, ..., -268.02094, -256.21655,\n         -256.72644], dtype=float32),\n  'neuropil_fluorescence': array([-254.53625, -254.0985 , -255.37346, ..., -253.01642, -253.12038,\n         -254.6539 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 568,\n  'fluo_channel': 0,\n  'fluorescence': array([-181.82007, -191.49445, -197.1931 , ..., -184.68832, -199.79988,\n         -166.51738], dtype=float32),\n  'neuropil_fluorescence': array([-163.01067, -169.59734, -179.176  , ..., -161.45334, -171.02133,\n         -178.01866], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 569,\n  'fluo_channel': 0,\n  'fluorescence': array([ -26.463896, -106.440254,  -32.48034 , ...,    5.7883  ,\n         -100.477455, -172.21754 ], dtype=float32),\n  'neuropil_fluorescence': array([-132.85028, -141.86723, -150.19774, ..., -166.53813, -155.05084,\n         -148.1921 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 570,\n  'fluo_channel': 0,\n  'fluorescence': array([ -64.09688, -126.46384, -141.05531, ..., -114.39621, -167.09659,\n         -153.70471], dtype=float32),\n  'neuropil_fluorescence': array([-182.38872, -188.19907, -185.     , ..., -182.74922, -176.46082,\n         -180.03134], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 571,\n  'fluo_channel': 0,\n  'fluorescence': array([-131.71439 ,   -8.910035,  -99.49104 , ..., -149.1056  ,\n          -75.86514 ,  109.96895 ], dtype=float32),\n  'neuropil_fluorescence': array([-197.55919, -194.69183, -194.94286, ..., -177.36734, -187.91632,\n         -192.17346], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 572,\n  'fluo_channel': 0,\n  'fluorescence': array([ -81.33411 ,  -78.36284 , -123.86353 , ...,  -36.3095  ,\n          -87.763466,  -92.43172 ], dtype=float32),\n  'neuropil_fluorescence': array([-193.8835 , -189.21198, -184.63431, ..., -188.48221, -192.36084,\n         -192.85275], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 573,\n  'fluo_channel': 0,\n  'fluorescence': array([ 18.462044 , -19.7913   ,  -9.831435 , ...,  55.852894 ,\n          36.61709  ,   0.2877335], dtype=float32),\n  'neuropil_fluorescence': array([-161.47034, -156.97363, -159.21758, ..., -170.37802, -172.32967,\n         -158.58022], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 574,\n  'fluo_channel': 0,\n  'fluorescence': array([-140.0636  , -135.65575 ,  -85.77244 , ..., -164.92834 ,\n         -125.007324, -157.81044 ], dtype=float32),\n  'neuropil_fluorescence': array([-162.92572, -161.72826, -152.53442, ..., -165.48732, -159.58696,\n         -148.81885], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 575,\n  'fluo_channel': 0,\n  'fluorescence': array([-222.23636, -220.56044, -263.47498, ..., -199.32524, -213.94649,\n         -227.5983 ], dtype=float32),\n  'neuropil_fluorescence': array([-256.04877, -258.9846 , -259.41592, ..., -255.54044, -256.93582,\n         -258.6714 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 576,\n  'fluo_channel': 0,\n  'fluorescence': array([ -92.55839 , -110.98308 ,  -38.562107, ..., -144.47302 ,\n         -208.00993 , -124.25516 ], dtype=float32),\n  'neuropil_fluorescence': array([-185.84091, -181.92694, -181.5974 , ..., -185.94806, -190.5065 ,\n         -176.2987 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 577,\n  'fluo_channel': 0,\n  'fluorescence': array([-146.02347 ,  -20.79377 ,  -27.696716, ...,  -72.44119 ,\n          -99.07663 , -118.838684], dtype=float32),\n  'neuropil_fluorescence': array([-159.4827 , -157.39209, -158.24876, ..., -154.4514 , -146.4794 ,\n         -147.30148], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 578,\n  'fluo_channel': 0,\n  'fluorescence': array([-208.76208, -198.22762, -203.00621, ..., -163.58134, -196.61818,\n         -186.65865], dtype=float32),\n  'neuropil_fluorescence': array([-199.81912, -195.21188, -203.5142 , ..., -194.41861, -200.21448,\n         -187.23514], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 579,\n  'fluo_channel': 0,\n  'fluorescence': array([-131.5382  , -109.51086 , -122.833984, ..., -123.95784 ,\n          -71.98564 , -129.43845 ], dtype=float32),\n  'neuropil_fluorescence': array([-204.04524, -213.62857, -203.12857, ..., -196.17857, -197.35477,\n         -190.67143], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 580,\n  'fluo_channel': 0,\n  'fluorescence': array([-73.240555 ,  44.644047 ,  34.71355  , ...,  -4.303959 ,\n          15.7045   ,   3.5981908], dtype=float32),\n  'neuropil_fluorescence': array([-136.3758 , -133.92145, -119.12739, ..., -125.64968, -132.92357,\n         -136.58174], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 581,\n  'fluo_channel': 0,\n  'fluorescence': array([-144.1496  , -165.7432  ,  -77.24269 , ..., -120.67213 ,\n         -130.51585 ,  -78.694244], dtype=float32),\n  'neuropil_fluorescence': array([-132.4989  , -122.47462 , -122.35541 , ..., -123.69095 ,\n         -124.1457  , -114.748344], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 582,\n  'fluo_channel': 0,\n  'fluorescence': array([-158.85744 , -182.8102  , -112.48643 , ...,  -54.667374,\n         -123.09556 ,  -62.479664], dtype=float32),\n  'neuropil_fluorescence': array([-176.45108, -154.03986, -169.77536, ..., -175.2355 , -166.30254,\n         -169.93478], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 583,\n  'fluo_channel': 0,\n  'fluorescence': array([-43.336338 ,  -6.3984437, 127.70326  , ...,  -4.7083497,\n          30.741306 , -84.937325 ], dtype=float32),\n  'neuropil_fluorescence': array([-165.9158 , -159.43814, -165.8866 , ..., -165.98282, -164.5    ,\n         -161.66151], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 584,\n  'fluo_channel': 0,\n  'fluorescence': array([-227.662  , -231.67247, -225.50674, ..., -225.7061 , -226.16428,\n         -234.26166], dtype=float32),\n  'neuropil_fluorescence': array([-245.57211, -234.15866, -235.13461, ..., -232.5048 , -234.3077 ,\n         -233.77884], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 585,\n  'fluo_channel': 0,\n  'fluorescence': array([-141.39539, -118.18041, -130.13792, ..., -187.33273,  -89.95172,\n         -172.42273], dtype=float32),\n  'neuropil_fluorescence': array([-189.82747, -197.67606, -190.75528, ..., -189.01936, -191.88733,\n         -189.97536], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 586,\n  'fluo_channel': 0,\n  'fluorescence': array([-159.9951 , -173.91306, -147.00835, ..., -171.40295, -152.12276,\n         -168.79102], dtype=float32),\n  'neuropil_fluorescence': array([-162.5717 , -157.71695, -155.3501 , ..., -156.74673, -159.892  ,\n         -159.4674 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 587,\n  'fluo_channel': 0,\n  'fluorescence': array([ -77.88856 , -106.76893 , -144.31187 , ...,  -89.909386,\n          -74.48068 , -125.07992 ], dtype=float32),\n  'neuropil_fluorescence': array([-193.16667, -182.9088 , -198.85063, ..., -184.70912, -178.19025,\n         -182.33333], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 588,\n  'fluo_channel': 0,\n  'fluorescence': array([-230.63564, -240.90602, -222.01936, ..., -219.0976 , -226.77094,\n         -228.44257], dtype=float32),\n  'neuropil_fluorescence': array([-220.96284, -226.05913, -217.4223 , ..., -224.3142 , -210.72804,\n         -219.78885], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 589,\n  'fluo_channel': 0,\n  'fluorescence': array([-182.61786, -102.99986, -125.37294, ..., -123.19986, -123.00761,\n          -92.92331], dtype=float32),\n  'neuropil_fluorescence': array([-172.30383, -177.41446, -174.52213, ..., -181.09587, -175.46017,\n         -190.08997], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 590,\n  'fluo_channel': 0,\n  'fluorescence': array([-133.59972 , -150.07552 , -139.61282 , ...,  -71.28163 ,\n         -126.679634,  -70.45546 ], dtype=float32),\n  'neuropil_fluorescence': array([-158.35321, -146.52982, -145.20642, ..., -144.62843, -142.01376,\n         -144.79129], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 591,\n  'fluo_channel': 0,\n  'fluorescence': array([-210.07437, -215.65994, -204.88275, ..., -193.40634, -208.95135,\n         -224.58943], dtype=float32),\n  'neuropil_fluorescence': array([-161.04106, -160.50308, -171.57289, ..., -163.42094, -150.42711,\n         -153.24846], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 592,\n  'fluo_channel': 0,\n  'fluorescence': array([-156.7545  , -143.60826 , -119.051926, ..., -118.5464  ,\n         -104.381226, -232.63475 ], dtype=float32),\n  'neuropil_fluorescence': array([-180.61552, -178.19698, -170.41287, ..., -154.73674, -160.70644,\n         -176.88068], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 593,\n  'fluo_channel': 0,\n  'fluorescence': array([-106.21168, -207.03502, -143.40831, ..., -190.68141, -220.09363,\n         -239.3132 ], dtype=float32),\n  'neuropil_fluorescence': array([-178.91933, -180.3042 , -178.76639, ..., -187.35461, -172.40169,\n         -175.04538], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 594,\n  'fluo_channel': 0,\n  'fluorescence': array([-114.058655, -125.50356 , -173.95033 , ...,  -91.84396 ,\n         -185.9835  , -204.50261 ], dtype=float32),\n  'neuropil_fluorescence': array([-165.62529, -169.12646, -162.26463, ..., -170.35362, -164.25293,\n         -175.1054 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 595,\n  'fluo_channel': 0,\n  'fluorescence': array([-122.84328, -114.97761, -106.55241, ..., -114.96795,  -82.66313,\n         -101.28988], dtype=float32),\n  'neuropil_fluorescence': array([-188.57265, -180.18234, -190.80057, ..., -185.88605, -177.25356,\n         -184.42735], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 596,\n  'fluo_channel': 0,\n  'fluorescence': array([-180.70853, -151.08119, -174.67456, ..., -142.78627, -187.97266,\n         -117.09983], dtype=float32),\n  'neuropil_fluorescence': array([-201.84454, -192.70998, -199.25522, ..., -197.23898, -197.7587 ,\n         -194.22041], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 597,\n  'fluo_channel': 0,\n  'fluorescence': array([ -42.437626,  -96.89003 ,  -76.54763 , ..., -149.28912 ,\n         -126.83033 , -185.66066 ], dtype=float32),\n  'neuropil_fluorescence': array([-191.91269, -183.36798, -169.4158 , ..., -180.79417, -184.2765 ,\n         -188.94386], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 598,\n  'fluo_channel': 0,\n  'fluorescence': array([ -25.710163, -153.10902 , -158.37611 , ..., -147.61305 ,\n         -142.91042 , -199.7548  ], dtype=float32),\n  'neuropil_fluorescence': array([-192.37866, -196.69191, -198.30464, ..., -198.07057, -199.73149,\n         -191.8864 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 599,\n  'fluo_channel': 0,\n  'fluorescence': array([-225.8549  , -182.34628 , -129.606   , ..., -213.41862 ,\n            8.190344, -221.55153 ], dtype=float32),\n  'neuropil_fluorescence': array([-169.96407, -169.79704, -160.73996, ..., -165.60464, -166.0592 ,\n         -171.42917], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 600,\n  'fluo_channel': 0,\n  'fluorescence': array([ -78.788025, -134.62701 , -136.5904  , ...,  -89.61179 ,\n         -160.83281 ,  -95.30639 ], dtype=float32),\n  'neuropil_fluorescence': array([-118.17978 , -122.22472 , -120.52809 , ..., -116.455055,\n         -120.17416 , -111.996254], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 601,\n  'fluo_channel': 0,\n  'fluorescence': array([-170.10707 ,    4.563939,   14.966257, ...,  -85.107315,\n         -220.71469 , -211.31935 ], dtype=float32),\n  'neuropil_fluorescence': array([-195.84923, -215.54767, -203.90244, ..., -209.31042, -207.29047,\n         -208.83371], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 602,\n  'fluo_channel': 0,\n  'fluorescence': array([-167.02237, -170.22693, -155.71864, ..., -144.17213, -198.63815,\n         -127.73578], dtype=float32),\n  'neuropil_fluorescence': array([-183.87817, -190.26227, -184.64128, ..., -200.35533, -186.5516 ,\n         -191.86125], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 603,\n  'fluo_channel': 0,\n  'fluorescence': array([-130.26723 ,  -37.46314 , -160.65263 , ...,  -27.891638,\n          -47.27759 ,  -38.89733 ], dtype=float32),\n  'neuropil_fluorescence': array([-129.33264, -128.48026, -133.72557, ..., -136.71518, -128.71518,\n         -136.1185 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 604,\n  'fluo_channel': 0,\n  'fluorescence': array([-170.46251, -167.63867, -172.9848 , ..., -154.96031, -191.60976,\n         -155.79042], dtype=float32),\n  'neuropil_fluorescence': array([-185.71178, -189.86967, -186.27318, ..., -185.4787 , -174.88972,\n         -175.74185], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 605,\n  'fluo_channel': 0,\n  'fluorescence': array([ -43.53342 , -103.815155,  -98.24749 , ...,  -58.26997 ,\n          -85.11441 , -187.4503  ], dtype=float32),\n  'neuropil_fluorescence': array([-137.991  , -132.03604, -146.97298, ..., -119.86712, -123.76802,\n         -111.88288], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 606,\n  'fluo_channel': 0,\n  'fluorescence': array([-131.69243, -160.38312, -123.64964, ..., -186.76697, -179.61217,\n         -146.10602], dtype=float32),\n  'neuropil_fluorescence': array([-185.36092, -173.98573, -173.1826 , ..., -173.01997, -172.45792,\n         -172.73181], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 607,\n  'fluo_channel': 0,\n  'fluorescence': array([-202.05734, -191.76814, -204.88245, ..., -184.42215, -208.3371 ,\n         -187.59294], dtype=float32),\n  'neuropil_fluorescence': array([-213.79515, -206.69273, -212.79515, ..., -212.1676 , -210.20671,\n         -215.29422], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 608,\n  'fluo_channel': 0,\n  'fluorescence': array([ -61.17057 ,   -9.204351, -126.519264, ...,  -90.22363 ,\n          109.7958  ,  -59.81562 ], dtype=float32),\n  'neuropil_fluorescence': array([-172.49567, -143.69481, -154.71861, ..., -176.82251, -163.8723 ,\n         -161.88528], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 609,\n  'fluo_channel': 0,\n  'fluorescence': array([-148.8929 , -165.24841, -132.13829, ..., -235.853  , -242.12975,\n         -231.22743], dtype=float32),\n  'neuropil_fluorescence': array([-231.82115, -234.69615, -231.24615, ..., -240.3423 , -240.61154,\n         -240.73654], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 610,\n  'fluo_channel': 0,\n  'fluorescence': array([-230.49666, -197.72073, -246.12405, ..., -215.76443, -248.50377,\n         -220.60023], dtype=float32),\n  'neuropil_fluorescence': array([-256.51877, -251.65121, -251.1435 , ..., -249.90729, -253.93819,\n         -255.25386], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 611,\n  'fluo_channel': 0,\n  'fluorescence': array([ -24.732044,  -56.085037,   45.44313 , ...,  -96.816734,\n         -158.73389 , -108.23691 ], dtype=float32),\n  'neuropil_fluorescence': array([-137.85178, -153.93362, -138.90044, ..., -152.25   , -143.68584,\n         -151.20354], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 612,\n  'fluo_channel': 0,\n  'fluorescence': array([-219.53955, -232.25667, -222.7173 , ..., -213.16649, -234.41705,\n         -229.6172 ], dtype=float32),\n  'neuropil_fluorescence': array([-209.27087, -211.68398, -207.83296, ..., -207.32054, -203.60045,\n         -202.16028], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 613,\n  'fluo_channel': 0,\n  'fluorescence': array([-104.21987 , -109.544426,  -73.128426, ...,  -90.886314,\n         -198.33513 , -215.29414 ], dtype=float32),\n  'neuropil_fluorescence': array([-180.75914, -174.86452, -180.45592, ..., -185.24731, -177.1957 ,\n         -184.85161], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 614,\n  'fluo_channel': 0,\n  'fluorescence': array([-143.72786 , -111.34546 ,  -56.564407, ..., -206.92514 ,\n         -134.71596 , -238.48956 ], dtype=float32),\n  'neuropil_fluorescence': array([-194.15312, -194.24574, -185.82042, ..., -190.95653, -195.60681,\n         -191.41399], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 615,\n  'fluo_channel': 0,\n  'fluorescence': array([-129.35138, -128.5604 , -104.46658, ..., -129.71309, -128.36896,\n         -143.03912], dtype=float32),\n  'neuropil_fluorescence': array([-127.88161, -118.51163, -125.30867, ..., -130.36998, -117.89641,\n         -129.3277 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 616,\n  'fluo_channel': 0,\n  'fluorescence': array([-87.539734,  37.470844,  16.055782, ..., -31.201454, -33.835552,\n         -55.92958 ], dtype=float32),\n  'neuropil_fluorescence': array([-166.46378, -163.75156, -163.04141, ..., -149.02278, -166.06212,\n         -171.82195], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 617,\n  'fluo_channel': 0,\n  'fluorescence': array([-179.35172, -198.42287, -214.58873, ..., -205.93695, -205.21231,\n         -213.00748], dtype=float32),\n  'neuropil_fluorescence': array([-225.93129, -213.96202, -210.85715, ..., -222.17902, -218.20796,\n         -218.78842], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 618,\n  'fluo_channel': 0,\n  'fluorescence': array([-228.43324, -197.77737, -190.56897, ..., -208.79195, -112.10949,\n         -180.22867], dtype=float32),\n  'neuropil_fluorescence': array([-200.42932, -195.30104, -201.52094, ..., -196.64398, -198.30367,\n         -195.46597], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 619,\n  'fluo_channel': 0,\n  'fluorescence': array([-131.97499 , -115.114975, -113.749435, ..., -138.08647 ,\n         -131.34363 , -173.61047 ], dtype=float32),\n  'neuropil_fluorescence': array([-155.49583, -162.18968, -160.60066, ..., -159.21964, -165.91515,\n         -173.15308], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 620,\n  'fluo_channel': 0,\n  'fluorescence': array([ 91.41125 ,  60.03601 , -51.868004, ...,  52.70398 , 121.27228 ,\n         -43.030834], dtype=float32),\n  'neuropil_fluorescence': array([-129.4437  , -124.912605, -123.93781 , ..., -114.44034 ,\n         -113.33446 , -120.72773 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 621,\n  'fluo_channel': 0,\n  'fluorescence': array([-156.0737  , -131.61891 ,  -48.476486, ..., -145.17378 ,\n         -165.17712 , -135.21638 ], dtype=float32),\n  'neuropil_fluorescence': array([-172.08159, -181.77989, -175.67932, ..., -175.94118, -179.31499,\n         -185.87856], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 622,\n  'fluo_channel': 0,\n  'fluorescence': array([ -92.141174,    9.249408,  -20.068817, ...,  -13.588897,\n         -138.85086 , -122.8742  ], dtype=float32),\n  'neuropil_fluorescence': array([-126.209526, -121.15238 , -119.11667 , ..., -130.91905 ,\n         -142.79048 , -125.1     ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 623,\n  'fluo_channel': 0,\n  'fluorescence': array([-241.83069, -265.85327, -227.98958, ..., -232.92253, -261.15445,\n         -235.86102], dtype=float32),\n  'neuropil_fluorescence': array([-235.07115, -226.90343, -229.02669, ..., -227.29987, -229.24269,\n         -228.87802], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 624,\n  'fluo_channel': 0,\n  'fluorescence': array([-191.59363, -149.26825, -134.32254, ..., -172.86278, -156.0717 ,\n         -158.3275 ], dtype=float32),\n  'neuropil_fluorescence': array([-197.24026, -202.10823, -200.61905, ..., -193.0238 , -199.16667,\n         -199.44373], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 625,\n  'fluo_channel': 0,\n  'fluorescence': array([-204.97084 ,   33.233864, -108.58409 , ..., -170.75471 ,\n         -208.11049 , -167.39348 ], dtype=float32),\n  'neuropil_fluorescence': array([-155.0391 , -143.0823 , -148.39917, ..., -147.16461, -133.4465 ,\n         -142.07819], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 626,\n  'fluo_channel': 0,\n  'fluorescence': array([-140.92766, -161.42712, -143.57509, ..., -129.71132, -152.07387,\n         -147.66548], dtype=float32),\n  'neuropil_fluorescence': array([-145.91681, -156.31918, -154.73006, ..., -144.01189, -154.14432,\n         -142.22072], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 627,\n  'fluo_channel': 0,\n  'fluorescence': array([-167.72337, -173.54358, -169.08575, ..., -203.62517, -172.1959 ,\n         -229.12636], dtype=float32),\n  'neuropil_fluorescence': array([-218.43077, -218.51624, -214.78119, ..., -220.1094 , -223.40685,\n         -227.0359 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 628,\n  'fluo_channel': 0,\n  'fluorescence': array([-116.05333 ,  -19.229687,  -66.12879 , ...,   84.83827 ,\n          -60.541763,  -51.940712], dtype=float32),\n  'neuropil_fluorescence': array([-151.35262, -160.35634, -159.93657, ..., -151.70895, -137.20709,\n         -140.22202], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 629,\n  'fluo_channel': 0,\n  'fluorescence': array([-193.01706 , -208.7729  ,  -93.658936, ..., -159.14653 ,\n         -191.99358 , -130.79865 ], dtype=float32),\n  'neuropil_fluorescence': array([-165.94344, -172.2202 , -163.5394 , ..., -164.22223, -166.68283,\n         -165.25252], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 630,\n  'fluo_channel': 0,\n  'fluorescence': array([-208.15218, -194.33842, -106.79065, ..., -186.85384, -224.13673,\n         -205.13673], dtype=float32),\n  'neuropil_fluorescence': array([-195.91798, -192.88959, -195.53627, ..., -183.38013, -190.26656,\n         -202.21451], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 631,\n  'fluo_channel': 0,\n  'fluorescence': array([-211.97984, -209.57277, -217.29625, ..., -169.86859, -206.21758,\n         -135.30153], dtype=float32),\n  'neuropil_fluorescence': array([-226.32614, -222.7628 , -219.95418, ..., -229.14017, -222.90565,\n         -229.33963], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 632,\n  'fluo_channel': 0,\n  'fluorescence': array([-183.39006 , -160.38562 , -184.72281 , ...,  -18.706097,\n          -21.271471,  -30.809387], dtype=float32),\n  'neuropil_fluorescence': array([-182.11209, -183.84589, -182.64973, ..., -179.78984, -178.993  ,\n         -177.99475], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 633,\n  'fluo_channel': 0,\n  'fluorescence': array([-111.15552, -152.81218, -130.93925, ..., -133.39557, -147.2707 ,\n         -136.22343], dtype=float32),\n  'neuropil_fluorescence': array([-208.535 , -204.2925, -206.3825, ..., -201.6225, -214.73  ,\n         -211.3075], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 634,\n  'fluo_channel': 0,\n  'fluorescence': array([-209.475  , -129.63919, -214.51237, ..., -224.83638, -124.57497,\n         -175.19745], dtype=float32),\n  'neuropil_fluorescence': array([-187.47487, -194.24371, -179.55528, ..., -197.5603 , -184.69598,\n         -187.99498], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 635,\n  'fluo_channel': 0,\n  'fluorescence': array([-219.38252, -107.10721, -210.9255 , ..., -227.14235, -236.12003,\n         -205.80003], dtype=float32),\n  'neuropil_fluorescence': array([-226.52174, -220.73535, -213.42345, ..., -215.09262, -219.43478,\n         -222.18526], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 636,\n  'fluo_channel': 0,\n  'fluorescence': array([-148.84888, -177.09737, -169.40657, ..., -241.0929 , -254.26128,\n         -265.97452], dtype=float32),\n  'neuropil_fluorescence': array([-216.85352, -207.78711, -201.84961, ..., -217.12695, -215.67383,\n         -218.5293 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 637,\n  'fluo_channel': 0,\n  'fluorescence': array([-132.54791 ,  -86.94355 , -112.84629 , ...,  -26.536997,\n         -151.21326 , -158.14125 ], dtype=float32),\n  'neuropil_fluorescence': array([-162.91486, -148.17822, -152.32277, ..., -158.07524, -151.91287,\n         -158.699  ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 638,\n  'fluo_channel': 0,\n  'fluorescence': array([ 14.536494, -85.70414 , -60.103397, ..., -54.93615 , -72.543274,\n         -97.78499 ], dtype=float32),\n  'neuropil_fluorescence': array([-128.45438, -131.37408, -137.78285, ..., -130.573  , -132.43977,\n         -119.48175], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 639,\n  'fluo_channel': 0,\n  'fluorescence': array([-103.88789 ,  -96.98051 ,  -42.993607, ...,  -67.0258  ,\n         -123.58305 , -122.463165], dtype=float32),\n  'neuropil_fluorescence': array([-166.60326, -162.87967, -172.93983, ..., -166.33496, -155.41463,\n         -162.32033], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 640,\n  'fluo_channel': 0,\n  'fluorescence': array([-100.02193 , -105.80917 ,  -33.736347, ...,  -88.787544,\n          -87.73083 ,  -90.26866 ], dtype=float32),\n  'neuropil_fluorescence': array([-169.99533, -140.39252, -139.39018, ..., -147.85513, -148.55841,\n         -160.4229 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 641,\n  'fluo_channel': 0,\n  'fluorescence': array([  -5.4990196 ,   -0.35682058,   47.973267  , ..., -130.337     ,\n         -183.8708    ,  -60.957764  ], dtype=float32),\n  'neuropil_fluorescence': array([-101.39365,  -98.42543,  -89.33007, ...,  -88.05868, -104.76283,\n         -108.98533], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 642,\n  'fluo_channel': 0,\n  'fluorescence': array([-230.05109, -277.14233, -272.37662, ..., -274.05115, -266.36398,\n         -264.63043], dtype=float32),\n  'neuropil_fluorescence': array([-267.81873, -262.63544, -265.9002 , ..., -264.95316, -267.12628,\n         -268.18127], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 643,\n  'fluo_channel': 0,\n  'fluorescence': array([-216.44005, -199.71294, -218.62115, ..., -227.60904, -227.87825,\n         -222.55975], dtype=float32),\n  'neuropil_fluorescence': array([-229.32253, -229.12318, -227.09076, ..., -228.45056, -230.78606,\n         -232.32901], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 644,\n  'fluo_channel': 0,\n  'fluorescence': array([-179.06734  , -174.22765  ,  111.06119  , ..., -118.68311  ,\n         -108.453766 ,    5.8192186], dtype=float32),\n  'neuropil_fluorescence': array([-165.52242, -156.18965, -151.98103, ..., -160.4    , -157.90344,\n         -156.67586], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 645,\n  'fluo_channel': 0,\n  'fluorescence': array([-193.20273, -169.46234, -202.26596, ..., -170.49335, -139.61879,\n         -179.07227], dtype=float32),\n  'neuropil_fluorescence': array([-220.12607, -213.29887, -213.66714, ..., -222.11897, -213.98158,\n         -219.7493 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 646,\n  'fluo_channel': 0,\n  'fluorescence': array([ -34.22454 ,  -54.887295, -101.66256 , ...,   26.54926 ,\n         -107.95246 , -107.339836], dtype=float32),\n  'neuropil_fluorescence': array([-168.99234, -169.20116, -156.65709, ..., -151.841  , -161.70882,\n         -155.3295 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 647,\n  'fluo_channel': 0,\n  'fluorescence': array([-194.40784, -175.94489, -194.81284, ..., -164.02576, -165.13559,\n         -160.08438], dtype=float32),\n  'neuropil_fluorescence': array([-206.28635, -197.0905 , -197.48665, ..., -205.95401, -205.37389,\n         -202.14244], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 648,\n  'fluo_channel': 0,\n  'fluorescence': array([-152.43233, -137.07167, -120.07172, ..., -150.22449, -159.28838,\n         -139.73207], dtype=float32),\n  'neuropil_fluorescence': array([-168.41019, -156.68932, -163.14806, ..., -157.36893, -155.97572,\n         -150.10437], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 649,\n  'fluo_channel': 0,\n  'fluorescence': array([-165.24458, -154.97188, -183.93872, ..., -178.07184, -138.46681,\n         -165.95697], dtype=float32),\n  'neuropil_fluorescence': array([-203.83044, -199.87543, -202.11246, ..., -207.2007 , -191.8564 ,\n         -197.00693], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 650,\n  'fluo_channel': 0,\n  'fluorescence': array([-202.15622, -143.83665, -216.77919, ..., -155.9795 , -156.73088,\n         -179.60818], dtype=float32),\n  'neuropil_fluorescence': array([-191.77542, -186.21399, -187.31145, ..., -195.61229, -187.52118,\n         -183.87076], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 651,\n  'fluo_channel': 0,\n  'fluorescence': array([-153.96413, -171.8715 , -212.1513 , ..., -192.04312, -170.9553 ,\n         -158.67558], dtype=float32),\n  'neuropil_fluorescence': array([-217.63065, -197.5603 , -191.5804 , ..., -209.4196 , -189.49246,\n         -190.73618], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 652,\n  'fluo_channel': 0,\n  'fluorescence': array([-183.25934, -173.8655 , -169.18344, ..., -170.126  , -172.02878,\n         -144.66899], dtype=float32),\n  'neuropil_fluorescence': array([-179.15277, -173.41667, -173.2745 , ..., -171.25572, -167.31046,\n         -175.04575], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 653,\n  'fluo_channel': 0,\n  'fluorescence': array([-235.87508, -216.17197, -217.99292, ..., -233.31519, -216.25497,\n         -224.16586], dtype=float32),\n  'neuropil_fluorescence': array([-233.46248, -232.36105, -233.30426, ..., -234.66328, -234.64503,\n         -238.70386], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 654,\n  'fluo_channel': 0,\n  'fluorescence': array([-215.87903, -159.61482, -141.44676, ..., -139.47546, -172.21286,\n         -172.11476], dtype=float32),\n  'neuropil_fluorescence': array([-212.67488, -210.24384, -202.34975, ..., -214.1601 , -210.97537,\n         -212.43596], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 655,\n  'fluo_channel': 0,\n  'fluorescence': array([  37.53094 , -133.70828 , -123.24187 , ..., -141.8298  ,\n         -102.94827 ,  -55.449005], dtype=float32),\n  'neuropil_fluorescence': array([-118.55038 , -108.94403 , -116.8097  , ..., -105.25373 ,\n         -110.14552 , -109.466415], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 656,\n  'fluo_channel': 0,\n  'fluorescence': array([ -87.94225 ,  -74.97281 , -160.53525 , ..., -134.66527 ,\n          -74.949265,  -60.55113 ], dtype=float32),\n  'neuropil_fluorescence': array([-136.22333, -140.9921 , -129.23518, ..., -151.49406, -134.28261,\n         -131.7925 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 657,\n  'fluo_channel': 0,\n  'fluorescence': array([-190.68785, -213.02173, -195.5691 , ..., -220.94603, -245.6238 ,\n         -222.89606], dtype=float32),\n  'neuropil_fluorescence': array([-230.15   , -244.8158 , -237.69211, ..., -245.57368, -244.70264,\n         -237.44473], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 658,\n  'fluo_channel': 0,\n  'fluorescence': array([-167.46735, -183.76804, -116.8747 , ...,  -84.26784, -170.76772,\n         -170.19177], dtype=float32),\n  'neuropil_fluorescence': array([-212.50586, -208.49748, -212.39531, ..., -210.83083, -209.7923 ,\n         -210.20602], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 659,\n  'fluo_channel': 0,\n  'fluorescence': array([ -93.41641, -177.41298, -152.33113, ..., -140.90913, -136.04034,\n         -197.5668 ], dtype=float32),\n  'neuropil_fluorescence': array([-177.76697, -177.19449, -170.90092, ..., -173.82202, -169.3578 ,\n         -170.89908], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 660,\n  'fluo_channel': 0,\n  'fluorescence': array([-195.02763, -201.76613, -196.74753, ..., -206.1722 , -188.78796,\n         -234.10925], dtype=float32),\n  'neuropil_fluorescence': array([-202.10278, -195.09105, -199.58003, ..., -206.72835, -204.67401,\n         -208.0088 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 661,\n  'fluo_channel': 0,\n  'fluorescence': array([-214.26526, -163.37355, -163.45111, ..., -268.03967,  -17.18387,\n         -114.04902], dtype=float32),\n  'neuropil_fluorescence': array([-191.63562, -200.01822, -194.31377, ..., -195.23279, -187.01619,\n         -201.69838], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 662,\n  'fluo_channel': 0,\n  'fluorescence': array([-238.5938 , -253.17696, -253.75038, ..., -232.71916, -230.4461 ,\n         -250.97026], dtype=float32),\n  'neuropil_fluorescence': array([-243.80145, -241.95157, -246.3971 , ..., -245.96852, -245.68523,\n         -244.04358], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 663,\n  'fluo_channel': 0,\n  'fluorescence': array([-100.25771 , -120.77474 , -184.22737 , ..., -209.82172 ,\n          -30.380308, -223.47627 ], dtype=float32),\n  'neuropil_fluorescence': array([-205.25754, -180.62645, -181.11833, ..., -194.62413, -199.72389,\n         -207.7471 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 664,\n  'fluo_channel': 0,\n  'fluorescence': array([-249.3966 , -203.49355, -194.81601, ..., -215.16064, -239.09795,\n         -222.22641], dtype=float32),\n  'neuropil_fluorescence': array([-217.30382, -219.18169, -222.08397, ..., -218.4519 , -223.88245,\n         -217.49466], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 665,\n  'fluo_channel': 0,\n  'fluorescence': array([-197.90475, -210.04175, -224.90607, ..., -214.95317, -199.78525,\n         -217.06334], dtype=float32),\n  'neuropil_fluorescence': array([-198.66667, -198.37837, -198.18018, ..., -205.78828, -193.76126,\n         -198.09009], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 666,\n  'fluo_channel': 0,\n  'fluorescence': array([ -89.67066,  -43.36022, -152.61348, ..., -155.948  , -100.23357,\n         -137.86023], dtype=float32),\n  'neuropil_fluorescence': array([-142.01076, -141.78226, -148.54436, ..., -147.88979, -136.45027,\n         -138.43146], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 667,\n  'fluo_channel': 0,\n  'fluorescence': array([-175.7419  ,  -70.2671  ,  -76.234474, ..., -116.90792 ,\n         -115.46206 , -143.11058 ], dtype=float32),\n  'neuropil_fluorescence': array([-169.75871, -171.45274, -162.45772, ..., -159.61443, -159.95523,\n         -155.89801], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 668,\n  'fluo_channel': 0,\n  'fluorescence': array([-136.98257,  -98.1071 , -131.97798, ..., -126.18341, -155.92755,\n         -146.18999], dtype=float32),\n  'neuropil_fluorescence': array([-177.14578, -174.24808, -168.75447, ..., -162.50896, -173.844  ,\n         -168.93094], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 669,\n  'fluo_channel': 0,\n  'fluorescence': array([-221.32716, -192.33325, -189.47112, ..., -181.22255, -210.10733,\n         -210.37091], dtype=float32),\n  'neuropil_fluorescence': array([-186.46219, -198.56302, -199.45659, ..., -206.37816, -204.86835,\n         -202.35855], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 670,\n  'fluo_channel': 0,\n  'fluorescence': array([-226.77219, -211.57338, -219.53043, ..., -211.97218, -209.91791,\n         -217.74693], dtype=float32),\n  'neuropil_fluorescence': array([-177.78981, -176.47346, -174.26328, ..., -174.49469, -176.6051 ,\n         -164.6603 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 671,\n  'fluo_channel': 0,\n  'fluorescence': array([-231.51642, -208.53021, -192.63269, ..., -229.50154, -185.129  ,\n         -222.81334], dtype=float32),\n  'neuropil_fluorescence': array([-164.26967, -171.58427, -161.86517, ..., -135.1573 , -169.27248,\n         -168.51123], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 672,\n  'fluo_channel': 0,\n  'fluorescence': array([-224.11958, -217.02417, -181.43855, ..., -231.35945, -200.94171,\n         -189.17473], dtype=float32),\n  'neuropil_fluorescence': array([-210.5367 , -203.16978, -205.43741, ..., -201.33957, -208.74533,\n         -207.46907], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 673,\n  'fluo_channel': 0,\n  'fluorescence': array([-136.14565, -126.43081, -140.08974, ..., -206.46756, -123.51381,\n         -187.236  ], dtype=float32),\n  'neuropil_fluorescence': array([-213.80946, -207.2559 , -206.36023, ..., -201.89151, -213.59944,\n         -204.70375], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 674,\n  'fluo_channel': 0,\n  'fluorescence': array([ -41.314037,  -99.4758  ,  -88.36767 , ...,  -82.92126 ,\n         -142.42381 , -127.94219 ], dtype=float32),\n  'neuropil_fluorescence': array([ -97.62787 ,  -92.53752 ,  -97.964775, ...,  -93.48086 ,\n         -102.825424,  -95.13936 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 675,\n  'fluo_channel': 0,\n  'fluorescence': array([-123.291016,  -88.33966 ,  -93.2949  , ...,  -38.33169 ,\n          -94.690674, -109.73383 ], dtype=float32),\n  'neuropil_fluorescence': array([-147.88734, -160.38339, -146.0336 , ..., -144.23914, -138.0257 ,\n         -141.40317], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 676,\n  'fluo_channel': 0,\n  'fluorescence': array([ -94.45124, -163.58086, -117.26593, ..., -137.60904, -198.51129,\n          -64.06729], dtype=float32),\n  'neuropil_fluorescence': array([-136.10104, -137.87047, -131.86528, ..., -142.01295, -149.29016,\n         -152.71243], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 677,\n  'fluo_channel': 0,\n  'fluorescence': array([-210.26802, -228.74825, -246.75021, ..., -240.09543, -244.38936,\n         -243.59418], dtype=float32),\n  'neuropil_fluorescence': array([-243.13109, -244.99496, -243.77983, ..., -244.14622, -247.24706,\n         -241.60672], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 678,\n  'fluo_channel': 0,\n  'fluorescence': array([-181.17812 , -136.11066 , -162.0123  , ..., -145.1111  ,\n         -199.87544 , -124.052864], dtype=float32),\n  'neuropil_fluorescence': array([-168.76907, -166.98517, -172.67584, ..., -166.75847, -155.78601,\n         -166.4767 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 679,\n  'fluo_channel': 0,\n  'fluorescence': array([-197.86597, -129.06998, -167.8471 , ..., -210.82257, -172.66727,\n         -123.21742], dtype=float32),\n  'neuropil_fluorescence': array([-186.76181, -192.15811, -182.83572, ..., -186.67967, -186.19302,\n         -184.73923], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 680,\n  'fluo_channel': 0,\n  'fluorescence': array([-123.68043, -190.78271, -192.15605, ..., -182.13022, -169.96013,\n         -177.39888], dtype=float32),\n  'neuropil_fluorescence': array([-217.0835 , -230.17647, -229.99051, ..., -216.48956, -226.7002 ,\n         -227.7685 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 681,\n  'fluo_channel': 0,\n  'fluorescence': array([-159.41536  , -164.46268  ,  -91.974144 , ...,  -36.17326  ,\n            0.9919381, -112.68729  ], dtype=float32),\n  'neuropil_fluorescence': array([-126.89286 , -119.640755, -122.7584  , ..., -126.663864,\n         -111.207985, -132.2248  ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 682,\n  'fluo_channel': 0,\n  'fluorescence': array([-216.50798, -156.42506, -191.24586, ..., -183.5368 , -211.54205,\n         -205.8982 ], dtype=float32),\n  'neuropil_fluorescence': array([-217.7011 , -221.96556, -223.3168 , ..., -223.2934 , -227.34023,\n         -217.32368], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 683,\n  'fluo_channel': 0,\n  'fluorescence': array([-210.49397, -195.24751, -188.96617, ..., -211.32428, -147.61374,\n         -199.56917], dtype=float32),\n  'neuropil_fluorescence': array([-235.00813, -228.28455, -229.71545, ..., -228.62059, -234.79675,\n         -228.56097], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 684,\n  'fluo_channel': 0,\n  'fluorescence': array([ -62.56768 ,  -13.315788,   11.056266, ..., -139.56476 ,\n         -100.36052 , -107.327675], dtype=float32),\n  'neuropil_fluorescence': array([-155.77544, -148.5    , -142.05263, ..., -151.93684, -140.96317,\n         -147.3772 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 685,\n  'fluo_channel': 0,\n  'fluorescence': array([-262.17953, -239.69424, -245.9388 , ..., -238.51326, -221.94933,\n         -215.84103], dtype=float32),\n  'neuropil_fluorescence': array([-214.52077, -205.92041, -207.73183, ..., -212.20761, -209.34256,\n         -206.71454], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 686,\n  'fluo_channel': 0,\n  'fluorescence': array([-146.4721  ,  -94.536026, -201.4997  , ..., -190.62154 ,\n         -201.70634 , -212.50372 ], dtype=float32),\n  'neuropil_fluorescence': array([-187.67586, -190.69138, -191.88792, ..., -179.51552, -184.41379,\n         -180.03276], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 687,\n  'fluo_channel': 0,\n  'fluorescence': array([-129.13702 , -156.35014 ,  -36.222176, ..., -104.636345,\n         -195.49173 , -209.45601 ], dtype=float32),\n  'neuropil_fluorescence': array([-197.00485, -197.94012, -195.99191, ..., -190.42233, -196.32039,\n         -201.05988], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 688,\n  'fluo_channel': 0,\n  'fluorescence': array([-128.15654 , -128.9419  ,   32.42141 , ...,  -79.22858 ,\n          -12.550453,  -33.46091 ], dtype=float32),\n  'neuropil_fluorescence': array([-117.86703 , -114.010925, -128.44263 , ..., -110.33151 ,\n         -116.74681 , -120.333336], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 689,\n  'fluo_channel': 0,\n  'fluorescence': array([-207.89494, -145.40486, -153.16498, ..., -162.58244, -157.82726,\n         -181.67097], dtype=float32),\n  'neuropil_fluorescence': array([-208.15045, -210.21284, -205.73027, ..., -213.34496, -210.72478,\n         -206.12477], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 690,\n  'fluo_channel': 0,\n  'fluorescence': array([-166.33969, -210.36963, -144.88628, ..., -177.57649, -164.59685,\n         -173.02419], dtype=float32),\n  'neuropil_fluorescence': array([-206.60664, -198.01573, -191.59966, ..., -207.47902, -199.13986,\n         -206.35315], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 691,\n  'fluo_channel': 0,\n  'fluorescence': array([-220.23936, -209.6143 , -194.64153, ..., -191.2897 , -190.02214,\n         -202.98573], dtype=float32),\n  'neuropil_fluorescence': array([-199.02089, -201.0116 , -194.08585, ..., -203.67749, -194.28539,\n         -189.05568], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 692,\n  'fluo_channel': 0,\n  'fluorescence': array([-3.1187004e+01,  3.4650266e-02, -9.2786045e+00, ...,\n         -1.0403750e+02, -1.3705333e+02, -1.0278760e+01], dtype=float32),\n  'neuropil_fluorescence': array([-154.67839, -148.98438, -140.97005, ..., -151.54688, -152.41277,\n         -144.95964], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 693,\n  'fluo_channel': 0,\n  'fluorescence': array([-67.24846 ,  42.443176, -43.433033, ...,  75.187355, -19.474829,\n         171.01538 ], dtype=float32),\n  'neuropil_fluorescence': array([-113.534  , -111.53068, -103.50249, ..., -109.33499, -106.94362,\n         -117.40133], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 694,\n  'fluo_channel': 0,\n  'fluorescence': array([-43.418297, -94.65731 , -72.41997 , ..., -79.36263 , -86.56466 ,\n         -91.29576 ], dtype=float32),\n  'neuropil_fluorescence': array([-148.73923, -145.8475 , -146.29453, ..., -149.57043, -147.11874,\n         -151.07916], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 695,\n  'fluo_channel': 0,\n  'fluorescence': array([  27.816307, -173.64066 , -128.68834 , ..., -151.13176 ,\n         -165.83191 , -196.53996 ], dtype=float32),\n  'neuropil_fluorescence': array([-168.65402, -180.14113, -170.739  , ..., -162.25189, -174.92413,\n         -171.76935], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 696,\n  'fluo_channel': 0,\n  'fluorescence': array([-225.97357, -201.33453, -200.2796 , ..., -238.7339 , -210.89464,\n         -242.36789], dtype=float32),\n  'neuropil_fluorescence': array([-149.63026, -142.54343, -143.29736, ..., -147.13289, -144.60658,\n         -142.35263], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 697,\n  'fluo_channel': 0,\n  'fluorescence': array([ -86.11707  , -246.90413  ,  -78.93504  , ..., -109.43741  ,\n            3.3650272, -239.19505  ], dtype=float32),\n  'neuropil_fluorescence': array([-132.07219 , -132.76645 , -130.69427 , ..., -104.41189 ,\n         -110.825905, -100.242035], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 698,\n  'fluo_channel': 0,\n  'fluorescence': array([-215.83186, -200.76285, -242.58733, ..., -252.23991, -208.44153,\n         -206.40143], dtype=float32),\n  'neuropil_fluorescence': array([-181.00713, -175.11253, -173.1624 , ..., -182.67664, -174.88605,\n         -175.39316], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 699,\n  'fluo_channel': 0,\n  'fluorescence': array([ -35.7708  , -132.10384 ,  -27.650206, ...,  -82.132545,\n          -43.81643 , -205.17986 ], dtype=float32),\n  'neuropil_fluorescence': array([-157.02951, -142.67014, -134.2743 , ..., -157.6823 , -147.29861,\n         -153.44965], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 700,\n  'fluo_channel': 0,\n  'fluorescence': array([-177.40399, -203.71628, -201.64671, ..., -220.83691, -203.39027,\n         -219.65387], dtype=float32),\n  'neuropil_fluorescence': array([-214.60596, -222.80385, -217.82487, ..., -223.69527, -212.12259,\n         -222.44484], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 701,\n  'fluo_channel': 0,\n  'fluorescence': array([-75.829   ,  26.017944,  16.869003, ..., -91.85012 , -95.757195,\n         -95.04693 ], dtype=float32),\n  'neuropil_fluorescence': array([-161.26086, -163.47826, -158.02899, ..., -146.9793 , -153.35197,\n         -149.93788], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 702,\n  'fluo_channel': 0,\n  'fluorescence': array([-126.09973 , -113.463295,  -96.48954 , ..., -138.95073 ,\n         -194.3422  , -249.61449 ], dtype=float32),\n  'neuropil_fluorescence': array([-203.32233, -198.80188, -194.80031, ..., -199.22798, -208.38208,\n         -205.05661], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 703,\n  'fluo_channel': 0,\n  'fluorescence': array([-146.59404 ,   81.788216,  -15.430924, ..., -145.06573 ,\n         -199.69157 , -190.40451 ], dtype=float32),\n  'neuropil_fluorescence': array([-195.53261, -196.15036, -196.64854, ..., -194.80615, -191.77354,\n         -186.67392], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 704,\n  'fluo_channel': 0,\n  'fluorescence': array([-253.81422, -245.81097, -251.32437, ..., -231.60663, -247.09126,\n         -241.50838], dtype=float32),\n  'neuropil_fluorescence': array([-245.73666, -245.92334, -242.085  , ..., -242.89   , -245.155  ,\n         -243.98334], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 705,\n  'fluo_channel': 0,\n  'fluorescence': array([-198.09299, -157.67854, -113.644  , ..., -166.85953, -152.23355,\n         -184.77711], dtype=float32),\n  'neuropil_fluorescence': array([-140.528  , -138.70934, -139.744  , ..., -147.50133, -137.01334,\n         -133.02933], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 706,\n  'fluo_channel': 0,\n  'fluorescence': array([-175.24373 ,  -78.772354, -147.4093  , ..., -151.89934 ,\n         -125.338326, -123.766655], dtype=float32),\n  'neuropil_fluorescence': array([-173.71994, -169.74124, -169.2618 , ..., -169.48553, -174.70471,\n         -181.97108], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 707,\n  'fluo_channel': 0,\n  'fluorescence': array([-127.22002  , -209.636    , -167.43811  , ..., -102.559044 ,\n         -107.7965   ,    0.8383775], dtype=float32),\n  'neuropil_fluorescence': array([-169.62982, -179.67995, -170.31491, ..., -167.51028, -172.51929,\n         -174.67352], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 708,\n  'fluo_channel': 0,\n  'fluorescence': array([ -58.621433, -215.4382  ,  -28.030785, ..., -162.11484 ,\n         -123.38238 ,  -56.434513], dtype=float32),\n  'neuropil_fluorescence': array([-177.10866, -166.41248, -182.27164, ..., -170.44266, -170.34808,\n         -174.26358], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 709,\n  'fluo_channel': 0,\n  'fluorescence': array([-223.79417, -124.72834, -243.11795, ..., -240.72261, -244.87143,\n         -207.75238], dtype=float32),\n  'neuropil_fluorescence': array([-230.103  , -228.40915, -232.14163, ..., -232.17168, -233.897  ,\n         -234.22604], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 710,\n  'fluo_channel': 0,\n  'fluorescence': array([-180.31715, -144.30261,  -92.86425, ...,  -83.79868,    9.24042,\n         -157.50906], dtype=float32),\n  'neuropil_fluorescence': array([-124.7948 , -134.36417, -124.01156, ..., -131.80492, -137.57803,\n         -120.38006], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 711,\n  'fluo_channel': 0,\n  'fluorescence': array([ -63.325687, -116.495834, -171.47145 , ..., -153.15192 ,\n         -114.149086,  -83.09372 ], dtype=float32),\n  'neuropil_fluorescence': array([-163.22366, -140.51201, -156.6525 , ..., -155.62292, -149.81331,\n         -155.07579], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 712,\n  'fluo_channel': 0,\n  'fluorescence': array([   0.34203553,  -54.054047  , -139.33755   , ...,  -41.13028   ,\n            0.7412151 , -110.144356  ], dtype=float32),\n  'neuropil_fluorescence': array([-134.08867, -149.0665 , -142.1872 , ..., -139.19458, -142.89163,\n         -152.41872], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 713,\n  'fluo_channel': 0,\n  'fluorescence': array([-234.70535, -224.696  , -228.03574, ..., -247.81282, -197.59888,\n         -248.4041 ], dtype=float32),\n  'neuropil_fluorescence': array([-226.32411, -223.06587, -214.9249 , ..., -233.72333, -226.59026,\n         -227.49406], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 714,\n  'fluo_channel': 0,\n  'fluorescence': array([-110.921585,  -34.430187, -117.35167 , ...,  -90.6226  ,\n          -62.083115, -145.43896 ], dtype=float32),\n  'neuropil_fluorescence': array([-207.40747, -213.94557, -203.61742, ..., -209.87247, -208.62209,\n         -214.15863], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 715,\n  'fluo_channel': 0,\n  'fluorescence': array([-154.53525, -192.1216 , -114.54681, ..., -216.59459, -183.89465,\n         -151.36655], dtype=float32),\n  'neuropil_fluorescence': array([-203.53784, -183.09729, -190.23514, ..., -190.36217, -185.58919,\n         -199.0108 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 716,\n  'fluo_channel': 0,\n  'fluorescence': array([-222.8507 , -185.24796, -211.34305, ..., -173.08221, -143.93646,\n         -191.00479], dtype=float32),\n  'neuropil_fluorescence': array([-192.02661, -193.97562, -191.07095, ..., -188.57872, -188.72284,\n         -177.07317], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 717,\n  'fluo_channel': 0,\n  'fluorescence': array([ -42.45674 ,  -15.654961,  -27.80657 , ..., -127.729805,\n          -63.954857,  -18.081093], dtype=float32),\n  'neuropil_fluorescence': array([-164.82187 , -125.430336, -144.51675 , ..., -151.5097  ,\n         -132.68077 , -131.0053  ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 718,\n  'fluo_channel': 0,\n  'fluorescence': array([-283.0269 , -277.2139 , -263.21182, ..., -241.7052 , -243.31544,\n         -275.4909 ], dtype=float32),\n  'neuropil_fluorescence': array([-264.4194 , -267.03552, -266.0683 , ..., -265.17487, -264.63797,\n         -270.52597], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 719,\n  'fluo_channel': 0,\n  'fluorescence': array([-165.30806 , -194.41599 , -193.17021 , ..., -163.24593 ,\n         -107.890045, -163.6493  ], dtype=float32),\n  'neuropil_fluorescence': array([-192.35681, -182.95682, -182.32045, ..., -193.35681, -185.9909 ,\n         -188.87727], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 720,\n  'fluo_channel': 0,\n  'fluorescence': array([ -50.9003  ,   29.038527,  -21.736818, ...,   87.96052 ,\n         -156.19073 ,  -67.95454 ], dtype=float32),\n  'neuropil_fluorescence': array([ -92.9315 , -100.71429, -101.26223, ...,  -98.7906 ,  -99.45206,\n         -107.99217], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 721,\n  'fluo_channel': 0,\n  'fluorescence': array([-144.20357, -187.53534, -239.1716 , ..., -104.27026, -224.11356,\n         -234.13565], dtype=float32),\n  'neuropil_fluorescence': array([-179.06522, -181.68379, -174.04742, ..., -178.85968, -182.48419,\n         -194.76086], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 722,\n  'fluo_channel': 0,\n  'fluorescence': array([-156.36778 , -128.51591 , -151.49768 , ...,  -43.53277 ,\n          -15.219249,   60.803146], dtype=float32),\n  'neuropil_fluorescence': array([-184.90819, -194.45908, -187.79042, ..., -197.76646, -181.95808,\n         -191.02396], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 723,\n  'fluo_channel': 0,\n  'fluorescence': array([-120.37225 , -129.81532 , -115.482925, ..., -140.34564 ,\n         -110.53261 ,  -90.53718 ], dtype=float32),\n  'neuropil_fluorescence': array([-111.98394 , -117.848175, -100.24671 , ..., -119.633575,\n         -119.69489 , -100.95474 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 724,\n  'fluo_channel': 0,\n  'fluorescence': array([ -89.59346,  -65.72003, -125.07073, ..., -128.62386,  -68.39873,\n         -132.74586], dtype=float32),\n  'neuropil_fluorescence': array([-166.23666, -163.64   , -159.36833, ..., -168.51167, -169.43   ,\n         -155.37833], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 725,\n  'fluo_channel': 0,\n  'fluorescence': array([ -88.90971,  -66.37423, -123.45895, ..., -101.11947, -199.47041,\n         -212.24371], dtype=float32),\n  'neuropil_fluorescence': array([-154.52602, -155.32343, -145.86803, ..., -151.09851, -150.25836,\n         -144.3829 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 726,\n  'fluo_channel': 0,\n  'fluorescence': array([   8.265604, -110.27142 , -120.56903 , ...,  -99.465385,\n         -167.65471 ,  -29.030664], dtype=float32),\n  'neuropil_fluorescence': array([-125.73348, -124.93613, -109.     , ..., -110.95815, -124.97577,\n         -125.2489 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 727,\n  'fluo_channel': 0,\n  'fluorescence': array([ -45.074707,  -28.850134, -109.459496, ..., -135.03305 ,\n         -194.89397 , -161.53708 ], dtype=float32),\n  'neuropil_fluorescence': array([-156.5661 , -141.99814, -145.0447 , ..., -136.10242, -126.78771,\n         -127.27188], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 728,\n  'fluo_channel': 0,\n  'fluorescence': array([-114.43665,  -96.02723, -114.54288, ..., -107.1232 , -126.79855,\n         -118.14178], dtype=float32),\n  'neuropil_fluorescence': array([-181.27553, -173.45686, -175.93134, ..., -181.80194, -174.38116,\n         -183.34155], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 729,\n  'fluo_channel': 0,\n  'fluorescence': array([-142.64049, -165.73828, -158.91475, ..., -172.60182, -159.9373 ,\n         -163.14357], dtype=float32),\n  'neuropil_fluorescence': array([-120.44762 , -109.60408 , -105.25714 , ..., -118.69252 ,\n         -114.60408 , -113.779594], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 730,\n  'fluo_channel': 0,\n  'fluorescence': array([-220.85086 , -164.9695  , -149.43677 , ..., -133.79372 ,\n          -92.820946, -165.78044 ], dtype=float32),\n  'neuropil_fluorescence': array([-198.7886 , -194.85661, -194.19485, ..., -201.65993, -191.11765,\n         -192.79779], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 731,\n  'fluo_channel': 0,\n  'fluorescence': array([-79.20129 , -73.72924 , -37.223648, ..., -52.745388, -89.73793 ,\n         -61.801716], dtype=float32),\n  'neuropil_fluorescence': array([-152.38394, -151.80803, -148.11693, ..., -141.78708, -147.64398,\n         -134.41362], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 732,\n  'fluo_channel': 0,\n  'fluorescence': array([-158.78865, -176.12608, -122.24913, ..., -162.94507, -109.0015 ,\n         -179.16237], dtype=float32),\n  'neuropil_fluorescence': array([-146.44884, -166.7    , -155.53023, ..., -145.89302, -145.25116,\n         -151.7186 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 733,\n  'fluo_channel': 0,\n  'fluorescence': array([  65.579735,   -2.329785,   78.3253  , ...,  -15.730909,\n         -142.54912 , -106.82278 ], dtype=float32),\n  'neuropil_fluorescence': array([-155.27983, -158.13992, -148.66255, ..., -156.41563, -143.09053,\n         -146.18108], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 734,\n  'fluo_channel': 0,\n  'fluorescence': array([-170.08932,  -91.62335, -119.63348, ..., -168.31209, -123.85357,\n         -174.69972], dtype=float32),\n  'neuropil_fluorescence': array([-195.17334, -187.21715, -188.22667, ..., -187.12572, -191.84763,\n         -196.36952], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 735,\n  'fluo_channel': 0,\n  'fluorescence': array([ -61.42562 , -130.56409 ,  -50.128338, ...,  -61.317467,\n         -146.68849 , -195.4483  ], dtype=float32),\n  'neuropil_fluorescence': array([-166.84   , -165.27429, -147.21333, ..., -164.0781 , -160.69524,\n         -160.06667], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 736,\n  'fluo_channel': 0,\n  'fluorescence': array([-153.97612, -225.45866, -184.69427, ..., -200.75534, -155.56178,\n         -155.05093], dtype=float32),\n  'neuropil_fluorescence': array([-190.9205 , -187.28033, -192.57323, ..., -195.50418, -196.04184,\n         -192.17574], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 737,\n  'fluo_channel': 0,\n  'fluorescence': array([-118.11023 , -214.15169 , -164.89189 , ..., -225.24591 ,\n         -184.04846 , -123.607086], dtype=float32),\n  'neuropil_fluorescence': array([-158.77911, -170.69879, -159.749  , ..., -157.26506, -160.94579,\n         -174.74297], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 738,\n  'fluo_channel': 0,\n  'fluorescence': array([-113.73469, -167.90872, -144.23729, ..., -176.59738, -147.93709,\n         -158.59293], dtype=float32),\n  'neuropil_fluorescence': array([-184.10995, -193.07591, -180.73036, ..., -182.13351, -184.99738,\n         -185.19633], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 739,\n  'fluo_channel': 0,\n  'fluorescence': array([-188.35205 , -128.6012  ,  -98.30846 , ...,  -45.198708,\n         -169.31831 ,  -69.10567 ], dtype=float32),\n  'neuropil_fluorescence': array([-131.732, -122.954, -111.768, ..., -126.302, -115.57 , -125.076],\n        dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 740,\n  'fluo_channel': 0,\n  'fluorescence': array([-107.79558, -205.80956, -188.72556, ..., -129.91843, -200.49748,\n         -161.37714], dtype=float32),\n  'neuropil_fluorescence': array([-210.0113 , -215.53769, -211.32413, ..., -214.68593, -216.71106,\n         -218.48367], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 741,\n  'fluo_channel': 0,\n  'fluorescence': array([ -52.122963,    4.080852, -142.16037 , ..., -136.49153 ,\n          -86.51905 ,  -50.561115], dtype=float32),\n  'neuropil_fluorescence': array([-133.04724 , -117.07087 , -100.185036, ..., -121.15354 ,\n         -115.19685 , -105.41535 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 742,\n  'fluo_channel': 0,\n  'fluorescence': array([-153.55896, -215.35773, -236.8504 , ..., -180.3217 , -234.17612,\n         -244.78033], dtype=float32),\n  'neuropil_fluorescence': array([-215.16765, -215.79684, -211.30573, ..., -217.83235, -223.3491 ,\n         -217.65483], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 743,\n  'fluo_channel': 0,\n  'fluorescence': array([-100.68862 , -107.70567 , -119.9177  , ...,  -30.965237,\n         -148.32407 , -131.07509 ], dtype=float32),\n  'neuropil_fluorescence': array([-116.070206, -112.00379 , -112.546486, ...,  -96.74953 ,\n         -105.52372 , -110.25237 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 744,\n  'fluo_channel': 0,\n  'fluorescence': array([-135.3945  , -173.09148 , -134.55638 , ..., -110.812325,\n         -120.11844 , -127.803474], dtype=float32),\n  'neuropil_fluorescence': array([-169.36209, -158.91371, -161.59322, ..., -158.5285 , -160.04005,\n         -159.31741], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 745,\n  'fluo_channel': 0,\n  'fluorescence': array([-191.15187, -137.4714 , -149.21396, ..., -201.2988 , -114.75813,\n         -221.94987], dtype=float32),\n  'neuropil_fluorescence': array([-150.0217  , -131.32755 , -132.0781  , ..., -123.67028 ,\n         -124.59653 , -124.386116], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 746,\n  'fluo_channel': 0,\n  'fluorescence': array([ -62.73708 , -122.61148 ,  -54.994293, ...,  -50.796474,\n         -140.30418 ,  -38.621307], dtype=float32),\n  'neuropil_fluorescence': array([-70.74215 , -71.53554 , -66.029755, ..., -75.578514, -69.671074,\n         -78.64959 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 747,\n  'fluo_channel': 0,\n  'fluorescence': array([-115.40379 , -135.70288 ,  -84.90526 , ...,  -79.93728 ,\n           79.0855  ,  -23.882107], dtype=float32),\n  'neuropil_fluorescence': array([-113.19715 , -119.30404 , -100.53682 , ...,  -97.9905  ,\n         -108.27316 , -102.931114], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 748,\n  'fluo_channel': 0,\n  'fluorescence': array([-249.83197, -225.96811, -244.37112, ..., -242.41159, -256.19107,\n         -252.82182], dtype=float32),\n  'neuropil_fluorescence': array([-210.675  , -219.94376, -215.48438, ..., -215.85156, -213.37813,\n         -213.06563], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 749,\n  'fluo_channel': 0,\n  'fluorescence': array([-208.99756, -232.70586, -230.70264, ..., -244.65947, -210.2357 ,\n         -251.13309], dtype=float32),\n  'neuropil_fluorescence': array([-246.4163 , -243.55078, -246.69814, ..., -255.6266 , -253.2804 ,\n         -248.00143], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 750,\n  'fluo_channel': 0,\n  'fluorescence': array([-185.03586, -173.43669, -216.35548, ..., -209.28108, -213.94124,\n         -188.42752], dtype=float32),\n  'neuropil_fluorescence': array([-238.94751, -239.20995, -239.12708, ..., -239.2127 , -240.75691,\n         -232.15608], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 751,\n  'fluo_channel': 0,\n  'fluorescence': array([-165.9935  , -128.22737 , -136.37091 , ..., -102.16601 ,\n         -108.529594, -145.35896 ], dtype=float32),\n  'neuropil_fluorescence': array([-143.1579 , -143.76732, -139.94737, ..., -156.13297, -147.72577,\n         -150.60942], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 752,\n  'fluo_channel': 0,\n  'fluorescence': array([-172.0875 , -238.43112, -252.06377, ..., -215.78316, -254.63895,\n         -221.72002], dtype=float32),\n  'neuropil_fluorescence': array([-222.0082 , -235.09563, -222.9153 , ..., -224.11201, -233.94809,\n         -235.2377 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 753,\n  'fluo_channel': 0,\n  'fluorescence': array([-184.69167, -173.51707, -191.56847, ..., -162.49773, -193.33974,\n         -180.75812], dtype=float32),\n  'neuropil_fluorescence': array([-207.53052, -200.16745, -205.28482, ..., -203.3881 , -215.34898,\n         -209.09703], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 754,\n  'fluo_channel': 0,\n  'fluorescence': array([-126.01726, -175.45062, -162.55025, ..., -179.40854, -230.12434,\n         -174.66727], dtype=float32),\n  'neuropil_fluorescence': array([-201.56842, -211.8421 , -203.84421, ..., -192.79579, -204.84421,\n         -204.65474], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 755,\n  'fluo_channel': 0,\n  'fluorescence': array([ -94.35704 ,  -53.687588,  -46.614727, ...,  -92.812164,\n         -140.84589 , -101.031784], dtype=float32),\n  'neuropil_fluorescence': array([-139.22655, -138.11931, -135.0992 , ..., -153.77345, -140.75871,\n         -142.11662], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 756,\n  'fluo_channel': 0,\n  'fluorescence': array([ -78.808395, -155.5227  , -156.0361  , ..., -154.74823 ,\n         -187.27731 , -142.10191 ], dtype=float32),\n  'neuropil_fluorescence': array([-175.42027, -177.19077, -180.769  , ..., -186.09686, -179.9538 ,\n         -189.90164], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 757,\n  'fluo_channel': 0,\n  'fluorescence': array([-114.1792  ,  -94.162605, -102.37154 , ..., -111.151085,\n         -115.090195, -136.01768 ], dtype=float32),\n  'neuropil_fluorescence': array([-158.70341, -156.80577, -153.79002, ..., -162.12862, -149.51706,\n         -158.36745], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 758,\n  'fluo_channel': 0,\n  'fluorescence': array([-195.64348, -210.04614, -154.38165, ..., -221.94814, -197.0479 ,\n         -181.79535], dtype=float32),\n  'neuropil_fluorescence': array([-214.19608, -217.25055, -209.86493, ..., -218.25926, -215.79956,\n         -216.58824], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 759,\n  'fluo_channel': 0,\n  'fluorescence': array([ 354.2737  ,  899.71936 ,  637.3665  , ...,  118.51681 ,\n            1.418913, -155.43651 ], dtype=float32),\n  'neuropil_fluorescence': array([-176.80635, -174.40475, -185.26825, ..., -179.38412, -180.18095,\n         -177.1492 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 760,\n  'fluo_channel': 0,\n  'fluorescence': array([-142.99588, -183.48813, -119.37564, ..., -175.30164, -112.76787,\n         -141.56699], dtype=float32),\n  'neuropil_fluorescence': array([-173.8036 , -167.26022, -177.93617, ..., -167.17513, -161.61865,\n         -170.43372], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 761,\n  'fluo_channel': 0,\n  'fluorescence': array([-83.65846 , -97.29331 , -57.86747 , ..., -43.56621 , -55.768147,\n         -76.08389 ], dtype=float32),\n  'neuropil_fluorescence': array([-87.950905, -91.      , -89.762276, ..., -98.96124 , -95.881134,\n         -92.12662 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 762,\n  'fluo_channel': 0,\n  'fluorescence': array([-248.92033, -224.02266, -212.40933, ..., -222.30428, -251.30827,\n         -237.56105], dtype=float32),\n  'neuropil_fluorescence': array([-223.63167, -213.77429, -218.34012, ..., -226.40439, -225.69122,\n         -217.8558 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 763,\n  'fluo_channel': 0,\n  'fluorescence': array([-147.74596, -174.21306, -116.04178, ..., -150.28879, -203.40067,\n         -144.07999], dtype=float32),\n  'neuropil_fluorescence': array([-186.19507, -187.67712, -199.6323 , ..., -194.15247, -190.2713 ,\n         -190.85875], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 764,\n  'fluo_channel': 0,\n  'fluorescence': array([-229.4827 , -215.8851 , -221.67058, ..., -225.95857, -231.71803,\n         -231.12581], dtype=float32),\n  'neuropil_fluorescence': array([-219.7117 , -224.37883, -224.29805, ..., -230.35655, -228.36072,\n         -227.60446], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 765,\n  'fluo_channel': 0,\n  'fluorescence': array([-171.90437,  -94.67342,  -29.97492, ...,  -64.64416,  -76.31843,\n         -166.36574], dtype=float32),\n  'neuropil_fluorescence': array([-173.08696, -177.44638, -174.87247, ..., -166.61739, -173.32608,\n         -173.89276], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 766,\n  'fluo_channel': 0,\n  'fluorescence': array([-124.79041, -211.84381, -170.3664 , ..., -164.52307, -219.51027,\n         -213.51147], dtype=float32),\n  'neuropil_fluorescence': array([-215.8076 , -199.21616, -207.30879, ..., -214.40855, -206.93112,\n         -210.33492], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 767,\n  'fluo_channel': 0,\n  'fluorescence': array([-120.22062 , -123.96972 ,  -20.887049, ...,  -37.89225 ,\n          -47.263283, -131.64648 ], dtype=float32),\n  'neuropil_fluorescence': array([-150.17346, -155.0238 , -156.91496, ..., -142.84354, -143.4966 ,\n         -135.12926], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 768,\n  'fluo_channel': 0,\n  'fluorescence': array([-123.22761, -187.9545 , -180.08025, ..., -224.32323, -228.82005,\n         -193.07437], dtype=float32),\n  'neuropil_fluorescence': array([-218.83594, -218.85   , -222.20468, ..., -211.50781, -213.68594,\n         -211.02031], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 769,\n  'fluo_channel': 0,\n  'fluorescence': array([-192.66078, -181.46507, -181.58632, ..., -179.93059, -192.6116 ,\n         -194.19484], dtype=float32),\n  'neuropil_fluorescence': array([-200.74664, -204.861  , -188.39238, ..., -196.89238, -196.36324,\n         -200.20404], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 770,\n  'fluo_channel': 0,\n  'fluorescence': array([-261.84042, -235.8656 , -210.85588, ..., -214.6622 , -239.89497,\n         -228.42886], dtype=float32),\n  'neuropil_fluorescence': array([-206.45529, -202.8672 , -202.18156, ..., -208.58266, -195.53387,\n         -202.23578], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 771,\n  'fluo_channel': 0,\n  'fluorescence': array([-226.80373, -121.49024, -203.89034, ..., -207.03928, -184.88567,\n         -147.96085], dtype=float32),\n  'neuropil_fluorescence': array([-171.79407, -183.18367, -178.77365, ..., -168.10576, -181.33952,\n         -171.85344], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 772,\n  'fluo_channel': 0,\n  'fluorescence': array([-239.01096, -153.70749, -195.1832 , ..., -175.93535, -158.01385,\n         -257.0419 ], dtype=float32),\n  'neuropil_fluorescence': array([-201.96948, -199.95058, -203.97675, ..., -199.45494, -203.98256,\n         -209.3372 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 773,\n  'fluo_channel': 0,\n  'fluorescence': array([ -54.60247  , -176.73462  , -130.60104  , ...,   17.699448 ,\n          -23.206394 ,   -7.7485013], dtype=float32),\n  'neuropil_fluorescence': array([-106.4464,  -99.1776,  -82.2464, ...,  -87.32  ,  -88.    ,\n         -100.7888], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 774,\n  'fluo_channel': 0,\n  'fluorescence': array([-207.95383, -144.67644, -169.09988, ..., -184.91216, -142.98003,\n         -129.6112 ], dtype=float32),\n  'neuropil_fluorescence': array([-176.41418, -189.09076, -184.0264 , ..., -188.23763, -185.36469,\n         -161.77722], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 775,\n  'fluo_channel': 0,\n  'fluorescence': array([-201.69212, -206.18909, -222.52382, ..., -207.32024, -188.35306,\n         -174.43126], dtype=float32),\n  'neuropil_fluorescence': array([-224.46297, -216.98148, -219.94444, ..., -223.19048, -223.29893,\n         -212.16931], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 776,\n  'fluo_channel': 0,\n  'fluorescence': array([-131.82997, -175.66365, -215.89796, ..., -173.35637, -155.22673,\n         -172.42265], dtype=float32),\n  'neuropil_fluorescence': array([-162.95918, -163.80867, -167.71173, ..., -175.11224, -172.5204 ,\n         -174.81378], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 777,\n  'fluo_channel': 0,\n  'fluorescence': array([-232.46931, -214.55853, -187.72394, ..., -200.86127, -152.05008,\n         -170.29256], dtype=float32),\n  'neuropil_fluorescence': array([-232.5815 , -227.04005, -228.7652 , ..., -229.63536, -227.5953 ,\n         -228.66713], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 778,\n  'fluo_channel': 0,\n  'fluorescence': array([-209.17041 ,  -66.693504, -141.16937 , ..., -196.40727 ,\n         -218.74692 , -158.69174 ], dtype=float32),\n  'neuropil_fluorescence': array([-150.75096, -149.27203, -147.977  , ..., -150.94827, -130.63792,\n         -143.21265], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 779,\n  'fluo_channel': 0,\n  'fluorescence': array([-111.35572 ,  -48.558002, -126.61696 , ..., -106.49934 ,\n         -147.62244 , -124.15893 ], dtype=float32),\n  'neuropil_fluorescence': array([-188.46307, -178.62769, -182.56923, ..., -187.09692, -186.3277 ,\n         -195.02461], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 780,\n  'fluo_channel': 0,\n  'fluorescence': array([-216.95192, -166.14346, -222.02379, ..., -143.94565, -204.0745 ,\n         -135.7519 ], dtype=float32),\n  'neuropil_fluorescence': array([-187.43852, -190.28592, -188.5526 , ..., -179.65186, -192.01038,\n         -184.80444], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 781,\n  'fluo_channel': 0,\n  'fluorescence': array([-133.01779, -115.27268, -181.39853, ..., -140.8184 , -186.50992,\n          -77.92204], dtype=float32),\n  'neuropil_fluorescence': array([-196.7893 , -195.36467, -189.77957, ..., -191.96272, -187.17503,\n         -189.33226], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 782,\n  'fluo_channel': 0,\n  'fluorescence': array([ -70.06774 ,  -76.69438 ,  -56.332035, ...,  -23.507818,\n         -104.60413 ,    5.470023], dtype=float32),\n  'neuropil_fluorescence': array([-160.93408, -154.1676 , -152.84181, ..., -160.22787, -153.0226 ,\n         -159.65726], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 783,\n  'fluo_channel': 0,\n  'fluorescence': array([-183.60986 ,  -28.284071, -184.32932 , ..., -163.37729 ,\n         -181.36952 , -102.67273 ], dtype=float32),\n  'neuropil_fluorescence': array([-120.74775, -105.77477, -117.39865, ..., -110.71622, -128.33333,\n         -122.6509 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 784,\n  'fluo_channel': 0,\n  'fluorescence': array([-76.9443  , -77.43386 , -82.826744, ...,  53.78385 ,  16.157015,\n         -71.55858 ], dtype=float32),\n  'neuropil_fluorescence': array([-189.61975, -187.11554, -185.14496, ..., -179.61134, -187.43068,\n         -187.90337], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 785,\n  'fluo_channel': 0,\n  'fluorescence': array([-106.18909 ,  -60.571625,  -68.2061  , ...,  -91.01521 ,\n          -77.99386 ,  -84.17367 ], dtype=float32),\n  'neuropil_fluorescence': array([-125.93298 , -122.261024, -122.13228 , ..., -135.67725 ,\n         -137.14992 , -136.35274 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 786,\n  'fluo_channel': 0,\n  'fluorescence': array([ -42.006496, -120.50251 ,  -27.289356, ...,  -82.361435,\n          -96.979645,  -80.97373 ], dtype=float32),\n  'neuropil_fluorescence': array([-152.8438 , -149.92886, -132.03766, ..., -152.62483, -147.36401,\n         -152.54114], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 787,\n  'fluo_channel': 0,\n  'fluorescence': array([-151.89352 ,  -74.56497 , -152.9891  , ..., -108.49523 ,\n         -141.49083 ,  -79.760025], dtype=float32),\n  'neuropil_fluorescence': array([-146.66917, -137.38535, -135.97557, ..., -128.52068, -130.71053,\n         -132.12595], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 788,\n  'fluo_channel': 0,\n  'fluorescence': array([-201.80879, -211.77031, -191.0243 , ..., -207.14313, -191.33925,\n         -194.21016], dtype=float32),\n  'neuropil_fluorescence': array([-200.8382 , -196.16711, -193.61273, ..., -188.33421, -189.81433,\n         -185.84085], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 789,\n  'fluo_channel': 0,\n  'fluorescence': array([-177.6131 , -219.35228, -137.82816, ..., -223.86812, -230.0837 ,\n         -124.6674 ], dtype=float32),\n  'neuropil_fluorescence': array([-188.07184, -192.39029, -183.37865, ..., -187.58252, -178.19223,\n         -192.85437], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 790,\n  'fluo_channel': 0,\n  'fluorescence': array([-166.07632, -192.75949, -179.78441, ..., -128.18748, -173.21283,\n         -133.88332], dtype=float32),\n  'neuropil_fluorescence': array([-188.66904, -183.44745, -178.91478, ..., -189.55966, -179.9375 ,\n         -180.7713 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 791,\n  'fluo_channel': 0,\n  'fluorescence': array([-171.58342, -230.89821, -169.22519, ..., -177.78882, -162.99081,\n         -159.14877], dtype=float32),\n  'neuropil_fluorescence': array([-200.4052 , -206.11896, -195.78253, ..., -191.79926, -188.31598,\n         -192.10966], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 792,\n  'fluo_channel': 0,\n  'fluorescence': array([-67.46408  ,  -3.4751992, -71.6537   , ..., -67.02958  ,\n         -53.35195  , -63.01948  ], dtype=float32),\n  'neuropil_fluorescence': array([-119.58203, -133.47852, -121.7168 , ..., -121.06641, -118.90039,\n         -134.42773], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 793,\n  'fluo_channel': 0,\n  'fluorescence': array([-173.72238, -233.50375, -153.90892, ..., -206.58508, -172.25746,\n         -202.34755], dtype=float32),\n  'neuropil_fluorescence': array([-201.     , -199.48676, -204.53477, ..., -210.17384, -205.11258,\n         -201.73178], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 794,\n  'fluo_channel': 0,\n  'fluorescence': array([-222.4469 , -205.46814, -238.86334, ..., -244.54509, -239.1756 ,\n         -196.55762], dtype=float32),\n  'neuropil_fluorescence': array([-245.65771, -247.79362, -242.17953, ..., -246.22652, -249.7953 ,\n         -240.5453 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 795,\n  'fluo_channel': 0,\n  'fluorescence': array([-130.87915, -153.02283, -235.17256, ..., -143.94212, -156.21292,\n         -214.97658], dtype=float32),\n  'neuropil_fluorescence': array([-217.5394 , -209.29697, -216.49849, ..., -214.18939, -213.13182,\n         -212.2303 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 796,\n  'fluo_channel': 0,\n  'fluorescence': array([-225.34483, -191.61084, -194.08736, ..., -222.01634, -209.84418,\n         -161.96776], dtype=float32),\n  'neuropil_fluorescence': array([-212.39386, -210.96368, -206.3324 , ..., -209.82123, -210.06984,\n         -211.58101], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 797,\n  'fluo_channel': 0,\n  'fluorescence': array([-193.874  , -214.7363 , -163.15985, ..., -170.63821, -204.03897,\n         -140.61502], dtype=float32),\n  'neuropil_fluorescence': array([-165.12584, -163.37752, -160.67953, ..., -179.67282, -184.72148,\n         -182.93625], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 798,\n  'fluo_channel': 0,\n  'fluorescence': array([ -78.501686,  -55.35439 ,  -81.93816 , ..., -170.06062 ,\n          -83.40946 ,  -18.775316], dtype=float32),\n  'neuropil_fluorescence': array([-123.88086, -127.7832 , -128.60352, ..., -118.69141, -109.23633,\n         -122.36914], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 799,\n  'fluo_channel': 0,\n  'fluorescence': array([-130.96132 ,   50.06063 ,  -90.37618 , ...,  -39.79966 ,\n         -166.07452 ,  -50.059986], dtype=float32),\n  'neuropil_fluorescence': array([-169.81697, -172.59416, -166.96552, ..., -162.57294, -161.26923,\n         -164.42441], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 800,\n  'fluo_channel': 0,\n  'fluorescence': array([-264.59396, -248.47656, -260.00162, ..., -250.42195, -256.64508,\n         -248.34827], dtype=float32),\n  'neuropil_fluorescence': array([-260.32846, -260.53323, -257.69547, ..., -266.59177, -260.9428 ,\n         -262.06915], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 801,\n  'fluo_channel': 0,\n  'fluorescence': array([-212.70706, -201.04831, -256.1961 , ..., -206.6625 , -196.26721,\n         -205.7863 ], dtype=float32),\n  'neuropil_fluorescence': array([-220.06323, -226.97005, -228.38103, ..., -236.33278, -229.2446 ,\n         -229.6589 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 802,\n  'fluo_channel': 0,\n  'fluorescence': array([-188.44012, -154.01938, -158.344  , ..., -151.28003,  -78.37155,\n         -209.10864], dtype=float32),\n  'neuropil_fluorescence': array([-211.53969, -202.37778, -206.73334, ..., -210.05556, -209.1    ,\n         -211.12857], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 803,\n  'fluo_channel': 0,\n  'fluorescence': array([-204.0111 , -167.69966, -185.42651, ..., -209.91232, -190.98419,\n         -225.88873], dtype=float32),\n  'neuropil_fluorescence': array([-216.5318 , -204.40459, -199.31044, ..., -217.68448, -204.06107,\n         -201.76335], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 804,\n  'fluo_channel': 0,\n  'fluorescence': array([-135.10283 , -146.83255 , -131.0768  , ..., -167.36176 ,\n          -80.364174, -102.41776 ], dtype=float32),\n  'neuropil_fluorescence': array([-198.21973, -194.83408, -197.59343, ..., -192.29446, -199.37668,\n         -193.4544 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 805,\n  'fluo_channel': 0,\n  'fluorescence': array([-102.72721 , -186.49748 , -151.61685 , ..., -124.798836,\n         -152.21062 , -198.89668 ], dtype=float32),\n  'neuropil_fluorescence': array([-177.84056, -171.15944, -185.46274, ..., -173.96187, -166.17157,\n         -175.7227 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 806,\n  'fluo_channel': 0,\n  'fluorescence': array([-67.67528 , -68.174805, -46.036274, ..., -54.829018, -77.21582 ,\n         -71.01514 ], dtype=float32),\n  'neuropil_fluorescence': array([-136.17049, -131.01202, -128.53442, ..., -142.85028, -131.8787 ,\n         -137.03934], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 807,\n  'fluo_channel': 0,\n  'fluorescence': array([-199.08557, -153.4967 , -211.71552, ..., -123.4533 , -166.0659 ,\n         -104.56361], dtype=float32),\n  'neuropil_fluorescence': array([-188.73009, -187.09293, -177.32744, ..., -186.25   , -182.8208 ,\n         -187.1062 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 808,\n  'fluo_channel': 0,\n  'fluorescence': array([-210.63577, -228.30605, -233.30121, ..., -220.394  , -242.58087,\n         -218.87892], dtype=float32),\n  'neuropil_fluorescence': array([-220.0626 , -210.5774 , -204.8087 , ..., -218.52696, -209.47304,\n         -217.14957], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 809,\n  'fluo_channel': 0,\n  'fluorescence': array([-180.68387, -236.36177, -195.34789, ..., -208.7744 , -175.97102,\n         -182.67957], dtype=float32),\n  'neuropil_fluorescence': array([-167.1787 , -171.38487, -164.57216, ..., -178.87285, -185.3024 ,\n         -189.63231], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 810,\n  'fluo_channel': 0,\n  'fluorescence': array([-248.58534, -246.17465, -210.31111, ..., -228.10928, -170.46188,\n         -192.207  ], dtype=float32),\n  'neuropil_fluorescence': array([-252.03107, -250.5339 , -235.63277, ..., -247.31921, -250.86159,\n         -246.66667], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 811,\n  'fluo_channel': 0,\n  'fluorescence': array([-227.80417, -173.41113, -159.36694, ..., -171.96967, -152.4379 ,\n         -149.20538], dtype=float32),\n  'neuropil_fluorescence': array([-185.14355, -181.98282, -178.57669, ..., -193.00613, -194.34233,\n         -201.16565], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 812,\n  'fluo_channel': 0,\n  'fluorescence': array([-189.87439, -233.75024, -182.22198, ..., -205.95566, -214.50583,\n         -215.78217], dtype=float32),\n  'neuropil_fluorescence': array([-224.89926, -226.60445, -220.12445, ..., -218.65038, -225.21481,\n         -217.47556], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 813,\n  'fluo_channel': 0,\n  'fluorescence': array([ -99.77002 ,  -89.91161 ,  -91.51027 , ..., -132.45317 ,\n         -171.5174  ,  -92.933395], dtype=float32),\n  'neuropil_fluorescence': array([-168.31342, -173.60744, -164.68658, ..., -180.17447, -179.15024,\n         -168.85138], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 814,\n  'fluo_channel': 0,\n  'fluorescence': array([-139.71059,  -83.3414 , -162.29128, ..., -165.42189, -162.02287,\n         -142.00525], dtype=float32),\n  'neuropil_fluorescence': array([-190.77167, -179.53833, -178.67   , ..., -195.725  , -193.89166,\n         -195.81833], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 815,\n  'fluo_channel': 0,\n  'fluorescence': array([-238.99089, -211.33762, -267.8564 , ..., -255.31332, -271.69632,\n         -249.0028 ], dtype=float32),\n  'neuropil_fluorescence': array([-249.96233, -250.65508, -244.72464, ..., -257.83914, -254.1971 ,\n         -253.4855 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 816,\n  'fluo_channel': 0,\n  'fluorescence': array([-133.99675, -146.84651, -164.87036, ..., -160.89626, -174.29097,\n         -196.20546], dtype=float32),\n  'neuropil_fluorescence': array([-193.81151, -188.27635, -192.54633, ..., -202.50958, -190.71565,\n         -198.29872], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 817,\n  'fluo_channel': 0,\n  'fluorescence': array([-167.35982, -178.38077, -200.23999, ..., -159.68828, -173.12587,\n         -173.64363], dtype=float32),\n  'neuropil_fluorescence': array([-228.37804, -218.08078, -224.83037, ..., -214.02423, -214.92245,\n         -214.87883], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 818,\n  'fluo_channel': 0,\n  'fluorescence': array([-185.90324 , -195.33138 , -221.59949 , ...,  -78.40014 ,\n         -134.90666 , -102.961655], dtype=float32),\n  'neuropil_fluorescence': array([-213.50296, -214.44379, -221.02367, ..., -223.12032, -221.41026,\n         -216.94872], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 819,\n  'fluo_channel': 0,\n  'fluorescence': array([-245.57033 ,  -81.41608 ,  119.1451  , ..., -132.47781 ,\n          -40.779552, -161.25784 ], dtype=float32),\n  'neuropil_fluorescence': array([-189.57143, -189.66884, -185.29654, ..., -177.61905, -188.56494,\n         -189.54112], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 820,\n  'fluo_channel': 0,\n  'fluorescence': array([-243.71336, -196.20837, -218.22978, ..., -183.83354, -202.48697,\n         -208.41028], dtype=float32),\n  'neuropil_fluorescence': array([-217.55211, -209.77667, -215.10794, ..., -214.17618, -212.63524,\n         -214.23822], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 821,\n  'fluo_channel': 0,\n  'fluorescence': array([-141.77461, -135.81442, -120.30414, ..., -175.78731, -172.23352,\n         -215.47824], dtype=float32),\n  'neuropil_fluorescence': array([-165.8339 , -154.1495 , -156.52159, ..., -157.33554, -158.43355,\n         -161.3422 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 822,\n  'fluo_channel': 0,\n  'fluorescence': array([-244.91669, -242.90634, -250.0064 , ..., -244.83987, -255.23636,\n         -252.54726], dtype=float32),\n  'neuropil_fluorescence': array([-255.3855 , -249.66031, -246.26527, ..., -247.34734, -252.15076,\n         -246.31107], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 823,\n  'fluo_channel': 0,\n  'fluorescence': array([-114.13576 ,  -19.655617,  -86.107086, ...,  -76.0918  ,\n         -115.915054,  -78.738945], dtype=float32),\n  'neuropil_fluorescence': array([-156.16917, -138.46992, -168.04512, ..., -156.93797, -154.0094 ,\n         -154.453  ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 824,\n  'fluo_channel': 0,\n  'fluorescence': array([ -30.48367 ,  -23.376513,  229.74347 , ..., -181.217   ,\n         -210.46558 , -208.90372 ], dtype=float32),\n  'neuropil_fluorescence': array([-206.93646, -203.58287, -202.9116 , ..., -189.31491, -210.67957,\n         -195.79558], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 825,\n  'fluo_channel': 0,\n  'fluorescence': array([-169.31262, -138.48804, -207.39827, ..., -164.6641 , -236.13966,\n         -166.435  ], dtype=float32),\n  'neuropil_fluorescence': array([-176.42383, -179.75264, -187.75113, ..., -178.9457 , -171.80544,\n         -178.25943], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 826,\n  'fluo_channel': 0,\n  'fluorescence': array([-117.81249 , -213.24226 ,  -32.643238, ..., -145.58365 ,\n          -60.54205 ,  -59.143784], dtype=float32),\n  'neuropil_fluorescence': array([-155.3842 , -161.41144, -148.45505, ..., -148.40054, -139.15804,\n         -145.88556], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 827,\n  'fluo_channel': 0,\n  'fluorescence': array([-201.16739, -189.19139, -114.55857, ..., -143.07845, -146.31786,\n         -141.71854], dtype=float32),\n  'neuropil_fluorescence': array([-192.34073, -169.24248, -162.56577, ..., -174.43582, -169.95087,\n         -152.4691 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 828,\n  'fluo_channel': 0,\n  'fluorescence': array([-266.87122, -266.5055 , -253.53957, ..., -244.82304, -270.09622,\n         -261.91998], dtype=float32),\n  'neuropil_fluorescence': array([-259.06888, -257.11847, -254.75482, ..., -258.7135 , -257.2438 ,\n         -256.40497], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 829,\n  'fluo_channel': 0,\n  'fluorescence': array([-260.9661 , -246.84438, -252.01881, ..., -247.39746, -241.86821,\n         -232.57518], dtype=float32),\n  'neuropil_fluorescence': array([-257.82266, -253.49478, -250.32639, ..., -256.88675, -253.20865,\n         -256.31744], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 830,\n  'fluo_channel': 0,\n  'fluorescence': array([-114.840515, -110.8344  ,  -15.895863, ..., -167.73436 ,\n          -98.716644,  -98.56726 ], dtype=float32),\n  'neuropil_fluorescence': array([-155.28175, -140.52931, -131.45439, ..., -146.0684 , -140.14333,\n         -139.91043], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 831,\n  'fluo_channel': 0,\n  'fluorescence': array([-213.08923, -219.07045, -248.056  , ..., -249.2061 , -189.05919,\n         -237.05038], dtype=float32),\n  'neuropil_fluorescence': array([-196.22191, -192.7191 , -198.33427, ..., -198.41011, -196.99158,\n         -187.3455 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 832,\n  'fluo_channel': 0,\n  'fluorescence': array([-222.45995, -219.10162, -214.97757, ..., -213.09764, -232.79433,\n         -225.31683], dtype=float32),\n  'neuropil_fluorescence': array([-239.76938, -234.66052, -234.36531, ..., -240.55904, -244.07565,\n         -237.77306], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 833,\n  'fluo_channel': 0,\n  'fluorescence': array([-120.114075, -143.52544 ,  -87.99677 , ...,  -98.42051 ,\n         -102.97729 ,  -75.40967 ], dtype=float32),\n  'neuropil_fluorescence': array([-142.91435, -128.28967, -129.73552, ..., -116.41814, -119.46096,\n         -141.79597], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 834,\n  'fluo_channel': 0,\n  'fluorescence': array([-144.3291 , -175.98048, -143.25117, ...,  -98.53779, -158.13667,\n         -157.0878 ], dtype=float32),\n  'neuropil_fluorescence': array([-105.31042 ,  -81.42917 ,  -77.120834, ...,  -83.625   ,\n          -91.18542 ,  -80.58125 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 835,\n  'fluo_channel': 0,\n  'fluorescence': array([-224.63086, -198.2158 , -194.04759, ..., -244.34512, -225.73361,\n         -264.16537], dtype=float32),\n  'neuropil_fluorescence': array([-199.97693, -187.44481, -199.08401, ..., -195.21582, -192.70511,\n         -190.43327], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 836,\n  'fluo_channel': 0,\n  'fluorescence': array([-161.42122 , -155.38814 , -178.665   , ..., -121.737564,\n         -195.77388 , -183.40727 ], dtype=float32),\n  'neuropil_fluorescence': array([-193.99268, -177.75824, -171.88828, ..., -217.3956 , -211.62088,\n         -214.85898], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 837,\n  'fluo_channel': 0,\n  'fluorescence': array([-227.61876 , -190.48544 ,   -9.966566, ..., -246.58835 ,\n         -214.55478 , -167.13106 ], dtype=float32),\n  'neuropil_fluorescence': array([-167.89871, -149.93555, -142.77716, ..., -158.814  , -168.14917,\n         -171.74402], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 838,\n  'fluo_channel': 0,\n  'fluorescence': array([-168.44739, -153.46498, -166.69736, ..., -171.21019, -172.75343,\n         -149.25555], dtype=float32),\n  'neuropil_fluorescence': array([-145.32486, -148.99455, -151.4991 , ..., -147.31941, -146.60435,\n         -137.85118], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 839,\n  'fluo_channel': 0,\n  'fluorescence': array([-142.92722, -160.8235 , -157.68605, ..., -167.23692, -139.09535,\n         -170.1716 ], dtype=float32),\n  'neuropil_fluorescence': array([-138.52965 , -130.59947 , -122.711464, ..., -137.91832 ,\n         -127.97892 , -129.54941 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 840,\n  'fluo_channel': 0,\n  'fluorescence': array([-152.52042, -116.3814 , -154.93259, ..., -168.37413, -172.0074 ,\n         -195.22112], dtype=float32),\n  'neuropil_fluorescence': array([-188.19037, -180.85542, -180.74458, ..., -184.1253 , -186.08434,\n         -196.2482 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 841,\n  'fluo_channel': 0,\n  'fluorescence': array([-212.9798 , -219.15445, -237.71436, ..., -228.95705, -234.73389,\n         -233.81111], dtype=float32),\n  'neuropil_fluorescence': array([-239.19266, -234.3188 , -231.83487, ..., -236.43349, -237.69037,\n         -232.04358], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 842,\n  'fluo_channel': 0,\n  'fluorescence': array([-130.46996 , -180.93172 ,  -95.7045  , ..., -108.053116,\n          -93.30031 , -104.148926], dtype=float32),\n  'neuropil_fluorescence': array([-151.98842, -144.29813, -137.85239, ..., -148.15485, -138.07814,\n         -141.8683 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 843,\n  'fluo_channel': 0,\n  'fluorescence': array([-202.96779, -185.48125, -159.39961, ..., -216.45848, -189.78664,\n         -157.92097], dtype=float32),\n  'neuropil_fluorescence': array([-156.35115, -138.76335, -143.     , ..., -169.43765, -147.07379,\n         -151.3308 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 844,\n  'fluo_channel': 0,\n  'fluorescence': array([-102.33958, -144.6884 , -105.17843, ..., -196.07698, -145.69548,\n         -141.56146], dtype=float32),\n  'neuropil_fluorescence': array([-182.84174, -171.64174, -164.20348, ..., -183.59653, -176.01913,\n         -172.36348], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 845,\n  'fluo_channel': 0,\n  'fluorescence': array([-169.837  , -168.23763, -187.6213 , ..., -185.92137, -197.71687,\n         -154.74927], dtype=float32),\n  'neuropil_fluorescence': array([-194.01279, -190.30946, -205.27621, ..., -199.4041 , -193.66496,\n         -190.41943], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 846,\n  'fluo_channel': 0,\n  'fluorescence': array([-175.79958 ,   15.248163, -258.84488 , ..., -186.26492 ,\n         -129.62184 ,  -70.57016 ], dtype=float32),\n  'neuropil_fluorescence': array([-136.15802, -145.87407, -136.36049, ..., -143.63951, -144.62222,\n         -148.91357], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 847,\n  'fluo_channel': 0,\n  'fluorescence': array([-201.47034, -157.92819, -194.5286 , ..., -236.53885, -192.88612,\n         -171.35345], dtype=float32),\n  'neuropil_fluorescence': array([-219.26382, -211.74184, -213.40709, ..., -214.90923, -210.0454 ,\n         -205.95886], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 848,\n  'fluo_channel': 0,\n  'fluorescence': array([-120.607185, -169.32959 , -212.63611 , ...,  -68.958244,\n         -191.04604 , -195.14833 ], dtype=float32),\n  'neuropil_fluorescence': array([-199.24814, -205.49814, -199.37874, ..., -200.85262, -189.98508,\n         -192.44029], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 849,\n  'fluo_channel': 0,\n  'fluorescence': array([-10.618191 ,  -5.714352 , -15.409399 , ...,   2.0386207,\n         -22.251492 ,  38.816856 ], dtype=float32),\n  'neuropil_fluorescence': array([-162.17717, -152.3084 , -156.51837, ..., -149.3937 , -148.90552,\n         -146.08923], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 850,\n  'fluo_channel': 0,\n  'fluorescence': array([-261.3212 , -261.67462, -262.32678, ..., -257.34137, -253.1168 ,\n         -260.66434], dtype=float32),\n  'neuropil_fluorescence': array([-255.46542, -257.5271 , -258.85422, ..., -256.88785, -254.92711,\n         -255.80748], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 851,\n  'fluo_channel': 0,\n  'fluorescence': array([-189.73732, -173.03354, -165.42523, ..., -156.06807, -197.9551 ,\n         -185.42271], dtype=float32),\n  'neuropil_fluorescence': array([-193.92728, -197.18863, -189.92728, ..., -196.425  , -202.19772,\n         -188.425  ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 852,\n  'fluo_channel': 0,\n  'fluorescence': array([-274.10266, -276.51355, -259.26242, ..., -273.551  , -279.89578,\n         -271.53055], dtype=float32),\n  'neuropil_fluorescence': array([-278.17657, -276.72305, -275.70633, ..., -273.94797, -273.5818 ,\n         -277.25278], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 853,\n  'fluo_channel': 0,\n  'fluorescence': array([ -18.0062  , -139.16515 ,  -21.890457, ..., -168.14864 ,\n         -128.75255 , -192.28    ], dtype=float32),\n  'neuropil_fluorescence': array([-196.2328 , -186.76897, -191.65608, ..., -184.90123, -188.58025,\n         -189.07231], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 854,\n  'fluo_channel': 0,\n  'fluorescence': array([-128.10277, -162.41931, -131.89406, ..., -163.4011 , -139.2274 ,\n         -132.42877], dtype=float32),\n  'neuropil_fluorescence': array([-203.51286, -197.87897, -184.09682, ..., -202.24054, -200.21332,\n         -201.78215], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 855,\n  'fluo_channel': 0,\n  'fluorescence': array([-129.2458 , -147.05418, -159.00787, ..., -159.11134, -167.60934,\n         -118.79126], dtype=float32),\n  'neuropil_fluorescence': array([-191.05394, -196.5955 , -198.24944, ..., -194.90787, -199.06966,\n         -202.65393], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 856,\n  'fluo_channel': 0,\n  'fluorescence': array([-110.29295 ,  -81.68662 , -106.901825, ...,  -96.0791  ,\n          -90.06974 ,  -99.988945], dtype=float32),\n  'neuropil_fluorescence': array([-112.66525, -103.42796,  -94.98305, ...,  -80.18362,  -97.72881,\n         -101.23588], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 857,\n  'fluo_channel': 0,\n  'fluorescence': array([-112.39204 ,  -73.94268 , -110.83248 , ...,  -83.75138 ,\n          -67.789474,  -94.865036], dtype=float32),\n  'neuropil_fluorescence': array([-165.9974 , -173.87938, -172.1751 , ..., -167.72115, -155.32166,\n         -159.44098], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 858,\n  'fluo_channel': 0,\n  'fluorescence': array([ -86.51718 , -127.254944,  -79.117294, ..., -131.07986 ,\n          -85.56416 , -102.60556 ], dtype=float32),\n  'neuropil_fluorescence': array([-158.59409, -171.03226, -155.5242 , ..., -154.06451, -163.79033,\n         -146.06989], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 859,\n  'fluo_channel': 0,\n  'fluorescence': array([-109.04914, -123.23594, -140.10187, ..., -110.63604, -121.97067,\n          -93.7342 ], dtype=float32),\n  'neuropil_fluorescence': array([-207.59538, -205.68764, -203.61006, ..., -203.76729, -205.80504,\n         -208.22432], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 860,\n  'fluo_channel': 0,\n  'fluorescence': array([ -89.33455 ,  -94.27865 ,  -14.689084, ...,  -84.81268 ,\n          -99.7453  , -103.16487 ], dtype=float32),\n  'neuropil_fluorescence': array([-186.67546, -184.47493, -188.22163, ..., -198.87335, -205.16887,\n         -213.89973], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 861,\n  'fluo_channel': 0,\n  'fluorescence': array([-172.82338, -221.74019, -107.75824, ..., -208.84077, -119.7059 ,\n         -177.65927], dtype=float32),\n  'neuropil_fluorescence': array([-191.375  , -177.35625, -174.10208, ..., -187.5625 , -182.19167,\n         -187.52292], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 862,\n  'fluo_channel': 0,\n  'fluorescence': array([-184.74098, -196.50594, -228.00484, ..., -123.90244, -218.68445,\n         -184.0111 ], dtype=float32),\n  'neuropil_fluorescence': array([-195.46582, -189.66187, -190.60252, ..., -194.55215, -187.44064,\n         -192.4982 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 863,\n  'fluo_channel': 0,\n  'fluorescence': array([-152.74959, -225.01752, -112.93787, ..., -225.82901, -203.22003,\n         -215.8328 ], dtype=float32),\n  'neuropil_fluorescence': array([-168.22362, -174.12701, -161.80322, ..., -168.77103, -175.71735,\n         -177.59035], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 864,\n  'fluo_channel': 0,\n  'fluorescence': array([-239.56238, -248.8692 , -230.79199, ..., -245.77579, -256.6419 ,\n         -237.07564], dtype=float32),\n  'neuropil_fluorescence': array([-257.19318, -252.98181, -252.21591, ..., -258.11365, -258.28183,\n         -258.3682 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 865,\n  'fluo_channel': 0,\n  'fluorescence': array([-173.85509 , -202.90556 ,  -77.271515, ...,  -85.31194 ,\n         -183.84941 , -138.79306 ], dtype=float32),\n  'neuropil_fluorescence': array([-161.01852, -172.22896, -162.24579, ..., -170.41414, -169.79967,\n         -171.94444], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 866,\n  'fluo_channel': 0,\n  'fluorescence': array([-103.84259 , -125.7338  , -123.11113 , ...,  -74.952934,\n           -6.619964,  -78.04032 ], dtype=float32),\n  'neuropil_fluorescence': array([-139.72632, -148.55438, -142.05438, ..., -146.05087, -139.85965,\n         -145.19649], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 867,\n  'fluo_channel': 0,\n  'fluorescence': array([  11.045608,  -38.553696,  -85.67161 , ...,  -87.459236,\n         -136.98775 ,  -11.369106], dtype=float32),\n  'neuropil_fluorescence': array([-151.98375, -165.80325, -156.6408 , ..., -156.87546, -158.90974,\n         -157.10649], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 868,\n  'fluo_channel': 0,\n  'fluorescence': array([-187.0051 , -206.04315, -244.00058, ..., -234.72438, -207.171  ,\n         -223.19466], dtype=float32),\n  'neuropil_fluorescence': array([-235.09007, -232.26622, -228.07814, ..., -227.19867, -231.35762,\n         -228.98146], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 869,\n  'fluo_channel': 0,\n  'fluorescence': array([-47.074806, -83.02101 ,  20.128397, ...,  93.00578 ,  14.054504,\n         -70.05716 ], dtype=float32),\n  'neuropil_fluorescence': array([-119.797295,  -93.3491  , -101.63739 , ..., -106.65991 ,\n         -102.822075,  -87.63288 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 870,\n  'fluo_channel': 0,\n  'fluorescence': array([-161.29387, -132.17377, -117.57474, ..., -155.83421, -173.03328,\n         -116.92914], dtype=float32),\n  'neuropil_fluorescence': array([-174.52606, -158.79405, -163.9206 , ..., -167.83374, -160.3325 ,\n         -158.38957], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 871,\n  'fluo_channel': 0,\n  'fluorescence': array([-115.07484 , -122.870056, -128.23706 , ...,  -40.61209 ,\n          -57.580494,  -70.71657 ], dtype=float32),\n  'neuropil_fluorescence': array([-163.74185, -154.49185, -164.63858, ..., -186.14403, -179.03804,\n         -179.45381], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 872,\n  'fluo_channel': 0,\n  'fluorescence': array([-144.54672  ,  -13.3247595, -127.78941  , ...,  -15.210283 ,\n         -123.80369  , -171.452    ], dtype=float32),\n  'neuropil_fluorescence': array([-165.97722, -180.83827, -165.28246, ..., -158.40091, -164.98178,\n         -173.29385], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 873,\n  'fluo_channel': 0,\n  'fluorescence': array([-158.23334, -199.43936, -166.1429 , ..., -178.92784, -169.34288,\n         -181.23903], dtype=float32),\n  'neuropil_fluorescence': array([-226.14806, -225.14806, -226.90533, ..., -227.67961, -223.34952,\n         -215.04126], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 874,\n  'fluo_channel': 0,\n  'fluorescence': array([-172.96048 ,  -73.06844 , -166.51895 , ..., -164.03856 ,\n          -46.154007, -145.92775 ], dtype=float32),\n  'neuropil_fluorescence': array([-164.80571, -169.24777, -168.55615, ..., -162.53654, -165.89484,\n         -160.12122], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 875,\n  'fluo_channel': 0,\n  'fluorescence': array([ -89.94247 ,  -94.960625, -163.26562 , ..., -186.20021 ,\n         -180.3814  , -103.21429 ], dtype=float32),\n  'neuropil_fluorescence': array([-172.35007, -164.34564, -165.94682, ..., -166.5938 , -165.69276,\n         -177.18611], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 876,\n  'fluo_channel': 0,\n  'fluorescence': array([-249.95241, -230.01604, -236.2133 , ..., -142.9753 , -189.12253,\n         -231.52563], dtype=float32),\n  'neuropil_fluorescence': array([-228.97606, -220.33511, -221.60106, ..., -226.875  , -217.86967,\n         -222.74467], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 877,\n  'fluo_channel': 0,\n  'fluorescence': array([-154.53299 , -139.31665 ,  -86.95863 , ..., -200.66855 ,\n          -45.420498, -135.35434 ], dtype=float32),\n  'neuropil_fluorescence': array([-170.72871, -166.29901, -160.21387, ..., -159.48317, -162.32475,\n         -170.18217], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 878,\n  'fluo_channel': 0,\n  'fluorescence': array([ 69.394035,  98.49948 , -91.59274 , ...,  96.77296 , 142.42033 ,\n         150.36298 ], dtype=float32),\n  'neuropil_fluorescence': array([-140.5153 , -127.8852 , -125.17092, ..., -112.65306, -121.08673,\n         -102.10204], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 879,\n  'fluo_channel': 0,\n  'fluorescence': array([-210.53308, -215.97945, -249.15027, ..., -243.60794, -240.09291,\n         -217.06708], dtype=float32),\n  'neuropil_fluorescence': array([-237.72652, -229.19337, -237.79834, ..., -230.54697, -233.43922,\n         -238.32597], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 880,\n  'fluo_channel': 0,\n  'fluorescence': array([-200.25764, -104.82799, -215.88712, ..., -213.03908, -143.99495,\n         -158.014  ], dtype=float32),\n  'neuropil_fluorescence': array([-189.13972, -196.81947, -192.61067, ..., -195.59811, -179.62323,\n         -188.07849], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 881,\n  'fluo_channel': 0,\n  'fluorescence': array([-144.01656 , -103.17052 , -108.547844, ...,  -89.63725 ,\n          -19.922525, -156.52101 ], dtype=float32),\n  'neuropil_fluorescence': array([-147.80922, -152.04929, -164.15103, ..., -144.20349, -145.05882,\n         -157.97139], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 882,\n  'fluo_channel': 0,\n  'fluorescence': array([-247.843  , -232.49509, -215.89847, ..., -157.37398, -189.6741 ,\n         -196.1649 ], dtype=float32),\n  'neuropil_fluorescence': array([-207.07648, -209.56854, -189.64502, ..., -198.8023 , -201.75325,\n         -194.90475], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 883,\n  'fluo_channel': 0,\n  'fluorescence': array([-104.33463 , -112.19703 , -100.052185, ...,  -80.55807 ,\n         -133.52905 , -184.18391 ], dtype=float32),\n  'neuropil_fluorescence': array([-160.50204, -162.38115, -154.52254, ..., -149.47336, -152.0246 ,\n         -145.46721], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 884,\n  'fluo_channel': 0,\n  'fluorescence': array([-197.73857, -201.34505, -175.07562, ..., -219.95175, -212.66331,\n         -204.8127 ], dtype=float32),\n  'neuropil_fluorescence': array([-211.36993, -204.73032, -203.05489, ..., -204.7494 , -205.0382 ,\n         -208.20525], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 885,\n  'fluo_channel': 0,\n  'fluorescence': array([ -40.025364, -270.00684 ,  -87.51501 , ..., -233.23894 ,\n         -192.25273 , -208.72249 ], dtype=float32),\n  'neuropil_fluorescence': array([-143.37065, -141.77861, -136.29851, ..., -152.33582, -149.45274,\n         -155.9602 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 886,\n  'fluo_channel': 0,\n  'fluorescence': array([-190.78233, -182.98203, -175.292  , ..., -164.3175 , -194.14952,\n         -192.61029], dtype=float32),\n  'neuropil_fluorescence': array([-214.57143, -210.56085, -219.08466, ..., -211.83333, -212.45767,\n         -209.67195], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 887,\n  'fluo_channel': 0,\n  'fluorescence': array([-132.62827,  -96.24412, -110.53209, ...,  -54.20225,  -69.16483,\n          -72.35414], dtype=float32),\n  'neuropil_fluorescence': array([-153.49197, -150.10695, -151.10294, ..., -131.83423, -139.60695,\n         -146.31418], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 888,\n  'fluo_channel': 0,\n  'fluorescence': array([-178.88695, -176.21622, -194.31439, ..., -205.8401 , -178.12837,\n         -224.85521], dtype=float32),\n  'neuropil_fluorescence': array([-206.5831 , -211.0654 , -207.11989, ..., -217.66757, -219.67847,\n         -219.0218 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 889,\n  'fluo_channel': 0,\n  'fluorescence': array([-187.11176, -222.39943,  -89.45349, ..., -149.69118, -242.8378 ,\n         -112.29325], dtype=float32),\n  'neuropil_fluorescence': array([-123.142624, -129.10281 , -121.45439 , ..., -140.83748 ,\n         -133.0199  , -131.52405 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 890,\n  'fluo_channel': 0,\n  'fluorescence': array([-146.62793, -179.31114, -199.54218, ..., -171.24281, -208.41951,\n         -181.3257 ], dtype=float32),\n  'neuropil_fluorescence': array([-173.51389, -173.59375, -164.95139, ..., -165.08855, -172.6875 ,\n         -170.47917], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 891,\n  'fluo_channel': 0,\n  'fluorescence': array([-205.36229, -219.5235 , -170.28183, ..., -208.4725 , -199.10751,\n         -166.89592], dtype=float32),\n  'neuropil_fluorescence': array([-190.74954, -196.76576, -191.51892, ..., -200.47208, -182.28468,\n         -196.75856], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 892,\n  'fluo_channel': 0,\n  'fluorescence': array([-181.20877, -197.93279, -132.68265, ..., -180.05647, -109.55873,\n         -207.40178], dtype=float32),\n  'neuropil_fluorescence': array([-189.7395 , -174.05882, -177.9818 , ..., -182.70589, -181.13446,\n         -183.79692], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 893,\n  'fluo_channel': 0,\n  'fluorescence': array([-189.27138, -174.01271, -237.4017 , ..., -245.27112, -160.346  ,\n         -239.39107], dtype=float32),\n  'neuropil_fluorescence': array([-240.73425, -242.48228, -235.4685 , ..., -234.5    , -243.76181,\n         -237.02362], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 894,\n  'fluo_channel': 0,\n  'fluorescence': array([-102.3718   , -214.01353  ,  -65.16603  , ..., -168.94409  ,\n           -6.6211634,   16.823711 ], dtype=float32),\n  'neuropil_fluorescence': array([-171.59369, -169.62697, -159.09457, ..., -162.04553, -160.3205 ,\n         -165.97372], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 895,\n  'fluo_channel': 0,\n  'fluorescence': array([-246.09775, -176.42111, -189.70789, ..., -212.50954, -155.69348,\n         -235.72171], dtype=float32),\n  'neuropil_fluorescence': array([-232.68579, -228.64563, -227.28981, ..., -225.06026, -231.22238,\n         -227.37303], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 896,\n  'fluo_channel': 0,\n  'fluorescence': array([-201.0091 , -190.94016, -203.85579, ..., -218.01292, -241.8403 ,\n         -217.73032], dtype=float32),\n  'neuropil_fluorescence': array([-230.7388 , -223.47612, -231.69702, ..., -229.18358, -226.62686,\n         -228.89253], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 897,\n  'fluo_channel': 0,\n  'fluorescence': array([-192.08781, -155.8448 , -197.8108 , ..., -218.29459, -199.66656,\n         -218.66853], dtype=float32),\n  'neuropil_fluorescence': array([-226.35957, -223.96063, -226.45932, ..., -220.94751, -226.95013,\n         -221.7454 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 898,\n  'fluo_channel': 0,\n  'fluorescence': array([-135.29564 , -222.29636 , -236.54796 , ..., -118.198784,\n         -224.91515 , -235.07101 ], dtype=float32),\n  'neuropil_fluorescence': array([-169.71933, -168.90973, -175.11002, ..., -176.15656, -189.36812,\n         -185.11707], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 899,\n  'fluo_channel': 0,\n  'fluorescence': array([-198.64719, -132.01129, -278.28   , ..., -207.60617, -271.0369 ,\n         -271.07294], dtype=float32),\n  'neuropil_fluorescence': array([-231.36511, -216.51628, -225.52791, ..., -218.37442, -222.47906,\n         -216.57442], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 900,\n  'fluo_channel': 0,\n  'fluorescence': array([-126.12273 ,   50.989006,  -85.35864 , ...,  -26.875452,\n         -144.3209  ,  -79.32656 ], dtype=float32),\n  'neuropil_fluorescence': array([-147.21413, -156.54745, -138.77704, ..., -150.94923, -145.32451,\n         -155.09052], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 901,\n  'fluo_channel': 0,\n  'fluorescence': array([-194.28627, -222.8218 , -195.74817, ..., -128.44887, -182.63762,\n         -127.43348], dtype=float32),\n  'neuropil_fluorescence': array([-208.53937, -204.70854, -204.08543, ..., -210.11055, -206.66331,\n         -207.32495], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 902,\n  'fluo_channel': 0,\n  'fluorescence': array([-237.37318, -220.6563 , -130.59772, ..., -219.39098, -156.85211,\n         -223.56369], dtype=float32),\n  'neuropil_fluorescence': array([-171.99298, -167.06316, -160.11403, ..., -157.5193 , -164.81404,\n         -161.34035], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 903,\n  'fluo_channel': 0,\n  'fluorescence': array([-217.11026, -199.53758, -217.53587, ..., -191.76419, -202.95244,\n         -226.42525], dtype=float32),\n  'neuropil_fluorescence': array([-204.06396, -206.93604, -202.95164, ..., -205.81747, -215.04211,\n         -208.06396], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 904,\n  'fluo_channel': 0,\n  'fluorescence': array([ -96.751625, -194.71902 ,  -63.789783, ..., -177.31334 ,\n         -149.29514 , -170.61612 ], dtype=float32),\n  'neuropil_fluorescence': array([-196.55878, -197.88426, -203.24774, ..., -188.59132, -202.28029,\n         -196.55334], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 905,\n  'fluo_channel': 0,\n  'fluorescence': array([-185.93718, -176.9711 , -134.46071, ..., -142.96635, -157.66202,\n         -187.99147], dtype=float32),\n  'neuropil_fluorescence': array([-219.3926 , -214.75803, -210.92346, ..., -216.48642, -207.7284 ,\n         -210.97778], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 906,\n  'fluo_channel': 0,\n  'fluorescence': array([-216.0474  , -222.94983 , -143.7971  , ...,   25.699352,\n         -283.455   , -282.11597 ], dtype=float32),\n  'neuropil_fluorescence': array([-228.83775, -221.96754, -229.64897, ..., -230.89233, -222.30383,\n         -236.88643], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 907,\n  'fluo_channel': 0,\n  'fluorescence': array([-131.90086 , -123.542404, -111.23049 , ...,  -63.56282 ,\n          -89.6418  , -129.91245 ], dtype=float32),\n  'neuropil_fluorescence': array([-115.507355, -116.242645, -124.35539 , ..., -111.45098 ,\n         -119.629906, -125.92157 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 908,\n  'fluo_channel': 0,\n  'fluorescence': array([-40.98808  , -86.2093   , -11.400545 , ...,  -8.373084 ,\n         -41.947292 ,  -7.6051617], dtype=float32),\n  'neuropil_fluorescence': array([-122.48351 , -127.34223 , -117.42072 , ..., -120.20408 ,\n         -122.287285, -117.94977 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 909,\n  'fluo_channel': 0,\n  'fluorescence': array([-262.80585, -188.19467, -207.95087, ..., -240.26532, -266.72345,\n         -252.34799], dtype=float32),\n  'neuropil_fluorescence': array([-257.63412, -259.3865 , -253.20358, ..., -254.86383, -257.7084 ,\n         -260.53784], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 910,\n  'fluo_channel': 0,\n  'fluorescence': array([ -59.583195,   15.504307,  -28.1382  , ..., -131.13991 ,\n         -137.68477 ,  -44.49968 ], dtype=float32),\n  'neuropil_fluorescence': array([-157.04042, -151.22672, -139.96309, ..., -160.28647, -168.72583,\n         -162.58348], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 911,\n  'fluo_channel': 0,\n  'fluorescence': array([-248.6246 , -237.53337, -250.70457, ..., -271.6498 , -243.48778,\n         -283.86197], dtype=float32),\n  'neuropil_fluorescence': array([-261.83255, -262.17053, -263.7256 , ..., -264.2403 , -260.2651 ,\n         -267.2744 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 912,\n  'fluo_channel': 0,\n  'fluorescence': array([-208.41113, -177.6537 , -179.37665, ..., -168.16927, -157.28267,\n         -200.57199], dtype=float32),\n  'neuropil_fluorescence': array([-207.62216, -203.41904, -208.25853, ..., -200.53693, -203.723  ,\n         -194.95738], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 913,\n  'fluo_channel': 0,\n  'fluorescence': array([ -68.2993  , -178.42665 ,  -51.460564, ..., -102.543015,\n          -84.02238 , -234.71436 ], dtype=float32),\n  'neuropil_fluorescence': array([-188.185  , -189.15881, -192.29843, ..., -184.274  , -185.02618,\n         -185.15881], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 914,\n  'fluo_channel': 0,\n  'fluorescence': array([-110.144035, -140.16605 , -123.16182 , ..., -151.76007 ,\n          -98.2483  , -219.61127 ], dtype=float32),\n  'neuropil_fluorescence': array([-174.48422, -171.38013, -165.19559, ..., -170.80284, -175.31073,\n         -172.37381], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 915,\n  'fluo_channel': 0,\n  'fluorescence': array([ -69.86676 ,  -42.944824,  -54.954807, ..., -109.30866 ,\n          -70.52138 ,  -72.264496], dtype=float32),\n  'neuropil_fluorescence': array([-159.81023, -162.41423, -166.57846, ..., -168.9562 , -168.66423,\n         -168.2573 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 916,\n  'fluo_channel': 0,\n  'fluorescence': array([-165.26039, -142.24806, -169.62921, ..., -149.42068, -185.52048,\n         -169.7697 ], dtype=float32),\n  'neuropil_fluorescence': array([-185.39523, -180.6167 , -192.57411, ..., -191.16014, -180.5707 ,\n         -192.25554], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 917,\n  'fluo_channel': 0,\n  'fluorescence': array([ -65.4411  ,    8.383917,  -67.7347  , ..., -119.33582 ,\n         -108.544   , -132.85193 ], dtype=float32),\n  'neuropil_fluorescence': array([-168.82684, -171.81169, -154.87447, ..., -161.60173, -171.75757,\n         -166.50217], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 918,\n  'fluo_channel': 0,\n  'fluorescence': array([-188.44049, -158.21252, -131.02472, ..., -135.597  , -105.21483,\n         -140.76463], dtype=float32),\n  'neuropil_fluorescence': array([-168.1614 , -168.74387, -161.74036, ..., -165.96666, -162.98596,\n         -162.55789], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 919,\n  'fluo_channel': 0,\n  'fluorescence': array([-129.86037, -201.7487 , -239.04384, ..., -219.07376, -218.73184,\n         -190.82594], dtype=float32),\n  'neuropil_fluorescence': array([-209.54913, -203.05347, -213.48122, ..., -205.93063, -205.50578,\n         -193.16185], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 920,\n  'fluo_channel': 0,\n  'fluorescence': array([-168.41182 , -147.41495 , -117.504906, ..., -185.99348 ,\n         -133.24362 , -137.15204 ], dtype=float32),\n  'neuropil_fluorescence': array([-164.70084, -154.17978, -163.71489, ..., -177.48596, -172.21068,\n         -174.41432], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 921,\n  'fluo_channel': 0,\n  'fluorescence': array([-245.85217, -235.8636 , -195.38222, ..., -235.05496, -188.85402,\n         -204.27705], dtype=float32),\n  'neuropil_fluorescence': array([-238.46724, -241.89743, -238.95442, ..., -240.07123, -239.25356,\n         -235.5869 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 922,\n  'fluo_channel': 0,\n  'fluorescence': array([-196.91812, -225.28737, -189.11133, ..., -213.664  , -186.20078,\n         -210.49326], dtype=float32),\n  'neuropil_fluorescence': array([-169.89537, -121.7129 , -131.03893, ..., -179.66667, -176.66667,\n         -192.95134], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 923,\n  'fluo_channel': 0,\n  'fluorescence': array([ -53.23015 ,  -42.175102,  -85.204666, ..., -125.145836,\n         -132.93785 ,  -98.44239 ], dtype=float32),\n  'neuropil_fluorescence': array([-160.75294, -161.04852, -160.72942, ..., -158.35294, -164.1147 ,\n         -162.02942], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 924,\n  'fluo_channel': 0,\n  'fluorescence': array([ -99.91062,  -82.23226, -202.47964, ..., -146.49712, -169.44514,\n         -164.24911], dtype=float32),\n  'neuropil_fluorescence': array([-158.8544 , -159.05363, -162.02873, ..., -172.40805, -173.03639,\n         -161.84291], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 925,\n  'fluo_channel': 0,\n  'fluorescence': array([-150.97571 , -105.1415  , -112.934555, ..., -140.09065 ,\n         -138.75136 , -114.51051 ], dtype=float32),\n  'neuropil_fluorescence': array([-156.73524, -150.86081, -152.37367, ..., -153.81694, -158.14978,\n         -158.75946], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 926,\n  'fluo_channel': 0,\n  'fluorescence': array([-157.4865 , -173.78596, -204.11945, ..., -181.59636, -220.49907,\n         -200.36766], dtype=float32),\n  'neuropil_fluorescence': array([-202.08554, -200.10576, -198.62053, ..., -201.30794, -202.99066,\n         -209.16953], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 927,\n  'fluo_channel': 0,\n  'fluorescence': array([-200.23639, -212.39154, -197.30977, ..., -190.73848, -228.28888,\n         -212.96445], dtype=float32),\n  'neuropil_fluorescence': array([-234.47127, -231.06465, -231.81609, ..., -233.46983, -227.24281,\n         -226.10057], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 928,\n  'fluo_channel': 0,\n  'fluorescence': array([-158.49275 , -154.54883 , -154.1333  , ..., -105.18455 ,\n         -127.42473 , -113.656975], dtype=float32),\n  'neuropil_fluorescence': array([-158.92206, -165.85072, -158.18494, ..., -172.92339, -171.68164,\n         -162.27873], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 929,\n  'fluo_channel': 0,\n  'fluorescence': array([ -93.41197, -113.88998, -121.88081, ...,  -49.58626, -115.39173,\n         -150.90886], dtype=float32),\n  'neuropil_fluorescence': array([-172.56749, -167.96695, -172.03444, ..., -173.96832, -173.51378,\n         -182.3416 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 930,\n  'fluo_channel': 0,\n  'fluorescence': array([ -76.39257 ,  -71.833755,  -93.587685, ..., -108.41099 ,\n          -28.966047,  -94.66291 ], dtype=float32),\n  'neuropil_fluorescence': array([-191.7129 , -187.86897, -181.81117, ..., -183.12717, -182.85934,\n         -186.8921 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 931,\n  'fluo_channel': 0,\n  'fluorescence': array([-118.81075 , -160.65222 , -116.28632 , ...,  -21.842253,\n         -169.8631  ,  -67.039345], dtype=float32),\n  'neuropil_fluorescence': array([-183.6506 , -187.33391, -181.0809 , ..., -176.80724, -184.54733,\n         -186.53012], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 932,\n  'fluo_channel': 0,\n  'fluorescence': array([-181.8855 , -149.31265, -145.6869 , ..., -190.20943, -204.38762,\n         -111.49614], dtype=float32),\n  'neuropil_fluorescence': array([-191.87329, -186.44687, -187.05449, ..., -198.14714, -195.63896,\n         -198.55177], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 933,\n  'fluo_channel': 0,\n  'fluorescence': array([-113.13974, -133.87836, -139.49373, ...,  -77.71602, -123.52147,\n         -141.7725 ], dtype=float32),\n  'neuropil_fluorescence': array([-186.97714, -170.35048, -172.14667, ..., -175.26666, -173.69142,\n         -175.56572], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 934,\n  'fluo_channel': 0,\n  'fluorescence': array([-166.58997 , -178.89395 , -179.333   , ...,  -93.66964 ,\n          -48.363262, -136.73398 ], dtype=float32),\n  'neuropil_fluorescence': array([-133.4427 , -115.34375, -119.47656, ..., -120.94271, -116.1276 ,\n         -116.76823], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 935,\n  'fluo_channel': 0,\n  'fluorescence': array([-189.35817, -225.20337, -197.43504, ..., -164.55907, -172.31227,\n         -191.58105], dtype=float32),\n  'neuropil_fluorescence': array([-197.08359, -204.39969, -200.30092, ..., -202.2538 , -204.96657,\n         -197.25533], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 936,\n  'fluo_channel': 0,\n  'fluorescence': array([-202.87204, -170.45454, -172.93443, ..., -174.38503, -164.19484,\n         -165.36333], dtype=float32),\n  'neuropil_fluorescence': array([-192.2125 , -183.6875 , -178.53542, ..., -180.89792, -190.81876,\n         -180.4875 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 937,\n  'fluo_channel': 0,\n  'fluorescence': array([  92.656975,   18.133215,  -34.22058 , ...,  -80.31084 ,\n         -221.04973 ,  -52.652107], dtype=float32),\n  'neuropil_fluorescence': array([-160.43224, -158.80724, -145.32831, ..., -160.27711, -160.00452,\n         -153.73042], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 938,\n  'fluo_channel': 0,\n  'fluorescence': array([-199.64049, -148.32347, -150.17416, ..., -174.9996 , -186.15904,\n         -217.55814], dtype=float32),\n  'neuropil_fluorescence': array([-212.92032, -202.53784, -204.71115, ..., -213.74303, -205.3247 ,\n         -207.9243 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 939,\n  'fluo_channel': 0,\n  'fluorescence': array([-190.5392 , -247.08235, -218.59103, ..., -138.46107, -212.54031,\n         -231.48683], dtype=float32),\n  'neuropil_fluorescence': array([-208.6642 , -212.60503, -206.08136, ..., -210.16272, -210.6849 ,\n         -202.20119], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 940,\n  'fluo_channel': 0,\n  'fluorescence': array([-158.0065  , -108.782196, -109.40068 , ..., -166.24721 ,\n         -158.52757 , -162.78157 ], dtype=float32),\n  'neuropil_fluorescence': array([-174.28354, -147.96951, -154.39482, ..., -165.5442 , -150.87805,\n         -153.47104], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 941,\n  'fluo_channel': 0,\n  'fluorescence': array([-163.54286 ,  -70.69345 , -103.24095 , ..., -158.28085 ,\n         -152.66658 , -124.025734], dtype=float32),\n  'neuropil_fluorescence': array([-185.66736, -183.42769, -170.22728, ..., -177.44008, -185.92975,\n         -180.7252 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 942,\n  'fluo_channel': 0,\n  'fluorescence': array([-171.27975, -228.51166, -191.09334, ..., -171.80544,  -91.25371,\n         -164.5941 ], dtype=float32),\n  'neuropil_fluorescence': array([-195.37463, -195.98805, -192.12537, ..., -194.27463, -195.48955,\n         -190.83134], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 943,\n  'fluo_channel': 0,\n  'fluorescence': array([-200.5834 , -213.6249 , -223.81898, ..., -238.25366, -240.0212 ,\n         -239.18768], dtype=float32),\n  'neuropil_fluorescence': array([-235.40504, -232.79822, -234.16173, ..., -234.40059, -230.29228,\n         -228.28487], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 944,\n  'fluo_channel': 0,\n  'fluorescence': array([-278.23926, -247.48938, -231.16188, ..., -254.83084, -282.04218,\n         -251.70532], dtype=float32),\n  'neuropil_fluorescence': array([-262.44086, -265.93414, -261.9691 , ..., -263.1734 , -264.82123,\n         -264.81183], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 945,\n  'fluo_channel': 0,\n  'fluorescence': array([-137.85893, -168.61386, -146.11717, ..., -188.86758, -184.32938,\n         -138.98888], dtype=float32),\n  'neuropil_fluorescence': array([-184.8765 , -176.92624, -169.76158, ..., -173.98285, -171.37564,\n         -169.86621], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 946,\n  'fluo_channel': 0,\n  'fluorescence': array([ -49.224174,  -46.230114,  -21.740509, ..., -176.25626 ,\n         -212.73833 , -154.31303 ], dtype=float32),\n  'neuropil_fluorescence': array([-164.76933, -158.47333, -150.28   , ..., -164.68266, -165.99867,\n         -175.19333], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 947,\n  'fluo_channel': 0,\n  'fluorescence': array([-125.62413 , -106.87372 , -120.83483 , ...,  -98.980225,\n         -142.58672 , -144.61456 ], dtype=float32),\n  'neuropil_fluorescence': array([-144.60464, -137.28424, -131.5478 , ..., -144.18863, -151.94057,\n         -148.28165], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 948,\n  'fluo_channel': 0,\n  'fluorescence': array([-132.42816, -166.52785, -227.23505, ..., -127.45813, -221.88896,\n         -177.73729], dtype=float32),\n  'neuropil_fluorescence': array([-222.15918, -225.5347 , -215.57959, ..., -222.55646, -218.92517,\n         -226.53061], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 949,\n  'fluo_channel': 0,\n  'fluorescence': array([-227.30162, -201.08862, -240.07007, ..., -208.91208, -219.7262 ,\n         -229.396  ], dtype=float32),\n  'neuropil_fluorescence': array([-229.17427, -220.34439, -219.13693, ..., -229.95988, -228.84647,\n         -218.46059], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 950,\n  'fluo_channel': 0,\n  'fluorescence': array([-182.99854, -216.03073, -206.7394 , ..., -219.92746, -229.17719,\n         -203.40276], dtype=float32),\n  'neuropil_fluorescence': array([-222.26013, -222.23364, -223.41434, ..., -220.8162 , -219.02803,\n         -217.29439], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 951,\n  'fluo_channel': 0,\n  'fluorescence': array([-178.9976 , -157.1547 , -141.61806, ..., -179.53307, -168.32553,\n         -144.05066], dtype=float32),\n  'neuropil_fluorescence': array([-155.53972, -164.84477, -155.16064, ..., -159.25632, -161.18231,\n         -164.713  ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 952,\n  'fluo_channel': 0,\n  'fluorescence': array([-156.74625 , -159.51028 , -120.554794, ..., -184.57584 ,\n         -198.99359 , -184.16934 ], dtype=float32),\n  'neuropil_fluorescence': array([-168.16458, -154.84164, -154.20699, ..., -165.51994, -162.46384,\n         -162.09726], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 953,\n  'fluo_channel': 0,\n  'fluorescence': array([-117.30428 , -176.24773 ,  -99.570656, ..., -166.79308 ,\n          -29.219255, -183.03038 ], dtype=float32),\n  'neuropil_fluorescence': array([-166.73697, -173.216  , -169.4714 , ..., -166.80432, -173.10547,\n         -170.78908], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 954,\n  'fluo_channel': 0,\n  'fluorescence': array([-181.26254 , -128.31497 , -146.23584 , ...,  -60.869774,\n         -108.045334, -140.08754 ], dtype=float32),\n  'neuropil_fluorescence': array([-135.39247, -112.09733, -129.70015, ..., -105.6248 , -108.55887,\n         -122.4427 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 955,\n  'fluo_channel': 0,\n  'fluorescence': array([-135.69481 , -216.23524 , -152.04285 , ..., -123.98307 ,\n         -119.868675, -184.02249 ], dtype=float32),\n  'neuropil_fluorescence': array([-150.34782, -151.36957, -160.44565, ..., -148.53079, -144.28622,\n         -138.71921], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 956,\n  'fluo_channel': 0,\n  'fluorescence': array([-141.21036, -176.1273 , -123.36533, ..., -136.04485, -164.72382,\n         -189.74939], dtype=float32),\n  'neuropil_fluorescence': array([-190.2277 , -188.53343, -185.99681, ..., -185.53343, -188.56052,\n         -186.00636], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 957,\n  'fluo_channel': 0,\n  'fluorescence': array([-200.62341, -231.84785, -191.42583, ..., -210.00705, -211.52847,\n         -216.8036 ], dtype=float32),\n  'neuropil_fluorescence': array([-215.5225, -211.035 , -215.2325, ..., -218.1275, -211.8225,\n         -211.34  ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 958,\n  'fluo_channel': 0,\n  'fluorescence': array([-187.65353 , -119.578545, -114.386406, ..., -148.04825 ,\n         -107.13226 , -160.11418 ], dtype=float32),\n  'neuropil_fluorescence': array([-174.03763, -175.     , -170.72214, ..., -174.99565, -189.67294,\n         -183.37772], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 959,\n  'fluo_channel': 0,\n  'fluorescence': array([-213.06433, -215.58102, -176.3582 , ..., -222.91824, -161.1339 ,\n         -220.59436], dtype=float32),\n  'neuropil_fluorescence': array([-239.32634, -224.96985, -231.87286, ..., -229.66187, -231.09698,\n         -234.29752], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 960,\n  'fluo_channel': 0,\n  'fluorescence': array([-177.23755, -178.17834, -155.81131, ..., -206.75398, -203.03416,\n         -166.22435], dtype=float32),\n  'neuropil_fluorescence': array([-198.14357, -198.55919, -205.50127, ..., -202.97733, -205.45592,\n         -207.53401], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 961,\n  'fluo_channel': 0,\n  'fluorescence': array([-152.0411 , -159.71721, -170.74759, ..., -141.68477, -207.60211,\n         -182.78186], dtype=float32),\n  'neuropil_fluorescence': array([-207.7845 , -205.58112, -209.86682, ..., -217.54237, -202.79419,\n         -210.25665], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 962,\n  'fluo_channel': 0,\n  'fluorescence': array([-182.09924, -182.67673, -152.89725, ..., -197.94987, -152.4779 ,\n         -180.40979], dtype=float32),\n  'neuropil_fluorescence': array([-221.46939, -223.4731 , -217.62709, ..., -222.52504, -221.53989,\n         -220.3358 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 963,\n  'fluo_channel': 0,\n  'fluorescence': array([  46.522255,   47.099056, -146.63518 , ..., -137.46204 ,\n           14.230163,  -95.330864], dtype=float32),\n  'neuropil_fluorescence': array([-182.18073, -173.83936, -191.36145, ..., -181.77711, -171.90762,\n         -176.8032 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 964,\n  'fluo_channel': 0,\n  'fluorescence': array([ -10.027864,  -65.85363 , -106.56749 , ...,   28.883404,\n           92.38046 , -167.60571 ], dtype=float32),\n  'neuropil_fluorescence': array([-165.31818, -152.80302, -168.46536, ..., -167.01732, -156.86363,\n         -162.53464], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 965,\n  'fluo_channel': 0,\n  'fluorescence': array([ -10.886474, -113.60818 , -204.79048 , ..., -123.55171 ,\n          -98.320206,  -55.478832], dtype=float32),\n  'neuropil_fluorescence': array([-142.874, -145.22 , -131.648, ..., -139.548, -137.78 , -145.524],\n        dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 966,\n  'fluo_channel': 0,\n  'fluorescence': array([-193.84819, -154.53387, -202.9818 , ..., -167.40799, -198.76117,\n         -160.07729], dtype=float32),\n  'neuropil_fluorescence': array([-182.27065, -164.71881, -174.61687, ..., -178.5993 , -167.33217,\n         -177.93146], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 967,\n  'fluo_channel': 0,\n  'fluorescence': array([-206.85666 ,  -93.53594 , -132.8853  , ...,   87.91958 ,\n           18.222893,  -75.73029 ], dtype=float32),\n  'neuropil_fluorescence': array([-185.8692 , -185.846  , -170.41139, ..., -180.85443, -174.29958,\n         -183.35233], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 968,\n  'fluo_channel': 0,\n  'fluorescence': array([-189.57013, -144.77751, -182.03485, ..., -206.18092, -196.45398,\n         -144.55736], dtype=float32),\n  'neuropil_fluorescence': array([-137.3383 , -137.16045, -140.51741, ..., -132.65298, -133.67662,\n         -136.94029], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 969,\n  'fluo_channel': 0,\n  'fluorescence': array([-190.9107 , -197.76987, -209.75908, ..., -206.16832, -186.30415,\n         -206.7803 ], dtype=float32),\n  'neuropil_fluorescence': array([-207.84842, -204.75113, -195.04752, ..., -203.8733 , -208.02715,\n         -205.86652], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 970,\n  'fluo_channel': 0,\n  'fluorescence': array([-167.84135, -140.38712,  -99.86598, ..., -151.51794, -209.71387,\n         -123.15665], dtype=float32),\n  'neuropil_fluorescence': array([-160.89264, -156.1352 , -160.31412, ..., -153.     , -160.60835,\n         -162.17296], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 971,\n  'fluo_channel': 0,\n  'fluorescence': array([ -73.62459, -139.29701, -248.4175 , ..., -175.24684, -132.0771 ,\n         -116.43517], dtype=float32),\n  'neuropil_fluorescence': array([-204.8077 , -209.66454, -206.82265, ..., -208.43803, -212.13461,\n         -201.42094], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 972,\n  'fluo_channel': 0,\n  'fluorescence': array([-179.6259 , -145.73386, -179.98105, ..., -122.33374, -129.631  ,\n         -212.3726 ], dtype=float32),\n  'neuropil_fluorescence': array([-158.98618, -163.23732, -148.68433, ..., -153.10138, -158.06221,\n         -159.43779], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 973,\n  'fluo_channel': 0,\n  'fluorescence': array([-260.15677, -261.1032 , -253.88963, ..., -253.21906, -245.8208 ,\n         -236.7988 ], dtype=float32),\n  'neuropil_fluorescence': array([-249.01422, -253.90446, -246.88618, ..., -247.71341, -251.97562,\n         -250.57521], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 974,\n  'fluo_channel': 0,\n  'fluorescence': array([-193.47153, -158.10686, -179.78252, ..., -190.18723, -186.53366,\n         -164.73303], dtype=float32),\n  'neuropil_fluorescence': array([-193.9598 , -200.38191, -189.35678, ..., -184.24623, -199.0804 ,\n         -190.14322], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 975,\n  'fluo_channel': 0,\n  'fluorescence': array([-212.99634, -218.6476 , -210.36983, ..., -220.06516, -214.52422,\n         -226.15282], dtype=float32),\n  'neuropil_fluorescence': array([-218.26923, -221.97356, -222.38702, ..., -222.92548, -219.63461,\n         -222.39423], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 976,\n  'fluo_channel': 0,\n  'fluorescence': array([-132.90602 , -167.87877 ,  -99.960754, ..., -104.676056,\n         -103.24875 , -104.46414 ], dtype=float32),\n  'neuropil_fluorescence': array([-150.2299 , -144.1451 , -142.48215, ..., -158.39732, -147.8259 ,\n         -158.16965], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 977,\n  'fluo_channel': 0,\n  'fluorescence': array([-121.35285 , -123.056915,  -61.06739 , ...,  -33.60952 ,\n          -50.249744,  -24.092285], dtype=float32),\n  'neuropil_fluorescence': array([-126.02715, -133.72398, -138.08296, ..., -153.30167, -144.71945,\n         -142.02715], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 978,\n  'fluo_channel': 0,\n  'fluorescence': array([-182.63522, -195.26765, -197.64891, ..., -209.96257, -177.61952,\n         -183.36649], dtype=float32),\n  'neuropil_fluorescence': array([-215.63966, -222.61983, -208.64133, ..., -229.34875, -226.4281 ,\n         -214.79008], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 979,\n  'fluo_channel': 0,\n  'fluorescence': array([-159.01207, -171.67162, -186.93188, ..., -147.88324, -154.93475,\n         -159.01833], dtype=float32),\n  'neuropil_fluorescence': array([-157.23665, -149.65079, -133.06494, ..., -149.90187, -148.67532,\n         -152.61328], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 980,\n  'fluo_channel': 0,\n  'fluorescence': array([-136.65273 , -181.80357 , -163.23782 , ..., -106.316185,\n         -118.97747 , -151.5228  ], dtype=float32),\n  'neuropil_fluorescence': array([-138.01845, -142.97417, -131.9668 , ..., -149.33395, -150.41328,\n         -148.11992], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 981,\n  'fluo_channel': 0,\n  'fluorescence': array([-163.76308, -151.43355, -163.17064, ..., -195.66399, -175.8371 ,\n         -127.78596], dtype=float32),\n  'neuropil_fluorescence': array([-210.72206, -208.56798, -212.04683, ..., -209.84894, -214.24472,\n         -210.35649], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 982,\n  'fluo_channel': 0,\n  'fluorescence': array([-282.2631 , -275.769  , -282.44324, ..., -231.95564, -270.90497,\n         -249.55338], dtype=float32),\n  'neuropil_fluorescence': array([-243.67572, -243.01   , -239.11285, ..., -241.46571, -239.70572,\n         -241.07715], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 983,\n  'fluo_channel': 0,\n  'fluorescence': array([-185.94695, -176.1024 , -172.31601, ..., -179.771  , -195.66225,\n         -179.16043], dtype=float32),\n  'neuropil_fluorescence': array([-203.32181, -199.40292, -196.66623, ..., -196.92287, -195.17287,\n         -200.28192], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 984,\n  'fluo_channel': 0,\n  'fluorescence': array([-186.32065, -181.24478, -150.75185, ..., -162.48029, -191.13768,\n         -158.58405], dtype=float32),\n  'neuropil_fluorescence': array([-189.70833, -176.29398, -185.70602, ..., -183.06712, -173.55324,\n         -178.63889], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 985,\n  'fluo_channel': 0,\n  'fluorescence': array([-252.19783, -263.17944, -268.7679 , ..., -262.06323, -246.59589,\n         -268.0204 ], dtype=float32),\n  'neuropil_fluorescence': array([-268.32584, -254.06902, -248.29695, ..., -260.39325, -261.8154 ,\n         -267.9037 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 986,\n  'fluo_channel': 0,\n  'fluorescence': array([-235.51988, -255.45268, -257.35168, ..., -257.93005, -240.18242,\n         -274.19055], dtype=float32),\n  'neuropil_fluorescence': array([-252.75638, -252.62323, -253.09349, ..., -247.67705, -246.54108,\n         -252.1728 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 987,\n  'fluo_channel': 0,\n  'fluorescence': array([-130.19785, -170.44081, -186.24762, ..., -166.9638 , -168.42955,\n         -167.94446], dtype=float32),\n  'neuropil_fluorescence': array([-177.20833, -163.50397, -165.96428, ..., -175.18056, -175.91072,\n         -165.92262], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 988,\n  'fluo_channel': 0,\n  'fluorescence': array([-177.535   , -122.6576  , -212.5147  , ..., -180.94926 ,\n          -92.25063 ,   74.067825], dtype=float32),\n  'neuropil_fluorescence': array([-137.10799 , -131.08423 , -125.660904, ..., -125.816414,\n         -121.76026 , -125.87041 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 989,\n  'fluo_channel': 0,\n  'fluorescence': array([-238.65932, -263.07904, -211.39038, ...,  -84.54882, -165.48744,\n         -231.0023 ], dtype=float32),\n  'neuropil_fluorescence': array([-209.90863, -214.1286 , -210.42809, ..., -209.1303 , -210.978  ,\n         -205.6836 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 990,\n  'fluo_channel': 0,\n  'fluorescence': array([-196.2399 , -229.13577, -221.45683, ..., -213.09993, -267.3849 ,\n         -262.92258], dtype=float32),\n  'neuropil_fluorescence': array([-234.17926, -223.70935, -224.16005, ..., -226.50064, -228.01665,\n         -224.03458], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 991,\n  'fluo_channel': 0,\n  'fluorescence': array([ -68.89231, -102.13619, -178.08069, ..., -188.73334, -117.24588,\n         -109.37697], dtype=float32),\n  'neuropil_fluorescence': array([-145.54382, -154.65936, -155.07968, ..., -153.14542, -148.39243,\n         -156.78088], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 992,\n  'fluo_channel': 0,\n  'fluorescence': array([-214.59683, -207.96838, -223.52708, ..., -206.34372, -173.50673,\n         -195.83545], dtype=float32),\n  'neuropil_fluorescence': array([-195.22955, -190.25594, -191.11345, ..., -190.35884, -203.84433,\n         -192.59894], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 993,\n  'fluo_channel': 0,\n  'fluorescence': array([-172.373  , -152.31572, -177.1042 , ..., -169.13869, -208.51265,\n         -172.11568], dtype=float32),\n  'neuropil_fluorescence': array([-184.75241, -185.21634, -191.75   , ..., -187.13942, -185.90144,\n         -189.37259], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 994,\n  'fluo_channel': 0,\n  'fluorescence': array([-143.42648,  -76.11715, -147.98842, ...,  -80.70129,  -91.75559,\n         -163.49202], dtype=float32),\n  'neuropil_fluorescence': array([-179.9106 , -179.17056, -170.21596, ..., -179.61485, -182.62723,\n         -176.7703 ], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 995,\n  'fluo_channel': 0,\n  'fluorescence': array([ -98.089264, -158.80394 , -123.41379 , ...,  -85.5656  ,\n         -113.75857 , -160.3714  ], dtype=float32),\n  'neuropil_fluorescence': array([-166.17104, -165.83246, -158.9267 , ..., -148.93892, -154.43106,\n         -160.63351], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 996,\n  'fluo_channel': 0,\n  'fluorescence': array([-191.20702, -178.7378 , -231.83992, ..., -266.93115, -186.87474,\n         -139.3207 ], dtype=float32),\n  'neuropil_fluorescence': array([-197.80188, -212.66603, -206.44339, ..., -208.41698, -205.57547,\n         -207.81699], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 997,\n  'fluo_channel': 0,\n  'fluorescence': array([-158.4429 , -139.32195, -188.63174, ..., -119.06535, -151.57779,\n         -164.97113], dtype=float32),\n  'neuropil_fluorescence': array([-132.81573, -131.66795, -135.03262, ..., -130.13435, -122.26679,\n         -120.08445], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 998,\n  'fluo_channel': 0,\n  'fluorescence': array([-149.28456, -198.1097 , -189.56296, ..., -192.84952, -148.91757,\n         -197.23436], dtype=float32),\n  'neuropil_fluorescence': array([-211.3136, -209.3744, -210.9856, ..., -219.8768, -213.7328,\n         -219.6528], dtype=float32)},\n {'subject': 'subject1',\n  'session_datetime': datetime.datetime(2021, 4, 30, 12, 22, 15),\n  'scan_id': 0,\n  'paramset_idx': 0,\n  'curation_id': 0,\n  'mask': 999,\n  'fluo_channel': 0,\n  'fluorescence': array([-170.42632, -172.59734, -204.70363, ..., -214.27138, -169.64493,\n         -189.99509], dtype=float32),\n  'neuropil_fluorescence': array([-189.35484, -183.45776, -192.14594, ..., -197.69432, -189.61598,\n         -190.     ], dtype=float32)},\n ...]</pre> <p>Next, we will fetch the <code>fluorescence</code> attribute for <code>mask=10</code> with the <code>fetch1</code> method by passing the attribute as an argument to the method.</p> <p>By default, <code>fetch1()</code> returns all attributes of one of the entries in the table.  If a query has multiple entries, <code>fetch1()</code> imports the first entry in the table.</p> In\u00a0[41]: Copied! <pre>trace = (imaging.Fluorescence.Trace &amp; \"mask = '10'\").fetch1(\"fluorescence\")\n</pre> trace = (imaging.Fluorescence.Trace &amp; \"mask = '10'\").fetch1(\"fluorescence\") <p>Let's plot this trace.  First we will fetch the sampling rate of the data to define the x-axis values.</p> In\u00a0[42]: Copied! <pre>sampling_rate = (scan.ScanInfo &amp; session_key &amp; \"scan_id=0\").fetch1(\"fps\")\n</pre> sampling_rate = (scan.ScanInfo &amp; session_key &amp; \"scan_id=0\").fetch1(\"fps\") In\u00a0[43]: Copied! <pre>plt.plot(np.r_[: trace.size] * 1 / sampling_rate, trace)\nplt.title(\"Fluorescence trace for mask 10\")\nplt.xlabel(\"Time (s)\")\nplt.ylabel(\"Activity (a.u.)\");\n</pre> plt.plot(np.r_[: trace.size] * 1 / sampling_rate, trace) plt.title(\"Fluorescence trace for mask 10\") plt.xlabel(\"Time (s)\") plt.ylabel(\"Activity (a.u.)\"); <p>We will fetch and plot the average, motion-corrected image.</p> In\u00a0[44]: Copied! <pre>average_image = (imaging.MotionCorrection.Summary &amp; session_key &amp; \"field_idx=0\").fetch1(\n    \"average_image\"\n)\n</pre> average_image = (imaging.MotionCorrection.Summary &amp; session_key &amp; \"field_idx=0\").fetch1(     \"average_image\" ) In\u00a0[45]: Copied! <pre>plt.imshow(average_image)\n</pre> plt.imshow(average_image) Out[45]: <pre>&lt;matplotlib.image.AxesImage at 0x7f38b3f6f8e0&gt;</pre> <p>We will fetch mask coordinates and overlay these on the average image.</p> In\u00a0[46]: Copied! <pre>mask_xpix, mask_ypix = (\n    imaging.Segmentation.Mask * imaging.MaskClassification.MaskType\n    &amp; session_key\n    &amp; \"mask_center_z=0\"\n    &amp; \"mask_npix &gt; 130\"\n).fetch(\"mask_xpix\", \"mask_ypix\")\n</pre> mask_xpix, mask_ypix = (     imaging.Segmentation.Mask * imaging.MaskClassification.MaskType     &amp; session_key     &amp; \"mask_center_z=0\"     &amp; \"mask_npix &gt; 130\" ).fetch(\"mask_xpix\", \"mask_ypix\") In\u00a0[47]: Copied! <pre>mask_image = np.zeros(np.shape(average_image), dtype=bool)\nfor xpix, ypix in zip(mask_xpix, mask_ypix):\n    mask_image[ypix, xpix] = True\n</pre> mask_image = np.zeros(np.shape(average_image), dtype=bool) for xpix, ypix in zip(mask_xpix, mask_ypix):     mask_image[ypix, xpix] = True In\u00a0[48]: Copied! <pre>plt.imshow(average_image)\nplt.contour(mask_image, colors=\"white\", linewidths=0.5);\n</pre> plt.imshow(average_image) plt.contour(mask_image, colors=\"white\", linewidths=0.5); <p>This Element includes an interactive widget to plot the segmentations and traces to visualize the results after processing with Suite2p, CaImAn, or EXTRACT.</p> In\u00a0[49]: Copied! <pre>from element_calcium_imaging.plotting.widget import main\n</pre> from element_calcium_imaging.plotting.widget import main In\u00a0[50]: Copied! <pre>main(imaging)\n</pre> main(imaging) Out[50]: <pre>VBox(children=(HBox(children=(Dropdown(description='Result:', layout=Layout(display='flex', flex_flow='row', g\u2026</pre> <p>Congratulations!  You have learned about the DataJoint Element for Calcium Imaging and common DataJoint commands to interact with the pipeline, including insert, populate, query, and fetch.</p>"}, {"location": "tutorials/tutorial/#datajoint-element-for-calcium-imaging", "title": "DataJoint Element for Calcium Imaging\u00b6", "text": "<p>Open-source data pipeline to automate analyses and organize data</p> <p>In this tutorial, we will walk through processing two-photon calcium imaging data collected from ScanImage and processed with Suite2p.</p> <p>We will explain the following concepts as they relate to this pipeline:</p> <ul> <li>What is an Element versus a pipeline?</li> <li>Plot the pipeline with <code>dj.Diagram</code></li> <li>Insert data into tables</li> <li>Query table contents</li> <li>Fetch table contents</li> <li>Run the pipeline for your experiments</li> </ul> <p>For detailed documentation and tutorials on general DataJoint principles that support collaboration, automation, reproducibility, and visualizations:</p> <ul> <li><p>DataJoint for Python - Interactive Tutorials - Fundamentals including table tiers, query operations, fetch operations, automated computations with the <code>make</code> function, etc.</p> </li> <li><p>DataJoint for Python - Documentation</p> </li> <li><p>DataJoint Element for Calcium Imaging - Documentation</p> </li> </ul> <p>Let's start by importing the packages necessary to run this pipeline.</p>"}, {"location": "tutorials/tutorial/#combine-multiple-elements-into-a-pipeline", "title": "Combine multiple Elements into a pipeline\u00b6", "text": "<p>Each DataJoint Element is a modular set of tables that can be combined into a complete pipeline.</p> <p>Each Element contains 1 or more modules, and each module declares its own schema in the database.</p> <p>This tutorial pipeline is assembled from four DataJoint Elements.</p> Element Source Code Documentation Description Element Lab Link Link Lab management related information, such as Lab, User, Project, Protocol, Source. Element Animal Link Link General animal metadata and surgery information. Element Session Link Link General information of experimental sessions. Element Calcium Imaging Link Link Calcium imaging analysis with Suite2p, CaImAn, and EXTRACT. <p>By importing the modules for the first time, the schemas and tables will be created in the database.  Once created, importing modules will not create schemas and tables again, but the existing schemas/tables can be accessed.</p> <p>The Elements are imported and activated within the <code>tutorial_pipeline</code> script.</p>"}, {"location": "tutorials/tutorial/#diagram", "title": "Diagram\u00b6", "text": "<p>Let's plot the diagram of tables within multiple schemas and their dependencies using <code>dj.Diagram()</code>.</p>"}, {"location": "tutorials/tutorial/#table-types", "title": "Table Types\u00b6", "text": "<p>There are 5 table types in DataJoint.  Each of these appear in the diagram above.</p> Table tier Color and shape Description Manual table Green box Data entered from outside the pipeline, either by hand or with external helper scripts. Lookup table Gray box Small tables containing general facts and settings of the data pipeline; not specific to any experiment or dataset. Imported table Blue oval Data ingested automatically inside the pipeline but requiring access to data outside the pipeline. Computed table Red circle Data computed automatically entirely inside the pipeline. Part table Plain text Part tables share the same tier as their master table. <p>The diagram becomes clear when it's approached as a hierarchy of tables that define the order in which the pipeline expects to receive data in each of the tables.</p> <p>The tables higher up in the diagram such as <code>subject.Subject()</code> should be the first to receive data.</p> <p>Data is manually entered into the green rectangular tables with the <code>insert1()</code> method.</p> <p>Tables connected by a line depend on entries from the table above it.</p> <p>Tables with a purple oval or red circle will be automatically filled with relevant data by calling <code>populate()</code>. For example <code>scan.ScanInfo</code> and its part-table <code>scan.ScanInfo.Field</code> are both populated with <code>scan.ScanInfo.populate()</code>.</p>"}, {"location": "tutorials/tutorial/#datajoint-basics", "title": "DataJoint Basics\u00b6", "text": "<p>DataJoint pipelines can be run with four commands:</p> <ul> <li><code>Insert</code></li> <li><code>Populate</code></li> <li><code>Query</code></li> <li><code>Fetch</code></li> </ul> <p>In this demo we will:</p> <ul> <li><p><code>Insert</code> metadata about a subject, recording session, and parameters related to processing calcium imaging data through Suite2p.</p> </li> <li><p><code>Populate</code> tables with outputs of image processing including motion correction, segmentation, fluorescence traces and deconvolved activity traces.</p> </li> <li><p><code>Query</code> the data from the database.</p> </li> <li><p><code>Fetch</code> and plot calcium activity traces.</p> </li> </ul>"}, {"location": "tutorials/tutorial/#insert-entries-into-manual-tables", "title": "Insert entries into manual tables\u00b6", "text": "<p>Let's start with the first table in the schema diagram (i.e. <code>subject.Subject</code> table).</p> <p>To know what data to insert into the table, we can view its dependencies and attributes using the <code>.describe()</code> and <code>.heading</code> functions.</p>"}, {"location": "tutorials/tutorial/#automatically-populate-tables", "title": "Automatically populate tables\u00b6", "text": "<p><code>scan.ScanInfo</code> is the first table in the pipeline that can be populated automatically with the <code>populate</code> method.</p> <p>If a table contains a Part table, <code>populate()</code> inserts data into both.</p> <p>Let's populate the <code>scan.ScanInfo</code> and its Part table <code>scan.ScanInfo.Field</code>.</p>"}, {"location": "tutorials/tutorial/#query", "title": "Query\u00b6", "text": "<p>Queries allow you to view the contents of the database.  The simplest query is the instance of the table class.</p>"}, {"location": "tutorials/tutorial/#fetch", "title": "Fetch\u00b6", "text": "<p>The <code>fetch</code> and <code>fetch1</code> methods download the data from the query object into the workspace.</p> <p>Below we will run <code>fetch()</code> to return all attributes of all entries in the table.</p>"}, {"location": "tutorials/tutorial/#next-steps", "title": "Next steps\u00b6", "text": "<p>Follow the steps below to run this pipeline for your experiments:</p> <ul> <li>Create a fork of this repository to your GitHub account.</li> <li>Clone the repository to your local machine and configure for use with the instructions in the User Guide.</li> <li>The DataJoint team offers free Office Hours to help you setup this pipeline.</li> <li>If you have any questions, please reach out at support@datajoint.com.</li> </ul>"}]}